{"created": 1747276450.989225, "duration": 1.3629779815673828, "exitcode": 1, "root": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher", "environment": {}, "summary": {"passed": 215, "failed": 110, "total": 325, "collected": 325}, "collectors": [{"nodeid": "", "outcome": "passed", "result": [{"nodeid": "tests", "type": "Package"}]}, {"nodeid": "tests/bibliography/test_formatter.py::TestReferenceFormatter", "outcome": "passed", "result": [{"nodeid": "tests/bibliography/test_formatter.py::TestReferenceFormatter::test_apa_formatting", "type": "Function", "lineno": 101}, {"nodeid": "tests/bibliography/test_formatter.py::TestReferenceFormatter::test_mla_formatting", "type": "Function", "lineno": 133}, {"nodeid": "tests/bibliography/test_formatter.py::TestReferenceFormatter::test_harvard_formatting", "type": "Function", "lineno": 156}, {"nodeid": "tests/bibliography/test_formatter.py::TestReferenceFormatter::test_ieee_formatting", "type": "Function", "lineno": 170}, {"nodeid": "tests/bibliography/test_formatter.py::TestReferenceFormatter::test_in_text_citations", "type": "Function", "lineno": 182}, {"nodeid": "tests/bibliography/test_formatter.py::TestReferenceFormatter::test_generate_bibliography", "type": "Function", "lineno": 209}, {"nodeid": "tests/bibliography/test_formatter.py::TestReferenceFormatter::test_author_formatting", "type": "Function", "lineno": 238}]}, {"nodeid": "tests/bibliography/test_formatter.py", "outcome": "passed", "result": [{"nodeid": "tests/bibliography/test_formatter.py::TestReferenceFormatter", "type": "Class"}]}, {"nodeid": "tests/bibliography/test_importer.py::TestBibliographyImporter", "outcome": "passed", "result": [{"nodeid": "tests/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_json_single_reference", "type": "Function", "lineno": 10}, {"nodeid": "tests/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_json_multiple_references", "type": "Function", "lineno": 71}, {"nodeid": "tests/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_json_string", "type": "Function", "lineno": 143}, {"nodeid": "tests/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_invalid_json", "type": "Function", "lineno": 165}, {"nodeid": "tests/bibliography/test_importer.py::TestBibliographyImporter::test_import_handles_missing_fields", "type": "Function", "lineno": 170}, {"nodeid": "tests/bibliography/test_importer.py::TestBibliographyImporter::test_export_to_json", "type": "Function", "lineno": 186}, {"nodeid": "tests/bibliography/test_importer.py::TestBibliographyImporter::test_import_export_roundtrip", "type": "Function", "lineno": 262}, {"nodeid": "tests/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_bibtex_basic", "type": "Function", "lineno": 307}]}, {"nodeid": "tests/bibliography/test_importer.py", "outcome": "passed", "result": [{"nodeid": "tests/bibliography/test_importer.py::TestBibliographyImporter", "type": "Class"}]}, {"nodeid": "tests/bibliography/test_models.py::TestAuthor", "outcome": "passed", "result": [{"nodeid": "tests/bibliography/test_models.py::TestAuthor::test_create_person_author", "type": "Function", "lineno": 15}, {"nodeid": "tests/bibliography/test_models.py::TestAuthor::test_create_organization_author", "type": "Function", "lineno": 31}, {"nodeid": "tests/bibliography/test_models.py::TestAuthor::test_author_full_name_person", "type": "Function", "lineno": 45}, {"nodeid": "tests/bibliography/test_models.py::TestAuthor::test_author_full_name_organization", "type": "Function", "lineno": 76}]}, {"nodeid": "tests/bibliography/test_models.py::TestReference", "outcome": "passed", "result": [{"nodeid": "tests/bibliography/test_models.py::TestReference::test_create_journal_article", "type": "Function", "lineno": 92}, {"nodeid": "tests/bibliography/test_models.py::TestReference::test_create_book", "type": "Function", "lineno": 137}, {"nodeid": "tests/bibliography/test_models.py::TestReference::test_create_website", "type": "Function", "lineno": 164}, {"nodeid": "tests/bibliography/test_models.py::TestReference::test_update_reference", "type": "Function", "lineno": 190}, {"nodeid": "tests/bibliography/test_models.py::TestReference::test_add_author", "type": "Function", "lineno": 215}, {"nodeid": "tests/bibliography/test_models.py::TestReference::test_remove_author", "type": "Function", "lineno": 245}, {"nodeid": "tests/bibliography/test_models.py::TestReference::test_keywords", "type": "Function", "lineno": 280}, {"nodeid": "tests/bibliography/test_models.py::TestReference::test_notes", "type": "Function", "lineno": 313}, {"nodeid": "tests/bibliography/test_models.py::TestReference::test_custom_fields", "type": "Function", "lineno": 331}, {"nodeid": "tests/bibliography/test_models.py::TestReference::test_author_names_formatted", "type": "Function", "lineno": 366}]}, {"nodeid": "tests/bibliography/test_models.py::TestTaskReferenceLink", "outcome": "passed", "result": [{"nodeid": "tests/bibliography/test_models.py::TestTaskReferenceLink::test_create_task_reference_link", "type": "Function", "lineno": 416}, {"nodeid": "tests/bibliography/test_models.py::TestTaskReferenceLink::test_update_link", "type": "Function", "lineno": 435}, {"nodeid": "tests/bibliography/test_models.py::TestTaskReferenceLink::test_add_note", "type": "Function", "lineno": 453}]}, {"nodeid": "tests/bibliography/test_models.py", "outcome": "passed", "result": [{"nodeid": "tests/bibliography/test_models.py::TestAuthor", "type": "Class"}, {"nodeid": "tests/bibliography/test_models.py::TestReference", "type": "Class"}, {"nodeid": "tests/bibliography/test_models.py::TestTaskReferenceLink", "type": "Class"}]}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService", "outcome": "passed", "result": [{"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_create_author_methods", "type": "Function", "lineno": 26}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_create_journal_article", "type": "Function", "lineno": 49}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_create_book", "type": "Function", "lineno": 82}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_create_website", "type": "Function", "lineno": 111}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_create_generic_reference", "type": "Function", "lineno": 139}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_update_reference", "type": "Function", "lineno": 166}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_update_nonexistent_reference", "type": "Function", "lineno": 193}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_delete_reference", "type": "Function", "lineno": 205}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_search_references", "type": "Function", "lineno": 224}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_reference_modification_methods", "type": "Function", "lineno": 289}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_link_task_to_reference", "type": "Function", "lineno": 326}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_link_to_nonexistent_reference", "type": "Function", "lineno": 352}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_update_task_reference_link", "type": "Function", "lineno": 360}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_add_note_to_link", "type": "Function", "lineno": 388}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_get_references_by_task", "type": "Function", "lineno": 412}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_get_tasks_by_reference", "type": "Function", "lineno": 448}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_delete_task_reference_link", "type": "Function", "lineno": 468}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_citation_formatting", "type": "Function", "lineno": 490}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_in_text_citation_formatting", "type": "Function", "lineno": 524}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_generate_task_bibliography", "type": "Function", "lineno": 548}]}, {"nodeid": "tests/bibliography/test_service.py", "outcome": "passed", "result": [{"nodeid": "tests/bibliography/test_service.py::TestBibliographyService", "type": "Class"}]}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage", "outcome": "passed", "result": [{"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_create_and_get_reference", "type": "Function", "lineno": 53}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_update_reference", "type": "Function", "lineno": 64}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_update_nonexistent_reference", "type": "Function", "lineno": 79}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_delete_reference", "type": "Function", "lineno": 91}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_delete_nonexistent_reference", "type": "Function", "lineno": 111}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_list_references_empty", "type": "Function", "lineno": 116}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_list_references_with_filters", "type": "Function", "lineno": 121}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_task_reference_link_operations", "type": "Function", "lineno": 165}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_get_references_by_task", "type": "Function", "lineno": 217}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_get_links_by_task", "type": "Function", "lineno": 252}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_get_tasks_by_reference", "type": "Function", "lineno": 282}]}, {"nodeid": "tests/bibliography/test_storage.py", "outcome": "passed", "result": [{"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage", "type": "Class"}]}, {"nodeid": "tests/bibliography", "outcome": "passed", "result": [{"nodeid": "tests/bibliography/test_formatter.py", "type": "Module"}, {"nodeid": "tests/bibliography/test_importer.py", "type": "Module"}, {"nodeid": "tests/bibliography/test_models.py", "type": "Module"}, {"nodeid": "tests/bibliography/test_service.py", "type": "Module"}, {"nodeid": "tests/bibliography/test_storage.py", "type": "Module"}]}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDataset", "outcome": "passed", "result": [{"nodeid": "tests/dataset_versioning/test_models.py::TestDataset::test_create_dataset", "type": "Function", "lineno": 17}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDataset::test_update_dataset", "type": "Function", "lineno": 61}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDataset::test_dataset_tags", "type": "Function", "lineno": 88}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDataset::test_dataset_custom_metadata", "type": "Function", "lineno": 121}]}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDatasetVersion", "outcome": "passed", "result": [{"nodeid": "tests/dataset_versioning/test_models.py::TestDatasetVersion::test_create_dataset_version", "type": "Function", "lineno": 167}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDatasetVersion::test_update_version", "type": "Function", "lineno": 212}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDatasetVersion::test_version_custom_metadata", "type": "Function", "lineno": 234}]}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDataTransformation", "outcome": "passed", "result": [{"nodeid": "tests/dataset_versioning/test_models.py::TestDataTransformation::test_create_data_transformation", "type": "Function", "lineno": 267}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDataTransformation::test_update_transformation", "type": "Function", "lineno": 302}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDataTransformation::test_transformation_tags", "type": "Function", "lineno": 327}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDataTransformation::test_transformation_notes", "type": "Function", "lineno": 357}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDataTransformation::test_transformation_parameters", "type": "Function", "lineno": 376}]}, {"nodeid": "tests/dataset_versioning/test_models.py::TestTaskDatasetLink", "outcome": "passed", "result": [{"nodeid": "tests/dataset_versioning/test_models.py::TestTaskDatasetLink::test_create_task_dataset_link", "type": "Function", "lineno": 411}, {"nodeid": "tests/dataset_versioning/test_models.py::TestTaskDatasetLink::test_update_link", "type": "Function", "lineno": 432}, {"nodeid": "tests/dataset_versioning/test_models.py::TestTaskDatasetLink::test_link_notes", "type": "Function", "lineno": 455}]}, {"nodeid": "tests/dataset_versioning/test_models.py", "outcome": "passed", "result": [{"nodeid": "tests/dataset_versioning/test_models.py::TestDataset", "type": "Class"}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDatasetVersion", "type": "Class"}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDataTransformation", "type": "Class"}, {"nodeid": "tests/dataset_versioning/test_models.py::TestTaskDatasetLink", "type": "Class"}]}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService", "outcome": "passed", "result": [{"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_dataset", "type": "Function", "lineno": 23}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_update_dataset", "type": "Function", "lineno": 58}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_update_nonexistent_dataset", "type": "Function", "lineno": 86}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_delete_dataset", "type": "Function", "lineno": 94}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_list_datasets", "type": "Function", "lineno": 112}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_dataset_tags", "type": "Function", "lineno": 167}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_dataset_custom_metadata", "type": "Function", "lineno": 189}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_dataset_version", "type": "Function", "lineno": 214}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_dataset_version_with_parent", "type": "Function", "lineno": 253}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_version_nonexistent_dataset", "type": "Function", "lineno": 284}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_version_nonexistent_parent", "type": "Function", "lineno": 293}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_update_dataset_version", "type": "Function", "lineno": 310}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_version_operations", "type": "Function", "lineno": 348}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_data_transformation", "type": "Function", "lineno": 402}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_transformation_nonexistent_version", "type": "Function", "lineno": 455}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_transformation_operations", "type": "Function", "lineno": 465}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_link_task_to_dataset_version", "type": "Function", "lineno": 551}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_link_to_nonexistent_version", "type": "Function", "lineno": 582}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_task_dataset_link_operations", "type": "Function", "lineno": 590}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_dataset_lineage", "type": "Function", "lineno": 661}]}, {"nodeid": "tests/dataset_versioning/test_service.py", "outcome": "passed", "result": [{"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService", "type": "Class"}]}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage", "outcome": "passed", "result": [{"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_create_and_get_dataset", "type": "Function", "lineno": 43}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_update_dataset", "type": "Function", "lineno": 55}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_update_nonexistent_dataset", "type": "Function", "lineno": 70}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_delete_dataset", "type": "Function", "lineno": 83}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_delete_nonexistent_dataset", "type": "Function", "lineno": 114}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_list_datasets_empty", "type": "Function", "lineno": 119}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_list_datasets_with_filters", "type": "Function", "lineno": 124}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_dataset_version_operations", "type": "Function", "lineno": 160}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_version_lineage_operations", "type": "Function", "lineno": 223}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_data_transformation_operations", "type": "Function", "lineno": 266}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_task_dataset_link_operations", "type": "Function", "lineno": 344}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_get_lineage", "type": "Function", "lineno": 415}]}, {"nodeid": "tests/dataset_versioning/test_storage.py", "outcome": "passed", "result": [{"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage", "type": "Class"}]}, {"nodeid": "tests/dataset_versioning", "outcome": "passed", "result": [{"nodeid": "tests/dataset_versioning/test_models.py", "type": "Module"}, {"nodeid": "tests/dataset_versioning/test_service.py", "type": "Module"}, {"nodeid": "tests/dataset_versioning/test_storage.py", "type": "Module"}]}, {"nodeid": "tests/environment/test_models.py::TestPackageInfo", "outcome": "passed", "result": [{"nodeid": "tests/environment/test_models.py::TestPackageInfo::test_create_package_info", "type": "Function", "lineno": 18}]}, {"nodeid": "tests/environment/test_models.py::TestComputeResource", "outcome": "passed", "result": [{"nodeid": "tests/environment/test_models.py::TestComputeResource::test_create_compute_resource", "type": "Function", "lineno": 52}]}, {"nodeid": "tests/environment/test_models.py::TestEnvironmentSnapshot", "outcome": "passed", "result": [{"nodeid": "tests/environment/test_models.py::TestEnvironmentSnapshot::test_create_environment_snapshot", "type": "Function", "lineno": 82}, {"nodeid": "tests/environment/test_models.py::TestEnvironmentSnapshot::test_update_environment_snapshot", "type": "Function", "lineno": 181}, {"nodeid": "tests/environment/test_models.py::TestEnvironmentSnapshot::test_package_management", "type": "Function", "lineno": 206}, {"nodeid": "tests/environment/test_models.py::TestEnvironmentSnapshot::test_compute_resource_management", "type": "Function", "lineno": 253}, {"nodeid": "tests/environment/test_models.py::TestEnvironmentSnapshot::test_environment_variable_management", "type": "Function", "lineno": 293}, {"nodeid": "tests/environment/test_models.py::TestEnvironmentSnapshot::test_config_file_management", "type": "Function", "lineno": 327}, {"nodeid": "tests/environment/test_models.py::TestEnvironmentSnapshot::test_tag_management", "type": "Function", "lineno": 370}, {"nodeid": "tests/environment/test_models.py::TestEnvironmentSnapshot::test_custom_metadata_management", "type": "Function", "lineno": 403}]}, {"nodeid": "tests/environment/test_models.py::TestTaskEnvironmentLink", "outcome": "passed", "result": [{"nodeid": "tests/environment/test_models.py::TestTaskEnvironmentLink::test_create_task_environment_link", "type": "Function", "lineno": 447}, {"nodeid": "tests/environment/test_models.py::TestTaskEnvironmentLink::test_update_link", "type": "Function", "lineno": 468}, {"nodeid": "tests/environment/test_models.py::TestTaskEnvironmentLink::test_add_note", "type": "Function", "lineno": 491}]}, {"nodeid": "tests/environment/test_models.py", "outcome": "passed", "result": [{"nodeid": "tests/environment/test_models.py::TestPackageInfo", "type": "Class"}, {"nodeid": "tests/environment/test_models.py::TestComputeResource", "type": "Class"}, {"nodeid": "tests/environment/test_models.py::TestEnvironmentSnapshot", "type": "Class"}, {"nodeid": "tests/environment/test_models.py::TestTaskEnvironmentLink", "type": "Class"}]}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService", "outcome": "passed", "result": [{"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_create_environment_snapshot", "type": "Function", "lineno": 26}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_create_environment_with_packages_and_resources", "type": "Function", "lineno": 55}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_capture_current_environment", "type": "Function", "lineno": 140}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_update_environment", "type": "Function", "lineno": 169}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_update_nonexistent_environment", "type": "Function", "lineno": 206}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_delete_environment", "type": "Function", "lineno": 214}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_list_environments", "type": "Function", "lineno": 230}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_environment_tag_operations", "type": "Function", "lineno": 284}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_package_operations", "type": "Function", "lineno": 313}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_compute_resource_operations", "type": "Function", "lineno": 362}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_environment_variable_operations", "type": "Function", "lineno": 407}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_config_file_operations", "type": "Function", "lineno": 448}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_custom_metadata_operations", "type": "Function", "lineno": 501}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_compare_environments", "type": "Function", "lineno": 550}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_link_task_to_environment", "type": "Function", "lineno": 658}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_link_to_nonexistent_environment", "type": "Function", "lineno": 681}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_task_environment_link_operations", "type": "Function", "lineno": 689}]}, {"nodeid": "tests/environment/test_service.py", "outcome": "passed", "result": [{"nodeid": "tests/environment/test_service.py::TestEnvironmentService", "type": "Class"}]}, {"nodeid": "tests/environment/test_storage.py::TestInMemoryEnvironmentStorage", "outcome": "passed", "result": [{"nodeid": "tests/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_create_and_get_environment", "type": "Function", "lineno": 63}, {"nodeid": "tests/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_update_environment", "type": "Function", "lineno": 76}, {"nodeid": "tests/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_update_nonexistent_environment", "type": "Function", "lineno": 91}, {"nodeid": "tests/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_delete_environment", "type": "Function", "lineno": 102}, {"nodeid": "tests/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_delete_nonexistent_environment", "type": "Function", "lineno": 122}, {"nodeid": "tests/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_list_environments_empty", "type": "Function", "lineno": 127}, {"nodeid": "tests/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_list_environments_with_filters", "type": "Function", "lineno": 132}, {"nodeid": "tests/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_task_environment_link_operations", "type": "Function", "lineno": 163}]}, {"nodeid": "tests/environment/test_storage.py", "outcome": "passed", "result": [{"nodeid": "tests/environment/test_storage.py::TestInMemoryEnvironmentStorage", "type": "Class"}]}, {"nodeid": "tests/environment", "outcome": "passed", "result": [{"nodeid": "tests/environment/test_models.py", "type": "Module"}, {"nodeid": "tests/environment/test_service.py", "type": "Module"}, {"nodeid": "tests/environment/test_storage.py", "type": "Module"}]}, {"nodeid": "tests/experiment", "outcome": "passed", "result": []}, {"nodeid": "tests/experiment_tracking/test_models.py", "outcome": "passed", "result": [{"nodeid": "tests/experiment_tracking/test_models.py::test_parameter_creation", "type": "Function", "lineno": 10}, {"nodeid": "tests/experiment_tracking/test_models.py::test_metric_creation", "type": "Function", "lineno": 26}, {"nodeid": "tests/experiment_tracking/test_models.py::test_experiment_run_creation", "type": "Function", "lineno": 43}, {"nodeid": "tests/experiment_tracking/test_models.py::test_experiment_run_duration", "type": "Function", "lineno": 68}, {"nodeid": "tests/experiment_tracking/test_models.py::test_experiment_creation", "type": "Function", "lineno": 91}, {"nodeid": "tests/experiment_tracking/test_models.py::test_experiment_add_run", "type": "Function", "lineno": 111}, {"nodeid": "tests/experiment_tracking/test_models.py::test_experiment_get_run", "type": "Function", "lineno": 132}, {"nodeid": "tests/experiment_tracking/test_models.py::test_experiment_get_best_run", "type": "Function", "lineno": 152}, {"nodeid": "tests/experiment_tracking/test_models.py::test_experiment_comparison_creation", "type": "Function", "lineno": 191}, {"nodeid": "tests/experiment_tracking/test_models.py::test_experiment_comparison_add_methods", "type": "Function", "lineno": 210}]}, {"nodeid": "tests/experiment_tracking/test_service.py", "outcome": "passed", "result": [{"nodeid": "tests/experiment_tracking/test_service.py::test_create_experiment", "type": "Function", "lineno": 21}, {"nodeid": "tests/experiment_tracking/test_service.py::test_get_experiment", "type": "Function", "lineno": 36}, {"nodeid": "tests/experiment_tracking/test_service.py::test_get_experiment_by_name", "type": "Function", "lineno": 46}, {"nodeid": "tests/experiment_tracking/test_service.py::test_update_experiment", "type": "Function", "lineno": 58}, {"nodeid": "tests/experiment_tracking/test_service.py::test_delete_experiment", "type": "Function", "lineno": 71}, {"nodeid": "tests/experiment_tracking/test_service.py::test_list_experiments", "type": "Function", "lineno": 80}, {"nodeid": "tests/experiment_tracking/test_service.py::test_list_experiments_by_task", "type": "Function", "lineno": 92}, {"nodeid": "tests/experiment_tracking/test_service.py::test_add_parameter", "type": "Function", "lineno": 104}, {"nodeid": "tests/experiment_tracking/test_service.py::test_add_metric", "type": "Function", "lineno": 120}, {"nodeid": "tests/experiment_tracking/test_service.py::test_create_experiment_run", "type": "Function", "lineno": 136}, {"nodeid": "tests/experiment_tracking/test_service.py::test_create_experiment_run_nonexistent_experiment", "type": "Function", "lineno": 155}, {"nodeid": "tests/experiment_tracking/test_service.py::test_get_experiment_run", "type": "Function", "lineno": 163}, {"nodeid": "tests/experiment_tracking/test_service.py::test_run_lifecycle", "type": "Function", "lineno": 175}, {"nodeid": "tests/experiment_tracking/test_service.py::test_failed_and_aborted_runs", "type": "Function", "lineno": 212}, {"nodeid": "tests/experiment_tracking/test_service.py::test_get_best_run", "type": "Function", "lineno": 233}, {"nodeid": "tests/experiment_tracking/test_service.py::test_create_comparison", "type": "Function", "lineno": 261}, {"nodeid": "tests/experiment_tracking/test_service.py::test_get_comparison", "type": "Function", "lineno": 282}, {"nodeid": "tests/experiment_tracking/test_service.py::test_update_comparison", "type": "Function", "lineno": 292}, {"nodeid": "tests/experiment_tracking/test_service.py::test_delete_comparison", "type": "Function", "lineno": 305}, {"nodeid": "tests/experiment_tracking/test_service.py::test_list_comparisons", "type": "Function", "lineno": 314}, {"nodeid": "tests/experiment_tracking/test_service.py::test_get_comparison_data", "type": "Function", "lineno": 326}]}, {"nodeid": "tests/experiment_tracking/test_storage.py", "outcome": "passed", "result": [{"nodeid": "tests/experiment_tracking/test_storage.py::test_create_experiment", "type": "Function", "lineno": 48}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_get_experiment", "type": "Function", "lineno": 58}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_get_nonexistent_experiment", "type": "Function", "lineno": 68}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_update_experiment", "type": "Function", "lineno": 76}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_update_nonexistent_experiment", "type": "Function", "lineno": 89}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_delete_experiment", "type": "Function", "lineno": 97}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_delete_nonexistent_experiment", "type": "Function", "lineno": 106}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_list_experiments", "type": "Function", "lineno": 114}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_list_experiments_by_task", "type": "Function", "lineno": 127}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_get_experiment_by_name", "type": "Function", "lineno": 148}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_create_run", "type": "Function", "lineno": 160}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_create_run_nonexistent_experiment", "type": "Function", "lineno": 175}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_get_run", "type": "Function", "lineno": 183}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_update_run", "type": "Function", "lineno": 194}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_update_nonexistent_run", "type": "Function", "lineno": 214}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_delete_run", "type": "Function", "lineno": 222}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_delete_nonexistent_run", "type": "Function", "lineno": 236}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_create_comparison", "type": "Function", "lineno": 244}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_get_comparison", "type": "Function", "lineno": 254}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_update_comparison", "type": "Function", "lineno": 264}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_update_nonexistent_comparison", "type": "Function", "lineno": 279}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_delete_comparison", "type": "Function", "lineno": 287}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_delete_nonexistent_comparison", "type": "Function", "lineno": 296}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_list_comparisons", "type": "Function", "lineno": 304}]}, {"nodeid": "tests/experiment_tracking/test_visualizer.py", "outcome": "passed", "result": [{"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_parameter_table", "type": "Function", "lineno": 130}, {"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_empty_parameter_table", "type": "Function", "lineno": 140}, {"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_metric_table", "type": "Function", "lineno": 148}, {"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_empty_metric_table", "type": "Function", "lineno": 160}, {"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_artifact_table", "type": "Function", "lineno": 168}, {"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_empty_artifact_table", "type": "Function", "lineno": 177}, {"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_run_summary", "type": "Function", "lineno": 185}, {"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_experiment_summary", "type": "Function", "lineno": 210}, {"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_comparison_table", "type": "Function", "lineno": 229}, {"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_empty_comparison_table", "type": "Function", "lineno": 284}]}, {"nodeid": "tests/experiment_tracking", "outcome": "passed", "result": [{"nodeid": "tests/experiment_tracking/test_models.py", "type": "Module"}, {"nodeid": "tests/experiment_tracking/test_service.py", "type": "Module"}, {"nodeid": "tests/experiment_tracking/test_storage.py", "type": "Module"}, {"nodeid": "tests/experiment_tracking/test_visualizer.py", "type": "Module"}]}, {"nodeid": "tests/export/test_formatter.py", "outcome": "passed", "result": [{"nodeid": "tests/export/test_formatter.py::test_format_document_default", "type": "Function", "lineno": 51}, {"nodeid": "tests/export/test_formatter.py::test_format_document_nature", "type": "Function", "lineno": 89}, {"nodeid": "tests/export/test_formatter.py::test_format_document_science", "type": "Function", "lineno": 100}, {"nodeid": "tests/export/test_formatter.py::test_format_document_plos", "type": "Function", "lineno": 109}, {"nodeid": "tests/export/test_formatter.py::test_format_section", "type": "Function", "lineno": 118}, {"nodeid": "tests/export/test_formatter.py::test_format_text_block", "type": "Function", "lineno": 133}, {"nodeid": "tests/export/test_formatter.py::test_format_image_block", "type": "Function", "lineno": 141}, {"nodeid": "tests/export/test_formatter.py::test_format_table_block", "type": "Function", "lineno": 153}, {"nodeid": "tests/export/test_formatter.py::test_format_code_block", "type": "Function", "lineno": 171}, {"nodeid": "tests/export/test_formatter.py::test_format_equation_block", "type": "Function", "lineno": 186}, {"nodeid": "tests/export/test_formatter.py::test_format_citation_block", "type": "Function", "lineno": 194}]}, {"nodeid": "tests/export/test_models.py", "outcome": "passed", "result": [{"nodeid": "tests/export/test_models.py::test_document_creation", "type": "Function", "lineno": 10}, {"nodeid": "tests/export/test_models.py::test_section_creation", "type": "Function", "lineno": 32}, {"nodeid": "tests/export/test_models.py::test_text_block", "type": "Function", "lineno": 49}, {"nodeid": "tests/export/test_models.py::test_image_block", "type": "Function", "lineno": 58}, {"nodeid": "tests/export/test_models.py::test_table_block", "type": "Function", "lineno": 73}, {"nodeid": "tests/export/test_models.py::test_code_block", "type": "Function", "lineno": 93}, {"nodeid": "tests/export/test_models.py::test_equation_block", "type": "Function", "lineno": 107}, {"nodeid": "tests/export/test_models.py::test_citation_block", "type": "Function", "lineno": 117}, {"nodeid": "tests/export/test_models.py::test_document_with_sections_and_blocks", "type": "Function", "lineno": 129}]}, {"nodeid": "tests/export/test_service.py", "outcome": "passed", "result": [{"nodeid": "tests/export/test_service.py::test_create_document", "type": "Function", "lineno": 22}, {"nodeid": "tests/export/test_service.py::test_get_document", "type": "Function", "lineno": 42}, {"nodeid": "tests/export/test_service.py::test_update_document", "type": "Function", "lineno": 52}, {"nodeid": "tests/export/test_service.py::test_delete_document", "type": "Function", "lineno": 65}, {"nodeid": "tests/export/test_service.py::test_add_section", "type": "Function", "lineno": 74}, {"nodeid": "tests/export/test_service.py::test_add_section_with_order", "type": "Function", "lineno": 88}, {"nodeid": "tests/export/test_service.py::test_add_content_block", "type": "Function", "lineno": 105}, {"nodeid": "tests/export/test_service.py::test_create_content_blocks", "type": "Function", "lineno": 122}, {"nodeid": "tests/export/test_service.py::test_generate_markdown", "type": "Function", "lineno": 163}, {"nodeid": "tests/export/test_service.py::test_export_to_file", "type": "Function", "lineno": 183}]}, {"nodeid": "tests/export/test_storage.py", "outcome": "passed", "result": [{"nodeid": "tests/export/test_storage.py::test_create_document", "type": "Function", "lineno": 30}, {"nodeid": "tests/export/test_storage.py::test_get_document", "type": "Function", "lineno": 40}, {"nodeid": "tests/export/test_storage.py::test_get_nonexistent_document", "type": "Function", "lineno": 50}, {"nodeid": "tests/export/test_storage.py::test_update_document", "type": "Function", "lineno": 59}, {"nodeid": "tests/export/test_storage.py::test_update_nonexistent_document", "type": "Function", "lineno": 72}, {"nodeid": "tests/export/test_storage.py::test_delete_document", "type": "Function", "lineno": 80}, {"nodeid": "tests/export/test_storage.py::test_delete_nonexistent_document", "type": "Function", "lineno": 89}, {"nodeid": "tests/export/test_storage.py::test_list_documents", "type": "Function", "lineno": 98}]}, {"nodeid": "tests/export", "outcome": "passed", "result": [{"nodeid": "tests/export/test_formatter.py", "type": "Module"}, {"nodeid": "tests/export/test_models.py", "type": "Module"}, {"nodeid": "tests/export/test_service.py", "type": "Module"}, {"nodeid": "tests/export/test_storage.py", "type": "Module"}]}, {"nodeid": "tests/integration/test_multitask_workflow.py", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_multitask_workflow.py::test_multitask_research_project", "type": "Function", "lineno": 39}]}, {"nodeid": "tests/integration/test_research_workflow.py", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_research_workflow.py::test_complete_research_workflow", "type": "Function", "lineno": 39}]}, {"nodeid": "tests/integration", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_multitask_workflow.py", "type": "Module"}, {"nodeid": "tests/integration/test_research_workflow.py", "type": "Module"}]}, {"nodeid": "tests/performance/test_bibliography_performance.py::TestBibliographyPerformance", "outcome": "passed", "result": [{"nodeid": "tests/performance/test_bibliography_performance.py::TestBibliographyPerformance::test_large_bibliography_operations", "type": "Function", "lineno": 23}, {"nodeid": "tests/performance/test_bibliography_performance.py::TestBibliographyPerformance::test_task_reference_link_performance", "type": "Function", "lineno": 160}]}, {"nodeid": "tests/performance/test_bibliography_performance.py", "outcome": "passed", "result": [{"nodeid": "tests/performance/test_bibliography_performance.py::TestBibliographyPerformance", "type": "Class"}]}, {"nodeid": "tests/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance", "outcome": "passed", "result": [{"nodeid": "tests/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_dataset_operations_performance", "type": "Function", "lineno": 20}, {"nodeid": "tests/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_handle_large_dataset_catalog", "type": "Function", "lineno": 57}, {"nodeid": "tests/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_handle_100gb_dataset_metadata", "type": "Function", "lineno": 110}, {"nodeid": "tests/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_complex_transformation_chain_performance", "type": "Function", "lineno": 166}, {"nodeid": "tests/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_task_dataset_link_performance", "type": "Function", "lineno": 237}]}, {"nodeid": "tests/performance/test_dataset_versioning_performance.py", "outcome": "passed", "result": [{"nodeid": "tests/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance", "type": "Class"}]}, {"nodeid": "tests/performance/test_environment_performance.py::TestEnvironmentPerformance", "outcome": "passed", "result": [{"nodeid": "tests/performance/test_environment_performance.py::TestEnvironmentPerformance::test_environment_operations_performance", "type": "Function", "lineno": 21}, {"nodeid": "tests/performance/test_environment_performance.py::TestEnvironmentPerformance::test_environment_snapshot_generation_time", "type": "Function", "lineno": 57}, {"nodeid": "tests/performance/test_environment_performance.py::TestEnvironmentPerformance::test_large_environment_catalog_performance", "type": "Function", "lineno": 82}, {"nodeid": "tests/performance/test_environment_performance.py::TestEnvironmentPerformance::test_complex_environment_performance", "type": "Function", "lineno": 161}, {"nodeid": "tests/performance/test_environment_performance.py::TestEnvironmentPerformance::test_task_environment_link_performance", "type": "Function", "lineno": 211}]}, {"nodeid": "tests/performance/test_environment_performance.py", "outcome": "passed", "result": [{"nodeid": "tests/performance/test_environment_performance.py::TestEnvironmentPerformance", "type": "Class"}]}, {"nodeid": "tests/performance/test_experiment_tracking_performance.py", "outcome": "passed", "result": [{"nodeid": "tests/performance/test_experiment_tracking_performance.py::test_experiment_creation_performance", "type": "Function", "lineno": 114}, {"nodeid": "tests/performance/test_experiment_tracking_performance.py::test_best_run_query_performance", "type": "Function", "lineno": 138}, {"nodeid": "tests/performance/test_experiment_tracking_performance.py::test_comparison_performance", "type": "Function", "lineno": 174}, {"nodeid": "tests/performance/test_experiment_tracking_performance.py::test_large_experiment_performance", "type": "Function", "lineno": 228}]}, {"nodeid": "tests/performance/test_export_performance.py", "outcome": "passed", "result": [{"nodeid": "tests/performance/test_export_performance.py::test_document_creation_performance", "type": "Function", "lineno": 94}, {"nodeid": "tests/performance/test_export_performance.py::test_markdown_generation_performance", "type": "Function", "lineno": 116}, {"nodeid": "tests/performance/test_export_performance.py::test_file_export_performance", "type": "Function", "lineno": 142}, {"nodeid": "tests/performance/test_export_performance.py::test_large_document_performance", "type": "Function", "lineno": 173}]}, {"nodeid": "tests/performance/test_integration_performance.py", "outcome": "passed", "result": [{"nodeid": "tests/performance/test_integration_performance.py::test_large_research_project_performance", "type": "Function", "lineno": 46}]}, {"nodeid": "tests/performance/test_task_management_performance.py::TestTaskManagementPerformance", "outcome": "passed", "result": [{"nodeid": "tests/performance/test_task_management_performance.py::TestTaskManagementPerformance::test_task_operation_speed", "type": "Function", "lineno": 16}, {"nodeid": "tests/performance/test_task_management_performance.py::TestTaskManagementPerformance::test_large_task_list_performance", "type": "Function", "lineno": 51}, {"nodeid": "tests/performance/test_task_management_performance.py::TestTaskManagementPerformance::test_research_question_hierarchy_performance", "type": "Function", "lineno": 135}, {"nodeid": "tests/performance/test_task_management_performance.py::TestTaskManagementPerformance::test_task_question_association_performance", "type": "Function", "lineno": 202}]}, {"nodeid": "tests/performance/test_task_management_performance.py", "outcome": "passed", "result": [{"nodeid": "tests/performance/test_task_management_performance.py::TestTaskManagementPerformance", "type": "Class"}]}, {"nodeid": "tests/performance", "outcome": "passed", "result": [{"nodeid": "tests/performance/test_bibliography_performance.py", "type": "Module"}, {"nodeid": "tests/performance/test_dataset_versioning_performance.py", "type": "Module"}, {"nodeid": "tests/performance/test_environment_performance.py", "type": "Module"}, {"nodeid": "tests/performance/test_experiment_tracking_performance.py", "type": "Module"}, {"nodeid": "tests/performance/test_export_performance.py", "type": "Module"}, {"nodeid": "tests/performance/test_integration_performance.py", "type": "Module"}, {"nodeid": "tests/performance/test_task_management_performance.py", "type": "Module"}]}, {"nodeid": "tests/task_management/test_models.py::TestResearchQuestion", "outcome": "passed", "result": [{"nodeid": "tests/task_management/test_models.py::TestResearchQuestion::test_create_research_question", "type": "Function", "lineno": 14}, {"nodeid": "tests/task_management/test_models.py::TestResearchQuestion::test_create_with_parent", "type": "Function", "lineno": 28}, {"nodeid": "tests/task_management/test_models.py::TestResearchQuestion::test_update_question", "type": "Function", "lineno": 39}]}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask", "outcome": "passed", "result": [{"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_create_research_task", "type": "Function", "lineno": 60}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_task_with_due_date", "type": "Function", "lineno": 88}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_create_subtask", "type": "Function", "lineno": 99}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_update_task", "type": "Function", "lineno": 110}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_complete_task", "type": "Function", "lineno": 140}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_add_note", "type": "Function", "lineno": 155}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_manage_tags", "type": "Function", "lineno": 172}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_research_question_association", "type": "Function", "lineno": 199}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_subtask_management", "type": "Function", "lineno": 222}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_custom_metadata", "type": "Function", "lineno": 245}]}, {"nodeid": "tests/task_management/test_models.py", "outcome": "passed", "result": [{"nodeid": "tests/task_management/test_models.py::TestResearchQuestion", "type": "Class"}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask", "type": "Class"}]}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService", "outcome": "passed", "result": [{"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_create_task", "type": "Function", "lineno": 16}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_create_task_with_parent", "type": "Function", "lineno": 35}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_create_task_invalid_parent", "type": "Function", "lineno": 54}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_create_task_with_research_questions", "type": "Function", "lineno": 63}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_create_task_invalid_question", "type": "Function", "lineno": 83}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_update_task", "type": "Function", "lineno": 92}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_update_nonexistent_task", "type": "Function", "lineno": 121}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_delete_task", "type": "Function", "lineno": 129}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_add_task_note", "type": "Function", "lineno": 143}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_add_note_to_nonexistent_task", "type": "Function", "lineno": 159}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_tag_management", "type": "Function", "lineno": 164}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_custom_metadata", "type": "Function", "lineno": 189}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_filter_tasks", "type": "Function", "lineno": 206}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_research_question_operations", "type": "Function", "lineno": 264}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_research_question_hierarchy", "type": "Function", "lineno": 293}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_task_question_association", "type": "Function", "lineno": 325}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_associate_with_nonexistent_task", "type": "Function", "lineno": 359}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_associate_with_nonexistent_question", "type": "Function", "lineno": 368}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_get_subtasks", "type": "Function", "lineno": 378}]}, {"nodeid": "tests/task_management/test_service.py", "outcome": "passed", "result": [{"nodeid": "tests/task_management/test_service.py::TestTaskManagementService", "type": "Class"}]}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage", "outcome": "passed", "result": [{"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_create_and_get_task", "type": "Function", "lineno": 13}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_update_task", "type": "Function", "lineno": 30}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_update_nonexistent_task", "type": "Function", "lineno": 54}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_task", "type": "Function", "lineno": 66}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_nonexistent_task", "type": "Function", "lineno": 82}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_list_tasks_empty", "type": "Function", "lineno": 89}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_list_tasks_with_filters", "type": "Function", "lineno": 96}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_research_question_operations", "type": "Function", "lineno": 170}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_update_nonexistent_question", "type": "Function", "lineno": 204}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_nonexistent_question", "type": "Function", "lineno": 216}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_list_research_questions", "type": "Function", "lineno": 223}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_task_question_associations", "type": "Function", "lineno": 270}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_subtask_relationships", "type": "Function", "lineno": 316}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_task_subtask_cleanup", "type": "Function", "lineno": 359}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_question_cleanup", "type": "Function", "lineno": 386}]}, {"nodeid": "tests/task_management/test_storage.py", "outcome": "passed", "result": [{"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage", "type": "Class"}]}, {"nodeid": "tests/task_management", "outcome": "passed", "result": [{"nodeid": "tests/task_management/test_models.py", "type": "Module"}, {"nodeid": "tests/task_management/test_service.py", "type": "Module"}, {"nodeid": "tests/task_management/test_storage.py", "type": "Module"}]}, {"nodeid": "tests", "outcome": "passed", "result": [{"nodeid": "tests/bibliography", "type": "Package"}, {"nodeid": "tests/dataset_versioning", "type": "Package"}, {"nodeid": "tests/environment", "type": "Package"}, {"nodeid": "tests/experiment", "type": "Package"}, {"nodeid": "tests/experiment_tracking", "type": "Package"}, {"nodeid": "tests/export", "type": "Package"}, {"nodeid": "tests/integration", "type": "Package"}, {"nodeid": "tests/performance", "type": "Package"}, {"nodeid": "tests/task_management", "type": "Package"}]}], "tests": [{"nodeid": "tests/bibliography/test_formatter.py::TestReferenceFormatter::test_apa_formatting", "lineno": 101, "outcome": "passed", "keywords": ["test_apa_formatting", "TestReferenceFormatter", "test_formatter.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0006099720485508442, "outcome": "passed"}, "call": {"duration": 0.00016252300702035427, "outcome": "passed"}, "teardown": {"duration": 0.00011182704474776983, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_formatter.py::TestReferenceFormatter::test_mla_formatting", "lineno": 133, "outcome": "passed", "keywords": ["test_mla_formatting", "TestReferenceFormatter", "test_formatter.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00023596908431500196, "outcome": "passed"}, "call": {"duration": 0.00013013998977839947, "outcome": "passed"}, "teardown": {"duration": 9.4942981377244e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_formatter.py::TestReferenceFormatter::test_harvard_formatting", "lineno": 156, "outcome": "passed", "keywords": ["test_harvard_formatting", "TestReferenceFormatter", "test_formatter.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00021557090803980827, "outcome": "passed"}, "call": {"duration": 0.00010104302782565355, "outcome": "passed"}, "teardown": {"duration": 8.456304203718901e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_formatter.py::TestReferenceFormatter::test_ieee_formatting", "lineno": 170, "outcome": "passed", "keywords": ["test_ieee_formatting", "TestReferenceFormatter", "test_formatter.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00019614805933088064, "outcome": "passed"}, "call": {"duration": 9.788898751139641e-05, "outcome": "passed"}, "teardown": {"duration": 9.081698954105377e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_formatter.py::TestReferenceFormatter::test_in_text_citations", "lineno": 182, "outcome": "passed", "keywords": ["test_in_text_citations", "TestReferenceFormatter", "test_formatter.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00022758403792977333, "outcome": "passed"}, "call": {"duration": 0.00010255200322717428, "outcome": "passed"}, "teardown": {"duration": 8.546607568860054e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_formatter.py::TestReferenceFormatter::test_generate_bibliography", "lineno": 209, "outcome": "passed", "keywords": ["test_generate_bibliography", "TestReferenceFormatter", "test_formatter.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00019332300871610641, "outcome": "passed"}, "call": {"duration": 0.00012155994772911072, "outcome": "passed"}, "teardown": {"duration": 8.989102207124233e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_formatter.py::TestReferenceFormatter::test_author_formatting", "lineno": 238, "outcome": "passed", "keywords": ["test_author_formatting", "TestReferenceFormatter", "test_formatter.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.000187647994607687, "outcome": "passed"}, "call": {"duration": 0.00015433202497661114, "outcome": "passed"}, "teardown": {"duration": 9.074306581169367e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_json_single_reference", "lineno": 10, "outcome": "passed", "keywords": ["test_import_from_json_single_reference", "TestBibliographyImporter", "test_importer.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 9.58290183916688e-05, "outcome": "passed"}, "call": {"duration": 0.0001572250621393323, "outcome": "passed"}, "teardown": {"duration": 7.540802471339703e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_json_multiple_references", "lineno": 71, "outcome": "passed", "keywords": ["test_import_from_json_multiple_references", "TestBibliographyImporter", "test_importer.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.808196824043989e-05, "outcome": "passed"}, "call": {"duration": 0.00020777701865881681, "outcome": "passed"}, "teardown": {"duration": 8.381204679608345e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_json_string", "lineno": 143, "outcome": "passed", "keywords": ["test_import_from_json_string", "TestBibliographyImporter", "test_importer.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.997499778866768e-05, "outcome": "passed"}, "call": {"duration": 0.00016076501924544573, "outcome": "passed"}, "teardown": {"duration": 9.186705574393272e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_invalid_json", "lineno": 165, "outcome": "passed", "keywords": ["test_import_from_invalid_json", "TestBibliographyImporter", "test_importer.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.66220036894083e-05, "outcome": "passed"}, "call": {"duration": 0.0003543900093063712, "outcome": "passed"}, "teardown": {"duration": 8.069397881627083e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_importer.py::TestBibliographyImporter::test_import_handles_missing_fields", "lineno": 170, "outcome": "passed", "keywords": ["test_import_handles_missing_fields", "TestBibliographyImporter", "test_importer.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 8.279900066554546e-05, "outcome": "passed"}, "call": {"duration": 0.00012761505786329508, "outcome": "passed"}, "teardown": {"duration": 7.832993287593126e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_importer.py::TestBibliographyImporter::test_export_to_json", "lineno": 186, "outcome": "passed", "keywords": ["test_export_to_json", "TestBibliographyImporter", "test_importer.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.821503095328808e-05, "outcome": "passed"}, "call": {"duration": 0.0002498159883543849, "outcome": "passed"}, "teardown": {"duration": 7.715600077062845e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_importer.py::TestBibliographyImporter::test_import_export_roundtrip", "lineno": 262, "outcome": "passed", "keywords": ["test_import_export_roundtrip", "TestBibliographyImporter", "test_importer.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 8.433707989752293e-05, "outcome": "passed"}, "call": {"duration": 0.00021991797257214785, "outcome": "passed"}, "teardown": {"duration": 8.008896838873625e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_bibtex_basic", "lineno": 307, "outcome": "passed", "keywords": ["test_import_from_bibtex_basic", "TestBibliographyImporter", "test_importer.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.777393329888582e-05, "outcome": "passed"}, "call": {"duration": 0.0006607610266655684, "outcome": "passed"}, "teardown": {"duration": 8.911697659641504e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_models.py::TestAuthor::test_create_person_author", "lineno": 15, "outcome": "passed", "keywords": ["test_create_person_author", "TestAuthor", "test_models.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00010696507524698973, "outcome": "passed"}, "call": {"duration": 0.00010832794941961765, "outcome": "passed"}, "teardown": {"duration": 7.493409793823957e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_models.py::TestAuthor::test_create_organization_author", "lineno": 31, "outcome": "passed", "keywords": ["test_create_organization_author", "TestAuthor", "test_models.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.786194328218699e-05, "outcome": "passed"}, "call": {"duration": 9.887793567031622e-05, "outcome": "passed"}, "teardown": {"duration": 7.233000360429287e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_models.py::TestAuthor::test_author_full_name_person", "lineno": 45, "outcome": "passed", "keywords": ["test_author_full_name_person", "TestAuthor", "test_models.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.99759291112423e-05, "outcome": "passed"}, "call": {"duration": 0.0001219860278069973, "outcome": "passed"}, "teardown": {"duration": 7.755099795758724e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_models.py::TestAuthor::test_author_full_name_organization", "lineno": 76, "outcome": "passed", "keywords": ["test_author_full_name_organization", "TestAuthor", "test_models.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.80210830271244e-05, "outcome": "passed"}, "call": {"duration": 0.00010384304914623499, "outcome": "passed"}, "teardown": {"duration": 7.38929957151413e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_models.py::TestReference::test_create_journal_article", "lineno": 92, "outcome": "passed", "keywords": ["test_create_journal_article", "TestReference", "test_models.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.92450737208128e-05, "outcome": "passed"}, "call": {"duration": 0.000128320069052279, "outcome": "passed"}, "teardown": {"duration": 7.234909571707249e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_models.py::TestReference::test_create_book", "lineno": 137, "outcome": "passed", "keywords": ["test_create_book", "TestReference", "test_models.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.547193672508001e-05, "outcome": "passed"}, "call": {"duration": 0.00011042493861168623, "outcome": "passed"}, "teardown": {"duration": 7.93189974501729e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_models.py::TestReference::test_create_website", "lineno": 164, "outcome": "passed", "keywords": ["test_create_website", "TestReference", "test_models.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.557892240583897e-05, "outcome": "passed"}, "call": {"duration": 0.00011390203144401312, "outcome": "passed"}, "teardown": {"duration": 7.171800825744867e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_models.py::TestReference::test_update_reference", "lineno": 190, "outcome": "passed", "keywords": ["test_update_reference", "TestReference", "test_models.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 9.487301576882601e-05, "outcome": "passed"}, "call": {"duration": 0.0001482199877500534, "outcome": "passed"}, "teardown": {"duration": 7.517903577536345e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_models.py::TestReference::test_add_author", "lineno": 215, "outcome": "passed", "keywords": ["test_add_author", "TestReference", "test_models.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.438298780471087e-05, "outcome": "passed"}, "call": {"duration": 0.00012374110519886017, "outcome": "passed"}, "teardown": {"duration": 7.277994882315397e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_models.py::TestReference::test_remove_author", "lineno": 245, "outcome": "passed", "keywords": ["test_remove_author", "TestReference", "test_models.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.741502486169338e-05, "outcome": "passed"}, "call": {"duration": 0.00013866089284420013, "outcome": "passed"}, "teardown": {"duration": 7.383699994534254e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_models.py::TestReference::test_keywords", "lineno": 280, "outcome": "passed", "keywords": ["test_keywords", "TestReference", "test_models.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.367704529315233e-05, "outcome": "passed"}, "call": {"duration": 0.00011284498032182455, "outcome": "passed"}, "teardown": {"duration": 7.467891555279493e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_models.py::TestReference::test_notes", "lineno": 313, "outcome": "passed", "keywords": ["test_notes", "TestReference", "test_models.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.553305476903915e-05, "outcome": "passed"}, "call": {"duration": 0.00011947797611355782, "outcome": "passed"}, "teardown": {"duration": 7.2825001552701e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_models.py::TestReference::test_custom_fields", "lineno": 331, "outcome": "passed", "keywords": ["test_custom_fields", "TestReference", "test_models.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.630989421159029e-05, "outcome": "passed"}, "call": {"duration": 0.00010778196156024933, "outcome": "passed"}, "teardown": {"duration": 7.062789518386126e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_models.py::TestReference::test_author_names_formatted", "lineno": 366, "outcome": "passed", "keywords": ["test_author_names_formatted", "TestReference", "test_models.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.38899689167738e-05, "outcome": "passed"}, "call": {"duration": 0.00016167399007827044, "outcome": "passed"}, "teardown": {"duration": 7.658603135496378e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_models.py::TestTaskReferenceLink::test_create_task_reference_link", "lineno": 416, "outcome": "passed", "keywords": ["test_create_task_reference_link", "TestTaskReferenceLink", "test_models.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.436308078467846e-05, "outcome": "passed"}, "call": {"duration": 0.00011623499449342489, "outcome": "passed"}, "teardown": {"duration": 7.918407209217548e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_models.py::TestTaskReferenceLink::test_update_link", "lineno": 435, "outcome": "passed", "keywords": ["test_update_link", "TestTaskReferenceLink", "test_models.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 8.218199945986271e-05, "outcome": "passed"}, "call": {"duration": 0.00012685195542871952, "outcome": "passed"}, "teardown": {"duration": 7.409602403640747e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_models.py::TestTaskReferenceLink::test_add_note", "lineno": 453, "outcome": "passed", "keywords": ["test_add_note", "TestTaskReferenceLink", "test_models.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.406005170196295e-05, "outcome": "passed"}, "call": {"duration": 0.00010900408960878849, "outcome": "passed"}, "teardown": {"duration": 7.444503717124462e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_create_author_methods", "lineno": 26, "outcome": "failed", "keywords": ["test_create_author_methods", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001534700859338045, "outcome": "passed"}, "call": {"duration": 0.00011271401308476925, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/bibliography/test_service.py", "lineno": 31, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_person_author'"}, "traceback": [{"path": "tests/bibliography/test_service.py", "lineno": 31, "message": "AttributeError"}], "longrepr": "self = <tests.bibliography.test_service.TestBibliographyService object at 0x7f6938bc07a0>\n\n    def test_create_author_methods(self):\n        # Test the author creation helper methods\n    \n        # Create person author\n>       person_author = self.service.create_person_author(\n            first_name=\"John\",\n            last_name=\"Smith\",\n            orcid_id=\"0000-0001-2345-6789\",\n        )\nE       AttributeError: 'BibliographyService' object has no attribute 'create_person_author'\n\ntests/bibliography/test_service.py:31: AttributeError"}, "teardown": {"duration": 0.00013302895240485668, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_create_journal_article", "lineno": 49, "outcome": "failed", "keywords": ["test_create_journal_article", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014979299157857895, "outcome": "passed"}, "call": {"duration": 0.0001146799186244607, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/bibliography/test_service.py", "lineno": 52, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_person_author'"}, "traceback": [{"path": "tests/bibliography/test_service.py", "lineno": 52, "message": "AttributeError"}], "longrepr": "self = <tests.bibliography.test_service.TestBibliographyService object at 0x7f6938bc0950>\n\n    def test_create_journal_article(self):\n        # Test creating a journal article reference\n>       author1 = self.service.create_person_author(\"John\", \"Smith\")\nE       AttributeError: 'BibliographyService' object has no attribute 'create_person_author'\n\ntests/bibliography/test_service.py:52: AttributeError"}, "teardown": {"duration": 0.00013071601279079914, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_create_book", "lineno": 82, "outcome": "failed", "keywords": ["test_create_book", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014887098222970963, "outcome": "passed"}, "call": {"duration": 0.00010356598068028688, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/bibliography/test_service.py", "lineno": 85, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_person_author'"}, "traceback": [{"path": "tests/bibliography/test_service.py", "lineno": 85, "message": "AttributeError"}], "longrepr": "self = <tests.bibliography.test_service.TestBibliographyService object at 0x7f6938bc0b00>\n\n    def test_create_book(self):\n        # Test creating a book reference\n>       author = self.service.create_person_author(\"John\", \"Smith\")\nE       AttributeError: 'BibliographyService' object has no attribute 'create_person_author'\n\ntests/bibliography/test_service.py:85: AttributeError"}, "teardown": {"duration": 0.00012947199866175652, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_create_website", "lineno": 111, "outcome": "failed", "keywords": ["test_create_website", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00015150103718042374, "outcome": "passed"}, "call": {"duration": 0.00010506005492061377, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/bibliography/test_service.py", "lineno": 114, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_organization_author'"}, "traceback": [{"path": "tests/bibliography/test_service.py", "lineno": 114, "message": "AttributeError"}], "longrepr": "self = <tests.bibliography.test_service.TestBibliographyService object at 0x7f6938bc0cb0>\n\n    def test_create_website(self):\n        # Test creating a website reference\n>       org_author = self.service.create_organization_author(\"Test Organization\")\nE       AttributeError: 'BibliographyService' object has no attribute 'create_organization_author'\n\ntests/bibliography/test_service.py:114: AttributeError"}, "teardown": {"duration": 0.0001255379756912589, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_create_generic_reference", "lineno": 139, "outcome": "failed", "keywords": ["test_create_generic_reference", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014911801554262638, "outcome": "passed"}, "call": {"duration": 0.00010273000225424767, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/bibliography/test_service.py", "lineno": 142, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_person_author'"}, "traceback": [{"path": "tests/bibliography/test_service.py", "lineno": 142, "message": "AttributeError"}], "longrepr": "self = <tests.bibliography.test_service.TestBibliographyService object at 0x7f6938bc0e60>\n\n    def test_create_generic_reference(self):\n        # Test creating a generic reference\n>       author = self.service.create_person_author(\"John\", \"Smith\")\nE       AttributeError: 'BibliographyService' object has no attribute 'create_person_author'\n\ntests/bibliography/test_service.py:142: AttributeError"}, "teardown": {"duration": 0.0001263500889763236, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_update_reference", "lineno": 166, "outcome": "failed", "keywords": ["test_update_reference", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014643592294305563, "outcome": "passed"}, "call": {"duration": 0.00010472000576555729, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/bibliography/test_service.py", "lineno": 169, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_person_author'"}, "traceback": [{"path": "tests/bibliography/test_service.py", "lineno": 169, "message": "AttributeError"}], "longrepr": "self = <tests.bibliography.test_service.TestBibliographyService object at 0x7f6938bc1010>\n\n    def test_update_reference(self):\n        # Test updating a reference\n>       author = self.service.create_person_author(\"John\", \"Smith\")\nE       AttributeError: 'BibliographyService' object has no attribute 'create_person_author'\n\ntests/bibliography/test_service.py:169: AttributeError"}, "teardown": {"duration": 0.00012664101086556911, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_update_nonexistent_reference", "lineno": 193, "outcome": "failed", "keywords": ["test_update_nonexistent_reference", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014309294056147337, "outcome": "passed"}, "call": {"duration": 0.00022260891273617744, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/researchtrack/bibliography/storage.py", "lineno": 211, "message": "TypeError: unhashable type: 'Reference'"}, "traceback": [{"path": "tests/bibliography/test_service.py", "lineno": 204, "message": ""}, {"path": "researchtrack/bibliography/service.py", "lineno": 163, "message": "in update_reference"}, {"path": "researchtrack/bibliography/storage.py", "lineno": 211, "message": "TypeError"}], "longrepr": "self = <tests.bibliography.test_service.TestBibliographyService object at 0x7f6938bc11c0>\n\n    def test_update_nonexistent_reference(self):\n        # Test updating a nonexistent reference\n        ref = Reference(\n            id=uuid4(),\n            type=ReferenceType.BOOK,\n            title=\"Nonexistent Reference\",\n            authors=[],\n        )\n    \n        with pytest.raises(ValueError, match=\"Reference .* does not exist\"):\n>           self.service.update_reference(ref)\n\ntests/bibliography/test_service.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nresearchtrack/bibliography/service.py:163: in update_reference\n    reference = self._storage.get_reference(reference_id)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <researchtrack.bibliography.storage.InMemoryBibliographyStorage object at 0x7f693889aa20>\nreference_id = Reference(id=UUID('dbd24244-bc79-4e61-9295-8410f6b8a835'), type=<ReferenceType.BOOK: 'book'>, authors=[], title='Nonex...eated_at=datetime.datetime(2025, 5, 15, 2, 34, 9, 984097), updated_at=datetime.datetime(2025, 5, 15, 2, 34, 9, 984098))\n\n    def get_reference(self, reference_id: UUID) -> Optional[Reference]:\n>       return self._references.get(reference_id)\nE       TypeError: unhashable type: 'Reference'\n\nresearchtrack/bibliography/storage.py:211: TypeError"}, "teardown": {"duration": 0.00012934603728353977, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_delete_reference", "lineno": 205, "outcome": "failed", "keywords": ["test_delete_reference", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00016447203233838081, "outcome": "passed"}, "call": {"duration": 0.00010263198055326939, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/bibliography/test_service.py", "lineno": 208, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_person_author'"}, "traceback": [{"path": "tests/bibliography/test_service.py", "lineno": 208, "message": "AttributeError"}], "longrepr": "self = <tests.bibliography.test_service.TestBibliographyService object at 0x7f6938bc1370>\n\n    def test_delete_reference(self):\n        # Test deleting a reference\n>       author = self.service.create_person_author(\"John\", \"Smith\")\nE       AttributeError: 'BibliographyService' object has no attribute 'create_person_author'\n\ntests/bibliography/test_service.py:208: AttributeError"}, "teardown": {"duration": 0.00012842495925724506, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_search_references", "lineno": 224, "outcome": "failed", "keywords": ["test_search_references", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001475439639762044, "outcome": "passed"}, "call": {"duration": 0.00010572199244052172, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/bibliography/test_service.py", "lineno": 229, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_person_author'"}, "traceback": [{"path": "tests/bibliography/test_service.py", "lineno": 229, "message": "AttributeError"}], "longrepr": "self = <tests.bibliography.test_service.TestBibliographyService object at 0x7f6938bc1520>\n\n    def test_search_references(self):\n        # Test searching for references\n    \n        # Create some references to search\n>       author1 = self.service.create_person_author(\"John\", \"Smith\")\nE       AttributeError: 'BibliographyService' object has no attribute 'create_person_author'\n\ntests/bibliography/test_service.py:229: AttributeError"}, "teardown": {"duration": 0.0001263859448954463, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_reference_modification_methods", "lineno": 289, "outcome": "failed", "keywords": ["test_reference_modification_methods", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014520494733005762, "outcome": "passed"}, "call": {"duration": 0.00010190100874751806, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/bibliography/test_service.py", "lineno": 292, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_person_author'"}, "traceback": [{"path": "tests/bibliography/test_service.py", "lineno": 292, "message": "AttributeError"}], "longrepr": "self = <tests.bibliography.test_service.TestBibliographyService object at 0x7f6938bc16d0>\n\n    def test_reference_modification_methods(self):\n        # Test methods for modifying reference attributes\n>       author = self.service.create_person_author(\"John\", \"Smith\")\nE       AttributeError: 'BibliographyService' object has no attribute 'create_person_author'\n\ntests/bibliography/test_service.py:292: AttributeError"}, "teardown": {"duration": 0.0001271599903702736, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_link_task_to_reference", "lineno": 326, "outcome": "failed", "keywords": ["test_link_task_to_reference", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014790496788918972, "outcome": "passed"}, "call": {"duration": 0.00010408193338662386, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/bibliography/test_service.py", "lineno": 329, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_person_author'"}, "traceback": [{"path": "tests/bibliography/test_service.py", "lineno": 329, "message": "AttributeError"}], "longrepr": "self = <tests.bibliography.test_service.TestBibliographyService object at 0x7f6938bc1880>\n\n    def test_link_task_to_reference(self):\n        # Test linking tasks and references\n>       author = self.service.create_person_author(\"John\", \"Smith\")\nE       AttributeError: 'BibliographyService' object has no attribute 'create_person_author'\n\ntests/bibliography/test_service.py:329: AttributeError"}, "teardown": {"duration": 0.0001259869895875454, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_link_to_nonexistent_reference", "lineno": 352, "outcome": "passed", "keywords": ["test_link_to_nonexistent_reference", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001441680360585451, "outcome": "passed"}, "call": {"duration": 0.0001332429237663746, "outcome": "passed"}, "teardown": {"duration": 9.624101221561432e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_update_task_reference_link", "lineno": 360, "outcome": "failed", "keywords": ["test_update_task_reference_link", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012962694745510817, "outcome": "passed"}, "call": {"duration": 9.830005001276731e-05, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/bibliography/test_service.py", "lineno": 363, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_person_author'"}, "traceback": [{"path": "tests/bibliography/test_service.py", "lineno": 363, "message": "AttributeError"}], "longrepr": "self = <tests.bibliography.test_service.TestBibliographyService object at 0x7f6938bc1be0>\n\n    def test_update_task_reference_link(self):\n        # Test updating a task-reference link\n>       author = self.service.create_person_author(\"John\", \"Smith\")\nE       AttributeError: 'BibliographyService' object has no attribute 'create_person_author'\n\ntests/bibliography/test_service.py:363: AttributeError"}, "teardown": {"duration": 0.00012709898874163628, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_add_note_to_link", "lineno": 388, "outcome": "failed", "keywords": ["test_add_note_to_link", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001477920450270176, "outcome": "passed"}, "call": {"duration": 0.00010122696403414011, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/bibliography/test_service.py", "lineno": 391, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_person_author'"}, "traceback": [{"path": "tests/bibliography/test_service.py", "lineno": 391, "message": "AttributeError"}], "longrepr": "self = <tests.bibliography.test_service.TestBibliographyService object at 0x7f6938bc1d90>\n\n    def test_add_note_to_link(self):\n        # Test adding a note to a task-reference link\n>       author = self.service.create_person_author(\"John\", \"Smith\")\nE       AttributeError: 'BibliographyService' object has no attribute 'create_person_author'\n\ntests/bibliography/test_service.py:391: AttributeError"}, "teardown": {"duration": 0.00012702203821390867, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_get_references_by_task", "lineno": 412, "outcome": "failed", "keywords": ["test_get_references_by_task", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014587107580155134, "outcome": "passed"}, "call": {"duration": 0.00010382698383182287, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/bibliography/test_service.py", "lineno": 415, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_person_author'"}, "traceback": [{"path": "tests/bibliography/test_service.py", "lineno": 415, "message": "AttributeError"}], "longrepr": "self = <tests.bibliography.test_service.TestBibliographyService object at 0x7f6938b8f8f0>\n\n    def test_get_references_by_task(self):\n        # Test getting references associated with a task\n>       author1 = self.service.create_person_author(\"John\", \"Smith\")\nE       AttributeError: 'BibliographyService' object has no attribute 'create_person_author'\n\ntests/bibliography/test_service.py:415: AttributeError"}, "teardown": {"duration": 0.00012763496488332748, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_get_tasks_by_reference", "lineno": 448, "outcome": "failed", "keywords": ["test_get_tasks_by_reference", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014410796575248241, "outcome": "passed"}, "call": {"duration": 9.949400555342436e-05, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/bibliography/test_service.py", "lineno": 451, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_person_author'"}, "traceback": [{"path": "tests/bibliography/test_service.py", "lineno": 451, "message": "AttributeError"}], "longrepr": "self = <tests.bibliography.test_service.TestBibliographyService object at 0x7f6938bc1cd0>\n\n    def test_get_tasks_by_reference(self):\n        # Test getting tasks associated with a reference\n>       author = self.service.create_person_author(\"John\", \"Smith\")\nE       AttributeError: 'BibliographyService' object has no attribute 'create_person_author'\n\ntests/bibliography/test_service.py:451: AttributeError"}, "teardown": {"duration": 0.00013222894631326199, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_delete_task_reference_link", "lineno": 468, "outcome": "failed", "keywords": ["test_delete_task_reference_link", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014517898671329021, "outcome": "passed"}, "call": {"duration": 0.00010363094042986631, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/bibliography/test_service.py", "lineno": 471, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_person_author'"}, "traceback": [{"path": "tests/bibliography/test_service.py", "lineno": 471, "message": "AttributeError"}], "longrepr": "self = <tests.bibliography.test_service.TestBibliographyService object at 0x7f6938bc17c0>\n\n    def test_delete_task_reference_link(self):\n        # Test deleting a task-reference link\n>       author = self.service.create_person_author(\"John\", \"Smith\")\nE       AttributeError: 'BibliographyService' object has no attribute 'create_person_author'\n\ntests/bibliography/test_service.py:471: AttributeError"}, "teardown": {"duration": 0.00013325701002031565, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_citation_formatting", "lineno": 490, "outcome": "failed", "keywords": ["test_citation_formatting", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014371192082762718, "outcome": "passed"}, "call": {"duration": 0.0001027759863063693, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/bibliography/test_service.py", "lineno": 493, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_person_author'"}, "traceback": [{"path": "tests/bibliography/test_service.py", "lineno": 493, "message": "AttributeError"}], "longrepr": "self = <tests.bibliography.test_service.TestBibliographyService object at 0x7f6938bc12b0>\n\n    def test_citation_formatting(self):\n        # Test citation formatting through the service\n>       author1 = self.service.create_person_author(\"John\", \"Smith\")\nE       AttributeError: 'BibliographyService' object has no attribute 'create_person_author'\n\ntests/bibliography/test_service.py:493: AttributeError"}, "teardown": {"duration": 0.00013407401274889708, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_in_text_citation_formatting", "lineno": 524, "outcome": "failed", "keywords": ["test_in_text_citation_formatting", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014948297757655382, "outcome": "passed"}, "call": {"duration": 0.00010313000530004501, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/bibliography/test_service.py", "lineno": 527, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_person_author'"}, "traceback": [{"path": "tests/bibliography/test_service.py", "lineno": 527, "message": "AttributeError"}], "longrepr": "self = <tests.bibliography.test_service.TestBibliographyService object at 0x7f6938bc0da0>\n\n    def test_in_text_citation_formatting(self):\n        # Test in-text citation formatting\n>       author = self.service.create_person_author(\"John\", \"Smith\")\nE       AttributeError: 'BibliographyService' object has no attribute 'create_person_author'\n\ntests/bibliography/test_service.py:527: AttributeError"}, "teardown": {"duration": 0.00013410300016403198, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_service.py::TestBibliographyService::test_generate_task_bibliography", "lineno": 548, "outcome": "failed", "keywords": ["test_generate_task_bibliography", "TestBibliographyService", "test_service.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014973594807088375, "outcome": "passed"}, "call": {"duration": 0.00010162999387830496, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/bibliography/test_service.py", "lineno": 551, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_person_author'"}, "traceback": [{"path": "tests/bibliography/test_service.py", "lineno": 551, "message": "AttributeError"}], "longrepr": "self = <tests.bibliography.test_service.TestBibliographyService object at 0x7f6938bc0890>\n\n    def test_generate_task_bibliography(self):\n        # Test generating a bibliography for a task\n>       author1 = self.service.create_person_author(\"Alice\", \"Johnson\")\nE       AttributeError: 'BibliographyService' object has no attribute 'create_person_author'\n\ntests/bibliography/test_service.py:551: AttributeError"}, "teardown": {"duration": 0.0001379899913445115, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_create_and_get_reference", "lineno": 53, "outcome": "passed", "keywords": ["test_create_and_get_reference", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00020640401635318995, "outcome": "passed"}, "call": {"duration": 0.00010140403173863888, "outcome": "passed"}, "teardown": {"duration": 0.00010008306708186865, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_update_reference", "lineno": 64, "outcome": "passed", "keywords": ["test_update_reference", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00017769599799066782, "outcome": "passed"}, "call": {"duration": 9.329000022262335e-05, "outcome": "passed"}, "teardown": {"duration": 8.405698463320732e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_update_nonexistent_reference", "lineno": 79, "outcome": "passed", "keywords": ["test_update_nonexistent_reference", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00016089400742202997, "outcome": "passed"}, "call": {"duration": 0.00010934704914689064, "outcome": "passed"}, "teardown": {"duration": 8.379493374377489e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_delete_reference", "lineno": 91, "outcome": "passed", "keywords": ["test_delete_reference", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00015688396524637938, "outcome": "passed"}, "call": {"duration": 0.00010294001549482346, "outcome": "passed"}, "teardown": {"duration": 8.187699131667614e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_delete_nonexistent_reference", "lineno": 111, "outcome": "passed", "keywords": ["test_delete_nonexistent_reference", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00017333496361970901, "outcome": "passed"}, "call": {"duration": 9.179895278066397e-05, "outcome": "passed"}, "teardown": {"duration": 8.31440556794405e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_list_references_empty", "lineno": 116, "outcome": "passed", "keywords": ["test_list_references_empty", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00017134309746325016, "outcome": "passed"}, "call": {"duration": 8.881010580807924e-05, "outcome": "passed"}, "teardown": {"duration": 8.810404688119888e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_list_references_with_filters", "lineno": 121, "outcome": "passed", "keywords": ["test_list_references_with_filters", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00015499198343604803, "outcome": "passed"}, "call": {"duration": 0.00011851591989398003, "outcome": "passed"}, "teardown": {"duration": 8.776900358498096e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_task_reference_link_operations", "lineno": 165, "outcome": "passed", "keywords": ["test_task_reference_link_operations", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00016583502292633057, "outcome": "passed"}, "call": {"duration": 0.00012448406778275967, "outcome": "passed"}, "teardown": {"duration": 8.181191515177488e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_get_references_by_task", "lineno": 217, "outcome": "passed", "keywords": ["test_get_references_by_task", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001562880352139473, "outcome": "passed"}, "call": {"duration": 0.00011589995119720697, "outcome": "passed"}, "teardown": {"duration": 8.16460233181715e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_get_links_by_task", "lineno": 252, "outcome": "passed", "keywords": ["test_get_links_by_task", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00015519000589847565, "outcome": "passed"}, "call": {"duration": 0.00011062691919505596, "outcome": "passed"}, "teardown": {"duration": 7.955590263009071e-05, "outcome": "passed"}}, {"nodeid": "tests/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_get_tasks_by_reference", "lineno": 282, "outcome": "passed", "keywords": ["test_get_tasks_by_reference", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014958495739847422, "outcome": "passed"}, "call": {"duration": 0.00011625199113041162, "outcome": "passed"}, "teardown": {"duration": 8.434499613940716e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDataset::test_create_dataset", "lineno": 17, "outcome": "passed", "keywords": ["test_create_dataset", "TestDataset", "test_models.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0002559500280767679, "outcome": "passed"}, "call": {"duration": 0.00013763201422989368, "outcome": "passed"}, "teardown": {"duration": 8.029898162931204e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDataset::test_update_dataset", "lineno": 61, "outcome": "passed", "keywords": ["test_update_dataset", "TestDataset", "test_models.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.705600000917912e-05, "outcome": "passed"}, "call": {"duration": 0.00014117802493274212, "outcome": "passed"}, "teardown": {"duration": 7.359008304774761e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDataset::test_dataset_tags", "lineno": 88, "outcome": "passed", "keywords": ["test_dataset_tags", "TestDataset", "test_models.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.449497934430838e-05, "outcome": "passed"}, "call": {"duration": 0.00012257089838385582, "outcome": "passed"}, "teardown": {"duration": 7.224304135888815e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDataset::test_dataset_custom_metadata", "lineno": 121, "outcome": "passed", "keywords": ["test_dataset_custom_metadata", "TestDataset", "test_models.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.348309736698866e-05, "outcome": "passed"}, "call": {"duration": 0.0001994819613173604, "outcome": "passed"}, "teardown": {"duration": 8.425198029726744e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDatasetVersion::test_create_dataset_version", "lineno": 167, "outcome": "passed", "keywords": ["test_create_dataset_version", "TestDatasetVersion", "test_models.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 8.808099664747715e-05, "outcome": "passed"}, "call": {"duration": 0.0001318909926339984, "outcome": "passed"}, "teardown": {"duration": 7.682002615183592e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDatasetVersion::test_update_version", "lineno": 212, "outcome": "passed", "keywords": ["test_update_version", "TestDatasetVersion", "test_models.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.610803004354239e-05, "outcome": "passed"}, "call": {"duration": 0.00013197201769798994, "outcome": "passed"}, "teardown": {"duration": 7.334293331950903e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDatasetVersion::test_version_custom_metadata", "lineno": 234, "outcome": "passed", "keywords": ["test_version_custom_metadata", "TestDatasetVersion", "test_models.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.503503002226353e-05, "outcome": "passed"}, "call": {"duration": 0.00010561197996139526, "outcome": "passed"}, "teardown": {"duration": 7.316004484891891e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDataTransformation::test_create_data_transformation", "lineno": 267, "outcome": "passed", "keywords": ["test_create_data_transformation", "TestDataTransformation", "test_models.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 8.038000669330359e-05, "outcome": "passed"}, "call": {"duration": 0.00015245494432747364, "outcome": "passed"}, "teardown": {"duration": 8.336093742400408e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDataTransformation::test_update_transformation", "lineno": 302, "outcome": "passed", "keywords": ["test_update_transformation", "TestDataTransformation", "test_models.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.773004472255707e-05, "outcome": "passed"}, "call": {"duration": 0.00013304094318300486, "outcome": "passed"}, "teardown": {"duration": 7.478496991097927e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDataTransformation::test_transformation_tags", "lineno": 327, "outcome": "passed", "keywords": ["test_transformation_tags", "TestDataTransformation", "test_models.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.296493276953697e-05, "outcome": "passed"}, "call": {"duration": 0.0001093179453164339, "outcome": "passed"}, "teardown": {"duration": 7.679499685764313e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDataTransformation::test_transformation_notes", "lineno": 357, "outcome": "passed", "keywords": ["test_transformation_notes", "TestDataTransformation", "test_models.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.348100189119577e-05, "outcome": "passed"}, "call": {"duration": 0.00010550906881690025, "outcome": "passed"}, "teardown": {"duration": 7.340300362557173e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_models.py::TestDataTransformation::test_transformation_parameters", "lineno": 376, "outcome": "passed", "keywords": ["test_transformation_parameters", "TestDataTransformation", "test_models.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.55189685150981e-05, "outcome": "passed"}, "call": {"duration": 0.00011100003030151129, "outcome": "passed"}, "teardown": {"duration": 7.32749467715621e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_models.py::TestTaskDatasetLink::test_create_task_dataset_link", "lineno": 411, "outcome": "passed", "keywords": ["test_create_task_dataset_link", "TestTaskDatasetLink", "test_models.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.485807873308659e-05, "outcome": "passed"}, "call": {"duration": 0.00010741502046585083, "outcome": "passed"}, "teardown": {"duration": 7.140298839658499e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_models.py::TestTaskDatasetLink::test_update_link", "lineno": 432, "outcome": "passed", "keywords": ["test_update_link", "TestTaskDatasetLink", "test_models.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.375702261924744e-05, "outcome": "passed"}, "call": {"duration": 0.00012628198601305485, "outcome": "passed"}, "teardown": {"duration": 7.414608262479305e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_models.py::TestTaskDatasetLink::test_link_notes", "lineno": 455, "outcome": "passed", "keywords": ["test_link_notes", "TestTaskDatasetLink", "test_models.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.71631021052599e-05, "outcome": "passed"}, "call": {"duration": 0.00011060398537665606, "outcome": "passed"}, "teardown": {"duration": 7.378996815532446e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_dataset", "lineno": 23, "outcome": "failed", "keywords": ["test_create_dataset", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00015564996283501387, "outcome": "passed"}, "call": {"duration": 0.00010327703785151243, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/dataset_versioning/test_service.py", "lineno": 26, "message": "TypeError: DatasetVersioningService.create_dataset() got an unexpected keyword argument 'custom_metadata'"}, "traceback": [{"path": "tests/dataset_versioning/test_service.py", "lineno": 26, "message": "TypeError"}], "longrepr": "self = <tests.dataset_versioning.test_service.TestDatasetVersioningService object at 0x7f6938a34d70>\n\n    def test_create_dataset(self):\n        # Test creating a dataset\n>       dataset_id = self.service.create_dataset(\n            name=\"Test Dataset\",\n            format=DatasetFormat.CSV,\n            storage_type=DatasetStorageType.LOCAL,\n            location=\"/path/to/data.csv\",\n            description=\"Test dataset description\",\n            size_bytes=1024 * 1024,  # 1MB\n            row_count=1000,\n            column_count=10,\n            schema={\"col1\": \"integer\", \"col2\": \"string\"},\n            tags={\"test\", \"data\"},\n            hash=\"sha256:abcdef\",\n            version=\"1.0.0\",\n            custom_metadata={\"source\": \"Test source\"},\n        )\nE       TypeError: DatasetVersioningService.create_dataset() got an unexpected keyword argument 'custom_metadata'\n\ntests/dataset_versioning/test_service.py:26: TypeError"}, "teardown": {"duration": 0.00012940692249685526, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_update_dataset", "lineno": 58, "outcome": "passed", "keywords": ["test_update_dataset", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014893501065671444, "outcome": "passed"}, "call": {"duration": 0.0001499950885772705, "outcome": "passed"}, "teardown": {"duration": 9.063794277608395e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_update_nonexistent_dataset", "lineno": 86, "outcome": "passed", "keywords": ["test_update_nonexistent_dataset", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.000133198918774724, "outcome": "passed"}, "call": {"duration": 0.00018014898523688316, "outcome": "passed"}, "teardown": {"duration": 8.602393791079521e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_delete_dataset", "lineno": 94, "outcome": "passed", "keywords": ["test_delete_dataset", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012470991350710392, "outcome": "passed"}, "call": {"duration": 0.00012343807611614466, "outcome": "passed"}, "teardown": {"duration": 8.311506826430559e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_list_datasets", "lineno": 112, "outcome": "failed", "keywords": ["test_list_datasets", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001227509928867221, "outcome": "passed"}, "call": {"duration": 0.00015753705520182848, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/dataset_versioning/test_service.py", "lineno": 155, "message": "TypeError: DatasetVersioningService.list_datasets() got an unexpected keyword argument 'storage_type'"}, "traceback": [{"path": "tests/dataset_versioning/test_service.py", "lineno": 155, "message": "TypeError"}], "longrepr": "self = <tests.dataset_versioning.test_service.TestDatasetVersioningService object at 0x7f6938a35430>\n\n    def test_list_datasets(self):\n        # Test listing datasets with filters\n    \n        # Create some datasets with different attributes\n        self.service.create_dataset(\n            name=\"CSV Dataset\",\n            format=DatasetFormat.CSV,\n            storage_type=DatasetStorageType.LOCAL,\n            location=\"/path/to/csv.csv\",\n            tags={\"test\", \"csv\"},\n        )\n    \n        self.service.create_dataset(\n            name=\"Parquet Dataset\",\n            format=DatasetFormat.PARQUET,\n            storage_type=DatasetStorageType.S3,\n            location=\"s3://bucket/data.parquet\",\n            tags={\"test\", \"parquet\"},\n        )\n    \n        self.service.create_dataset(\n            name=\"Another CSV Dataset\",\n            format=DatasetFormat.CSV,\n            storage_type=DatasetStorageType.S3,\n            location=\"s3://bucket/data.csv\",\n            tags={\"test\", \"csv\", \"s3\"},\n        )\n    \n        # Get all datasets\n        all_datasets = self.service.list_datasets()\n        assert len(all_datasets) == 3\n    \n        # Filter by format\n        csv_datasets = self.service.list_datasets(format=DatasetFormat.CSV)\n        assert len(csv_datasets) == 2\n        assert {d.name for d in csv_datasets} == {\"CSV Dataset\", \"Another CSV Dataset\"}\n    \n        parquet_datasets = self.service.list_datasets(format=DatasetFormat.PARQUET)\n        assert len(parquet_datasets) == 1\n        assert parquet_datasets[0].name == \"Parquet Dataset\"\n    \n        # Filter by storage type\n>       s3_datasets = self.service.list_datasets(storage_type=DatasetStorageType.S3)\nE       TypeError: DatasetVersioningService.list_datasets() got an unexpected keyword argument 'storage_type'\n\ntests/dataset_versioning/test_service.py:155: TypeError"}, "teardown": {"duration": 0.0001290829386562109, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_dataset_tags", "lineno": 167, "outcome": "failed", "keywords": ["test_dataset_tags", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001480639912188053, "outcome": "passed"}, "call": {"duration": 0.0001410089898854494, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/dataset_versioning/test_service.py", "lineno": 178, "message": "AttributeError: 'DatasetVersioningService' object has no attribute 'add_dataset_tag'"}, "traceback": [{"path": "tests/dataset_versioning/test_service.py", "lineno": 178, "message": "AttributeError"}], "longrepr": "self = <tests.dataset_versioning.test_service.TestDatasetVersioningService object at 0x7f6938a355e0>\n\n    def test_dataset_tags(self):\n        # Test adding and removing tags\n        dataset_id = self.service.create_dataset(\n            name=\"Dataset with Tags\",\n            format=DatasetFormat.CSV,\n            storage_type=DatasetStorageType.LOCAL,\n            location=\"/path/to/tags.csv\",\n        )\n    \n        # Add tags\n>       self.service.add_dataset_tag(dataset_id, \"tag1\")\nE       AttributeError: 'DatasetVersioningService' object has no attribute 'add_dataset_tag'\n\ntests/dataset_versioning/test_service.py:178: AttributeError"}, "teardown": {"duration": 0.0001281779259443283, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_dataset_custom_metadata", "lineno": 189, "outcome": "failed", "keywords": ["test_dataset_custom_metadata", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014650006778538227, "outcome": "passed"}, "call": {"duration": 0.00013478891924023628, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/dataset_versioning/test_service.py", "lineno": 200, "message": "AttributeError: 'DatasetVersioningService' object has no attribute 'update_dataset_custom_metadata'. Did you mean: 'update_dataset_metadata'?"}, "traceback": [{"path": "tests/dataset_versioning/test_service.py", "lineno": 200, "message": "AttributeError"}], "longrepr": "self = <tests.dataset_versioning.test_service.TestDatasetVersioningService object at 0x7f6938a35790>\n\n    def test_dataset_custom_metadata(self):\n        # Test updating and removing custom metadata\n        dataset_id = self.service.create_dataset(\n            name=\"Dataset with Metadata\",\n            format=DatasetFormat.CSV,\n            storage_type=DatasetStorageType.LOCAL,\n            location=\"/path/to/metadata.csv\",\n        )\n    \n        # Update metadata\n>       self.service.update_dataset_custom_metadata(dataset_id, \"source\", \"Test source\")\nE       AttributeError: 'DatasetVersioningService' object has no attribute 'update_dataset_custom_metadata'. Did you mean: 'update_dataset_metadata'?\n\ntests/dataset_versioning/test_service.py:200: AttributeError"}, "teardown": {"duration": 0.00012744299601763487, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_dataset_version", "lineno": 214, "outcome": "failed", "keywords": ["test_create_dataset_version", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014569098129868507, "outcome": "passed"}, "call": {"duration": 0.00014379096683114767, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/dataset_versioning/test_service.py", "lineno": 225, "message": "TypeError: DatasetVersioningService.create_dataset_version() got an unexpected keyword argument 'custom_metadata'"}, "traceback": [{"path": "tests/dataset_versioning/test_service.py", "lineno": 225, "message": "TypeError"}], "longrepr": "self = <tests.dataset_versioning.test_service.TestDatasetVersioningService object at 0x7f6938a35940>\n\n    def test_create_dataset_version(self):\n        # Test creating a dataset version\n        dataset_id = self.service.create_dataset(\n            name=\"Dataset for Versioning\",\n            format=DatasetFormat.CSV,\n            storage_type=DatasetStorageType.LOCAL,\n            location=\"/path/to/data.csv\",\n        )\n    \n        # Create a version\n>       version_id = self.service.create_dataset_version(\n            dataset_id=dataset_id,\n            version_number=\"1.0.0\",\n            location=\"/path/to/versions/1.0.0/data.csv\",\n            creator=\"Test Creator\",\n            description=\"Initial version\",\n            hash=\"sha256:abcdef\",\n            size_bytes=1024 * 1024,\n            row_count=1000,\n            column_count=10,\n            schema={\"col1\": \"integer\", \"col2\": \"string\"},\n            custom_metadata={\"quality_score\": 0.9},\n        )\nE       TypeError: DatasetVersioningService.create_dataset_version() got an unexpected keyword argument 'custom_metadata'\n\ntests/dataset_versioning/test_service.py:225: TypeError"}, "teardown": {"duration": 0.00012756697833538055, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_dataset_version_with_parent", "lineno": 253, "outcome": "passed", "keywords": ["test_create_dataset_version_with_parent", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014865095727145672, "outcome": "passed"}, "call": {"duration": 0.00014526501763612032, "outcome": "passed"}, "teardown": {"duration": 8.799799252301455e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_version_nonexistent_dataset", "lineno": 284, "outcome": "passed", "keywords": ["test_create_version_nonexistent_dataset", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001285219332203269, "outcome": "passed"}, "call": {"duration": 0.00012529303785413504, "outcome": "passed"}, "teardown": {"duration": 8.264405187219381e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_version_nonexistent_parent", "lineno": 293, "outcome": "passed", "keywords": ["test_create_version_nonexistent_parent", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001222860300913453, "outcome": "passed"}, "call": {"duration": 0.0002232069382444024, "outcome": "passed"}, "teardown": {"duration": 9.126507211476564e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_update_dataset_version", "lineno": 310, "outcome": "passed", "keywords": ["test_update_dataset_version", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00013240298721939325, "outcome": "passed"}, "call": {"duration": 0.00015459698624908924, "outcome": "passed"}, "teardown": {"duration": 8.612894453108311e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_version_operations", "lineno": 348, "outcome": "failed", "keywords": ["test_version_operations", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001233030343428254, "outcome": "passed"}, "call": {"duration": 0.00016859511379152536, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/dataset_versioning/test_service.py", "lineno": 386, "message": "AttributeError: 'DatasetVersioningService' object has no attribute 'get_latest_dataset_version'. Did you mean: 'delete_dataset_version'?"}, "traceback": [{"path": "tests/dataset_versioning/test_service.py", "lineno": 386, "message": "AttributeError"}], "longrepr": "self = <tests.dataset_versioning.test_service.TestDatasetVersioningService object at 0x7f6938a361b0>\n\n    def test_version_operations(self):\n        # Test various version operations\n        dataset_id = self.service.create_dataset(\n            name=\"Dataset for Versions\",\n            format=DatasetFormat.CSV,\n            storage_type=DatasetStorageType.LOCAL,\n            location=\"/path/to/data.csv\",\n        )\n    \n        # Create multiple versions\n        v1_id = self.service.create_dataset_version(\n            dataset_id=dataset_id,\n            version_number=\"1.0.0\",\n            location=\"/path/to/v1.csv\",\n        )\n    \n        v2_id = self.service.create_dataset_version(\n            dataset_id=dataset_id,\n            version_number=\"1.1.0\",\n            location=\"/path/to/v2.csv\",\n            parent_version_id=v1_id,\n        )\n    \n        v3_id = self.service.create_dataset_version(\n            dataset_id=dataset_id,\n            version_number=\"2.0.0\",\n            location=\"/path/to/v3.csv\",\n            parent_version_id=v2_id,\n        )\n    \n        # List versions\n        versions = self.service.list_dataset_versions(dataset_id)\n    \n        assert len(versions) == 3\n        assert {v.version_number for v in versions} == {\"1.0.0\", \"1.1.0\", \"2.0.0\"}\n    \n        # Get latest version\n>       latest = self.service.get_latest_dataset_version(dataset_id)\nE       AttributeError: 'DatasetVersioningService' object has no attribute 'get_latest_dataset_version'. Did you mean: 'delete_dataset_version'?\n\ntests/dataset_versioning/test_service.py:386: AttributeError"}, "teardown": {"duration": 0.00012808095198124647, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_data_transformation", "lineno": 402, "outcome": "failed", "keywords": ["test_create_data_transformation", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014938798267394304, "outcome": "passed"}, "call": {"duration": 0.00015504192560911179, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/dataset_versioning/test_service.py", "lineno": 427, "message": "TypeError: DatasetVersioningService.create_data_transformation() got an unexpected keyword argument 'input_dataset_version_id'"}, "traceback": [{"path": "tests/dataset_versioning/test_service.py", "lineno": 427, "message": "TypeError"}], "longrepr": "self = <tests.dataset_versioning.test_service.TestDatasetVersioningService object at 0x7f6938a36360>\n\n    def test_create_data_transformation(self):\n        # Test creating a data transformation\n        dataset_id = self.service.create_dataset(\n            name=\"Dataset\",\n            format=DatasetFormat.CSV,\n            storage_type=DatasetStorageType.LOCAL,\n            location=\"/path/to/data.csv\",\n        )\n    \n        # Create input and output versions\n        input_id = self.service.create_dataset_version(\n            dataset_id=dataset_id,\n            version_number=\"1.0.0\",\n            location=\"/path/to/input.csv\",\n        )\n    \n        output_id = self.service.create_dataset_version(\n            dataset_id=dataset_id,\n            version_number=\"1.1.0\",\n            location=\"/path/to/output.csv\",\n            parent_version_id=input_id,\n        )\n    \n        # Create transformation\n>       transformation_id = self.service.create_data_transformation(\n            input_dataset_version_id=input_id,\n            output_dataset_version_id=output_id,\n            transformation_type=DataTransformationType.CLEANING,\n            name=\"Data Cleaning\",\n            description=\"Removed outliers and filled missing values\",\n            parameters={\n                \"outlier_threshold\": 3.0,\n                \"fill_method\": \"mean\",\n            },\n            code_reference=\"https://github.com/repo/cleaning.py\",\n            execution_time_seconds=45.2,\n            tags={\"cleaning\", \"preprocessing\"},\n        )\nE       TypeError: DatasetVersioningService.create_data_transformation() got an unexpected keyword argument 'input_dataset_version_id'\n\ntests/dataset_versioning/test_service.py:427: TypeError"}, "teardown": {"duration": 0.00012855499517172575, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_transformation_nonexistent_version", "lineno": 455, "outcome": "failed", "keywords": ["test_create_transformation_nonexistent_version", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014635291881859303, "outcome": "passed"}, "call": {"duration": 0.0001961980015039444, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/dataset_versioning/test_service.py", "lineno": 459, "message": "TypeError: DatasetVersioningService.create_data_transformation() got an unexpected keyword argument 'input_dataset_version_id'"}, "traceback": [{"path": "tests/dataset_versioning/test_service.py", "lineno": 459, "message": "TypeError"}], "longrepr": "self = <tests.dataset_versioning.test_service.TestDatasetVersioningService object at 0x7f6938a36510>\n\n    def test_create_transformation_nonexistent_version(self):\n        # Test creating a transformation with a non-existent input version\n        with pytest.raises(ValueError, match=\"Input dataset version .* does not exist\"):\n>           self.service.create_data_transformation(\n                input_dataset_version_id=uuid4(),\n                output_dataset_version_id=uuid4(),\n                transformation_type=DataTransformationType.CLEANING,\n                name=\"Invalid Transformation\",\n            )\nE           TypeError: DatasetVersioningService.create_data_transformation() got an unexpected keyword argument 'input_dataset_version_id'\n\ntests/dataset_versioning/test_service.py:459: TypeError"}, "teardown": {"duration": 0.0001284669851884246, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_transformation_operations", "lineno": 465, "outcome": "failed", "keywords": ["test_transformation_operations", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014675897546112537, "outcome": "passed"}, "call": {"duration": 0.00015885010361671448, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/dataset_versioning/test_service.py", "lineno": 489, "message": "TypeError: DatasetVersioningService.create_data_transformation() got an unexpected keyword argument 'input_dataset_version_id'"}, "traceback": [{"path": "tests/dataset_versioning/test_service.py", "lineno": 489, "message": "TypeError"}], "longrepr": "self = <tests.dataset_versioning.test_service.TestDatasetVersioningService object at 0x7f6938bebe00>\n\n    def test_transformation_operations(self):\n        # Test various transformation operations\n        dataset_id = self.service.create_dataset(\n            name=\"Dataset\",\n            format=DatasetFormat.CSV,\n            storage_type=DatasetStorageType.LOCAL,\n            location=\"/path/to/data.csv\",\n        )\n    \n        # Create versions\n        v1_id = self.service.create_dataset_version(\n            dataset_id=dataset_id,\n            version_number=\"1.0.0\",\n            location=\"/path/to/v1.csv\",\n        )\n    \n        v2_id = self.service.create_dataset_version(\n            dataset_id=dataset_id,\n            version_number=\"1.1.0\",\n            location=\"/path/to/v2.csv\",\n        )\n    \n        # Create transformation\n>       transformation_id = self.service.create_data_transformation(\n            input_dataset_version_id=v1_id,\n            output_dataset_version_id=v2_id,\n            transformation_type=DataTransformationType.CLEANING,\n            name=\"Original Name\",\n            description=\"Original description\",\n        )\nE       TypeError: DatasetVersioningService.create_data_transformation() got an unexpected keyword argument 'input_dataset_version_id'\n\ntests/dataset_versioning/test_service.py:489: TypeError"}, "teardown": {"duration": 0.00013632001355290413, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_link_task_to_dataset_version", "lineno": 551, "outcome": "failed", "keywords": ["test_link_task_to_dataset_version", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014876201748847961, "outcome": "passed"}, "call": {"duration": 0.00015584798529744148, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/dataset_versioning/test_service.py", "lineno": 575, "message": "AttributeError: 'DatasetVersioningService' object has no attribute 'get_task_dataset_link'"}, "traceback": [{"path": "tests/dataset_versioning/test_service.py", "lineno": 575, "message": "AttributeError"}], "longrepr": "self = <tests.dataset_versioning.test_service.TestDatasetVersioningService object at 0x7f6938a36300>\n\n    def test_link_task_to_dataset_version(self):\n        # Test linking a task to a dataset version\n        dataset_id = self.service.create_dataset(\n            name=\"Dataset\",\n            format=DatasetFormat.CSV,\n            storage_type=DatasetStorageType.LOCAL,\n            location=\"/path/to/data.csv\",\n        )\n    \n        version_id = self.service.create_dataset_version(\n            dataset_id=dataset_id,\n            version_number=\"1.0.0\",\n            location=\"/path/to/v1.csv\",\n        )\n    \n        # Create link\n        link_id = self.service.link_task_to_dataset_version(\n            task_id=self.task_id1,\n            dataset_version_id=version_id,\n            usage_type=\"input\",\n            description=\"Primary input dataset\",\n        )\n    \n>       link = self.service.get_task_dataset_link(link_id)\nE       AttributeError: 'DatasetVersioningService' object has no attribute 'get_task_dataset_link'\n\ntests/dataset_versioning/test_service.py:575: AttributeError"}, "teardown": {"duration": 0.00013058900367468596, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_link_to_nonexistent_version", "lineno": 582, "outcome": "passed", "keywords": ["test_link_to_nonexistent_version", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014853698667138815, "outcome": "passed"}, "call": {"duration": 0.00018931296654045582, "outcome": "passed"}, "teardown": {"duration": 9.220908395946026e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_task_dataset_link_operations", "lineno": 590, "outcome": "failed", "keywords": ["test_task_dataset_link_operations", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012885197065770626, "outcome": "passed"}, "call": {"duration": 0.00015680701471865177, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/dataset_versioning/test_service.py", "lineno": 620, "message": "AttributeError: 'DatasetVersioningService' object has no attribute 'update_task_dataset_link'"}, "traceback": [{"path": "tests/dataset_versioning/test_service.py", "lineno": 620, "message": "AttributeError"}], "longrepr": "self = <tests.dataset_versioning.test_service.TestDatasetVersioningService object at 0x7f6938a358b0>\n\n    def test_task_dataset_link_operations(self):\n        # Test various link operations\n        dataset_id = self.service.create_dataset(\n            name=\"Dataset\",\n            format=DatasetFormat.CSV,\n            storage_type=DatasetStorageType.LOCAL,\n            location=\"/path/to/data.csv\",\n        )\n    \n        version_id = self.service.create_dataset_version(\n            dataset_id=dataset_id,\n            version_number=\"1.0.0\",\n            location=\"/path/to/v1.csv\",\n        )\n    \n        # Create links for different tasks\n        link_id1 = self.service.link_task_to_dataset_version(\n            task_id=self.task_id1,\n            dataset_version_id=version_id,\n            usage_type=\"input\",\n        )\n    \n        link_id2 = self.service.link_task_to_dataset_version(\n            task_id=self.task_id2,\n            dataset_version_id=version_id,\n            usage_type=\"reference\",\n        )\n    \n        # Update a link\n>       update_result = self.service.update_task_dataset_link(\n            link_id=link_id1,\n            usage_type=\"updated_type\",\n            description=\"Added description\",\n        )\nE       AttributeError: 'DatasetVersioningService' object has no attribute 'update_task_dataset_link'\n\ntests/dataset_versioning/test_service.py:620: AttributeError"}, "teardown": {"duration": 0.00012813101056963205, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_service.py::TestDatasetVersioningService::test_dataset_lineage", "lineno": 661, "outcome": "failed", "keywords": ["test_dataset_lineage", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014592905063182116, "outcome": "passed"}, "call": {"duration": 0.00017727701924741268, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/dataset_versioning/test_service.py", "lineno": 693, "message": "TypeError: DatasetVersioningService.create_data_transformation() got an unexpected keyword argument 'input_dataset_version_id'"}, "traceback": [{"path": "tests/dataset_versioning/test_service.py", "lineno": 693, "message": "TypeError"}], "longrepr": "self = <tests.dataset_versioning.test_service.TestDatasetVersioningService object at 0x7f6938a353a0>\n\n    def test_dataset_lineage(self):\n        # Test getting dataset lineage\n        dataset_id = self.service.create_dataset(\n            name=\"Dataset\",\n            format=DatasetFormat.CSV,\n            storage_type=DatasetStorageType.LOCAL,\n            location=\"/path/to/data.csv\",\n        )\n    \n        # Create a sequence of versions\n        v1_id = self.service.create_dataset_version(\n            dataset_id=dataset_id,\n            version_number=\"1.0.0\",\n            location=\"/path/to/v1.csv\",\n        )\n    \n        v2_id = self.service.create_dataset_version(\n            dataset_id=dataset_id,\n            version_number=\"1.1.0\",\n            location=\"/path/to/v2.csv\",\n            parent_version_id=v1_id,\n        )\n    \n        v3_id = self.service.create_dataset_version(\n            dataset_id=dataset_id,\n            version_number=\"2.0.0\",\n            location=\"/path/to/v3.csv\",\n            parent_version_id=v2_id,\n        )\n    \n        # Create transformations between versions\n>       t1_id = self.service.create_data_transformation(\n            input_dataset_version_id=v1_id,\n            output_dataset_version_id=v2_id,\n            transformation_type=DataTransformationType.CLEANING,\n            name=\"Cleaning transformation\",\n        )\nE       TypeError: DatasetVersioningService.create_data_transformation() got an unexpected keyword argument 'input_dataset_version_id'\n\ntests/dataset_versioning/test_service.py:693: TypeError"}, "teardown": {"duration": 0.0001300580333918333, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_create_and_get_dataset", "lineno": 43, "outcome": "passed", "keywords": ["test_create_and_get_dataset", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00019117107149213552, "outcome": "passed"}, "call": {"duration": 9.516801219433546e-05, "outcome": "passed"}, "teardown": {"duration": 8.72729578986764e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_update_dataset", "lineno": 55, "outcome": "passed", "keywords": ["test_update_dataset", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00016911595594137907, "outcome": "passed"}, "call": {"duration": 9.905197657644749e-05, "outcome": "passed"}, "teardown": {"duration": 8.263008203357458e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_update_nonexistent_dataset", "lineno": 70, "outcome": "passed", "keywords": ["test_update_nonexistent_dataset", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001456469763070345, "outcome": "passed"}, "call": {"duration": 9.997899178415537e-05, "outcome": "passed"}, "teardown": {"duration": 8.39349813759327e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_delete_dataset", "lineno": 83, "outcome": "passed", "keywords": ["test_delete_dataset", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001540440134704113, "outcome": "passed"}, "call": {"duration": 0.00011523510329425335, "outcome": "passed"}, "teardown": {"duration": 8.241005707532167e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_delete_nonexistent_dataset", "lineno": 114, "outcome": "passed", "keywords": ["test_delete_nonexistent_dataset", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001425709342584014, "outcome": "passed"}, "call": {"duration": 8.671893738210201e-05, "outcome": "passed"}, "teardown": {"duration": 8.197303395718336e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_list_datasets_empty", "lineno": 119, "outcome": "passed", "keywords": ["test_list_datasets_empty", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014039105735719204, "outcome": "passed"}, "call": {"duration": 8.143601007759571e-05, "outcome": "passed"}, "teardown": {"duration": 7.899000775068998e-05, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_list_datasets_with_filters", "lineno": 124, "outcome": "failed", "keywords": ["test_list_datasets_with_filters", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014197500422596931, "outcome": "passed"}, "call": {"duration": 0.00010578404180705547, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/dataset_versioning/test_storage.py", "lineno": 140, "message": "TypeError: InMemoryDatasetStorage.list_datasets() got an unexpected keyword argument 'storage_type'"}, "traceback": [{"path": "tests/dataset_versioning/test_storage.py", "lineno": 140, "message": "TypeError"}], "longrepr": "self = <tests.dataset_versioning.test_storage.TestInMemoryDatasetStorage object at 0x7f6938a37c50>\n\n    def test_list_datasets_with_filters(self):\n        # Test listing datasets with various filters\n        self.storage.create_dataset(self.dataset1)\n        self.storage.create_dataset(self.dataset2)\n    \n        # Filter by format\n        csv_datasets = self.storage.list_datasets(format=DatasetFormat.CSV)\n        assert len(csv_datasets) == 1\n        assert csv_datasets[0].name == \"Climate Data 2010-2020\"\n    \n        parquet_datasets = self.storage.list_datasets(format=DatasetFormat.PARQUET)\n        assert len(parquet_datasets) == 1\n        assert parquet_datasets[0].name == \"Census Data 2020\"\n    \n        # Filter by storage type\n>       s3_datasets = self.storage.list_datasets(storage_type=DatasetStorageType.S3)\nE       TypeError: InMemoryDatasetStorage.list_datasets() got an unexpected keyword argument 'storage_type'\n\ntests/dataset_versioning/test_storage.py:140: TypeError"}, "teardown": {"duration": 0.00013105303514748812, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_dataset_version_operations", "lineno": 160, "outcome": "failed", "keywords": ["test_dataset_version_operations", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00017331901472061872, "outcome": "passed"}, "call": {"duration": 0.00014109897892922163, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/dataset_versioning/test_storage.py", "lineno": 207, "message": "AttributeError: 'InMemoryDatasetStorage' object has no attribute 'get_latest_dataset_version'. Did you mean: 'delete_dataset_version'?"}, "traceback": [{"path": "tests/dataset_versioning/test_storage.py", "lineno": 207, "message": "AttributeError"}], "longrepr": "self = <tests.dataset_versioning.test_storage.TestInMemoryDatasetStorage object at 0x7f6938a37e00>\n\n    def test_dataset_version_operations(self):\n        # Test dataset version CRUD operations\n        dataset_id = self.storage.create_dataset(self.dataset1)\n    \n        # Create versions\n        version1 = DatasetVersion(\n            dataset_id=dataset_id,\n            version_number=\"1.0.0\",\n            location=\"s3://test-bucket/climate-2010-2020/v1.0.0.csv\",\n            creator=\"Researcher A\",\n        )\n    \n        version2 = DatasetVersion(\n            dataset_id=dataset_id,\n            version_number=\"2.0.0\",\n            location=\"s3://test-bucket/climate-2010-2020/v2.0.0.csv\",\n            creator=\"Researcher B\",\n        )\n    \n        version_id1 = self.storage.create_dataset_version(version1)\n        version_id2 = self.storage.create_dataset_version(version2)\n    \n        # Test retrieving versions\n        retrieved_version1 = self.storage.get_dataset_version(version_id1)\n    \n        assert retrieved_version1 is not None\n        assert retrieved_version1.id == version_id1\n        assert retrieved_version1.dataset_id == dataset_id\n        assert retrieved_version1.version_number == \"1.0.0\"\n        assert retrieved_version1.creator == \"Researcher A\"\n    \n        # Test updating a version\n        version1.description = \"Initial version\"\n        update_result = self.storage.update_dataset_version(version1)\n        updated_version1 = self.storage.get_dataset_version(version_id1)\n    \n        assert update_result is True\n        assert updated_version1.description == \"Initial version\"\n    \n        # Test listing versions\n        versions = self.storage.list_dataset_versions(dataset_id)\n    \n        assert len(versions) == 2\n        assert {v.version_number for v in versions} == {\"1.0.0\", \"2.0.0\"}\n    \n        # Test get latest version\n>       latest_version = self.storage.get_latest_dataset_version(dataset_id)\nE       AttributeError: 'InMemoryDatasetStorage' object has no attribute 'get_latest_dataset_version'. Did you mean: 'delete_dataset_version'?\n\ntests/dataset_versioning/test_storage.py:207: AttributeError"}, "teardown": {"duration": 0.00013033498544245958, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_version_lineage_operations", "lineno": 223, "outcome": "failed", "keywords": ["test_version_lineage_operations", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00017453799955546856, "outcome": "passed"}, "call": {"duration": 0.00025394908152520657, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/dataset_versioning/test_storage.py", "lineno": 265, "message": "AssertionError: assert UUID('76e5afdd-d6fa-43f6-875f-5e13fd96571c') is None\n +  where UUID('76e5afdd-d6fa-43f6-875f-5e13fd96571c') = DatasetVersion(id=UUID('633b9a5f-9db7-4fd3-af5d-b9ec2f7cc3f6'), dataset_id=UUID('73e3c158-cc7c-44d8-a491-eab5f58000ba'...on_id=UUID('76e5afdd-d6fa-43f6-875f-5e13fd96571c'), row_count=None, column_count=None, schema=None, custom_metadata={}).parent_version_id"}, "traceback": [{"path": "tests/dataset_versioning/test_storage.py", "lineno": 265, "message": "AssertionError"}], "longrepr": "self = <tests.dataset_versioning.test_storage.TestInMemoryDatasetStorage object at 0x7f6938a37fb0>\n\n    def test_version_lineage_operations(self):\n        # Test version lineage with parent references\n        dataset_id = self.storage.create_dataset(self.dataset1)\n    \n        # Create a sequence of versions with parent relationships\n        version1 = DatasetVersion(\n            dataset_id=dataset_id,\n            version_number=\"1.0.0\",\n            location=\"s3://test-bucket/climate-2010-2020/v1.0.0.csv\",\n        )\n        version_id1 = self.storage.create_dataset_version(version1)\n    \n        version2 = DatasetVersion(\n            dataset_id=dataset_id,\n            version_number=\"1.1.0\",\n            location=\"s3://test-bucket/climate-2010-2020/v1.1.0.csv\",\n            parent_version_id=version_id1,\n        )\n        version_id2 = self.storage.create_dataset_version(version2)\n    \n        version3 = DatasetVersion(\n            dataset_id=dataset_id,\n            version_number=\"2.0.0\",\n            location=\"s3://test-bucket/climate-2010-2020/v2.0.0.csv\",\n            parent_version_id=version_id2,\n        )\n        version_id3 = self.storage.create_dataset_version(version3)\n    \n        # Verify parent references\n        v2 = self.storage.get_dataset_version(version_id2)\n        v3 = self.storage.get_dataset_version(version_id3)\n    \n        assert v2.parent_version_id == version_id1\n        assert v3.parent_version_id == version_id2\n    \n        # Test deleting a version in the middle of the lineage\n        # Parent references should be updated to maintain chain integrity\n        self.storage.delete_dataset_version(version_id2)\n    \n        # Verify the updated parent references\n        v3_updated = self.storage.get_dataset_version(version_id3)\n>       assert v3_updated.parent_version_id is None\nE       AssertionError: assert UUID('76e5afdd-d6fa-43f6-875f-5e13fd96571c') is None\nE        +  where UUID('76e5afdd-d6fa-43f6-875f-5e13fd96571c') = DatasetVersion(id=UUID('633b9a5f-9db7-4fd3-af5d-b9ec2f7cc3f6'), dataset_id=UUID('73e3c158-cc7c-44d8-a491-eab5f58000ba'...on_id=UUID('76e5afdd-d6fa-43f6-875f-5e13fd96571c'), row_count=None, column_count=None, schema=None, custom_metadata={}).parent_version_id\n\ntests/dataset_versioning/test_storage.py:265: AssertionError"}, "teardown": {"duration": 0.00012855499517172575, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_data_transformation_operations", "lineno": 266, "outcome": "failed", "keywords": ["test_data_transformation_operations", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00016938801854848862, "outcome": "passed"}, "call": {"duration": 0.00015417905524373055, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/dataset_versioning/test_storage.py", "lineno": 321, "message": "AttributeError: 'InMemoryDatasetStorage' object has no attribute 'list_data_transformations'. Did you mean: 'get_data_transformation'?"}, "traceback": [{"path": "tests/dataset_versioning/test_storage.py", "lineno": 321, "message": "AttributeError"}], "longrepr": "self = <tests.dataset_versioning.test_storage.TestInMemoryDatasetStorage object at 0x7f6938a681a0>\n\n    def test_data_transformation_operations(self):\n        # Test data transformation CRUD operations\n        dataset_id = self.storage.create_dataset(self.dataset1)\n    \n        # Create versions for input/output\n        input_version = DatasetVersion(\n            dataset_id=dataset_id,\n            version_number=\"1.0.0\",\n            location=\"s3://test-bucket/input-version.csv\",\n        )\n        input_version_id = self.storage.create_dataset_version(input_version)\n    \n        output_version = DatasetVersion(\n            dataset_id=dataset_id,\n            version_number=\"1.1.0\",\n            location=\"s3://test-bucket/output-version.csv\",\n        )\n        output_version_id = self.storage.create_dataset_version(output_version)\n    \n        # Create transformation\n        transformation = DataTransformation(\n            type=DataTransformationType.CLEANING,\n            name=\"Data Cleaning Step\",\n            description=\"Remove outliers and normalize data\",\n            input_dataset_version_id=input_version_id,\n            output_dataset_version_id=output_version_id,\n            parameters={\"outlier_threshold\": 3.0},\n            code_reference=\"https://github.com/repo/cleaning.py\",\n        )\n    \n        transformation_id = self.storage.create_data_transformation(transformation)\n    \n        # Test retrieving transformation\n        retrieved_transformation = self.storage.get_data_transformation(transformation_id)\n    \n        assert retrieved_transformation is not None\n        assert retrieved_transformation.id == transformation_id\n        assert retrieved_transformation.type == DataTransformationType.CLEANING\n        assert retrieved_transformation.name == \"Data Cleaning Step\"\n        assert retrieved_transformation.input_dataset_version_id == input_version_id\n        assert retrieved_transformation.output_dataset_version_id == output_version_id\n    \n        # Test updating transformation\n        transformation.description = \"Updated description\"\n        transformation.execution_time_seconds = 45.2\n    \n        update_result = self.storage.update_data_transformation(transformation)\n        updated_transformation = self.storage.get_data_transformation(transformation_id)\n    \n        assert update_result is True\n        assert updated_transformation.description == \"Updated description\"\n        assert updated_transformation.execution_time_seconds == 45.2\n    \n        # Test listing transformations\n>       transformations_by_input = self.storage.list_data_transformations(\n            input_dataset_version_id=input_version_id\n        )\nE       AttributeError: 'InMemoryDatasetStorage' object has no attribute 'list_data_transformations'. Did you mean: 'get_data_transformation'?\n\ntests/dataset_versioning/test_storage.py:321: AttributeError"}, "teardown": {"duration": 0.00013215001672506332, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_task_dataset_link_operations", "lineno": 344, "outcome": "failed", "keywords": ["test_task_dataset_link_operations", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00017227197531610727, "outcome": "passed"}, "call": {"duration": 0.0001455129822716117, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/dataset_versioning/test_storage.py", "lineno": 393, "message": "AttributeError: 'InMemoryDatasetStorage' object has no attribute 'get_dataset_versions_by_task'. Did you mean: 'get_dataset_versions_for_task'?"}, "traceback": [{"path": "tests/dataset_versioning/test_storage.py", "lineno": 393, "message": "AttributeError"}], "longrepr": "self = <tests.dataset_versioning.test_storage.TestInMemoryDatasetStorage object at 0x7f6938a68350>\n\n    def test_task_dataset_link_operations(self):\n        # Test task-dataset link CRUD operations\n        dataset_id = self.storage.create_dataset(self.dataset1)\n    \n        # Create a version\n        version = DatasetVersion(\n            dataset_id=dataset_id,\n            version_number=\"1.0.0\",\n            location=\"s3://test-bucket/v1.0.0.csv\",\n        )\n        version_id = self.storage.create_dataset_version(version)\n    \n        # Create links between tasks and the dataset version\n        link1 = TaskDatasetLink(\n            task_id=self.task_id1,\n            dataset_version_id=version_id,\n            usage_type=\"input\",\n            description=\"Primary input dataset\",\n        )\n    \n        link2 = TaskDatasetLink(\n            task_id=self.task_id2,\n            dataset_version_id=version_id,\n            usage_type=\"reference\",\n            description=\"Reference dataset\",\n        )\n    \n        link_id1 = self.storage.create_task_dataset_link(link1)\n        link_id2 = self.storage.create_task_dataset_link(link2)\n    \n        # Test retrieving link\n        retrieved_link = self.storage.get_task_dataset_link(link_id1)\n    \n        assert retrieved_link is not None\n        assert retrieved_link.id == link_id1\n        assert retrieved_link.task_id == self.task_id1\n        assert retrieved_link.dataset_version_id == version_id\n        assert retrieved_link.usage_type == \"input\"\n    \n        # Test updating link\n        link1.description = \"Updated description\"\n        update_result = self.storage.update_task_dataset_link(link1)\n        updated_link = self.storage.get_task_dataset_link(link_id1)\n    \n        assert update_result is True\n        assert updated_link.description == \"Updated description\"\n    \n        # Test querying links\n>       task1_versions = self.storage.get_dataset_versions_by_task(self.task_id1)\nE       AttributeError: 'InMemoryDatasetStorage' object has no attribute 'get_dataset_versions_by_task'. Did you mean: 'get_dataset_versions_for_task'?\n\ntests/dataset_versioning/test_storage.py:393: AttributeError"}, "teardown": {"duration": 0.0001284389290958643, "outcome": "passed"}}, {"nodeid": "tests/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_get_lineage", "lineno": 415, "outcome": "failed", "keywords": ["test_get_lineage", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00017113902140408754, "outcome": "passed"}, "call": {"duration": 0.00015619106125086546, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/dataset_versioning/test_storage.py", "lineno": 462, "message": "AttributeError: 'InMemoryDatasetStorage' object has no attribute 'get_lineage'"}, "traceback": [{"path": "tests/dataset_versioning/test_storage.py", "lineno": 462, "message": "AttributeError"}], "longrepr": "self = <tests.dataset_versioning.test_storage.TestInMemoryDatasetStorage object at 0x7f6938a68500>\n\n    def test_get_lineage(self):\n        # Test lineage tracking\n        dataset_id = self.storage.create_dataset(self.dataset1)\n    \n        # Create a sequence of versions and transformations\n        v1 = DatasetVersion(\n            dataset_id=dataset_id,\n            version_number=\"1.0.0\",\n            location=\"/path/to/v1.csv\",\n        )\n        v1_id = self.storage.create_dataset_version(v1)\n    \n        v2 = DatasetVersion(\n            dataset_id=dataset_id,\n            version_number=\"1.1.0\",\n            location=\"/path/to/v2.csv\",\n            parent_version_id=v1_id,\n        )\n        v2_id = self.storage.create_dataset_version(v2)\n    \n        v3 = DatasetVersion(\n            dataset_id=dataset_id,\n            version_number=\"2.0.0\",\n            location=\"/path/to/v3.csv\",\n            parent_version_id=v2_id,\n        )\n        v3_id = self.storage.create_dataset_version(v3)\n    \n        # Create transformations between versions\n        t1 = DataTransformation(\n            type=DataTransformationType.CLEANING,\n            name=\"Initial cleaning\",\n            input_dataset_version_id=v1_id,\n            output_dataset_version_id=v2_id,\n        )\n        t1_id = self.storage.create_data_transformation(t1)\n    \n        t2 = DataTransformation(\n            type=DataTransformationType.FEATURE_ENGINEERING,\n            name=\"Feature engineering\",\n            input_dataset_version_id=v2_id,\n            output_dataset_version_id=v3_id,\n        )\n        t2_id = self.storage.create_data_transformation(t2)\n    \n        # Get lineage starting from v3\n>       lineage = self.storage.get_lineage(v3_id)\nE       AttributeError: 'InMemoryDatasetStorage' object has no attribute 'get_lineage'\n\ntests/dataset_versioning/test_storage.py:462: AttributeError"}, "teardown": {"duration": 0.0001311160158365965, "outcome": "passed"}}, {"nodeid": "tests/environment/test_models.py::TestPackageInfo::test_create_package_info", "lineno": 18, "outcome": "passed", "keywords": ["test_create_package_info", "TestPackageInfo", "test_models.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00027062196750193834, "outcome": "passed"}, "call": {"duration": 0.000119617092423141, "outcome": "passed"}, "teardown": {"duration": 8.002994582056999e-05, "outcome": "passed"}}, {"nodeid": "tests/environment/test_models.py::TestComputeResource::test_create_compute_resource", "lineno": 52, "outcome": "passed", "keywords": ["test_create_compute_resource", "TestComputeResource", "test_models.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 8.085498120635748e-05, "outcome": "passed"}, "call": {"duration": 0.00010054500307887793, "outcome": "passed"}, "teardown": {"duration": 7.745495531708002e-05, "outcome": "passed"}}, {"nodeid": "tests/environment/test_models.py::TestEnvironmentSnapshot::test_create_environment_snapshot", "lineno": 82, "outcome": "passed", "keywords": ["test_create_environment_snapshot", "TestEnvironmentSnapshot", "test_models.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.690209895372391e-05, "outcome": "passed"}, "call": {"duration": 0.0001441040076315403, "outcome": "passed"}, "teardown": {"duration": 7.502397056668997e-05, "outcome": "passed"}}, {"nodeid": "tests/environment/test_models.py::TestEnvironmentSnapshot::test_update_environment_snapshot", "lineno": 181, "outcome": "passed", "keywords": ["test_update_environment_snapshot", "TestEnvironmentSnapshot", "test_models.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.429602555930614e-05, "outcome": "passed"}, "call": {"duration": 0.00014924502465873957, "outcome": "passed"}, "teardown": {"duration": 7.362500764429569e-05, "outcome": "passed"}}, {"nodeid": "tests/environment/test_models.py::TestEnvironmentSnapshot::test_package_management", "lineno": 206, "outcome": "passed", "keywords": ["test_package_management", "TestEnvironmentSnapshot", "test_models.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.385294884443283e-05, "outcome": "passed"}, "call": {"duration": 0.00013223197311162949, "outcome": "passed"}, "teardown": {"duration": 7.853901479393244e-05, "outcome": "passed"}}, {"nodeid": "tests/environment/test_models.py::TestEnvironmentSnapshot::test_compute_resource_management", "lineno": 253, "outcome": "passed", "keywords": ["test_compute_resource_management", "TestEnvironmentSnapshot", "test_models.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.741700392216444e-05, "outcome": "passed"}, "call": {"duration": 0.00012158893514424562, "outcome": "passed"}, "teardown": {"duration": 7.326900959014893e-05, "outcome": "passed"}}, {"nodeid": "tests/environment/test_models.py::TestEnvironmentSnapshot::test_environment_variable_management", "lineno": 293, "outcome": "passed", "keywords": ["test_environment_variable_management", "TestEnvironmentSnapshot", "test_models.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.457600440829992e-05, "outcome": "passed"}, "call": {"duration": 0.00010826298967003822, "outcome": "passed"}, "teardown": {"duration": 7.489498239010572e-05, "outcome": "passed"}}, {"nodeid": "tests/environment/test_models.py::TestEnvironmentSnapshot::test_config_file_management", "lineno": 327, "outcome": "passed", "keywords": ["test_config_file_management", "TestEnvironmentSnapshot", "test_models.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 8.066801819950342e-05, "outcome": "passed"}, "call": {"duration": 0.00011031492613255978, "outcome": "passed"}, "teardown": {"duration": 7.094198372215033e-05, "outcome": "passed"}}, {"nodeid": "tests/environment/test_models.py::TestEnvironmentSnapshot::test_tag_management", "lineno": 370, "outcome": "passed", "keywords": ["test_tag_management", "TestEnvironmentSnapshot", "test_models.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.660896517336369e-05, "outcome": "passed"}, "call": {"duration": 0.00011239899322390556, "outcome": "passed"}, "teardown": {"duration": 7.362896576523781e-05, "outcome": "passed"}}, {"nodeid": "tests/environment/test_models.py::TestEnvironmentSnapshot::test_custom_metadata_management", "lineno": 403, "outcome": "passed", "keywords": ["test_custom_metadata_management", "TestEnvironmentSnapshot", "test_models.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 8.252100087702274e-05, "outcome": "passed"}, "call": {"duration": 0.00011506001465022564, "outcome": "passed"}, "teardown": {"duration": 7.335399277508259e-05, "outcome": "passed"}}, {"nodeid": "tests/environment/test_models.py::TestTaskEnvironmentLink::test_create_task_environment_link", "lineno": 447, "outcome": "passed", "keywords": ["test_create_task_environment_link", "TestTaskEnvironmentLink", "test_models.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.562292739748955e-05, "outcome": "passed"}, "call": {"duration": 0.0001077230554074049, "outcome": "passed"}, "teardown": {"duration": 7.142999675124884e-05, "outcome": "passed"}}, {"nodeid": "tests/environment/test_models.py::TestTaskEnvironmentLink::test_update_link", "lineno": 468, "outcome": "passed", "keywords": ["test_update_link", "TestTaskEnvironmentLink", "test_models.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 8.021097164601088e-05, "outcome": "passed"}, "call": {"duration": 0.00012717896606773138, "outcome": "passed"}, "teardown": {"duration": 7.398799061775208e-05, "outcome": "passed"}}, {"nodeid": "tests/environment/test_models.py::TestTaskEnvironmentLink::test_add_note", "lineno": 491, "outcome": "passed", "keywords": ["test_add_note", "TestTaskEnvironmentLink", "test_models.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.514306344091892e-05, "outcome": "passed"}, "call": {"duration": 0.00011138198897242546, "outcome": "passed"}, "teardown": {"duration": 7.33319902792573e-05, "outcome": "passed"}}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_create_environment_snapshot", "lineno": 26, "outcome": "failed", "keywords": ["test_create_environment_snapshot", "TestEnvironmentService", "test_service.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001477670157328248, "outcome": "passed"}, "call": {"duration": 9.694101754575968e-05, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_service.py", "lineno": 29, "message": "AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'"}, "traceback": [{"path": "tests/environment/test_service.py", "lineno": 29, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_service.TestEnvironmentService object at 0x7f6938ab0ad0>\n\n    def test_create_environment_snapshot(self):\n        # Test creating a basic environment snapshot\n>       env_id = self.service.create_environment_snapshot(\n            name=\"Test Environment\",\n            environment_type=EnvironmentType.CONDA,\n            description=\"Test environment description\",\n            python_version=\"3.10.4\",\n            os_type=OperatingSystemType.LINUX,\n            os_version=\"Ubuntu 22.04\",\n            architecture=\"x86_64\",\n            kernel_version=\"5.15.0-58-generic\",\n            tags={\"test\", \"conda\"},\n            custom_metadata={\"purpose\": \"testing\"},\n        )\nE       AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'\n\ntests/environment/test_service.py:29: AttributeError"}, "teardown": {"duration": 0.00012857804540544748, "outcome": "passed"}}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_create_environment_with_packages_and_resources", "lineno": 55, "outcome": "failed", "keywords": ["test_create_environment_with_packages_and_resources", "TestEnvironmentService", "test_service.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001493670279160142, "outcome": "passed"}, "call": {"duration": 0.00012201105710119009, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_service.py", "lineno": 102, "message": "AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'"}, "traceback": [{"path": "tests/environment/test_service.py", "lineno": 102, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_service.TestEnvironmentService object at 0x7f6938ab0650>\n\n    def test_create_environment_with_packages_and_resources(self):\n        # Test creating an environment with packages and compute resources\n        compute_resources = [\n            ComputeResource(\n                type=ComputeResourceType.CPU,\n                count=8,\n                model=\"Intel Xeon\",\n                memory_gb=32.0,\n            ),\n            ComputeResource(\n                type=ComputeResourceType.GPU,\n                count=2,\n                model=\"NVIDIA A100\",\n                memory_gb=40.0,\n            ),\n        ]\n    \n        packages = [\n            PackageInfo(\n                name=\"numpy\",\n                version=\"1.24.3\",\n                manager=PackageManagerType.PIP,\n            ),\n            PackageInfo(\n                name=\"pandas\",\n                version=\"2.0.0\",\n                manager=PackageManagerType.PIP,\n            ),\n            PackageInfo(\n                name=\"tensorflow\",\n                version=\"2.12.0\",\n                manager=PackageManagerType.PIP,\n            ),\n        ]\n    \n        env_vars = {\n            \"PYTHONPATH\": \"/home/user/project\",\n            \"TF_FORCE_GPU_ALLOW_GROWTH\": \"true\",\n            \"CUDA_VISIBLE_DEVICES\": \"0,1\",\n        }\n    \n        config_files = {\n            \"/home/user/.keras/keras.json\": '{\"backend\": \"tensorflow\", \"image_data_format\": \"channels_last\"}',\n            \"/home/user/project/config.yaml\": \"batch_size: 32\\nlearning_rate: 0.001\",\n        }\n    \n>       env_id = self.service.create_environment_snapshot(\n            name=\"ML Environment\",\n            environment_type=EnvironmentType.CONDA,\n            description=\"Machine learning environment\",\n            python_version=\"3.9.16\",\n            compute_resources=compute_resources,\n            environment_variables=env_vars,\n            packages=packages,\n            config_files=config_files,\n            container_image=\"tensorflow/tensorflow\",\n            container_tag=\"2.12.0-gpu\",\n            cloud_provider=\"AWS\",\n            cloud_region=\"us-west-2\",\n            instance_type=\"p3.8xlarge\",\n            tags={\"ml\", \"gpu\", \"tensorflow\"},\n        )\nE       AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'\n\ntests/environment/test_service.py:102: AttributeError"}, "teardown": {"duration": 0.00012835499364882708, "outcome": "passed"}}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_capture_current_environment", "lineno": 140, "outcome": "failed", "keywords": ["test_capture_current_environment", "TestEnvironmentService", "test_service.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00015967502258718014, "outcome": "passed"}, "call": {"duration": 0.0001053099986165762, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_service.py", "lineno": 144, "message": "TypeError: EnvironmentService.capture_current_environment() got an unexpected keyword argument 'environment_type'"}, "traceback": [{"path": "tests/environment/test_service.py", "lineno": 144, "message": "TypeError"}], "longrepr": "self = <tests.environment.test_service.TestEnvironmentService object at 0x7f6938ab01d0>\n\n    def test_capture_current_environment(self):\n        # Test capturing the current environment\n        # This is a simplified test since we can't directly test the actual environment detection\n>       env_id = self.service.capture_current_environment(\n            name=\"Current Environment\",\n            description=\"Captured from the current Python environment\",\n            environment_type=EnvironmentType.LOCAL,\n            include_packages=True,\n            include_env_vars=True,\n            tags={\"current\", \"test\"},\n            custom_metadata={\"purpose\": \"testing\"},\n        )\nE       TypeError: EnvironmentService.capture_current_environment() got an unexpected keyword argument 'environment_type'\n\ntests/environment/test_service.py:144: TypeError"}, "teardown": {"duration": 0.00012918596621602774, "outcome": "passed"}}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_update_environment", "lineno": 169, "outcome": "failed", "keywords": ["test_update_environment", "TestEnvironmentService", "test_service.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014940602704882622, "outcome": "passed"}, "call": {"duration": 0.00010175304487347603, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_service.py", "lineno": 172, "message": "AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'"}, "traceback": [{"path": "tests/environment/test_service.py", "lineno": 172, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_service.TestEnvironmentService object at 0x7f6938ab1760>\n\n    def test_update_environment(self):\n        # Test updating an environment\n>       env_id = self.service.create_environment_snapshot(\n            name=\"Original Name\",\n            environment_type=EnvironmentType.LOCAL,\n            description=\"Original description\",\n        )\nE       AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'\n\ntests/environment/test_service.py:172: AttributeError"}, "teardown": {"duration": 0.00012819794937968254, "outcome": "passed"}}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_update_nonexistent_environment", "lineno": 206, "outcome": "failed", "keywords": ["test_update_nonexistent_environment", "TestEnvironmentService", "test_service.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00015682994853705168, "outcome": "passed"}, "call": {"duration": 0.0001886390382423997, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_service.py", "lineno": 210, "message": "AttributeError: 'EnvironmentService' object has no attribute 'update_environment'"}, "traceback": [{"path": "tests/environment/test_service.py", "lineno": 210, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_service.TestEnvironmentService object at 0x7f6938ab1910>\n\n    def test_update_nonexistent_environment(self):\n        # Test updating a non-existent environment\n        with pytest.raises(ValueError, match=\"Environment snapshot .* does not exist\"):\n>           self.service.update_environment(\n                environment_id=uuid4(),\n                name=\"Updated Name\",\n            )\nE           AttributeError: 'EnvironmentService' object has no attribute 'update_environment'\n\ntests/environment/test_service.py:210: AttributeError"}, "teardown": {"duration": 0.00012780004180967808, "outcome": "passed"}}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_delete_environment", "lineno": 214, "outcome": "failed", "keywords": ["test_delete_environment", "TestEnvironmentService", "test_service.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001463999506086111, "outcome": "passed"}, "call": {"duration": 0.00010815099813044071, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_service.py", "lineno": 217, "message": "AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'"}, "traceback": [{"path": "tests/environment/test_service.py", "lineno": 217, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_service.TestEnvironmentService object at 0x7f6938ab1ac0>\n\n    def test_delete_environment(self):\n        # Test deleting an environment\n>       env_id = self.service.create_environment_snapshot(\n            name=\"Environment to Delete\",\n            environment_type=EnvironmentType.LOCAL,\n        )\nE       AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'\n\ntests/environment/test_service.py:217: AttributeError"}, "teardown": {"duration": 0.00014254404231905937, "outcome": "passed"}}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_list_environments", "lineno": 230, "outcome": "failed", "keywords": ["test_list_environments", "TestEnvironmentService", "test_service.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.000148105900734663, "outcome": "passed"}, "call": {"duration": 0.00010176096111536026, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_service.py", "lineno": 235, "message": "AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'"}, "traceback": [{"path": "tests/environment/test_service.py", "lineno": 235, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_service.TestEnvironmentService object at 0x7f6938ab1c70>\n\n    def test_list_environments(self):\n        # Test listing environments with filters\n    \n        # Create environments with different attributes\n>       self.service.create_environment_snapshot(\n            name=\"Conda Environment\",\n            environment_type=EnvironmentType.CONDA,\n            tags={\"python\", \"conda\"},\n        )\nE       AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'\n\ntests/environment/test_service.py:235: AttributeError"}, "teardown": {"duration": 0.0001296560512855649, "outcome": "passed"}}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_environment_tag_operations", "lineno": 284, "outcome": "failed", "keywords": ["test_environment_tag_operations", "TestEnvironmentService", "test_service.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014693697448819876, "outcome": "passed"}, "call": {"duration": 0.00010069599375128746, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_service.py", "lineno": 287, "message": "AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'"}, "traceback": [{"path": "tests/environment/test_service.py", "lineno": 287, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_service.TestEnvironmentService object at 0x7f6938ab1e20>\n\n    def test_environment_tag_operations(self):\n        # Test adding and removing tags\n>       env_id = self.service.create_environment_snapshot(\n            name=\"Tag Test Environment\",\n            environment_type=EnvironmentType.LOCAL,\n            tags={\"initial\"},\n        )\nE       AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'\n\ntests/environment/test_service.py:287: AttributeError"}, "teardown": {"duration": 0.00013416900765150785, "outcome": "passed"}}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_package_operations", "lineno": 313, "outcome": "failed", "keywords": ["test_package_operations", "TestEnvironmentService", "test_service.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014508096501231194, "outcome": "passed"}, "call": {"duration": 0.0001016340684145689, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_service.py", "lineno": 316, "message": "AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'"}, "traceback": [{"path": "tests/environment/test_service.py", "lineno": 316, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_service.TestEnvironmentService object at 0x7f6938ab1fd0>\n\n    def test_package_operations(self):\n        # Test adding and removing packages\n>       env_id = self.service.create_environment_snapshot(\n            name=\"Package Test Environment\",\n            environment_type=EnvironmentType.VENV,\n            packages=[\n                PackageInfo(\n                    name=\"initial-package\",\n                    version=\"1.0.0\",\n                    manager=PackageManagerType.PIP,\n                ),\n            ],\n        )\nE       AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'\n\ntests/environment/test_service.py:316: AttributeError"}, "teardown": {"duration": 0.00013556296471506357, "outcome": "passed"}}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_compute_resource_operations", "lineno": 362, "outcome": "failed", "keywords": ["test_compute_resource_operations", "TestEnvironmentService", "test_service.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014759704936295748, "outcome": "passed"}, "call": {"duration": 0.0001027820399031043, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_service.py", "lineno": 365, "message": "AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'"}, "traceback": [{"path": "tests/environment/test_service.py", "lineno": 365, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_service.TestEnvironmentService object at 0x7f6938ab2180>\n\n    def test_compute_resource_operations(self):\n        # Test adding and removing compute resources\n>       env_id = self.service.create_environment_snapshot(\n            name=\"Compute Resource Test Environment\",\n            environment_type=EnvironmentType.LOCAL,\n            compute_resources=[\n                ComputeResource(\n                    type=ComputeResourceType.CPU,\n                    count=4,\n                    model=\"Initial CPU\",\n                ),\n            ],\n        )\nE       AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'\n\ntests/environment/test_service.py:365: AttributeError"}, "teardown": {"duration": 0.00012732401955872774, "outcome": "passed"}}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_environment_variable_operations", "lineno": 407, "outcome": "failed", "keywords": ["test_environment_variable_operations", "TestEnvironmentService", "test_service.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014625804033130407, "outcome": "passed"}, "call": {"duration": 0.00011288095265626907, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_service.py", "lineno": 410, "message": "AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'"}, "traceback": [{"path": "tests/environment/test_service.py", "lineno": 410, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_service.TestEnvironmentService object at 0x7f6938ab2330>\n\n    def test_environment_variable_operations(self):\n        # Test adding and removing environment variables\n>       env_id = self.service.create_environment_snapshot(\n            name=\"Environment Variable Test\",\n            environment_type=EnvironmentType.LOCAL,\n            environment_variables={\n                \"INITIAL_VAR\": \"initial_value\",\n            },\n        )\nE       AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'\n\ntests/environment/test_service.py:410: AttributeError"}, "teardown": {"duration": 0.0001288919011130929, "outcome": "passed"}}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_config_file_operations", "lineno": 448, "outcome": "failed", "keywords": ["test_config_file_operations", "TestEnvironmentService", "test_service.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001467219553887844, "outcome": "passed"}, "call": {"duration": 0.00010266306344419718, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_service.py", "lineno": 451, "message": "AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'"}, "traceback": [{"path": "tests/environment/test_service.py", "lineno": 451, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_service.TestEnvironmentService object at 0x7f6938ab24e0>\n\n    def test_config_file_operations(self):\n        # Test adding and removing configuration files\n>       env_id = self.service.create_environment_snapshot(\n            name=\"Config File Test\",\n            environment_type=EnvironmentType.LOCAL,\n            config_files={\n                \"/initial/file.conf\": \"initial content\",\n            },\n        )\nE       AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'\n\ntests/environment/test_service.py:451: AttributeError"}, "teardown": {"duration": 0.00012899702414870262, "outcome": "passed"}}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_custom_metadata_operations", "lineno": 501, "outcome": "failed", "keywords": ["test_custom_metadata_operations", "TestEnvironmentService", "test_service.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014983001165091991, "outcome": "passed"}, "call": {"duration": 0.00010272895451635122, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_service.py", "lineno": 504, "message": "AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'"}, "traceback": [{"path": "tests/environment/test_service.py", "lineno": 504, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_service.TestEnvironmentService object at 0x7f6938ab2690>\n\n    def test_custom_metadata_operations(self):\n        # Test updating and removing custom metadata\n>       env_id = self.service.create_environment_snapshot(\n            name=\"Metadata Test\",\n            environment_type=EnvironmentType.LOCAL,\n            custom_metadata={\n                \"initial_key\": \"initial_value\",\n            },\n        )\nE       AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'\n\ntests/environment/test_service.py:504: AttributeError"}, "teardown": {"duration": 0.0001296279951930046, "outcome": "passed"}}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_compare_environments", "lineno": 550, "outcome": "failed", "keywords": ["test_compare_environments", "TestEnvironmentService", "test_service.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001618770183995366, "outcome": "passed"}, "call": {"duration": 0.00010586204007267952, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_service.py", "lineno": 553, "message": "AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'"}, "traceback": [{"path": "tests/environment/test_service.py", "lineno": 553, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_service.TestEnvironmentService object at 0x7f6938ab2840>\n\n    def test_compare_environments(self):\n        # Test comparing two environments\n>       env_id1 = self.service.create_environment_snapshot(\n            name=\"Environment 1\",\n            environment_type=EnvironmentType.CONDA,\n            python_version=\"3.9.12\",\n            os_type=OperatingSystemType.LINUX,\n            os_version=\"Ubuntu 20.04\",\n            packages=[\n                PackageInfo(\n                    name=\"numpy\",\n                    version=\"1.22.3\",\n                    manager=PackageManagerType.CONDA,\n                ),\n                PackageInfo(\n                    name=\"pandas\",\n                    version=\"1.4.2\",\n                    manager=PackageManagerType.CONDA,\n                ),\n                PackageInfo(\n                    name=\"matplotlib\",\n                    version=\"3.5.1\",\n                    manager=PackageManagerType.CONDA,\n                ),\n            ],\n            environment_variables={\n                \"PATH\": \"/usr/bin:/bin\",\n                \"PYTHONPATH\": \"/home/user/project\",\n                \"LANG\": \"en_US.UTF-8\",\n            },\n            config_files={\n                \"/home/user/.condarc\": \"channels:\\n  - conda-forge\\n  - defaults\",\n                \"/home/user/project/config.yaml\": \"param1: value1\\nparam2: value2\",\n            },\n        )\nE       AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'\n\ntests/environment/test_service.py:553: AttributeError"}, "teardown": {"duration": 0.00013026699889451265, "outcome": "passed"}}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_link_task_to_environment", "lineno": 658, "outcome": "failed", "keywords": ["test_link_task_to_environment", "TestEnvironmentService", "test_service.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001478919293731451, "outcome": "passed"}, "call": {"duration": 0.00010089308489114046, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_service.py", "lineno": 661, "message": "AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'"}, "traceback": [{"path": "tests/environment/test_service.py", "lineno": 661, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_service.TestEnvironmentService object at 0x7f6938ab29f0>\n\n    def test_link_task_to_environment(self):\n        # Test linking a task to an environment\n>       env_id = self.service.create_environment_snapshot(\n            name=\"Environment for Task\",\n            environment_type=EnvironmentType.LOCAL,\n        )\nE       AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'\n\ntests/environment/test_service.py:661: AttributeError"}, "teardown": {"duration": 0.0001273839734494686, "outcome": "passed"}}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_link_to_nonexistent_environment", "lineno": 681, "outcome": "failed", "keywords": ["test_link_to_nonexistent_environment", "TestEnvironmentService", "test_service.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001621069386601448, "outcome": "passed"}, "call": {"duration": 0.00012146495282649994, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_service.py", "lineno": 685, "message": "TypeError: EnvironmentService.link_task_to_environment() got an unexpected keyword argument 'environment_id'"}, "traceback": [{"path": "tests/environment/test_service.py", "lineno": 685, "message": "TypeError"}], "longrepr": "self = <tests.environment.test_service.TestEnvironmentService object at 0x7f6938ab2ba0>\n\n    def test_link_to_nonexistent_environment(self):\n        # Test linking to a non-existent environment\n        with pytest.raises(ValueError, match=\"Environment snapshot .* does not exist\"):\n>           self.service.link_task_to_environment(\n                task_id=self.task_id1,\n                environment_id=uuid4(),\n            )\nE           TypeError: EnvironmentService.link_task_to_environment() got an unexpected keyword argument 'environment_id'\n\ntests/environment/test_service.py:685: TypeError"}, "teardown": {"duration": 0.00012750597670674324, "outcome": "passed"}}, {"nodeid": "tests/environment/test_service.py::TestEnvironmentService::test_task_environment_link_operations", "lineno": 689, "outcome": "failed", "keywords": ["test_task_environment_link_operations", "TestEnvironmentService", "test_service.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00015826697926968336, "outcome": "passed"}, "call": {"duration": 0.00010425003711134195, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_service.py", "lineno": 692, "message": "AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'"}, "traceback": [{"path": "tests/environment/test_service.py", "lineno": 692, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_service.TestEnvironmentService object at 0x7f6938ab2d50>\n\n    def test_task_environment_link_operations(self):\n        # Test various link operations\n>       env_id1 = self.service.create_environment_snapshot(\n            name=\"Environment 1\",\n            environment_type=EnvironmentType.LOCAL,\n        )\nE       AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'\n\ntests/environment/test_service.py:692: AttributeError"}, "teardown": {"duration": 0.0001294559333473444, "outcome": "passed"}}, {"nodeid": "tests/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_create_and_get_environment", "lineno": 63, "outcome": "failed", "keywords": ["test_create_and_get_environment", "TestInMemoryEnvironmentStorage", "test_storage.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00020378991030156612, "outcome": "passed"}, "call": {"duration": 0.00011104694567620754, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_storage.py", "lineno": 66, "message": "AttributeError: 'InMemoryEnvironmentStorage' object has no attribute 'create_environment'"}, "traceback": [{"path": "tests/environment/test_storage.py", "lineno": 66, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_storage.TestInMemoryEnvironmentStorage object at 0x7f6938ab2630>\n\n    def test_create_and_get_environment(self):\n        # Test creating and retrieving an environment\n>       env_id = self.storage.create_environment(self.environment1)\nE       AttributeError: 'InMemoryEnvironmentStorage' object has no attribute 'create_environment'\n\ntests/environment/test_storage.py:66: AttributeError"}, "teardown": {"duration": 0.0001284449826925993, "outcome": "passed"}}, {"nodeid": "tests/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_update_environment", "lineno": 76, "outcome": "failed", "keywords": ["test_update_environment", "TestInMemoryEnvironmentStorage", "test_storage.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001864650985226035, "outcome": "passed"}, "call": {"duration": 0.00010564306285232306, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_storage.py", "lineno": 79, "message": "AttributeError: 'InMemoryEnvironmentStorage' object has no attribute 'create_environment'"}, "traceback": [{"path": "tests/environment/test_storage.py", "lineno": 79, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_storage.TestInMemoryEnvironmentStorage object at 0x7f6938ab2120>\n\n    def test_update_environment(self):\n        # Test updating an environment\n>       env_id = self.storage.create_environment(self.environment1)\nE       AttributeError: 'InMemoryEnvironmentStorage' object has no attribute 'create_environment'\n\ntests/environment/test_storage.py:79: AttributeError"}, "teardown": {"duration": 0.00012622191570699215, "outcome": "passed"}}, {"nodeid": "tests/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_update_nonexistent_environment", "lineno": 91, "outcome": "failed", "keywords": ["test_update_nonexistent_environment", "TestInMemoryEnvironmentStorage", "test_storage.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00018847105093300343, "outcome": "passed"}, "call": {"duration": 0.0001326689962297678, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_storage.py", "lineno": 100, "message": "AttributeError: 'InMemoryEnvironmentStorage' object has no attribute 'update_environment'"}, "traceback": [{"path": "tests/environment/test_storage.py", "lineno": 100, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_storage.TestInMemoryEnvironmentStorage object at 0x7f6938ab1c10>\n\n    def test_update_nonexistent_environment(self):\n        # Test updating an environment that doesn't exist\n        nonexistent_env = EnvironmentSnapshot(\n            id=uuid4(),\n            name=\"Nonexistent Environment\",\n            type=EnvironmentType.LOCAL,\n        )\n    \n>       update_result = self.storage.update_environment(nonexistent_env)\nE       AttributeError: 'InMemoryEnvironmentStorage' object has no attribute 'update_environment'\n\ntests/environment/test_storage.py:100: AttributeError"}, "teardown": {"duration": 0.00012752099428325891, "outcome": "passed"}}, {"nodeid": "tests/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_delete_environment", "lineno": 102, "outcome": "failed", "keywords": ["test_delete_environment", "TestInMemoryEnvironmentStorage", "test_storage.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00019265804439783096, "outcome": "passed"}, "call": {"duration": 0.00010459101758897305, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_storage.py", "lineno": 105, "message": "AttributeError: 'InMemoryEnvironmentStorage' object has no attribute 'create_environment'"}, "traceback": [{"path": "tests/environment/test_storage.py", "lineno": 105, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_storage.TestInMemoryEnvironmentStorage object at 0x7f6938ab1700>\n\n    def test_delete_environment(self):\n        # Test deleting an environment\n>       env_id = self.storage.create_environment(self.environment1)\nE       AttributeError: 'InMemoryEnvironmentStorage' object has no attribute 'create_environment'\n\ntests/environment/test_storage.py:105: AttributeError"}, "teardown": {"duration": 0.0001421560300514102, "outcome": "passed"}}, {"nodeid": "tests/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_delete_nonexistent_environment", "lineno": 122, "outcome": "failed", "keywords": ["test_delete_nonexistent_environment", "TestInMemoryEnvironmentStorage", "test_storage.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00019593501929193735, "outcome": "passed"}, "call": {"duration": 0.00011009990703314543, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_storage.py", "lineno": 125, "message": "AttributeError: 'InMemoryEnvironmentStorage' object has no attribute 'delete_environment'"}, "traceback": [{"path": "tests/environment/test_storage.py", "lineno": 125, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_storage.TestInMemoryEnvironmentStorage object at 0x7f6938ab2e40>\n\n    def test_delete_nonexistent_environment(self):\n        # Test deleting an environment that doesn't exist\n>       delete_result = self.storage.delete_environment(uuid4())\nE       AttributeError: 'InMemoryEnvironmentStorage' object has no attribute 'delete_environment'\n\ntests/environment/test_storage.py:125: AttributeError"}, "teardown": {"duration": 0.00014521193224936724, "outcome": "passed"}}, {"nodeid": "tests/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_list_environments_empty", "lineno": 127, "outcome": "failed", "keywords": ["test_list_environments_empty", "TestInMemoryEnvironmentStorage", "test_storage.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00019326794426888227, "outcome": "passed"}, "call": {"duration": 0.00010996498167514801, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_storage.py", "lineno": 130, "message": "AttributeError: 'InMemoryEnvironmentStorage' object has no attribute 'list_environments'"}, "traceback": [{"path": "tests/environment/test_storage.py", "lineno": 130, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_storage.TestInMemoryEnvironmentStorage object at 0x7f6938ab37a0>\n\n    def test_list_environments_empty(self):\n        # Test listing environments when storage is empty\n>       environments = self.storage.list_environments()\nE       AttributeError: 'InMemoryEnvironmentStorage' object has no attribute 'list_environments'\n\ntests/environment/test_storage.py:130: AttributeError"}, "teardown": {"duration": 0.00014159095007926226, "outcome": "passed"}}, {"nodeid": "tests/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_list_environments_with_filters", "lineno": 132, "outcome": "failed", "keywords": ["test_list_environments_with_filters", "TestInMemoryEnvironmentStorage", "test_storage.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00018462503794580698, "outcome": "passed"}, "call": {"duration": 0.00010645203292369843, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_storage.py", "lineno": 135, "message": "AttributeError: 'InMemoryEnvironmentStorage' object has no attribute 'create_environment'"}, "traceback": [{"path": "tests/environment/test_storage.py", "lineno": 135, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_storage.TestInMemoryEnvironmentStorage object at 0x7f6938ab3950>\n\n    def test_list_environments_with_filters(self):\n        # Test listing environments with various filters\n>       self.storage.create_environment(self.environment1)\nE       AttributeError: 'InMemoryEnvironmentStorage' object has no attribute 'create_environment'\n\ntests/environment/test_storage.py:135: AttributeError"}, "teardown": {"duration": 0.00012717396020889282, "outcome": "passed"}}, {"nodeid": "tests/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_task_environment_link_operations", "lineno": 163, "outcome": "failed", "keywords": ["test_task_environment_link_operations", "TestInMemoryEnvironmentStorage", "test_storage.py", "environment", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001858340110629797, "outcome": "passed"}, "call": {"duration": 0.00010393396951258183, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/environment/test_storage.py", "lineno": 166, "message": "AttributeError: 'InMemoryEnvironmentStorage' object has no attribute 'create_environment'"}, "traceback": [{"path": "tests/environment/test_storage.py", "lineno": 166, "message": "AttributeError"}], "longrepr": "self = <tests.environment.test_storage.TestInMemoryEnvironmentStorage object at 0x7f6938ab3b00>\n\n    def test_task_environment_link_operations(self):\n        # Test task-environment link CRUD operations\n>       env_id1 = self.storage.create_environment(self.environment1)\nE       AttributeError: 'InMemoryEnvironmentStorage' object has no attribute 'create_environment'\n\ntests/environment/test_storage.py:166: AttributeError"}, "teardown": {"duration": 0.00012899294961243868, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_models.py::test_parameter_creation", "lineno": 10, "outcome": "passed", "keywords": ["test_parameter_creation", "test_models.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0002670970279723406, "outcome": "passed"}, "call": {"duration": 0.0001175649231299758, "outcome": "passed"}, "teardown": {"duration": 8.068396709859371e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_models.py::test_metric_creation", "lineno": 26, "outcome": "passed", "keywords": ["test_metric_creation", "test_models.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 8.206104394048452e-05, "outcome": "passed"}, "call": {"duration": 0.00010903505608439445, "outcome": "passed"}, "teardown": {"duration": 7.457099854946136e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_models.py::test_experiment_run_creation", "lineno": 43, "outcome": "passed", "keywords": ["test_experiment_run_creation", "test_models.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.842900231480598e-05, "outcome": "passed"}, "call": {"duration": 0.00012289592996239662, "outcome": "passed"}, "teardown": {"duration": 7.34659843146801e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_models.py::test_experiment_run_duration", "lineno": 68, "outcome": "passed", "keywords": ["test_experiment_run_duration", "test_models.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.339695002883673e-05, "outcome": "passed"}, "call": {"duration": 0.00012893008533865213, "outcome": "passed"}, "teardown": {"duration": 8.514500223100185e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_models.py::test_experiment_creation", "lineno": 91, "outcome": "passed", "keywords": ["test_experiment_creation", "test_models.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.733795791864395e-05, "outcome": "passed"}, "call": {"duration": 0.00010633596684783697, "outcome": "passed"}, "teardown": {"duration": 7.707101758569479e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_models.py::test_experiment_add_run", "lineno": 111, "outcome": "passed", "keywords": ["test_experiment_add_run", "test_models.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.435400038957596e-05, "outcome": "passed"}, "call": {"duration": 0.00014123006258159876, "outcome": "passed"}, "teardown": {"duration": 7.466401439160109e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_models.py::test_experiment_get_run", "lineno": 132, "outcome": "passed", "keywords": ["test_experiment_get_run", "test_models.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.432792335748672e-05, "outcome": "passed"}, "call": {"duration": 0.0001136179780587554, "outcome": "passed"}, "teardown": {"duration": 7.180997636169195e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_models.py::test_experiment_get_best_run", "lineno": 152, "outcome": "passed", "keywords": ["test_experiment_get_best_run", "test_models.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 8.024310227483511e-05, "outcome": "passed"}, "call": {"duration": 0.00018672400619834661, "outcome": "passed"}, "teardown": {"duration": 7.40870600566268e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_models.py::test_experiment_comparison_creation", "lineno": 191, "outcome": "passed", "keywords": ["test_experiment_comparison_creation", "test_models.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.402198389172554e-05, "outcome": "passed"}, "call": {"duration": 0.00011260807514190674, "outcome": "passed"}, "teardown": {"duration": 7.235701195895672e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_models.py::test_experiment_comparison_add_methods", "lineno": 210, "outcome": "passed", "keywords": ["test_experiment_comparison_add_methods", "test_models.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.261906284838915e-05, "outcome": "passed"}, "call": {"duration": 0.00011373998131603003, "outcome": "passed"}, "teardown": {"duration": 7.254502270370722e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_create_experiment", "lineno": 21, "outcome": "passed", "keywords": ["test_create_experiment", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00016084802336990833, "outcome": "passed"}, "call": {"duration": 0.00011354801245033741, "outcome": "passed"}, "teardown": {"duration": 9.86569793894887e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_get_experiment", "lineno": 36, "outcome": "passed", "keywords": ["test_get_experiment", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012789200991392136, "outcome": "passed"}, "call": {"duration": 0.00010467600077390671, "outcome": "passed"}, "teardown": {"duration": 8.623301982879639e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_get_experiment_by_name", "lineno": 46, "outcome": "failed", "keywords": ["test_get_experiment_by_name", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012034398969262838, "outcome": "passed"}, "call": {"duration": 0.00012517999857664108, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_service.py", "lineno": 50, "message": "AttributeError: 'ExperimentService' object has no attribute 'get_experiment_by_name'"}, "traceback": [{"path": "tests/experiment_tracking/test_service.py", "lineno": 50, "message": "AttributeError"}], "longrepr": "service = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f69387175f0>\n\n    def test_get_experiment_by_name(service):\n        \"\"\"Test retrieving an experiment by name through the service.\"\"\"\n        service.create_experiment(name=\"Test Experiment\")\n>       retrieved = service.get_experiment_by_name(\"Test Experiment\")\nE       AttributeError: 'ExperimentService' object has no attribute 'get_experiment_by_name'\n\ntests/experiment_tracking/test_service.py:50: AttributeError"}, "teardown": {"duration": 0.0001348849618807435, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_update_experiment", "lineno": 58, "outcome": "failed", "keywords": ["test_update_experiment", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00015495100524276495, "outcome": "passed"}, "call": {"duration": 0.00013927696272730827, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/researchtrack/experiment_tracking/storage.py", "lineno": 231, "message": "TypeError: unhashable type: 'Experiment'"}, "traceback": [{"path": "tests/experiment_tracking/test_service.py", "lineno": 63, "message": ""}, {"path": "researchtrack/experiment_tracking/service.py", "lineno": 108, "message": "in update_experiment"}, {"path": "researchtrack/experiment_tracking/storage.py", "lineno": 231, "message": "TypeError"}], "longrepr": "service = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f6938760c80>\n\n    def test_update_experiment(service):\n        \"\"\"Test updating an experiment through the service.\"\"\"\n        experiment = service.create_experiment(name=\"Original Name\")\n        experiment.name = \"Updated Name\"\n>       updated = service.update_experiment(experiment)\n\ntests/experiment_tracking/test_service.py:63: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nresearchtrack/experiment_tracking/service.py:108: in update_experiment\n    experiment = self._storage.get_experiment(experiment_id)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <researchtrack.experiment_tracking.storage.InMemoryExperimentStorage object at 0x7f6938761550>\nexperiment_id = Experiment(id=UUID('827f5565-a9ad-4d66-96db-015d3236ecf4'), name='Updated Name', description=None, task_id=None, datas...tetime(2025, 5, 15, 2, 34, 10, 531517), updated_at=datetime.datetime(2025, 5, 15, 2, 34, 10, 531518), runs=[], tags=[])\n\n    def get_experiment(self, experiment_id: UUID) -> Optional[Experiment]:\n>       return self._experiments.get(experiment_id)\nE       TypeError: unhashable type: 'Experiment'\n\nresearchtrack/experiment_tracking/storage.py:231: TypeError"}, "teardown": {"duration": 0.00013694306835532188, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_delete_experiment", "lineno": 71, "outcome": "passed", "keywords": ["test_delete_experiment", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00015628105029463768, "outcome": "passed"}, "call": {"duration": 0.00011899496894329786, "outcome": "passed"}, "teardown": {"duration": 9.48059605434537e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_list_experiments", "lineno": 80, "outcome": "passed", "keywords": ["test_list_experiments", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014207104686647654, "outcome": "passed"}, "call": {"duration": 0.00012528302613645792, "outcome": "passed"}, "teardown": {"duration": 9.426800534129143e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_list_experiments_by_task", "lineno": 92, "outcome": "passed", "keywords": ["test_list_experiments_by_task", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00013071007560938597, "outcome": "passed"}, "call": {"duration": 0.00012109905946999788, "outcome": "passed"}, "teardown": {"duration": 9.169196709990501e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_add_parameter", "lineno": 104, "outcome": "failed", "keywords": ["test_add_parameter", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00013650895562022924, "outcome": "passed"}, "call": {"duration": 9.889097418636084e-05, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_service.py", "lineno": 107, "message": "AttributeError: 'ExperimentService' object has no attribute 'add_parameter'. Did you mean: 'create_parameter'?"}, "traceback": [{"path": "tests/experiment_tracking/test_service.py", "lineno": 107, "message": "AttributeError"}], "longrepr": "service = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f69385f3d40>\n\n    def test_add_parameter(service):\n        \"\"\"Test creating a parameter through the service.\"\"\"\n>       param = service.add_parameter(\n            name=\"learning_rate\",\n            type=ParameterType.FLOAT,\n            value=0.001,\n            description=\"Learning rate for optimizer\"\n        )\nE       AttributeError: 'ExperimentService' object has no attribute 'add_parameter'. Did you mean: 'create_parameter'?\n\ntests/experiment_tracking/test_service.py:107: AttributeError"}, "teardown": {"duration": 0.00013496202882379293, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_add_metric", "lineno": 120, "outcome": "failed", "keywords": ["test_add_metric", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00015848607290536165, "outcome": "passed"}, "call": {"duration": 0.00011080398689955473, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_service.py", "lineno": 123, "message": "AttributeError: 'ExperimentService' object has no attribute 'add_metric'. Did you mean: 'add_run_metric'?"}, "traceback": [{"path": "tests/experiment_tracking/test_service.py", "lineno": 123, "message": "AttributeError"}], "longrepr": "service = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f69385f1010>\n\n    def test_add_metric(service):\n        \"\"\"Test creating a metric through the service.\"\"\"\n>       metric = service.add_metric(\n            name=\"accuracy\",\n            type=MetricType.ACCURACY,\n            value=0.95,\n            description=\"Validation accuracy\"\n        )\nE       AttributeError: 'ExperimentService' object has no attribute 'add_metric'. Did you mean: 'add_run_metric'?\n\ntests/experiment_tracking/test_service.py:123: AttributeError"}, "teardown": {"duration": 0.0001364590134471655, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_create_experiment_run", "lineno": 136, "outcome": "failed", "keywords": ["test_create_experiment_run", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014314206782728434, "outcome": "passed"}, "call": {"duration": 0.0001357899745926261, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_service.py", "lineno": 140, "message": "AttributeError: 'ExperimentService' object has no attribute 'add_parameter'. Did you mean: 'create_parameter'?"}, "traceback": [{"path": "tests/experiment_tracking/test_service.py", "lineno": 140, "message": "AttributeError"}], "longrepr": "service = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f69385f1bb0>\n\n    def test_create_experiment_run(service):\n        \"\"\"Test creating an experiment run through the service.\"\"\"\n        experiment = service.create_experiment(name=\"Test Experiment\")\n>       param = service.add_parameter(name=\"p1\", type=ParameterType.FLOAT, value=0.1)\nE       AttributeError: 'ExperimentService' object has no attribute 'add_parameter'. Did you mean: 'create_parameter'?\n\ntests/experiment_tracking/test_service.py:140: AttributeError"}, "teardown": {"duration": 0.00013518997002393007, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_create_experiment_run_nonexistent_experiment", "lineno": 155, "outcome": "failed", "keywords": ["test_create_experiment_run_nonexistent_experiment", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014318397734314203, "outcome": "passed"}, "call": {"duration": 9.866710752248764e-05, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_service.py", "lineno": 158, "message": "AttributeError: 'ExperimentService' object has no attribute 'add_parameter'. Did you mean: 'create_parameter'?"}, "traceback": [{"path": "tests/experiment_tracking/test_service.py", "lineno": 158, "message": "AttributeError"}], "longrepr": "service = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f69385f2840>\n\n    def test_create_experiment_run_nonexistent_experiment(service):\n        \"\"\"Test creating a run for a non-existent experiment.\"\"\"\n>       param = service.add_parameter(name=\"p1\", type=ParameterType.FLOAT, value=0.1)\nE       AttributeError: 'ExperimentService' object has no attribute 'add_parameter'. Did you mean: 'create_parameter'?\n\ntests/experiment_tracking/test_service.py:158: AttributeError"}, "teardown": {"duration": 0.0001345720374956727, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_get_experiment_run", "lineno": 163, "outcome": "failed", "keywords": ["test_get_experiment_run", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014344800729304552, "outcome": "passed"}, "call": {"duration": 0.00014538096729665995, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_service.py", "lineno": 169, "message": "AttributeError: 'ExperimentService' object has no attribute 'get_experiment_run'. Did you mean: 'create_experiment_run'?"}, "traceback": [{"path": "tests/experiment_tracking/test_service.py", "lineno": 169, "message": "AttributeError"}], "longrepr": "service = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f69385f33b0>\n\n    def test_get_experiment_run(service):\n        \"\"\"Test retrieving an experiment run through the service.\"\"\"\n        experiment = service.create_experiment(name=\"Test Experiment\")\n        run = service.create_experiment_run(experiment.id, [])\n    \n>       retrieved = service.get_experiment_run(run.id)\nE       AttributeError: 'ExperimentService' object has no attribute 'get_experiment_run'. Did you mean: 'create_experiment_run'?\n\ntests/experiment_tracking/test_service.py:169: AttributeError"}, "teardown": {"duration": 0.0001331630628556013, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_run_lifecycle", "lineno": 175, "outcome": "failed", "keywords": ["test_run_lifecycle", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00015400303527712822, "outcome": "passed"}, "call": {"duration": 0.00012835196685045958, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_service.py", "lineno": 179, "message": "AttributeError: 'ExperimentService' object has no attribute 'add_parameter'. Did you mean: 'create_parameter'?"}, "traceback": [{"path": "tests/experiment_tracking/test_service.py", "lineno": 179, "message": "AttributeError"}], "longrepr": "service = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f69387635f0>\n\n    def test_run_lifecycle(service):\n        \"\"\"Test the complete lifecycle of an experiment run.\"\"\"\n        experiment = service.create_experiment(name=\"Test Experiment\")\n>       param = service.add_parameter(name=\"p1\", type=ParameterType.FLOAT, value=0.1)\nE       AttributeError: 'ExperimentService' object has no attribute 'add_parameter'. Did you mean: 'create_parameter'?\n\ntests/experiment_tracking/test_service.py:179: AttributeError"}, "teardown": {"duration": 0.00013575097545981407, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_failed_and_aborted_runs", "lineno": 212, "outcome": "failed", "keywords": ["test_failed_and_aborted_runs", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.000144643010571599, "outcome": "passed"}, "call": {"duration": 0.00017078605014830828, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_service.py", "lineno": 222, "message": "AttributeError: 'bool' object has no attribute 'status'"}, "traceback": [{"path": "tests/experiment_tracking/test_service.py", "lineno": 222, "message": "AttributeError"}], "longrepr": "service = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f6938774c80>\n\n    def test_failed_and_aborted_runs(service):\n        \"\"\"Test marking runs as failed or aborted.\"\"\"\n        experiment = service.create_experiment(name=\"Test Experiment\")\n    \n        # Create and start a run that will fail\n        failed_run = service.create_experiment_run(experiment.id, [])\n        service.start_run(failed_run.id)\n        failed_run = service.fail_run(failed_run.id)\n    \n>       assert failed_run.status == ExperimentStatus.FAILED\nE       AttributeError: 'bool' object has no attribute 'status'\n\ntests/experiment_tracking/test_service.py:222: AttributeError"}, "teardown": {"duration": 0.00013477506581693888, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_get_best_run", "lineno": 233, "outcome": "passed", "keywords": ["test_get_best_run", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014208396896719933, "outcome": "passed"}, "call": {"duration": 0.00021426798775792122, "outcome": "passed"}, "teardown": {"duration": 0.00010382803156971931, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_create_comparison", "lineno": 261, "outcome": "passed", "keywords": ["test_create_comparison", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012996396981179714, "outcome": "passed"}, "call": {"duration": 0.0001222820719704032, "outcome": "passed"}, "teardown": {"duration": 9.20869642868638e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_get_comparison", "lineno": 282, "outcome": "passed", "keywords": ["test_get_comparison", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012696499470621347, "outcome": "passed"}, "call": {"duration": 0.00011141796130686998, "outcome": "passed"}, "teardown": {"duration": 9.341805707663298e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_update_comparison", "lineno": 292, "outcome": "failed", "keywords": ["test_update_comparison", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001272780355066061, "outcome": "passed"}, "call": {"duration": 0.00012742297258228064, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_service.py", "lineno": 297, "message": "AttributeError: 'ExperimentService' object has no attribute 'update_comparison'. Did you mean: 'create_comparison'?"}, "traceback": [{"path": "tests/experiment_tracking/test_service.py", "lineno": 297, "message": "AttributeError"}], "longrepr": "service = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f6938629cd0>\n\n    def test_update_comparison(service):\n        \"\"\"Test updating a comparison through the service.\"\"\"\n        comparison = service.create_comparison(name=\"Original Name\")\n        comparison.name = \"Updated Name\"\n>       updated = service.update_comparison(comparison)\nE       AttributeError: 'ExperimentService' object has no attribute 'update_comparison'. Did you mean: 'create_comparison'?\n\ntests/experiment_tracking/test_service.py:297: AttributeError"}, "teardown": {"duration": 0.0001343559706583619, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_delete_comparison", "lineno": 305, "outcome": "failed", "keywords": ["test_delete_comparison", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001442920183762908, "outcome": "passed"}, "call": {"duration": 0.00013303302694112062, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_service.py", "lineno": 309, "message": "AttributeError: 'ExperimentService' object has no attribute 'delete_comparison'. Did you mean: 'create_comparison'?"}, "traceback": [{"path": "tests/experiment_tracking/test_service.py", "lineno": 309, "message": "AttributeError"}], "longrepr": "service = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f6938629d00>\n\n    def test_delete_comparison(service):\n        \"\"\"Test deleting a comparison through the service.\"\"\"\n        comparison = service.create_comparison(name=\"Test Comparison\")\n>       result = service.delete_comparison(comparison.id)\nE       AttributeError: 'ExperimentService' object has no attribute 'delete_comparison'. Did you mean: 'create_comparison'?\n\ntests/experiment_tracking/test_service.py:309: AttributeError"}, "teardown": {"duration": 0.00014929391909390688, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_list_comparisons", "lineno": 314, "outcome": "failed", "keywords": ["test_list_comparisons", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014842406380921602, "outcome": "passed"}, "call": {"duration": 0.00013342290185391903, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_service.py", "lineno": 320, "message": "AttributeError: 'ExperimentService' object has no attribute 'list_comparisons'. Did you mean: 'get_comparison'?"}, "traceback": [{"path": "tests/experiment_tracking/test_service.py", "lineno": 320, "message": "AttributeError"}], "longrepr": "service = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f69385f2ae0>\n\n    def test_list_comparisons(service):\n        \"\"\"Test listing comparisons through the service.\"\"\"\n        service.create_comparison(name=\"Comparison 1\")\n        service.create_comparison(name=\"Comparison 2\")\n    \n>       comparisons = service.list_comparisons()\nE       AttributeError: 'ExperimentService' object has no attribute 'list_comparisons'. Did you mean: 'get_comparison'?\n\ntests/experiment_tracking/test_service.py:320: AttributeError"}, "teardown": {"duration": 0.00013285793829709291, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_service.py::test_get_comparison_data", "lineno": 326, "outcome": "failed", "keywords": ["test_get_comparison_data", "test_service.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014255091082304716, "outcome": "passed"}, "call": {"duration": 0.00041576800867915154, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_service.py", "lineno": 354, "message": "AssertionError: assert 3 == 2\n +  where 3 = len({'comparison': {'created_at': '2025-05-15T02:34:10.613216', 'description': None, 'id': 'b035483e-4eda-415f-89aa-94fc5a...3-ae70-4111-a63b-71dab75b2754', 'experiment_name': 'Experiment 2', 'id': '9177836b-4693-4ab6-93d8-797caa8cfc65', ...}]})"}, "traceback": [{"path": "tests/experiment_tracking/test_service.py", "lineno": 354, "message": "AssertionError"}], "longrepr": "service = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f69385f22d0>\n\n    def test_get_comparison_data(service):\n        \"\"\"Test getting comparison data through the service.\"\"\"\n        # Create experiments and runs with metrics\n        experiment1 = service.create_experiment(name=\"Experiment 1\")\n        run1 = service.create_experiment_run(experiment1.id, [])\n        service.start_run(run1.id)\n        service.add_run_metric(run1.id, \"accuracy\", MetricType.ACCURACY, 0.9)\n        service.add_run_metric(run1.id, \"loss\", MetricType.LOSS, 0.1)\n        service.complete_run(run1.id)\n    \n        experiment2 = service.create_experiment(name=\"Experiment 2\")\n        run2 = service.create_experiment_run(experiment2.id, [])\n        service.start_run(run2.id)\n        service.add_run_metric(run2.id, \"accuracy\", MetricType.ACCURACY, 0.85)\n        service.add_run_metric(run2.id, \"loss\", MetricType.LOSS, 0.15)\n        service.complete_run(run2.id)\n    \n        # Create a comparison\n        comparison = service.create_comparison(\n            name=\"Test Comparison\",\n            run_ids=[run1.id, run2.id],\n            metrics=[\"accuracy\", \"loss\"]\n        )\n    \n        # Get comparison data\n        data = service.get_comparison_data(comparison.id)\n    \n>       assert len(data) == 2\nE       AssertionError: assert 3 == 2\nE        +  where 3 = len({'comparison': {'created_at': '2025-05-15T02:34:10.613216', 'description': None, 'id': 'b035483e-4eda-415f-89aa-94fc5a...3-ae70-4111-a63b-71dab75b2754', 'experiment_name': 'Experiment 2', 'id': '9177836b-4693-4ab6-93d8-797caa8cfc65', ...}]})\n\ntests/experiment_tracking/test_service.py:354: AssertionError"}, "teardown": {"duration": 0.00013464700896292925, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_create_experiment", "lineno": 48, "outcome": "failed", "keywords": ["test_create_experiment", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001774119446054101, "outcome": "passed"}, "call": {"duration": 0.00010894704610109329, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_storage.py", "lineno": 53, "message": "AttributeError: 'UUID' object has no attribute 'id'"}, "traceback": [{"path": "tests/experiment_tracking/test_storage.py", "lineno": 53, "message": "AttributeError"}], "longrepr": "storage = <researchtrack.experiment_tracking.storage.InMemoryExperimentStorage object at 0x7f69385f1190>\nsample_experiment = Experiment(id=UUID('2b12ef84-fd22-4ab5-858d-b3d3ca646982'), name='Test Experiment', description='A test experiment', t...2, 34, 10, 618624), updated_at=datetime.datetime(2025, 5, 15, 2, 34, 10, 618625), runs=[], tags=['test', 'experiment'])\n\n    def test_create_experiment(storage, sample_experiment):\n        \"\"\"Test creating an experiment in storage.\"\"\"\n        created = storage.create_experiment(sample_experiment)\n    \n>       assert created.id == sample_experiment.id\nE       AttributeError: 'UUID' object has no attribute 'id'\n\ntests/experiment_tracking/test_storage.py:53: AttributeError"}, "teardown": {"duration": 0.00013046700041741133, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_get_experiment", "lineno": 58, "outcome": "passed", "keywords": ["test_get_experiment", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00015696091577410698, "outcome": "passed"}, "call": {"duration": 9.11529641598463e-05, "outcome": "passed"}, "teardown": {"duration": 8.77890270203352e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_get_nonexistent_experiment", "lineno": 68, "outcome": "passed", "keywords": ["test_get_nonexistent_experiment", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00010647694580256939, "outcome": "passed"}, "call": {"duration": 8.904794231057167e-05, "outcome": "passed"}, "teardown": {"duration": 8.081796113401651e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_update_experiment", "lineno": 76, "outcome": "failed", "keywords": ["test_update_experiment", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014381203800439835, "outcome": "passed"}, "call": {"duration": 0.00010155490599572659, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/uuid.py", "lineno": 278, "message": "TypeError: UUID objects are immutable"}, "traceback": [{"path": "tests/experiment_tracking/test_storage.py", "lineno": 80, "message": ""}, {"path": "../../../../.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/uuid.py", "lineno": 278, "message": "TypeError"}], "longrepr": "storage = <researchtrack.experiment_tracking.storage.InMemoryExperimentStorage object at 0x7f6938600fe0>\nsample_experiment = Experiment(id=UUID('fb10ea59-fa09-4c0a-a77d-a2da1d3c5b5c'), name='Test Experiment', description='A test experiment', t...2, 34, 10, 624000), updated_at=datetime.datetime(2025, 5, 15, 2, 34, 10, 624001), runs=[], tags=['test', 'experiment'])\n\n    def test_update_experiment(storage, sample_experiment):\n        \"\"\"Test updating an experiment in storage.\"\"\"\n        created = storage.create_experiment(sample_experiment)\n>       created.name = \"Updated Experiment\"\n\ntests/experiment_tracking/test_storage.py:80: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = UUID('fb10ea59-fa09-4c0a-a77d-a2da1d3c5b5c'), name = 'name'\nvalue = 'Updated Experiment'\n\n    def __setattr__(self, name, value):\n>       raise TypeError('UUID objects are immutable')\nE       TypeError: UUID objects are immutable\n\n../../../../.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/uuid.py:278: TypeError"}, "teardown": {"duration": 0.00013211497571319342, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_update_nonexistent_experiment", "lineno": 89, "outcome": "failed", "keywords": ["test_update_nonexistent_experiment", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012146809604018927, "outcome": "passed"}, "call": {"duration": 0.0001717249397188425, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_storage.py", "lineno": 95, "message": "assert False is None"}, "traceback": [{"path": "tests/experiment_tracking/test_storage.py", "lineno": 95, "message": "AssertionError"}], "longrepr": "storage = <researchtrack.experiment_tracking.storage.InMemoryExperimentStorage object at 0x7f6938601e80>\n\n    def test_update_nonexistent_experiment(storage):\n        \"\"\"Test updating an experiment that doesn't exist.\"\"\"\n        experiment = Experiment(name=\"Nonexistent Experiment\")\n        updated = storage.update_experiment(experiment)\n    \n>       assert updated is None\nE       assert False is None\n\ntests/experiment_tracking/test_storage.py:95: AssertionError"}, "teardown": {"duration": 0.00012566405348479748, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_delete_experiment", "lineno": 97, "outcome": "passed", "keywords": ["test_delete_experiment", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00017118698451668024, "outcome": "passed"}, "call": {"duration": 9.302608668804169e-05, "outcome": "passed"}, "teardown": {"duration": 8.89080110937357e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_delete_nonexistent_experiment", "lineno": 106, "outcome": "passed", "keywords": ["test_delete_nonexistent_experiment", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001031169667840004, "outcome": "passed"}, "call": {"duration": 8.931790944188833e-05, "outcome": "passed"}, "teardown": {"duration": 8.642592001706362e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_list_experiments", "lineno": 114, "outcome": "passed", "keywords": ["test_list_experiments", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00013470998965203762, "outcome": "passed"}, "call": {"duration": 0.00010245502926409245, "outcome": "passed"}, "teardown": {"duration": 8.601404260843992e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_list_experiments_by_task", "lineno": 127, "outcome": "passed", "keywords": ["test_list_experiments_by_task", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001397270243614912, "outcome": "passed"}, "call": {"duration": 0.0001345650525763631, "outcome": "passed"}, "teardown": {"duration": 8.916098158806562e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_get_experiment_by_name", "lineno": 148, "outcome": "failed", "keywords": ["test_get_experiment_by_name", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00013467995449900627, "outcome": "passed"}, "call": {"duration": 9.8424032330513e-05, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_storage.py", "lineno": 152, "message": "AttributeError: 'InMemoryExperimentStorage' object has no attribute 'get_experiment_by_name'"}, "traceback": [{"path": "tests/experiment_tracking/test_storage.py", "lineno": 152, "message": "AttributeError"}], "longrepr": "storage = <researchtrack.experiment_tracking.storage.InMemoryExperimentStorage object at 0x7f6938602720>\nsample_experiment = Experiment(id=UUID('7054d46a-2018-4a61-984e-b32c1a18e1b6'), name='Test Experiment', description='A test experiment', t...2, 34, 10, 640797), updated_at=datetime.datetime(2025, 5, 15, 2, 34, 10, 640798), runs=[], tags=['test', 'experiment'])\n\n    def test_get_experiment_by_name(storage, sample_experiment):\n        \"\"\"Test retrieving an experiment by name.\"\"\"\n        storage.create_experiment(sample_experiment)\n>       retrieved = storage.get_experiment_by_name(\"Test Experiment\")\nE       AttributeError: 'InMemoryExperimentStorage' object has no attribute 'get_experiment_by_name'\n\ntests/experiment_tracking/test_storage.py:152: AttributeError"}, "teardown": {"duration": 0.0001304569886997342, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_create_run", "lineno": 160, "outcome": "failed", "keywords": ["test_create_run", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00020262098405510187, "outcome": "passed"}, "call": {"duration": 0.00011025601997971535, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_storage.py", "lineno": 164, "message": "TypeError: InMemoryExperimentStorage.create_run() takes 2 positional arguments but 3 were given"}, "traceback": [{"path": "tests/experiment_tracking/test_storage.py", "lineno": 164, "message": "TypeError"}], "longrepr": "storage = <researchtrack.experiment_tracking.storage.InMemoryExperimentStorage object at 0x7f6938603470>\nsample_experiment = Experiment(id=UUID('3e234a41-ed8d-4322-9d81-8df37e12843f'), name='Test Experiment', description='A test experiment', t...2, 34, 10, 646820), updated_at=datetime.datetime(2025, 5, 15, 2, 34, 10, 646821), runs=[], tags=['test', 'experiment'])\nsample_run = ExperimentRun(id=UUID('b8fe8d7e-d41d-42c9-8b0f-d1d2699bf9eb'), experiment_id=UUID('3e234a41-ed8d-4322-9d81-8df37e12843...e.FLOAT: 'float'>, value=0.1, description=None)], metrics={}, artifacts={}, start_time=None, end_time=None, notes=None)\n\n    def test_create_run(storage, sample_experiment, sample_run):\n        \"\"\"Test creating a run in storage.\"\"\"\n        storage.create_experiment(sample_experiment)\n>       created = storage.create_run(sample_experiment.id, sample_run)\nE       TypeError: InMemoryExperimentStorage.create_run() takes 2 positional arguments but 3 were given\n\ntests/experiment_tracking/test_storage.py:164: TypeError"}, "teardown": {"duration": 0.00013941398356109858, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_create_run_nonexistent_experiment", "lineno": 175, "outcome": "failed", "keywords": ["test_create_run_nonexistent_experiment", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0002125368919223547, "outcome": "passed"}, "call": {"duration": 0.0001133530167862773, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_storage.py", "lineno": 179, "message": "TypeError: InMemoryExperimentStorage.create_run() takes 2 positional arguments but 3 were given"}, "traceback": [{"path": "tests/experiment_tracking/test_storage.py", "lineno": 179, "message": "TypeError"}], "longrepr": "storage = <researchtrack.experiment_tracking.storage.InMemoryExperimentStorage object at 0x7f69385f2210>\nsample_run = ExperimentRun(id=UUID('abd4041a-a8cf-4070-a4db-50b9ff1eab4b'), experiment_id=UUID('b0a69e6c-55ec-46e2-b120-581834c857c...e.FLOAT: 'float'>, value=0.1, description=None)], metrics={}, artifacts={}, start_time=None, end_time=None, notes=None)\n\n    def test_create_run_nonexistent_experiment(storage, sample_run):\n        \"\"\"Test creating a run for a non-existent experiment.\"\"\"\n        non_existent_id = uuid4()\n>       created = storage.create_run(non_existent_id, sample_run)\nE       TypeError: InMemoryExperimentStorage.create_run() takes 2 positional arguments but 3 were given\n\ntests/experiment_tracking/test_storage.py:179: TypeError"}, "teardown": {"duration": 0.00013772898819297552, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_get_run", "lineno": 183, "outcome": "failed", "keywords": ["test_get_run", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.000202848925255239, "outcome": "passed"}, "call": {"duration": 0.00010682595893740654, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_storage.py", "lineno": 187, "message": "TypeError: InMemoryExperimentStorage.create_run() takes 2 positional arguments but 3 were given"}, "traceback": [{"path": "tests/experiment_tracking/test_storage.py", "lineno": 187, "message": "TypeError"}], "longrepr": "storage = <researchtrack.experiment_tracking.storage.InMemoryExperimentStorage object at 0x7f69385f1be0>\nsample_experiment = Experiment(id=UUID('c20b398a-1e0b-40ec-bb7e-780653a660b2'), name='Test Experiment', description='A test experiment', t...2, 34, 10, 655513), updated_at=datetime.datetime(2025, 5, 15, 2, 34, 10, 655515), runs=[], tags=['test', 'experiment'])\nsample_run = ExperimentRun(id=UUID('2b1ed7f6-2a4e-491e-b5fa-d04e23af8336'), experiment_id=UUID('c20b398a-1e0b-40ec-bb7e-780653a660b...e.FLOAT: 'float'>, value=0.1, description=None)], metrics={}, artifacts={}, start_time=None, end_time=None, notes=None)\n\n    def test_get_run(storage, sample_experiment, sample_run):\n        \"\"\"Test retrieving a run from storage.\"\"\"\n        storage.create_experiment(sample_experiment)\n>       storage.create_run(sample_experiment.id, sample_run)\nE       TypeError: InMemoryExperimentStorage.create_run() takes 2 positional arguments but 3 were given\n\ntests/experiment_tracking/test_storage.py:187: TypeError"}, "teardown": {"duration": 0.00014509703032672405, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_update_run", "lineno": 194, "outcome": "failed", "keywords": ["test_update_run", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00019883096683770418, "outcome": "passed"}, "call": {"duration": 0.00010793004184961319, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_storage.py", "lineno": 198, "message": "TypeError: InMemoryExperimentStorage.create_run() takes 2 positional arguments but 3 were given"}, "traceback": [{"path": "tests/experiment_tracking/test_storage.py", "lineno": 198, "message": "TypeError"}], "longrepr": "storage = <researchtrack.experiment_tracking.storage.InMemoryExperimentStorage object at 0x7f693862a420>\nsample_experiment = Experiment(id=UUID('2e4bdcf2-3e65-47a4-81aa-3df6e0a7feb1'), name='Test Experiment', description='A test experiment', t...2, 34, 10, 659655), updated_at=datetime.datetime(2025, 5, 15, 2, 34, 10, 659656), runs=[], tags=['test', 'experiment'])\nsample_run = ExperimentRun(id=UUID('6fadc8c9-32f8-4a15-a197-7f04bfd4b8dd'), experiment_id=UUID('2e4bdcf2-3e65-47a4-81aa-3df6e0a7feb...e.FLOAT: 'float'>, value=0.1, description=None)], metrics={}, artifacts={}, start_time=None, end_time=None, notes=None)\n\n    def test_update_run(storage, sample_experiment, sample_run):\n        \"\"\"Test updating a run in storage.\"\"\"\n        storage.create_experiment(sample_experiment)\n>       storage.create_run(sample_experiment.id, sample_run)\nE       TypeError: InMemoryExperimentStorage.create_run() takes 2 positional arguments but 3 were given\n\ntests/experiment_tracking/test_storage.py:198: TypeError"}, "teardown": {"duration": 0.00013737694825977087, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_update_nonexistent_run", "lineno": 214, "outcome": "failed", "keywords": ["test_update_nonexistent_run", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00011869007721543312, "outcome": "passed"}, "call": {"duration": 0.00018304598052054644, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_storage.py", "lineno": 220, "message": "assert False is None"}, "traceback": [{"path": "tests/experiment_tracking/test_storage.py", "lineno": 220, "message": "AssertionError"}], "longrepr": "storage = <researchtrack.experiment_tracking.storage.InMemoryExperimentStorage object at 0x7f6938adbe00>\n\n    def test_update_nonexistent_run(storage):\n        \"\"\"Test updating a run that doesn't exist.\"\"\"\n        run = ExperimentRun(experiment_id=uuid4(), run_number=1)\n        updated = storage.update_run(run)\n    \n>       assert updated is None\nE       assert False is None\n\ntests/experiment_tracking/test_storage.py:220: AssertionError"}, "teardown": {"duration": 0.0001256170216947794, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_delete_run", "lineno": 222, "outcome": "failed", "keywords": ["test_delete_run", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00019985402468591928, "outcome": "passed"}, "call": {"duration": 0.00011428992729634047, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_storage.py", "lineno": 226, "message": "TypeError: InMemoryExperimentStorage.create_run() takes 2 positional arguments but 3 were given"}, "traceback": [{"path": "tests/experiment_tracking/test_storage.py", "lineno": 226, "message": "TypeError"}], "longrepr": "storage = <researchtrack.experiment_tracking.storage.InMemoryExperimentStorage object at 0x7f6938923890>\nsample_experiment = Experiment(id=UUID('13d542bc-fd2d-41b4-8ef8-26d460c3712c'), name='Test Experiment', description='A test experiment', t...2, 34, 10, 667886), updated_at=datetime.datetime(2025, 5, 15, 2, 34, 10, 667887), runs=[], tags=['test', 'experiment'])\nsample_run = ExperimentRun(id=UUID('4bc2e0cc-3686-46cc-84c7-6edc6ef16113'), experiment_id=UUID('13d542bc-fd2d-41b4-8ef8-26d460c3712...e.FLOAT: 'float'>, value=0.1, description=None)], metrics={}, artifacts={}, start_time=None, end_time=None, notes=None)\n\n    def test_delete_run(storage, sample_experiment, sample_run):\n        \"\"\"Test deleting a run from storage.\"\"\"\n        storage.create_experiment(sample_experiment)\n>       storage.create_run(sample_experiment.id, sample_run)\nE       TypeError: InMemoryExperimentStorage.create_run() takes 2 positional arguments but 3 were given\n\ntests/experiment_tracking/test_storage.py:226: TypeError"}, "teardown": {"duration": 0.00013701501302421093, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_delete_nonexistent_run", "lineno": 236, "outcome": "passed", "keywords": ["test_delete_nonexistent_run", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001319649163633585, "outcome": "passed"}, "call": {"duration": 0.00010231498163193464, "outcome": "passed"}, "teardown": {"duration": 8.912407793104649e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_create_comparison", "lineno": 244, "outcome": "failed", "keywords": ["test_create_comparison", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014463195111602545, "outcome": "passed"}, "call": {"duration": 9.838002733886242e-05, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_storage.py", "lineno": 249, "message": "AttributeError: 'UUID' object has no attribute 'id'"}, "traceback": [{"path": "tests/experiment_tracking/test_storage.py", "lineno": 249, "message": "AttributeError"}], "longrepr": "storage = <researchtrack.experiment_tracking.storage.InMemoryExperimentStorage object at 0x7f6938762db0>\nsample_comparison = ExperimentComparison(id=UUID('9b1bf012-29b4-4313-af6c-1f3cd4cedc27'), name='Test Comparison', description='A test comp...eriment_ids=[], run_ids=[], metrics=['accuracy', 'loss'], created_at=datetime.datetime(2025, 5, 15, 2, 34, 10, 672646))\n\n    def test_create_comparison(storage, sample_comparison):\n        \"\"\"Test creating a comparison in storage.\"\"\"\n        created = storage.create_comparison(sample_comparison)\n    \n>       assert created.id == sample_comparison.id\nE       AttributeError: 'UUID' object has no attribute 'id'\n\ntests/experiment_tracking/test_storage.py:249: AttributeError"}, "teardown": {"duration": 0.00013143394608050585, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_get_comparison", "lineno": 254, "outcome": "passed", "keywords": ["test_get_comparison", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00015810399781912565, "outcome": "passed"}, "call": {"duration": 8.945597801357508e-05, "outcome": "passed"}, "teardown": {"duration": 9.03840409591794e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_update_comparison", "lineno": 264, "outcome": "failed", "keywords": ["test_update_comparison", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00015005504246801138, "outcome": "passed"}, "call": {"duration": 0.00010265491437166929, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_storage.py", "lineno": 273, "message": "AttributeError: 'bool' object has no attribute 'name'"}, "traceback": [{"path": "tests/experiment_tracking/test_storage.py", "lineno": 273, "message": "AttributeError"}], "longrepr": "storage = <researchtrack.experiment_tracking.storage.InMemoryExperimentStorage object at 0x7f6938602720>\nsample_comparison = ExperimentComparison(id=UUID('2efdf87b-d360-4626-b0aa-339a7d9e6440'), name='Updated Comparison', description='A test c...eriment_ids=[], run_ids=[], metrics=['accuracy', 'loss'], created_at=datetime.datetime(2025, 5, 15, 2, 34, 10, 677389))\n\n    def test_update_comparison(storage, sample_comparison):\n        \"\"\"Test updating a comparison in storage.\"\"\"\n        storage.create_comparison(sample_comparison)\n    \n        # Update the comparison\n        sample_comparison.name = \"Updated Comparison\"\n        updated = storage.update_comparison(sample_comparison)\n    \n>       assert updated.name == \"Updated Comparison\"\nE       AttributeError: 'bool' object has no attribute 'name'\n\ntests/experiment_tracking/test_storage.py:273: AttributeError"}, "teardown": {"duration": 0.0001374630955979228, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_update_nonexistent_comparison", "lineno": 279, "outcome": "failed", "keywords": ["test_update_nonexistent_comparison", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00011982000432908535, "outcome": "passed"}, "call": {"duration": 0.00016646203584969044, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_storage.py", "lineno": 285, "message": "assert False is None"}, "traceback": [{"path": "tests/experiment_tracking/test_storage.py", "lineno": 285, "message": "AssertionError"}], "longrepr": "storage = <researchtrack.experiment_tracking.storage.InMemoryExperimentStorage object at 0x7f6938601310>\n\n    def test_update_nonexistent_comparison(storage):\n        \"\"\"Test updating a comparison that doesn't exist.\"\"\"\n        comparison = ExperimentComparison(name=\"Nonexistent Comparison\")\n        updated = storage.update_comparison(comparison)\n    \n>       assert updated is None\nE       assert False is None\n\ntests/experiment_tracking/test_storage.py:285: AssertionError"}, "teardown": {"duration": 0.0001391629921272397, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_delete_comparison", "lineno": 287, "outcome": "passed", "keywords": ["test_delete_comparison", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00015798397362232208, "outcome": "passed"}, "call": {"duration": 9.241898078471422e-05, "outcome": "passed"}, "teardown": {"duration": 9.325705468654633e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_delete_nonexistent_comparison", "lineno": 296, "outcome": "passed", "keywords": ["test_delete_nonexistent_comparison", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00011827598791569471, "outcome": "passed"}, "call": {"duration": 9.253202006220818e-05, "outcome": "passed"}, "teardown": {"duration": 8.119107224047184e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_storage.py::test_list_comparisons", "lineno": 304, "outcome": "passed", "keywords": ["test_list_comparisons", "test_storage.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00013691396452486515, "outcome": "passed"}, "call": {"duration": 0.0001026540994644165, "outcome": "passed"}, "teardown": {"duration": 8.556304965168238e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_parameter_table", "lineno": 130, "outcome": "failed", "keywords": ["test_format_parameter_table", "test_visualizer.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0002237099688500166, "outcome": "passed"}, "call": {"duration": 0.00017774105072021484, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_visualizer.py", "lineno": 138, "message": "AssertionError: assert '| dropout | float | 0.5 | |' in '| Parameter | Type | Value | Description |\\n| --- | --- | --- | --- |\\n| learning_rate | float | 0.001 | Learning rate for optimizer |\\n| batch_size | integer | 32 | Training batch size |\\n| dropout | float | 0.5 |  |'"}, "traceback": [{"path": "tests/experiment_tracking/test_visualizer.py", "lineno": 138, "message": "AssertionError"}], "longrepr": "visualizer = <researchtrack.experiment_tracking.visualizer.ExperimentVisualizer object at 0x7f69386d82f0>\nsample_run = ExperimentRun(id=UUID('d0b1fe59-abbd-4e3b-8d02-2a8a496f3743'), experiment_id=UUID('d8a91f73-4573-4747-adf6-c7b596ffc65...e(2023, 1, 1, 10, 0), end_time=datetime.datetime(2023, 1, 1, 10, 30), notes='This run tested a modified architecture.')\n\n    def test_format_parameter_table(visualizer, sample_run):\n        \"\"\"Test formatting parameters as a markdown table.\"\"\"\n        table = visualizer.format_parameter_table(sample_run)\n    \n        assert \"| Parameter | Type | Value | Description |\" in table\n        assert \"| learning_rate | float | 0.001 | Learning rate for optimizer |\" in table\n        assert \"| batch_size | integer | 32 | Training batch size |\" in table\n>       assert \"| dropout | float | 0.5 | |\" in table\nE       AssertionError: assert '| dropout | float | 0.5 | |' in '| Parameter | Type | Value | Description |\\n| --- | --- | --- | --- |\\n| learning_rate | float | 0.001 | Learning rate for optimizer |\\n| batch_size | integer | 32 | Training batch size |\\n| dropout | float | 0.5 |  |'\n\ntests/experiment_tracking/test_visualizer.py:138: AssertionError"}, "teardown": {"duration": 0.00012915197294205427, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_empty_parameter_table", "lineno": 140, "outcome": "passed", "keywords": ["test_format_empty_parameter_table", "test_visualizer.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012293504551053047, "outcome": "passed"}, "call": {"duration": 0.00010836997535079718, "outcome": "passed"}, "teardown": {"duration": 8.539599366486073e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_metric_table", "lineno": 148, "outcome": "passed", "keywords": ["test_format_metric_table", "test_visualizer.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00020305695943534374, "outcome": "passed"}, "call": {"duration": 0.00013069307897239923, "outcome": "passed"}, "teardown": {"duration": 8.857296779751778e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_empty_metric_table", "lineno": 160, "outcome": "passed", "keywords": ["test_format_empty_metric_table", "test_visualizer.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001033400185406208, "outcome": "passed"}, "call": {"duration": 0.00010208203457295895, "outcome": "passed"}, "teardown": {"duration": 8.209003135561943e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_artifact_table", "lineno": 168, "outcome": "passed", "keywords": ["test_format_artifact_table", "test_visualizer.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0003144190413877368, "outcome": "passed"}, "call": {"duration": 0.0001277249539270997, "outcome": "passed"}, "teardown": {"duration": 0.0001016249880194664, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_empty_artifact_table", "lineno": 177, "outcome": "passed", "keywords": ["test_format_empty_artifact_table", "test_visualizer.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012485496699810028, "outcome": "passed"}, "call": {"duration": 0.00011532602366060019, "outcome": "passed"}, "teardown": {"duration": 8.852803148329258e-05, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_run_summary", "lineno": 185, "outcome": "passed", "keywords": ["test_format_run_summary", "test_visualizer.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00018176797311753035, "outcome": "passed"}, "call": {"duration": 0.0001424560323357582, "outcome": "passed"}, "teardown": {"duration": 0.00010077795013785362, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_experiment_summary", "lineno": 210, "outcome": "failed", "keywords": ["test_format_experiment_summary", "test_visualizer.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00019644293934106827, "outcome": "passed"}, "call": {"duration": 0.00021558499429374933, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_visualizer.py", "lineno": 227, "message": "AssertionError: assert '| 3 | running | 2023-01-01 12:00:00 | - | |' in '# Experiment: Test Experiment\\n\\nA test experiment for neural network architectures\\n\\n**Created**: 2023-01-01 09:00:...eted | 2023-01-01 11:00:00 | 2700.00s | accuracy: 0.9500, loss: 0.0500 |\\n| 3 | running | 2023-01-01 12:00:00 | - |  |'"}, "traceback": [{"path": "tests/experiment_tracking/test_visualizer.py", "lineno": 227, "message": "AssertionError"}], "longrepr": "visualizer = <researchtrack.experiment_tracking.visualizer.ExperimentVisualizer object at 0x7f69386d9790>\nsample_experiment = Experiment(id=UUID('6cf269b5-80a6-482e-8819-3dbfbe273492'), name='Test Experiment', description='A test experiment for...me=datetime.datetime(2023, 1, 1, 12, 0), end_time=None, notes=None)], tags=['test', 'neural-network', 'deep-learning'])\n\n    def test_format_experiment_summary(visualizer, sample_experiment):\n        \"\"\"Test formatting a complete experiment summary.\"\"\"\n        summary = visualizer.format_experiment_summary(sample_experiment)\n    \n        # Check for all major sections\n        assert \"# Experiment: Test Experiment\" in summary\n        assert \"A test experiment for neural network architectures\" in summary\n        assert \"**Created**: 2023-01-01 09:00:00\" in summary\n        assert \"**Last Updated**: 2023-01-01 11:00:00\" in summary\n        assert \"**Tags**: test, neural-network, deep-learning\" in summary\n        assert f\"**Runs ({len(sample_experiment.runs)})**\" in summary\n    \n        # Check for run information in the table\n        assert \"| Run # | Status | Start Time | Duration | Key Metrics |\" in summary\n        assert \"| 1 | completed | 2023-01-01 10:00:00 | 1800.00s | accuracy: 0.9200, loss: 0.0800 |\" in summary\n        assert \"| 2 | completed | 2023-01-01 11:00:00 | 2700.00s | accuracy: 0.9500, loss: 0.0500 |\" in summary\n>       assert \"| 3 | running | 2023-01-01 12:00:00 | - | |\" in summary\nE       AssertionError: assert '| 3 | running | 2023-01-01 12:00:00 | - | |' in '# Experiment: Test Experiment\\n\\nA test experiment for neural network architectures\\n\\n**Created**: 2023-01-01 09:00:...eted | 2023-01-01 11:00:00 | 2700.00s | accuracy: 0.9500, loss: 0.0500 |\\n| 3 | running | 2023-01-01 12:00:00 | - |  |'\n\ntests/experiment_tracking/test_visualizer.py:227: AssertionError"}, "teardown": {"duration": 0.0001346800709143281, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_comparison_table", "lineno": 229, "outcome": "failed", "keywords": ["test_format_comparison_table", "test_visualizer.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012448604684323072, "outcome": "passed"}, "call": {"duration": 0.00021841202396899462, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/experiment_tracking/test_visualizer.py", "lineno": 258, "message": "AssertionError: assert '| Run/Experiment | accuracy | f1 | loss | precision |' in '|Run/Experiment|accuracy|f1|loss|precision|\\n|---|---|---|---|---|\\n|ExperimentA:Run1|0.92|0.91|0.08|-|\\n|ExperimentA:Run2|0.95|0.94|0.05|-|\\n|ExperimentB:Run1|0.90|-|0.10|0.89|\\n|ExperimentB:Best|0.93|-|0.07|0.92|'\n +  where '|Run/Experiment|accuracy|f1|loss|precision|\\n|---|---|---|---|---|\\n|ExperimentA:Run1|0.92|0.91|0.08|-|\\n|ExperimentA:Run2|0.95|0.94|0.05|-|\\n|ExperimentB:Run1|0.90|-|0.10|0.89|\\n|ExperimentB:Best|0.93|-|0.07|0.92|' = <built-in method replace of str object at 0x7f69389717f0>(' ', '')\n +    where <built-in method replace of str object at 0x7f69389717f0> = '| Run/Experiment | accuracy | f1 | loss | precision |\\n| --- | --- | --- | --- | --- |\\n| Experiment A:Run 1 | 0.92 |...5 | 0.94 | 0.05 | - |\\n| Experiment B:Run 1 | 0.90 | - | 0.10 | 0.89 |\\n| Experiment B:Best | 0.93 | - | 0.07 | 0.92 |'.replace"}, "traceback": [{"path": "tests/experiment_tracking/test_visualizer.py", "lineno": 258, "message": "AssertionError"}], "longrepr": "visualizer = <researchtrack.experiment_tracking.visualizer.ExperimentVisualizer object at 0x7f69386da1b0>\n\n    def test_format_comparison_table(visualizer):\n        \"\"\"Test formatting a comparison table of multiple runs/experiments.\"\"\"\n        comparison_data = {\n            \"Experiment A:Run 1\": {\n                \"accuracy\": 0.92,\n                \"loss\": 0.08,\n                \"f1\": 0.91\n            },\n            \"Experiment A:Run 2\": {\n                \"accuracy\": 0.95,\n                \"loss\": 0.05,\n                \"f1\": 0.94\n            },\n            \"Experiment B:Run 1\": {\n                \"accuracy\": 0.90,\n                \"loss\": 0.10,\n                \"precision\": 0.89\n            },\n            \"Experiment B:Best\": {\n                \"accuracy\": 0.93,\n                \"loss\": 0.07,\n                \"precision\": 0.92\n            }\n        }\n    \n        table = visualizer.format_comparison_table(comparison_data)\n    \n        # Check for table header and all metrics\n>       assert \"| Run/Experiment | accuracy | f1 | loss | precision |\" in table.replace(\" \", \"\")\nE       AssertionError: assert '| Run/Experiment | accuracy | f1 | loss | precision |' in '|Run/Experiment|accuracy|f1|loss|precision|\\n|---|---|---|---|---|\\n|ExperimentA:Run1|0.92|0.91|0.08|-|\\n|ExperimentA:Run2|0.95|0.94|0.05|-|\\n|ExperimentB:Run1|0.90|-|0.10|0.89|\\n|ExperimentB:Best|0.93|-|0.07|0.92|'\nE        +  where '|Run/Experiment|accuracy|f1|loss|precision|\\n|---|---|---|---|---|\\n|ExperimentA:Run1|0.92|0.91|0.08|-|\\n|ExperimentA:Run2|0.95|0.94|0.05|-|\\n|ExperimentB:Run1|0.90|-|0.10|0.89|\\n|ExperimentB:Best|0.93|-|0.07|0.92|' = <built-in method replace of str object at 0x7f69389717f0>(' ', '')\nE        +    where <built-in method replace of str object at 0x7f69389717f0> = '| Run/Experiment | accuracy | f1 | loss | precision |\\n| --- | --- | --- | --- | --- |\\n| Experiment A:Run 1 | 0.92 |...5 | 0.94 | 0.05 | - |\\n| Experiment B:Run 1 | 0.90 | - | 0.10 | 0.89 |\\n| Experiment B:Best | 0.93 | - | 0.07 | 0.92 |'.replace\n\ntests/experiment_tracking/test_visualizer.py:258: AssertionError"}, "teardown": {"duration": 0.00012889597564935684, "outcome": "passed"}}, {"nodeid": "tests/experiment_tracking/test_visualizer.py::test_format_empty_comparison_table", "lineno": 284, "outcome": "passed", "keywords": ["test_format_empty_comparison_table", "test_visualizer.py", "experiment_tracking", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00011833501048386097, "outcome": "passed"}, "call": {"duration": 8.69539799168706e-05, "outcome": "passed"}, "teardown": {"duration": 8.577201515436172e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_formatter.py::test_format_document_default", "lineno": 51, "outcome": "passed", "keywords": ["test_format_document_default", "test_formatter.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0004093049792572856, "outcome": "passed"}, "call": {"duration": 0.00017041608225554228, "outcome": "passed"}, "teardown": {"duration": 9.636592585593462e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_formatter.py::test_format_document_nature", "lineno": 89, "outcome": "passed", "keywords": ["test_format_document_nature", "test_formatter.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00020211003720760345, "outcome": "passed"}, "call": {"duration": 0.00024140696041285992, "outcome": "passed"}, "teardown": {"duration": 9.194400627166033e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_formatter.py::test_format_document_science", "lineno": 100, "outcome": "passed", "keywords": ["test_format_document_science", "test_formatter.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00019652594346553087, "outcome": "passed"}, "call": {"duration": 0.00010975904297083616, "outcome": "passed"}, "teardown": {"duration": 8.579902350902557e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_formatter.py::test_format_document_plos", "lineno": 109, "outcome": "passed", "keywords": ["test_format_document_plos", "test_formatter.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00018924300093203783, "outcome": "passed"}, "call": {"duration": 0.00010992598254233599, "outcome": "passed"}, "teardown": {"duration": 8.851499296724796e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_formatter.py::test_format_section", "lineno": 118, "outcome": "passed", "keywords": ["test_format_section", "test_formatter.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00010228203609585762, "outcome": "passed"}, "call": {"duration": 0.00011174404062330723, "outcome": "passed"}, "teardown": {"duration": 8.08140030130744e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_formatter.py::test_format_text_block", "lineno": 133, "outcome": "passed", "keywords": ["test_format_text_block", "test_formatter.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 9.993801359087229e-05, "outcome": "passed"}, "call": {"duration": 9.535008575767279e-05, "outcome": "passed"}, "teardown": {"duration": 8.166895713657141e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_formatter.py::test_format_image_block", "lineno": 141, "outcome": "passed", "keywords": ["test_format_image_block", "test_formatter.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00010657403618097305, "outcome": "passed"}, "call": {"duration": 9.896699339151382e-05, "outcome": "passed"}, "teardown": {"duration": 8.186197374016047e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_formatter.py::test_format_table_block", "lineno": 153, "outcome": "passed", "keywords": ["test_format_table_block", "test_formatter.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 9.894708637148142e-05, "outcome": "passed"}, "call": {"duration": 0.00010016700252890587, "outcome": "passed"}, "teardown": {"duration": 7.842190098017454e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_formatter.py::test_format_code_block", "lineno": 171, "outcome": "passed", "keywords": ["test_format_code_block", "test_formatter.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00010521593503654003, "outcome": "passed"}, "call": {"duration": 9.532901458442211e-05, "outcome": "passed"}, "teardown": {"duration": 7.874297443777323e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_formatter.py::test_format_equation_block", "lineno": 186, "outcome": "passed", "keywords": ["test_format_equation_block", "test_formatter.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001020330237224698, "outcome": "passed"}, "call": {"duration": 9.15860291570425e-05, "outcome": "passed"}, "teardown": {"duration": 7.904705125838518e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_formatter.py::test_format_citation_block", "lineno": 194, "outcome": "passed", "keywords": ["test_format_citation_block", "test_formatter.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00011112703941762447, "outcome": "passed"}, "call": {"duration": 9.925791528075933e-05, "outcome": "passed"}, "teardown": {"duration": 8.261401671916246e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_models.py::test_document_creation", "lineno": 10, "outcome": "passed", "keywords": ["test_document_creation", "test_models.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 9.15030250325799e-05, "outcome": "passed"}, "call": {"duration": 0.00010960304643958807, "outcome": "passed"}, "teardown": {"duration": 7.397693116217852e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_models.py::test_section_creation", "lineno": 32, "outcome": "passed", "keywords": ["test_section_creation", "test_models.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.391802500933409e-05, "outcome": "passed"}, "call": {"duration": 0.00010643899440765381, "outcome": "passed"}, "teardown": {"duration": 7.322896271944046e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_models.py::test_text_block", "lineno": 49, "outcome": "passed", "keywords": ["test_text_block", "test_models.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 8.854304905980825e-05, "outcome": "passed"}, "call": {"duration": 9.291793685406446e-05, "outcome": "passed"}, "teardown": {"duration": 7.187202572822571e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_models.py::test_image_block", "lineno": 58, "outcome": "passed", "keywords": ["test_image_block", "test_models.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.346202619373798e-05, "outcome": "passed"}, "call": {"duration": 9.476603008806705e-05, "outcome": "passed"}, "teardown": {"duration": 7.291603833436966e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_models.py::test_table_block", "lineno": 73, "outcome": "passed", "keywords": ["test_table_block", "test_models.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.401895709335804e-05, "outcome": "passed"}, "call": {"duration": 9.707792196422815e-05, "outcome": "passed"}, "teardown": {"duration": 7.23780831322074e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_models.py::test_code_block", "lineno": 93, "outcome": "passed", "keywords": ["test_code_block", "test_models.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.250101771205664e-05, "outcome": "passed"}, "call": {"duration": 9.237299673259258e-05, "outcome": "passed"}, "teardown": {"duration": 7.244804874062538e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_models.py::test_equation_block", "lineno": 107, "outcome": "passed", "keywords": ["test_equation_block", "test_models.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.30069587007165e-05, "outcome": "passed"}, "call": {"duration": 9.132002014666796e-05, "outcome": "passed"}, "teardown": {"duration": 7.658102549612522e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_models.py::test_citation_block", "lineno": 117, "outcome": "passed", "keywords": ["test_citation_block", "test_models.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.510196883231401e-05, "outcome": "passed"}, "call": {"duration": 9.59599856287241e-05, "outcome": "passed"}, "teardown": {"duration": 7.18460651114583e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_models.py::test_document_with_sections_and_blocks", "lineno": 129, "outcome": "passed", "keywords": ["test_document_with_sections_and_blocks", "test_models.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.422303315252066e-05, "outcome": "passed"}, "call": {"duration": 0.00012769002933055162, "outcome": "passed"}, "teardown": {"duration": 8.076801896095276e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_service.py::test_create_document", "lineno": 22, "outcome": "passed", "keywords": ["test_create_document", "test_service.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014775095041841269, "outcome": "passed"}, "call": {"duration": 0.0001124669797718525, "outcome": "passed"}, "teardown": {"duration": 9.672995656728745e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_service.py::test_get_document", "lineno": 42, "outcome": "passed", "keywords": ["test_get_document", "test_service.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014317210298031569, "outcome": "passed"}, "call": {"duration": 0.00010612001642584801, "outcome": "passed"}, "teardown": {"duration": 8.924503345042467e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_service.py::test_update_document", "lineno": 52, "outcome": "passed", "keywords": ["test_update_document", "test_service.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001208320027217269, "outcome": "passed"}, "call": {"duration": 0.00011576595716178417, "outcome": "passed"}, "teardown": {"duration": 9.501294698566198e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_service.py::test_delete_document", "lineno": 65, "outcome": "passed", "keywords": ["test_delete_document", "test_service.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012073398102074862, "outcome": "passed"}, "call": {"duration": 0.00010186503641307354, "outcome": "passed"}, "teardown": {"duration": 8.807005360722542e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_service.py::test_add_section", "lineno": 74, "outcome": "passed", "keywords": ["test_add_section", "test_service.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00011750799603760242, "outcome": "passed"}, "call": {"duration": 0.0005256860749796033, "outcome": "passed"}, "teardown": {"duration": 0.0001122219255194068, "outcome": "passed"}}, {"nodeid": "tests/export/test_service.py::test_add_section_with_order", "lineno": 88, "outcome": "passed", "keywords": ["test_add_section_with_order", "test_service.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00013626692816615105, "outcome": "passed"}, "call": {"duration": 0.00013568007852882147, "outcome": "passed"}, "teardown": {"duration": 9.334797505289316e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_service.py::test_add_content_block", "lineno": 105, "outcome": "passed", "keywords": ["test_add_content_block", "test_service.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012814602814614773, "outcome": "passed"}, "call": {"duration": 0.00014188699424266815, "outcome": "passed"}, "teardown": {"duration": 9.258103091269732e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_service.py::test_create_content_blocks", "lineno": 122, "outcome": "passed", "keywords": ["test_create_content_blocks", "test_service.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00013386004138737917, "outcome": "passed"}, "call": {"duration": 0.00013605004642158747, "outcome": "passed"}, "teardown": {"duration": 9.331502951681614e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_service.py::test_generate_markdown", "lineno": 163, "outcome": "passed", "keywords": ["test_generate_markdown", "test_service.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012341805268079042, "outcome": "passed"}, "call": {"duration": 0.00013457005843520164, "outcome": "passed"}, "teardown": {"duration": 9.110500104725361e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_service.py::test_export_to_file", "lineno": 183, "outcome": "passed", "keywords": ["test_export_to_file", "test_service.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012265006080269814, "outcome": "passed"}, "call": {"duration": 0.0009479669388383627, "outcome": "passed"}, "teardown": {"duration": 0.00011072203051298857, "outcome": "passed"}}, {"nodeid": "tests/export/test_storage.py::test_create_document", "lineno": 30, "outcome": "passed", "keywords": ["test_create_document", "test_storage.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00018804799765348434, "outcome": "passed"}, "call": {"duration": 9.336101356893778e-05, "outcome": "passed"}, "teardown": {"duration": 8.828402496874332e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_storage.py::test_get_document", "lineno": 40, "outcome": "passed", "keywords": ["test_get_document", "test_storage.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00017593393567949533, "outcome": "passed"}, "call": {"duration": 9.937398135662079e-05, "outcome": "passed"}, "teardown": {"duration": 8.877809159457684e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_storage.py::test_get_nonexistent_document", "lineno": 50, "outcome": "passed", "keywords": ["test_get_nonexistent_document", "test_storage.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00010322895832359791, "outcome": "passed"}, "call": {"duration": 8.980301208794117e-05, "outcome": "passed"}, "teardown": {"duration": 8.502497803419828e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_storage.py::test_update_document", "lineno": 59, "outcome": "passed", "keywords": ["test_update_document", "test_storage.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001698819687590003, "outcome": "passed"}, "call": {"duration": 9.1206980869174e-05, "outcome": "passed"}, "teardown": {"duration": 8.49839998409152e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_storage.py::test_update_nonexistent_document", "lineno": 72, "outcome": "passed", "keywords": ["test_update_nonexistent_document", "test_storage.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00010346097405999899, "outcome": "passed"}, "call": {"duration": 9.905605111271143e-05, "outcome": "passed"}, "teardown": {"duration": 7.912004366517067e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_storage.py::test_delete_document", "lineno": 80, "outcome": "passed", "keywords": ["test_delete_document", "test_storage.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014832289889454842, "outcome": "passed"}, "call": {"duration": 8.378003258258104e-05, "outcome": "passed"}, "teardown": {"duration": 8.313602302223444e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_storage.py::test_delete_nonexistent_document", "lineno": 89, "outcome": "passed", "keywords": ["test_delete_nonexistent_document", "test_storage.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 9.695393964648247e-05, "outcome": "passed"}, "call": {"duration": 8.680194150656462e-05, "outcome": "passed"}, "teardown": {"duration": 7.932493463158607e-05, "outcome": "passed"}}, {"nodeid": "tests/export/test_storage.py::test_list_documents", "lineno": 98, "outcome": "passed", "keywords": ["test_list_documents", "test_storage.py", "export", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014665897469967604, "outcome": "passed"}, "call": {"duration": 0.00010784598998725414, "outcome": "passed"}, "teardown": {"duration": 9.003700688481331e-05, "outcome": "passed"}}, {"nodeid": "tests/integration/test_multitask_workflow.py::test_multitask_research_project", "lineno": 39, "outcome": "failed", "keywords": ["test_multitask_research_project", "test_multitask_workflow.py", "integration", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0003055410925298929, "outcome": "passed"}, "call": {"duration": 0.00013940292410552502, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/integration/test_multitask_workflow.py", "lineno": 62, "message": "AttributeError: 'UUID' object has no attribute 'id'"}, "traceback": [{"path": "tests/integration/test_multitask_workflow.py", "lineno": 62, "message": "AttributeError"}], "longrepr": "services = {'bibliography': <researchtrack.bibliography.service.BibliographyService object at 0x7f6938601670>, 'dataset': <resear...69386034d0>, 'experiment': <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f69386026c0>, ...}\n\n    def test_multitask_research_project(services):\n        \"\"\"\n        Test a research project with multiple interconnected tasks.\n    \n        This test simulates a complex research project with:\n        1. A main research task with subtasks\n        2. Shared bibliographic references\n        3. Datasets that evolve across tasks\n        4. Multiple experiment runs with comparisons\n        5. Consolidated reporting\n        \"\"\"\n        # 1. Create main research task\n        main_task = services[\"task\"].create_task(\n            title=\"Improving NLP Models for Scientific Literature\",\n            description=\"Research project to improve NLP models for scientific literature analysis\",\n            tags=[\"nlp\", \"science\", \"literature\"]\n        )\n    \n        # Create subtasks\n        data_task = services[\"task\"].create_task(\n            title=\"Data Collection and Preprocessing\",\n            description=\"Collect and preprocess scientific papers dataset\",\n>           parent_id=main_task.id,\n            tags=[\"data\", \"preprocessing\"]\n        )\nE       AttributeError: 'UUID' object has no attribute 'id'\n\ntests/integration/test_multitask_workflow.py:62: AttributeError"}, "teardown": {"duration": 0.00015362701378762722, "outcome": "passed"}}, {"nodeid": "tests/integration/test_research_workflow.py::test_complete_research_workflow", "lineno": 39, "outcome": "failed", "keywords": ["test_complete_research_workflow", "test_research_workflow.py", "integration", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00014609494246542454, "outcome": "passed"}, "call": {"duration": 0.00013645703438669443, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/integration/test_research_workflow.py", "lineno": 60, "message": "AttributeError: 'UUID' object has no attribute 'id'"}, "traceback": [{"path": "tests/integration/test_research_workflow.py", "lineno": 60, "message": "AttributeError"}], "longrepr": "services = {'bibliography': <researchtrack.bibliography.service.BibliographyService object at 0x7f69386291f0>, 'dataset': <resear...69386292e0>, 'experiment': <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f6938629310>, ...}\n\n    def test_complete_research_workflow(services):\n        \"\"\"\n        Test a complete research workflow from task creation to publication.\n    \n        This test simulates a research workflow where:\n        1. A research task is created\n        2. Bibliographic references are added\n        3. A dataset is versioned\n        4. The computational environment is captured\n        5. Experiments are run\n        6. Results are exported as an academic document\n        \"\"\"\n        # 1. Create a research task\n        task = services[\"task\"].create_task(\n            title=\"Investigate Neural Network Performance\",\n            description=\"Investigate performance of different neural network architectures on image classification\"\n        )\n    \n        # Add research questions\n        question = services[\"task\"].create_research_question(\n>           task_id=task.id,\n            question=\"Which neural network architecture performs best on image classification?\"\n        )\nE       AttributeError: 'UUID' object has no attribute 'id'\n\ntests/integration/test_research_workflow.py:60: AttributeError"}, "teardown": {"duration": 0.00012611295096576214, "outcome": "passed"}}, {"nodeid": "tests/performance/test_bibliography_performance.py::TestBibliographyPerformance::test_large_bibliography_operations", "lineno": 23, "outcome": "failed", "keywords": ["test_large_bibliography_operations", "TestBibliographyPerformance", "test_bibliography_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0003182570217177272, "outcome": "passed"}, "call": {"duration": 0.00010936998296529055, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/performance/test_bibliography_performance.py", "lineno": 35, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_person_author'"}, "traceback": [{"path": "tests/performance/test_bibliography_performance.py", "lineno": 35, "message": "AttributeError"}], "longrepr": "self = <tests.performance.test_bibliography_performance.TestBibliographyPerformance object at 0x7f6938800a40>\n\n    def test_large_bibliography_operations(self):\n        \"\"\"Test performance with a large bibliography (10,000+ references).\"\"\"\n        # Create a large number of references\n        reference_ids = []\n    \n        # Create 10,000 references\n        start_time = time.time()\n    \n        # Pre-generate some authors to reuse\n        authors = []\n        for i in range(1000):  # 1000 different authors\n>           author = self.service.create_person_author(\n                first_name=f\"FirstName{i}\",\n                last_name=f\"LastName{i}\",\n            )\nE           AttributeError: 'BibliographyService' object has no attribute 'create_person_author'\n\ntests/performance/test_bibliography_performance.py:35: AttributeError"}, "teardown": {"duration": 0.00012876896653324366, "outcome": "passed"}}, {"nodeid": "tests/performance/test_bibliography_performance.py::TestBibliographyPerformance::test_task_reference_link_performance", "lineno": 160, "outcome": "failed", "keywords": ["test_task_reference_link_performance", "TestBibliographyPerformance", "test_bibliography_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001561579992994666, "outcome": "passed"}, "call": {"duration": 0.0001063270028680563, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/performance/test_bibliography_performance.py", "lineno": 169, "message": "AttributeError: 'BibliographyService' object has no attribute 'create_person_author'"}, "traceback": [{"path": "tests/performance/test_bibliography_performance.py", "lineno": 169, "message": "AttributeError"}], "longrepr": "self = <tests.performance.test_bibliography_performance.TestBibliographyPerformance object at 0x7f6938800bf0>\n\n    def test_task_reference_link_performance(self):\n        \"\"\"Test performance with many task-reference links.\"\"\"\n        # Create references and tasks\n        reference_ids = []\n        task_ids = []\n    \n        # Create 1000 references\n        for i in range(1000):\n>           author = self.service.create_person_author(\n                first_name=f\"Author{i}\",\n                last_name=f\"LastName{i}\",\n            )\nE           AttributeError: 'BibliographyService' object has no attribute 'create_person_author'\n\ntests/performance/test_bibliography_performance.py:169: AttributeError"}, "teardown": {"duration": 0.00012949202209711075, "outcome": "passed"}}, {"nodeid": "tests/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_dataset_operations_performance", "lineno": 20, "outcome": "passed", "keywords": ["test_dataset_operations_performance", "TestDatasetVersioningPerformance", "test_dataset_versioning_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00016565294936299324, "outcome": "passed"}, "call": {"duration": 0.00014767295215278864, "outcome": "passed"}, "teardown": {"duration": 9.291607420891523e-05, "outcome": "passed"}}, {"nodeid": "tests/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_handle_large_dataset_catalog", "lineno": 57, "outcome": "failed", "keywords": ["test_handle_large_dataset_catalog", "TestDatasetVersioningPerformance", "test_dataset_versioning_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012084399349987507, "outcome": "passed"}, "call": {"duration": 0.009155755047686398, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/performance/test_dataset_versioning_performance.py", "lineno": 86, "message": "TypeError: DatasetVersioningService.list_datasets() got an unexpected keyword argument 'storage_type'"}, "traceback": [{"path": "tests/performance/test_dataset_versioning_performance.py", "lineno": 86, "message": "TypeError"}], "longrepr": "self = <tests.performance.test_dataset_versioning_performance.TestDatasetVersioningPerformance object at 0x7f69388015e0>\n\n    def test_handle_large_dataset_catalog(self):\n        \"\"\"Test performance with a large number of datasets (1000+).\"\"\"\n        dataset_ids = []\n    \n        # Create 1000 datasets\n        formats = list(DatasetFormat)\n        storage_types = list(DatasetStorageType)\n    \n        start_time = time.time()\n        for i in range(1000):\n            dataset_id = self.service.create_dataset(\n                name=f\"Dataset {i}\",\n                format=formats[i % len(formats)],\n                storage_type=storage_types[i % len(storage_types)],\n                location=f\"/path/to/data_{i}.csv\",\n                tags={f\"tag{i % 10}\", f\"category{i % 5}\"},\n            )\n            dataset_ids.append(dataset_id)\n    \n        creation_time = time.time() - start_time\n        avg_creation_time = creation_time / 1000\n    \n        # Test listing with various filters\n        start_time = time.time()\n        csv_datasets = self.service.list_datasets(format=DatasetFormat.CSV)\n        list_by_format_time = time.time() - start_time\n    \n        start_time = time.time()\n>       s3_datasets = self.service.list_datasets(storage_type=DatasetStorageType.S3)\nE       TypeError: DatasetVersioningService.list_datasets() got an unexpected keyword argument 'storage_type'\n\ntests/performance/test_dataset_versioning_performance.py:86: TypeError"}, "teardown": {"duration": 0.00012972101103514433, "outcome": "passed"}}, {"nodeid": "tests/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_handle_100gb_dataset_metadata", "lineno": 110, "outcome": "passed", "keywords": ["test_handle_100gb_dataset_metadata", "TestDatasetVersioningPerformance", "test_dataset_versioning_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00013374490663409233, "outcome": "passed"}, "call": {"duration": 0.0004011630080640316, "outcome": "passed"}, "teardown": {"duration": 9.654497262090445e-05, "outcome": "passed"}}, {"nodeid": "tests/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_complex_transformation_chain_performance", "lineno": 166, "outcome": "failed", "keywords": ["test_complex_transformation_chain_performance", "TestDatasetVersioningPerformance", "test_dataset_versioning_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001394239952787757, "outcome": "passed"}, "call": {"duration": 0.00017974001821130514, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/performance/test_dataset_versioning_performance.py", "lineno": 204, "message": "TypeError: DatasetVersioningService.create_data_transformation() got an unexpected keyword argument 'input_dataset_version_id'"}, "traceback": [{"path": "tests/performance/test_dataset_versioning_performance.py", "lineno": 204, "message": "TypeError"}], "longrepr": "self = <tests.performance.test_dataset_versioning_performance.TestDatasetVersioningPerformance object at 0x7f6938801940>\n\n    def test_complex_transformation_chain_performance(self):\n        \"\"\"Test performance with a complex chain of dataset transformations.\"\"\"\n        # Create a dataset\n        dataset_id = self.service.create_dataset(\n            name=\"Transformation Test Dataset\",\n            format=DatasetFormat.CSV,\n            storage_type=DatasetStorageType.S3,\n            location=\"s3://bucket/data.csv\",\n        )\n    \n        # Create a chain of 20 versions with transformations between them\n        version_ids = []\n        transformation_ids = []\n    \n        # Create first version\n        first_version_id = self.service.create_dataset_version(\n            dataset_id=dataset_id,\n            version_number=\"1.0.0\",\n            location=\"s3://bucket/versions/1.0.0/data.csv\",\n        )\n        version_ids.append(first_version_id)\n    \n        # Create chain of versions and transformations\n        start_time = time.time()\n    \n        for i in range(1, 20):\n            # Create next version\n            next_version_id = self.service.create_dataset_version(\n                dataset_id=dataset_id,\n                version_number=f\"1.{i}.0\",\n                location=f\"s3://bucket/versions/1.{i}.0/data.csv\",\n                parent_version_id=version_ids[-1],\n            )\n            version_ids.append(next_version_id)\n    \n            # Create transformation between versions\n            transformation_type = list(DataTransformationType)[i % len(list(DataTransformationType))]\n>           transformation_id = self.service.create_data_transformation(\n                input_dataset_version_id=version_ids[-2],\n                output_dataset_version_id=version_ids[-1],\n                transformation_type=transformation_type,\n                name=f\"Transformation {i}\",\n                description=f\"Transform data from version 1.{i-1}.0 to 1.{i}.0\",\n                parameters={\n                    \"param1\": i,\n                    \"param2\": f\"value{i}\",\n                    \"param3\": [j for j in range(i)],\n                },\n            )\nE           TypeError: DatasetVersioningService.create_data_transformation() got an unexpected keyword argument 'input_dataset_version_id'\n\ntests/performance/test_dataset_versioning_performance.py:204: TypeError"}, "teardown": {"duration": 0.00013072893489152193, "outcome": "passed"}}, {"nodeid": "tests/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_task_dataset_link_performance", "lineno": 237, "outcome": "failed", "keywords": ["test_task_dataset_link_performance", "TestDatasetVersioningPerformance", "test_dataset_versioning_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001464060042053461, "outcome": "passed"}, "call": {"duration": 0.03727773006539792, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/performance/test_dataset_versioning_performance.py", "lineno": 305, "message": "IndexError: list index out of range"}, "traceback": [{"path": "tests/performance/test_dataset_versioning_performance.py", "lineno": 305, "message": "IndexError"}], "longrepr": "self = <tests.performance.test_dataset_versioning_performance.TestDatasetVersioningPerformance object at 0x7f6938801af0>\n\n    def test_task_dataset_link_performance(self):\n        \"\"\"Test performance with many task-dataset links.\"\"\"\n        # Create datasets and versions\n        dataset_ids = []\n        version_ids = []\n    \n        for i in range(10):\n            dataset_id = self.service.create_dataset(\n                name=f\"Dataset {i}\",\n                format=DatasetFormat.CSV,\n                storage_type=DatasetStorageType.LOCAL,\n                location=f\"/path/to/data_{i}.csv\",\n            )\n            dataset_ids.append(dataset_id)\n    \n            # Create 5 versions for each dataset\n            for j in range(5):\n                version_id = self.service.create_dataset_version(\n                    dataset_id=dataset_id,\n                    version_number=f\"1.{j}.0\",\n                    location=f\"/path/to/versions/dataset_{i}/1.{j}.0/data.csv\",\n                )\n                version_ids.append(version_id)\n    \n        # Create 100 task IDs\n        task_ids = [uuid4() for _ in range(100)]\n    \n        # Create links (each task uses 5-10 dataset versions)\n        link_ids = []\n    \n        start_time = time.time()\n        for i, task_id in enumerate(task_ids):\n            # Determine how many versions for this task\n            num_versions = 5 + (i % 6)  # 5-10 versions\n    \n            for j in range(num_versions):\n                # Pick a version (ensure distribution across all versions)\n                version_index = (i * 7 + j * 13) % len(version_ids)\n                version_id = version_ids[version_index]\n    \n                # Create the link\n                usage_type = \"input\" if j < 2 else \"reference\" if j < 5 else \"output\"\n                link_id = self.service.link_task_to_dataset_version(\n                    task_id=task_id,\n                    dataset_version_id=version_id,\n                    usage_type=usage_type,\n                    description=f\"Link {i}-{j} description\",\n                )\n                link_ids.append(link_id)\n    \n        link_creation_time = time.time() - start_time\n        avg_link_creation_time = link_creation_time / len(link_ids)\n    \n        # Test querying links\n        query_times = []\n        for i in range(20):  # Test with 20 random tasks\n            task_id = task_ids[i * 5]\n    \n            start_time = time.time()\n            versions = self.service.get_dataset_versions_by_task(task_id)\n            query_times.append(time.time() - start_time)\n    \n            start_time = time.time()\n            links = self.service.get_links_by_task(task_id)\n            query_times.append(time.time() - start_time)\n    \n        for i in range(20):  # Test with 20 random versions\n>           version_id = version_ids[i * 10]\nE           IndexError: list index out of range\n\ntests/performance/test_dataset_versioning_performance.py:305: IndexError"}, "teardown": {"duration": 0.00015443796291947365, "outcome": "passed"}}, {"nodeid": "tests/performance/test_environment_performance.py::TestEnvironmentPerformance::test_environment_operations_performance", "lineno": 21, "outcome": "failed", "keywords": ["test_environment_operations_performance", "TestEnvironmentPerformance", "test_environment_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.000163101009093225, "outcome": "passed"}, "call": {"duration": 0.00011286803055554628, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/performance/test_environment_performance.py", "lineno": 26, "message": "AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'"}, "traceback": [{"path": "tests/performance/test_environment_performance.py", "lineno": 26, "message": "AttributeError"}], "longrepr": "self = <tests.performance.test_environment_performance.TestEnvironmentPerformance object at 0x7f6938802390>\n\n    def test_environment_operations_performance(self):\n        \"\"\"Test performance of basic environment operations.\"\"\"\n        # Create an environment\n        start_time = time.time()\n>       env_id = self.service.create_environment_snapshot(\n            name=\"Performance Test Environment\",\n            environment_type=EnvironmentType.CONDA,\n            description=\"Environment for performance testing\",\n        )\nE       AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'\n\ntests/performance/test_environment_performance.py:26: AttributeError"}, "teardown": {"duration": 0.0001548730069771409, "outcome": "passed"}}, {"nodeid": "tests/performance/test_environment_performance.py::TestEnvironmentPerformance::test_environment_snapshot_generation_time", "lineno": 57, "outcome": "failed", "keywords": ["test_environment_snapshot_generation_time", "TestEnvironmentPerformance", "test_environment_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00015502795577049255, "outcome": "passed"}, "call": {"duration": 0.00010947301052510738, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/performance/test_environment_performance.py", "lineno": 63, "message": "TypeError: EnvironmentService.capture_current_environment() got an unexpected keyword argument 'environment_type'"}, "traceback": [{"path": "tests/performance/test_environment_performance.py", "lineno": 63, "message": "TypeError"}], "longrepr": "self = <tests.performance.test_environment_performance.TestEnvironmentPerformance object at 0x7f6938801700>\n\n    def test_environment_snapshot_generation_time(self):\n        \"\"\"Test that environment snapshots can be generated in under 5 seconds.\"\"\"\n        # Generate a comprehensive environment snapshot with all features\n        start_time = time.time()\n    \n>       env_id = self.service.capture_current_environment(\n            name=\"Comprehensive Snapshot\",\n            description=\"Complete environment snapshot with all details\",\n            environment_type=EnvironmentType.LOCAL,\n            include_packages=True,\n            include_env_vars=True,\n            tags={\"performance\", \"test\"},\n            custom_metadata={\"purpose\": \"performance testing\"},\n        )\nE       TypeError: EnvironmentService.capture_current_environment() got an unexpected keyword argument 'environment_type'\n\ntests/performance/test_environment_performance.py:63: TypeError"}, "teardown": {"duration": 0.00014000502415001392, "outcome": "passed"}}, {"nodeid": "tests/performance/test_environment_performance.py::TestEnvironmentPerformance::test_large_environment_catalog_performance", "lineno": 82, "outcome": "failed", "keywords": ["test_large_environment_catalog_performance", "TestEnvironmentPerformance", "test_environment_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00016174698248505592, "outcome": "passed"}, "call": {"duration": 0.0001441549975425005, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/performance/test_environment_performance.py", "lineno": 115, "message": "AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'"}, "traceback": [{"path": "tests/performance/test_environment_performance.py", "lineno": 115, "message": "AttributeError"}], "longrepr": "self = <tests.performance.test_environment_performance.TestEnvironmentPerformance object at 0x7f6938800b60>\n\n    def test_large_environment_catalog_performance(self):\n        \"\"\"Test performance with many environments and complex queries.\"\"\"\n        env_ids = []\n    \n        # Generate a variety of environment types\n        env_types = list(EnvironmentType)\n    \n        # Create 100 environments with varying characteristics\n        start_time = time.time()\n        for i in range(100):\n            env_type = env_types[i % len(env_types)]\n    \n            # Create a set of tags\n            tags = {\"env\" + str(i % 10)}\n            if i % 2 == 0:\n                tags.add(\"even\")\n            if i % 3 == 0:\n                tags.add(\"divisible-by-3\")\n            if i % 5 == 0:\n                tags.add(\"divisible-by-5\")\n    \n            # Create some packages\n            packages = []\n            for j in range(5):  # 5 packages per environment\n                packages.append(\n                    PackageInfo(\n                        name=f\"package-{j}\",\n                        version=f\"1.{i}.{j}\",\n                        manager=PackageManagerType.PIP,\n                    )\n                )\n    \n>           env_id = self.service.create_environment_snapshot(\n                name=f\"Environment {i}\",\n                environment_type=env_type,\n                description=f\"Description for environment {i}\",\n                python_version=f\"3.{i % 3 + 8}.{i % 10}\",  # Vary Python versions\n                packages=packages,\n                tags=tags,\n                custom_metadata={\"index\": i},\n            )\nE           AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'\n\ntests/performance/test_environment_performance.py:115: AttributeError"}, "teardown": {"duration": 0.0001365800853818655, "outcome": "passed"}}, {"nodeid": "tests/performance/test_environment_performance.py::TestEnvironmentPerformance::test_complex_environment_performance", "lineno": 161, "outcome": "failed", "keywords": ["test_complex_environment_performance", "TestEnvironmentPerformance", "test_environment_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00013964297249913216, "outcome": "passed"}, "call": {"duration": 0.0010848779929801822, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/performance/test_environment_performance.py", "lineno": 186, "message": "AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'"}, "traceback": [{"path": "tests/performance/test_environment_performance.py", "lineno": 186, "message": "AttributeError"}], "longrepr": "self = <tests.performance.test_environment_performance.TestEnvironmentPerformance object at 0x7f69388024b0>\n\n    def test_complex_environment_performance(self):\n        \"\"\"Test performance with a very complex environment configuration.\"\"\"\n        # Create a complex environment with many components\n        packages = []\n        for i in range(500):  # 500 packages\n            packages.append(\n                PackageInfo(\n                    name=f\"package-{i}\",\n                    version=f\"1.0.{i}\",\n                    manager=PackageManagerType.PIP if i % 2 == 0 else PackageManagerType.CONDA,\n                )\n            )\n    \n        # Create many environment variables\n        env_vars = {}\n        for i in range(200):  # 200 environment variables\n            env_vars[f\"ENV_VAR_{i}\"] = f\"value_{i}\"\n    \n        # Create configuration files\n        config_files = {}\n        for i in range(100):  # 100 config files\n            config_files[f\"/path/to/config_{i}.yaml\"] = f\"config: {i}\\nsettings:\\n  value: {i}\"\n    \n        start_time = time.time()\n>       env_id = self.service.create_environment_snapshot(\n            name=\"Complex Environment\",\n            environment_type=EnvironmentType.CONDA,\n            description=\"A very complex environment with many components\",\n            python_version=\"3.10.4\",\n            packages=packages,\n            environment_variables=env_vars,\n            config_files=config_files,\n            tags={\"complex\", \"test\", \"performance\"},\n        )\nE       AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'\n\ntests/performance/test_environment_performance.py:186: AttributeError"}, "teardown": {"duration": 0.00014117301907390356, "outcome": "passed"}}, {"nodeid": "tests/performance/test_environment_performance.py::TestEnvironmentPerformance::test_task_environment_link_performance", "lineno": 211, "outcome": "failed", "keywords": ["test_task_environment_link_performance", "TestEnvironmentPerformance", "test_environment_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00013942306395620108, "outcome": "passed"}, "call": {"duration": 0.00010573503095656633, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/performance/test_environment_performance.py", "lineno": 219, "message": "AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'"}, "traceback": [{"path": "tests/performance/test_environment_performance.py", "lineno": 219, "message": "AttributeError"}], "longrepr": "self = <tests.performance.test_environment_performance.TestEnvironmentPerformance object at 0x7f6938802660>\n\n    def test_task_environment_link_performance(self):\n        \"\"\"Test performance with many task-environment links.\"\"\"\n        # Create environments and task IDs\n        env_ids = []\n        task_ids = []\n    \n        for i in range(10):\n>           env_id = self.service.create_environment_snapshot(\n                name=f\"Environment {i}\",\n                environment_type=EnvironmentType.LOCAL,\n            )\nE           AttributeError: 'EnvironmentService' object has no attribute 'create_environment_snapshot'\n\ntests/performance/test_environment_performance.py:219: AttributeError"}, "teardown": {"duration": 0.00013994891196489334, "outcome": "passed"}}, {"nodeid": "tests/performance/test_experiment_tracking_performance.py::test_experiment_creation_performance", "lineno": 114, "outcome": "failed", "keywords": ["test_experiment_creation_performance", "test_experiment_tracking_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00013797101564705372, "outcome": "passed"}, "call": {"duration": 0.0001464280067011714, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/performance/test_experiment_tracking_performance.py", "lineno": 64, "message": "AttributeError: 'ExperimentService' object has no attribute 'add_parameter'. Did you mean: 'create_parameter'?"}, "traceback": [{"path": "tests/performance/test_experiment_tracking_performance.py", "lineno": 119, "message": ""}, {"path": "tests/performance/test_experiment_tracking_performance.py", "lineno": 64, "message": "AttributeError"}], "longrepr": "experiment_service = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f693826ba70>\n\n    def test_experiment_creation_performance(experiment_service):\n        \"\"\"Test the performance of creating an experiment with many runs.\"\"\"\n        start_time = time.time()\n    \n>       experiment, runs = create_experiment_with_runs(\n            experiment_service,\n            num_runs=20,\n            params_per_run=10,\n            metrics_per_run=10\n        )\n\ntests/performance/test_experiment_tracking_performance.py:119: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nservice = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f693826ba70>\nnum_runs = 20, params_per_run = 10, metrics_per_run = 10\n\n    def create_experiment_with_runs(service, num_runs=10, params_per_run=5, metrics_per_run=5):\n        \"\"\"Create an experiment with multiple runs for performance testing.\"\"\"\n        experiment = service.create_experiment(\n            name=f\"Performance Test Experiment with {num_runs} runs\",\n            description=\"Experiment created for performance testing\",\n            tags=[\"performance\", \"test\", \"benchmark\"]\n        )\n    \n        runs = []\n    \n        # Create multiple runs with parameters and metrics\n        for i in range(num_runs):\n            # Create parameters\n            parameters = []\n            for _ in range(params_per_run):\n                param_data = create_random_parameter()\n>               param = service.add_parameter(\n                    name=param_data[\"name\"],\n                    type=param_data[\"type\"],\n                    value=param_data[\"value\"],\n                    description=param_data[\"description\"]\n                )\nE               AttributeError: 'ExperimentService' object has no attribute 'add_parameter'. Did you mean: 'create_parameter'?\n\ntests/performance/test_experiment_tracking_performance.py:64: AttributeError"}, "teardown": {"duration": 0.00012753193732351065, "outcome": "passed"}}, {"nodeid": "tests/performance/test_experiment_tracking_performance.py::test_best_run_query_performance", "lineno": 138, "outcome": "failed", "keywords": ["test_best_run_query_performance", "test_experiment_tracking_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012153701391071081, "outcome": "passed"}, "call": {"duration": 0.00013813702389597893, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/performance/test_experiment_tracking_performance.py", "lineno": 64, "message": "AttributeError: 'ExperimentService' object has no attribute 'add_parameter'. Did you mean: 'create_parameter'?"}, "traceback": [{"path": "tests/performance/test_experiment_tracking_performance.py", "lineno": 141, "message": ""}, {"path": "tests/performance/test_experiment_tracking_performance.py", "lineno": 64, "message": "AttributeError"}], "longrepr": "experiment_service = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f693826b4d0>\n\n    def test_best_run_query_performance(experiment_service):\n        \"\"\"Test the performance of querying for the best run in an experiment.\"\"\"\n>       experiment, runs = create_experiment_with_runs(\n            experiment_service,\n            num_runs=50,\n            params_per_run=10,\n            metrics_per_run=10\n        )\n\ntests/performance/test_experiment_tracking_performance.py:141: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nservice = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f693826b4d0>\nnum_runs = 50, params_per_run = 10, metrics_per_run = 10\n\n    def create_experiment_with_runs(service, num_runs=10, params_per_run=5, metrics_per_run=5):\n        \"\"\"Create an experiment with multiple runs for performance testing.\"\"\"\n        experiment = service.create_experiment(\n            name=f\"Performance Test Experiment with {num_runs} runs\",\n            description=\"Experiment created for performance testing\",\n            tags=[\"performance\", \"test\", \"benchmark\"]\n        )\n    \n        runs = []\n    \n        # Create multiple runs with parameters and metrics\n        for i in range(num_runs):\n            # Create parameters\n            parameters = []\n            for _ in range(params_per_run):\n                param_data = create_random_parameter()\n>               param = service.add_parameter(\n                    name=param_data[\"name\"],\n                    type=param_data[\"type\"],\n                    value=param_data[\"value\"],\n                    description=param_data[\"description\"]\n                )\nE               AttributeError: 'ExperimentService' object has no attribute 'add_parameter'. Did you mean: 'create_parameter'?\n\ntests/performance/test_experiment_tracking_performance.py:64: AttributeError"}, "teardown": {"duration": 0.00012886000331491232, "outcome": "passed"}}, {"nodeid": "tests/performance/test_experiment_tracking_performance.py::test_comparison_performance", "lineno": 174, "outcome": "failed", "keywords": ["test_comparison_performance", "test_experiment_tracking_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012123002670705318, "outcome": "passed"}, "call": {"duration": 0.00013820407912135124, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/performance/test_experiment_tracking_performance.py", "lineno": 64, "message": "AttributeError: 'ExperimentService' object has no attribute 'add_parameter'. Did you mean: 'create_parameter'?"}, "traceback": [{"path": "tests/performance/test_experiment_tracking_performance.py", "lineno": 178, "message": ""}, {"path": "tests/performance/test_experiment_tracking_performance.py", "lineno": 64, "message": "AttributeError"}], "longrepr": "experiment_service = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f693829a5a0>\n\n    def test_comparison_performance(experiment_service):\n        \"\"\"Test the performance of creating and querying experiment comparisons.\"\"\"\n        # Create multiple experiments with runs\n>       experiment1, runs1 = create_experiment_with_runs(\n            experiment_service, num_runs=10, params_per_run=5, metrics_per_run=5\n        )\n\ntests/performance/test_experiment_tracking_performance.py:178: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nservice = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f693829a5a0>\nnum_runs = 10, params_per_run = 5, metrics_per_run = 5\n\n    def create_experiment_with_runs(service, num_runs=10, params_per_run=5, metrics_per_run=5):\n        \"\"\"Create an experiment with multiple runs for performance testing.\"\"\"\n        experiment = service.create_experiment(\n            name=f\"Performance Test Experiment with {num_runs} runs\",\n            description=\"Experiment created for performance testing\",\n            tags=[\"performance\", \"test\", \"benchmark\"]\n        )\n    \n        runs = []\n    \n        # Create multiple runs with parameters and metrics\n        for i in range(num_runs):\n            # Create parameters\n            parameters = []\n            for _ in range(params_per_run):\n                param_data = create_random_parameter()\n>               param = service.add_parameter(\n                    name=param_data[\"name\"],\n                    type=param_data[\"type\"],\n                    value=param_data[\"value\"],\n                    description=param_data[\"description\"]\n                )\nE               AttributeError: 'ExperimentService' object has no attribute 'add_parameter'. Did you mean: 'create_parameter'?\n\ntests/performance/test_experiment_tracking_performance.py:64: AttributeError"}, "teardown": {"duration": 0.00012813997454941273, "outcome": "passed"}}, {"nodeid": "tests/performance/test_experiment_tracking_performance.py::test_large_experiment_performance", "lineno": 228, "outcome": "failed", "keywords": ["test_large_experiment_performance", "test_experiment_tracking_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012182595673948526, "outcome": "passed"}, "call": {"duration": 0.0001403900096192956, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/performance/test_experiment_tracking_performance.py", "lineno": 64, "message": "AttributeError: 'ExperimentService' object has no attribute 'add_parameter'. Did you mean: 'create_parameter'?"}, "traceback": [{"path": "tests/performance/test_experiment_tracking_performance.py", "lineno": 233, "message": ""}, {"path": "tests/performance/test_experiment_tracking_performance.py", "lineno": 64, "message": "AttributeError"}], "longrepr": "experiment_service = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f693829b3b0>\n\n    def test_large_experiment_performance(experiment_service):\n        \"\"\"Test performance with a very large experiment with many runs.\"\"\"\n        start_time = time.time()\n    \n>       experiment, runs = create_experiment_with_runs(\n            experiment_service,\n            num_runs=100,\n            params_per_run=20,\n            metrics_per_run=20\n        )\n\ntests/performance/test_experiment_tracking_performance.py:233: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nservice = <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f693829b3b0>\nnum_runs = 100, params_per_run = 20, metrics_per_run = 20\n\n    def create_experiment_with_runs(service, num_runs=10, params_per_run=5, metrics_per_run=5):\n        \"\"\"Create an experiment with multiple runs for performance testing.\"\"\"\n        experiment = service.create_experiment(\n            name=f\"Performance Test Experiment with {num_runs} runs\",\n            description=\"Experiment created for performance testing\",\n            tags=[\"performance\", \"test\", \"benchmark\"]\n        )\n    \n        runs = []\n    \n        # Create multiple runs with parameters and metrics\n        for i in range(num_runs):\n            # Create parameters\n            parameters = []\n            for _ in range(params_per_run):\n                param_data = create_random_parameter()\n>               param = service.add_parameter(\n                    name=param_data[\"name\"],\n                    type=param_data[\"type\"],\n                    value=param_data[\"value\"],\n                    description=param_data[\"description\"]\n                )\nE               AttributeError: 'ExperimentService' object has no attribute 'add_parameter'. Did you mean: 'create_parameter'?\n\ntests/performance/test_experiment_tracking_performance.py:64: AttributeError"}, "teardown": {"duration": 0.0001338990405201912, "outcome": "passed"}}, {"nodeid": "tests/performance/test_export_performance.py::test_document_creation_performance", "lineno": 94, "outcome": "passed", "keywords": ["test_document_creation_performance", "test_export_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00013631803449243307, "outcome": "passed"}, "call": {"duration": 0.0023226740304380655, "outcome": "passed"}, "teardown": {"duration": 0.00010439602192491293, "outcome": "passed"}}, {"nodeid": "tests/performance/test_export_performance.py::test_markdown_generation_performance", "lineno": 116, "outcome": "passed", "keywords": ["test_markdown_generation_performance", "test_export_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001238610129803419, "outcome": "passed"}, "call": {"duration": 0.00267823098693043, "outcome": "passed"}, "teardown": {"duration": 9.680702351033688e-05, "outcome": "passed"}}, {"nodeid": "tests/performance/test_export_performance.py::test_file_export_performance", "lineno": 142, "outcome": "passed", "keywords": ["test_file_export_performance", "test_export_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0010605689603835344, "outcome": "passed"}, "call": {"duration": 0.0032704490004107356, "outcome": "passed"}, "teardown": {"duration": 0.0001145779388025403, "outcome": "passed"}}, {"nodeid": "tests/performance/test_export_performance.py::test_large_document_performance", "lineno": 173, "outcome": "passed", "keywords": ["test_large_document_performance", "test_export_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012690096627920866, "outcome": "passed"}, "call": {"duration": 0.012309306999668479, "outcome": "passed", "stdout": "Large document creation time: 0.01s\nLarge document markdown generation time: 0.00s\nTotal content blocks: 1000\n"}, "teardown": {"duration": 0.00010702793952077627, "outcome": "passed"}}, {"nodeid": "tests/performance/test_integration_performance.py::test_large_research_project_performance", "lineno": 46, "outcome": "failed", "keywords": ["test_large_research_project_performance", "test_integration_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00016478996258229017, "outcome": "passed"}, "call": {"duration": 0.00016110099386423826, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/performance/test_integration_performance.py", "lineno": 73, "message": "AttributeError: 'UUID' object has no attribute 'id'"}, "traceback": [{"path": "tests/performance/test_integration_performance.py", "lineno": 73, "message": "AttributeError"}], "longrepr": "services = {'bibliography': <researchtrack.bibliography.service.BibliographyService object at 0x7f6938728380>, 'dataset': <resear...69387284d0>, 'experiment': <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f6938728500>, ...}\n\n    def test_large_research_project_performance(services):\n        \"\"\"\n        Test the performance of a large-scale research project workflow.\n    \n        This test simulates a complex research project with:\n        - Multiple research tasks and questions\n        - Many bibliographic references\n        - Multiple datasets with versions\n        - Several environment snapshots\n        - Multiple experiments with many runs\n        - Document generation with the results\n        \"\"\"\n        start_time = time.time()\n    \n        # 1. Create research tasks and questions\n        tasks = []\n        for i in range(10):\n            task = services[\"task\"].create_task(\n                title=f\"Research Task {i+1}: {random_string(20)}\",\n                description=f\"Description for task {i+1}: {random_string(100)}\",\n                tags=[f\"tag{i+1}\", \"research\", random_string(8)]\n            )\n    \n            # Add research questions\n            for j in range(5):\n                question = services[\"task\"].create_research_question(\n>                   task_id=task.id,\n                    question=f\"Question {j+1} for Task {i+1}: {random_string(50)}?\"\n                )\nE               AttributeError: 'UUID' object has no attribute 'id'\n\ntests/performance/test_integration_performance.py:73: AttributeError"}, "teardown": {"duration": 0.00014549901243299246, "outcome": "passed"}}, {"nodeid": "tests/performance/test_task_management_performance.py::TestTaskManagementPerformance::test_task_operation_speed", "lineno": 16, "outcome": "passed", "keywords": ["test_task_operation_speed", "TestTaskManagementPerformance", "test_task_management_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00015692808665335178, "outcome": "passed"}, "call": {"duration": 0.0001611521001905203, "outcome": "passed"}, "teardown": {"duration": 9.293295443058014e-05, "outcome": "passed"}}, {"nodeid": "tests/performance/test_task_management_performance.py::TestTaskManagementPerformance::test_large_task_list_performance", "lineno": 51, "outcome": "passed", "keywords": ["test_large_task_list_performance", "TestTaskManagementPerformance", "test_task_management_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012506800703704357, "outcome": "passed"}, "call": {"duration": 0.011064574937336147, "outcome": "passed"}, "teardown": {"duration": 0.00010875402949750423, "outcome": "passed"}}, {"nodeid": "tests/performance/test_task_management_performance.py::TestTaskManagementPerformance::test_research_question_hierarchy_performance", "lineno": 135, "outcome": "passed", "keywords": ["test_research_question_hierarchy_performance", "TestTaskManagementPerformance", "test_task_management_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00013364595361053944, "outcome": "passed"}, "call": {"duration": 0.001268854015506804, "outcome": "passed"}, "teardown": {"duration": 0.00010319706052541733, "outcome": "passed"}}, {"nodeid": "tests/performance/test_task_management_performance.py::TestTaskManagementPerformance::test_task_question_association_performance", "lineno": 202, "outcome": "passed", "keywords": ["test_task_question_association_performance", "TestTaskManagementPerformance", "test_task_management_performance.py", "performance", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00013015605509281158, "outcome": "passed"}, "call": {"duration": 0.011914578964933753, "outcome": "passed"}, "teardown": {"duration": 0.0001132959732785821, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_models.py::TestResearchQuestion::test_create_research_question", "lineno": 14, "outcome": "passed", "keywords": ["test_create_research_question", "TestResearchQuestion", "test_models.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0002719240728765726, "outcome": "passed"}, "call": {"duration": 0.00012127007357776165, "outcome": "passed"}, "teardown": {"duration": 8.136697579175234e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_models.py::TestResearchQuestion::test_create_with_parent", "lineno": 28, "outcome": "passed", "keywords": ["test_create_with_parent", "TestResearchQuestion", "test_models.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 8.433195762336254e-05, "outcome": "passed"}, "call": {"duration": 0.00010805495548993349, "outcome": "passed"}, "teardown": {"duration": 7.561896927654743e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_models.py::TestResearchQuestion::test_update_question", "lineno": 39, "outcome": "passed", "keywords": ["test_update_question", "TestResearchQuestion", "test_models.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.587997242808342e-05, "outcome": "passed"}, "call": {"duration": 0.00012933998368680477, "outcome": "passed"}, "teardown": {"duration": 7.767695933580399e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_create_research_task", "lineno": 60, "outcome": "passed", "keywords": ["test_create_research_task", "TestResearchTask", "test_models.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 8.01159767434001e-05, "outcome": "passed"}, "call": {"duration": 0.0001185849541798234, "outcome": "passed"}, "teardown": {"duration": 7.353303954005241e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_task_with_due_date", "lineno": 88, "outcome": "passed", "keywords": ["test_task_with_due_date", "TestResearchTask", "test_models.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.52799678593874e-05, "outcome": "passed"}, "call": {"duration": 0.00010755995754152536, "outcome": "passed"}, "teardown": {"duration": 8.273706771433353e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_create_subtask", "lineno": 99, "outcome": "passed", "keywords": ["test_create_subtask", "TestResearchTask", "test_models.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.514993194490671e-05, "outcome": "passed"}, "call": {"duration": 0.00010249693877995014, "outcome": "passed"}, "teardown": {"duration": 7.099006325006485e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_update_task", "lineno": 110, "outcome": "passed", "keywords": ["test_update_task", "TestResearchTask", "test_models.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 8.252006955444813e-05, "outcome": "passed"}, "call": {"duration": 0.00013035500887781382, "outcome": "passed"}, "teardown": {"duration": 7.519393693655729e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_complete_task", "lineno": 140, "outcome": "passed", "keywords": ["test_complete_task", "TestResearchTask", "test_models.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.903203368186951e-05, "outcome": "passed"}, "call": {"duration": 0.00011381600052118301, "outcome": "passed"}, "teardown": {"duration": 7.312290836125612e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_add_note", "lineno": 155, "outcome": "passed", "keywords": ["test_add_note", "TestResearchTask", "test_models.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.344793993979692e-05, "outcome": "passed"}, "call": {"duration": 0.0001043989323079586, "outcome": "passed"}, "teardown": {"duration": 7.478997576981783e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_manage_tags", "lineno": 172, "outcome": "passed", "keywords": ["test_manage_tags", "TestResearchTask", "test_models.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.40931136533618e-05, "outcome": "passed"}, "call": {"duration": 0.00010832399129867554, "outcome": "passed"}, "teardown": {"duration": 7.031101267784834e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_research_question_association", "lineno": 199, "outcome": "passed", "keywords": ["test_research_question_association", "TestResearchTask", "test_models.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.609801832586527e-05, "outcome": "passed"}, "call": {"duration": 0.00011665408965200186, "outcome": "passed"}, "teardown": {"duration": 7.309892680495977e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_subtask_management", "lineno": 222, "outcome": "passed", "keywords": ["test_subtask_management", "TestResearchTask", "test_models.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.296702824532986e-05, "outcome": "passed"}, "call": {"duration": 0.00011147791519761086, "outcome": "passed"}, "teardown": {"duration": 7.066805846989155e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_models.py::TestResearchTask::test_custom_metadata", "lineno": 245, "outcome": "passed", "keywords": ["test_custom_metadata", "TestResearchTask", "test_models.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.228297181427479e-05, "outcome": "passed"}, "call": {"duration": 0.00011954898945987225, "outcome": "passed"}, "teardown": {"duration": 7.441500201821327e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_create_task", "lineno": 16, "outcome": "passed", "keywords": ["test_create_task", "TestTaskManagementService", "test_service.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001422930508852005, "outcome": "passed"}, "call": {"duration": 0.00013014394789934158, "outcome": "passed"}, "teardown": {"duration": 8.55129910632968e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_create_task_with_parent", "lineno": 35, "outcome": "passed", "keywords": ["test_create_task_with_parent", "TestTaskManagementService", "test_service.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001194800715893507, "outcome": "passed"}, "call": {"duration": 0.00013382791075855494, "outcome": "passed"}, "teardown": {"duration": 8.370098657906055e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_create_task_invalid_parent", "lineno": 54, "outcome": "passed", "keywords": ["test_create_task_invalid_parent", "TestTaskManagementService", "test_service.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00011474196799099445, "outcome": "passed"}, "call": {"duration": 0.00020717596635222435, "outcome": "passed"}, "teardown": {"duration": 8.914992213249207e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_create_task_with_research_questions", "lineno": 63, "outcome": "passed", "keywords": ["test_create_task_with_research_questions", "TestTaskManagementService", "test_service.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00011732301209121943, "outcome": "passed"}, "call": {"duration": 0.00020481296814978123, "outcome": "passed"}, "teardown": {"duration": 8.896901272237301e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_create_task_invalid_question", "lineno": 83, "outcome": "passed", "keywords": ["test_create_task_invalid_question", "TestTaskManagementService", "test_service.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012040894944220781, "outcome": "passed"}, "call": {"duration": 0.00018793996423482895, "outcome": "passed"}, "teardown": {"duration": 8.424196857959032e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_update_task", "lineno": 92, "outcome": "passed", "keywords": ["test_update_task", "TestTaskManagementService", "test_service.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00011302193161100149, "outcome": "passed"}, "call": {"duration": 0.0001330679515376687, "outcome": "passed"}, "teardown": {"duration": 8.48080962896347e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_update_nonexistent_task", "lineno": 121, "outcome": "passed", "keywords": ["test_update_nonexistent_task", "TestTaskManagementService", "test_service.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00011909101158380508, "outcome": "passed"}, "call": {"duration": 0.0001780870370566845, "outcome": "passed"}, "teardown": {"duration": 8.859601803123951e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_delete_task", "lineno": 129, "outcome": "passed", "keywords": ["test_delete_task", "TestTaskManagementService", "test_service.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00012458907440304756, "outcome": "passed"}, "call": {"duration": 0.00011547794565558434, "outcome": "passed"}, "teardown": {"duration": 8.354696910828352e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_add_task_note", "lineno": 143, "outcome": "passed", "keywords": ["test_add_task_note", "TestTaskManagementService", "test_service.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00011195300612598658, "outcome": "passed"}, "call": {"duration": 0.00011935504153370857, "outcome": "passed"}, "teardown": {"duration": 9.606208186596632e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_add_note_to_nonexistent_task", "lineno": 159, "outcome": "passed", "keywords": ["test_add_note_to_nonexistent_task", "TestTaskManagementService", "test_service.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00011347001418471336, "outcome": "passed"}, "call": {"duration": 0.00011253193952143192, "outcome": "passed"}, "teardown": {"duration": 8.419400546699762e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_tag_management", "lineno": 164, "outcome": "passed", "keywords": ["test_tag_management", "TestTaskManagementService", "test_service.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00011473207268863916, "outcome": "passed"}, "call": {"duration": 0.00013965601101517677, "outcome": "passed"}, "teardown": {"duration": 8.709891699254513e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_custom_metadata", "lineno": 189, "outcome": "passed", "keywords": ["test_custom_metadata", "TestTaskManagementService", "test_service.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00011382799129933119, "outcome": "passed"}, "call": {"duration": 0.00011601205915212631, "outcome": "passed"}, "teardown": {"duration": 8.104601874947548e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_filter_tasks", "lineno": 206, "outcome": "passed", "keywords": ["test_filter_tasks", "TestTaskManagementService", "test_service.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00010861596092581749, "outcome": "passed"}, "call": {"duration": 0.00016401708126068115, "outcome": "passed"}, "teardown": {"duration": 8.741801138967276e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_research_question_operations", "lineno": 264, "outcome": "passed", "keywords": ["test_research_question_operations", "TestTaskManagementService", "test_service.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00011835107579827309, "outcome": "passed"}, "call": {"duration": 0.00013788696378469467, "outcome": "passed"}, "teardown": {"duration": 8.334696758538485e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_research_question_hierarchy", "lineno": 293, "outcome": "failed", "keywords": ["test_research_question_hierarchy", "TestTaskManagementService", "test_service.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00011751602869480848, "outcome": "passed"}, "call": {"duration": 0.00026715092826634645, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 323, "message": "AssertionError: assert 3 == 1\n +  where 3 = len([ResearchQuestion(id=UUID('a25c509f-9ff8-4c55-ac8d-a8ec6c72dcab'), text='How do climate factors affect agricultural yi...at=datetime.datetime(2025, 5, 15, 2, 34, 10, 968694), parent_question_id=UUID('a25c509f-9ff8-4c55-ac8d-a8ec6c72dcab'))])"}, "traceback": [{"path": "tests/task_management/test_service.py", "lineno": 323, "message": "AssertionError"}], "longrepr": "self = <tests.task_management.test_service.TestTaskManagementService object at 0x7f6938858c80>\n\n    def test_research_question_hierarchy(self):\n        # Test creating a hierarchy of research questions\n        parent_id = self.service.create_research_question(\n            text=\"How do climate factors affect agricultural yields?\",\n            description=\"Main research area\",\n        )\n    \n        sub_id1 = self.service.create_research_question(\n            text=\"How does temperature variation impact wheat production?\",\n            description=\"Temperature sub-question\",\n            parent_question_id=parent_id,\n        )\n    \n        sub_id2 = self.service.create_research_question(\n            text=\"How does precipitation pattern affect corn yields?\",\n            description=\"Precipitation sub-question\",\n            parent_question_id=parent_id,\n        )\n    \n        # List sub-questions\n        sub_questions = self.service.list_research_questions(parent_question_id=parent_id)\n        assert len(sub_questions) == 2\n        assert {q.text for q in sub_questions} == {\n            \"How does temperature variation impact wheat production?\",\n            \"How does precipitation pattern affect corn yields?\",\n        }\n    \n        # List top-level questions\n        top_questions = self.service.list_research_questions(parent_question_id=None)\n>       assert len(top_questions) == 1\nE       AssertionError: assert 3 == 1\nE        +  where 3 = len([ResearchQuestion(id=UUID('a25c509f-9ff8-4c55-ac8d-a8ec6c72dcab'), text='How do climate factors affect agricultural yi...at=datetime.datetime(2025, 5, 15, 2, 34, 10, 968694), parent_question_id=UUID('a25c509f-9ff8-4c55-ac8d-a8ec6c72dcab'))])\n\ntests/task_management/test_service.py:323: AssertionError"}, "teardown": {"duration": 0.0001327419886365533, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_task_question_association", "lineno": 325, "outcome": "passed", "keywords": ["test_task_question_association", "TestTaskManagementService", "test_service.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00013921293430030346, "outcome": "passed"}, "call": {"duration": 0.00014638400170952082, "outcome": "passed"}, "teardown": {"duration": 9.946990758180618e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_associate_with_nonexistent_task", "lineno": 359, "outcome": "passed", "keywords": ["test_associate_with_nonexistent_task", "TestTaskManagementService", "test_service.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.0001204019645228982, "outcome": "passed"}, "call": {"duration": 0.0001319959992542863, "outcome": "passed"}, "teardown": {"duration": 8.537806570529938e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_associate_with_nonexistent_question", "lineno": 368, "outcome": "passed", "keywords": ["test_associate_with_nonexistent_question", "TestTaskManagementService", "test_service.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00011433602776378393, "outcome": "passed"}, "call": {"duration": 0.00014933908823877573, "outcome": "passed"}, "teardown": {"duration": 8.6418935097754e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_service.py::TestTaskManagementService::test_get_subtasks", "lineno": 378, "outcome": "passed", "keywords": ["test_get_subtasks", "TestTaskManagementService", "test_service.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00011793500743806362, "outcome": "passed"}, "call": {"duration": 0.00014016602654010057, "outcome": "passed"}, "teardown": {"duration": 8.917110972106457e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_create_and_get_task", "lineno": 13, "outcome": "passed", "keywords": ["test_create_and_get_task", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 0.00010315899271517992, "outcome": "passed"}, "call": {"duration": 0.00011597201228141785, "outcome": "passed"}, "teardown": {"duration": 7.612304762005806e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_update_task", "lineno": 30, "outcome": "passed", "keywords": ["test_update_task", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.715192623436451e-05, "outcome": "passed"}, "call": {"duration": 0.00010712200310081244, "outcome": "passed"}, "teardown": {"duration": 7.563503459095955e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_update_nonexistent_task", "lineno": 54, "outcome": "passed", "keywords": ["test_update_nonexistent_task", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.37590016797185e-05, "outcome": "passed"}, "call": {"duration": 0.00010006199590861797, "outcome": "passed"}, "teardown": {"duration": 7.127400022000074e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_task", "lineno": 66, "outcome": "passed", "keywords": ["test_delete_task", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.413094863295555e-05, "outcome": "passed"}, "call": {"duration": 0.00010145606938749552, "outcome": "passed"}, "teardown": {"duration": 7.260194979608059e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_nonexistent_task", "lineno": 82, "outcome": "passed", "keywords": ["test_delete_nonexistent_task", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.462711073458195e-05, "outcome": "passed"}, "call": {"duration": 8.762511424720287e-05, "outcome": "passed"}, "teardown": {"duration": 7.277796976268291e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_list_tasks_empty", "lineno": 89, "outcome": "passed", "keywords": ["test_list_tasks_empty", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.346505299210548e-05, "outcome": "passed"}, "call": {"duration": 8.327001705765724e-05, "outcome": "passed"}, "teardown": {"duration": 7.281906437128782e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_list_tasks_with_filters", "lineno": 96, "outcome": "passed", "keywords": ["test_list_tasks_with_filters", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.196597289294004e-05, "outcome": "passed"}, "call": {"duration": 0.00016067700926214457, "outcome": "passed"}, "teardown": {"duration": 7.280893623828888e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_research_question_operations", "lineno": 170, "outcome": "passed", "keywords": ["test_research_question_operations", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.582700345665216e-05, "outcome": "passed"}, "call": {"duration": 0.00011669495142996311, "outcome": "passed"}, "teardown": {"duration": 7.050391286611557e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_update_nonexistent_question", "lineno": 204, "outcome": "passed", "keywords": ["test_update_nonexistent_question", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.22960103303194e-05, "outcome": "passed"}, "call": {"duration": 9.683496318757534e-05, "outcome": "passed"}, "teardown": {"duration": 6.985000800341368e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_nonexistent_question", "lineno": 216, "outcome": "passed", "keywords": ["test_delete_nonexistent_question", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.64940632507205e-05, "outcome": "passed"}, "call": {"duration": 0.00010579603258520365, "outcome": "passed"}, "teardown": {"duration": 7.334200199693441e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_list_research_questions", "lineno": 223, "outcome": "failed", "keywords": ["test_list_research_questions", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.385096978396177e-05, "outcome": "passed"}, "call": {"duration": 0.0002705079969018698, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 268, "message": "AssertionError: assert 4 == 2\n +  where 4 = len([ResearchQuestion(id=UUID('1301f136-fe9c-4011-8f8d-9d6643117729'), text='Main research question', description='The mai...025, 5, 15, 2, 34, 10, 981829), updated_at=datetime.datetime(2025, 5, 15, 2, 34, 10, 981830), parent_question_id=None)])"}, "traceback": [{"path": "tests/task_management/test_storage.py", "lineno": 268, "message": "AssertionError"}], "longrepr": "self = <tests.task_management.test_storage.TestInMemoryTaskStorage object at 0x7f693885a240>\n\n    def test_list_research_questions(self):\n        # Test listing research questions\n        storage = InMemoryTaskStorage()\n    \n        # Create parent question\n        parent_question = ResearchQuestion(\n            text=\"Main research question\",\n            description=\"The main area of investigation\",\n        )\n        parent_id = storage.create_research_question(parent_question)\n    \n        # Create sub-questions\n        sub_question1 = ResearchQuestion(\n            text=\"Sub-question 1\",\n            description=\"First sub-area\",\n            parent_question_id=parent_id,\n        )\n        sub_question2 = ResearchQuestion(\n            text=\"Sub-question 2\",\n            description=\"Second sub-area\",\n            parent_question_id=parent_id,\n        )\n    \n        # Create unrelated question\n        unrelated_question = ResearchQuestion(\n            text=\"Unrelated question\",\n            description=\"Different research area\",\n        )\n    \n        sub_id1 = storage.create_research_question(sub_question1)\n        sub_id2 = storage.create_research_question(sub_question2)\n        unrelated_id = storage.create_research_question(unrelated_question)\n    \n        # List all questions\n        all_questions = storage.list_research_questions()\n        assert len(all_questions) == 4\n    \n        # List sub-questions\n        sub_questions = storage.list_research_questions(parent_question_id=parent_id)\n        assert len(sub_questions) == 2\n        assert {q.text for q in sub_questions} == {\"Sub-question 1\", \"Sub-question 2\"}\n    \n        # List top-level questions (no parent)\n        top_questions = storage.list_research_questions(parent_question_id=None)\n>       assert len(top_questions) == 2\nE       AssertionError: assert 4 == 2\nE        +  where 4 = len([ResearchQuestion(id=UUID('1301f136-fe9c-4011-8f8d-9d6643117729'), text='Main research question', description='The mai...025, 5, 15, 2, 34, 10, 981829), updated_at=datetime.datetime(2025, 5, 15, 2, 34, 10, 981830), parent_question_id=None)])\n\ntests/task_management/test_storage.py:268: AssertionError"}, "teardown": {"duration": 0.00011756701860576868, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_task_question_associations", "lineno": 270, "outcome": "passed", "keywords": ["test_task_question_associations", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 8.661695756018162e-05, "outcome": "passed"}, "call": {"duration": 0.00016068597324192524, "outcome": "passed"}, "teardown": {"duration": 8.019793312996626e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_subtask_relationships", "lineno": 316, "outcome": "passed", "keywords": ["test_subtask_relationships", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.666298188269138e-05, "outcome": "passed"}, "call": {"duration": 0.0001307469792664051, "outcome": "passed"}, "teardown": {"duration": 7.350801024585962e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_task_subtask_cleanup", "lineno": 359, "outcome": "passed", "keywords": ["test_delete_task_subtask_cleanup", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.933599408715963e-05, "outcome": "passed"}, "call": {"duration": 0.0001237459946423769, "outcome": "passed"}, "teardown": {"duration": 7.324293255805969e-05, "outcome": "passed"}}, {"nodeid": "tests/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_question_cleanup", "lineno": 386, "outcome": "passed", "keywords": ["test_delete_question_cleanup", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "tests", "command_line_task_manager_researcher", ""], "setup": {"duration": 7.365690544247627e-05, "outcome": "passed"}, "call": {"duration": 0.00013418309390544891, "outcome": "passed"}, "teardown": {"duration": 0.0001039779745042324, "outcome": "passed"}}], "warnings": [{"message": "pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html", "category": "DeprecationWarning", "when": "collect", "filename": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/.venv/lib/python3.12/site-packages/pybtex/plugin/__init__.py", "lineno": 26}, {"message": "Field name \"schema\" in \"Dataset\" shadows an attribute in parent \"BaseModel\"", "category": "UserWarning", "when": "collect", "filename": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py", "lineno": 198}, {"message": "Field name \"schema\" in \"DatasetVersion\" shadows an attribute in parent \"BaseModel\"", "category": "UserWarning", "when": "collect", "filename": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py", "lineno": 198}]}