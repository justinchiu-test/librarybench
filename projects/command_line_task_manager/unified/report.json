{"created": 1747350920.762629, "duration": 10.520300388336182, "exitcode": 1, "root": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified", "environment": {}, "summary": {"passed": 360, "failed": 56, "total": 416, "collected": 416}, "collectors": [{"nodeid": "", "outcome": "passed", "result": [{"nodeid": "tests", "type": "Package"}]}, {"nodeid": "tests/researcher/bibliography/test_formatter.py::TestReferenceFormatter", "outcome": "passed", "result": [{"nodeid": "tests/researcher/bibliography/test_formatter.py::TestReferenceFormatter::test_apa_formatting", "type": "Function", "lineno": 101}, {"nodeid": "tests/researcher/bibliography/test_formatter.py::TestReferenceFormatter::test_mla_formatting", "type": "Function", "lineno": 133}, {"nodeid": "tests/researcher/bibliography/test_formatter.py::TestReferenceFormatter::test_harvard_formatting", "type": "Function", "lineno": 156}, {"nodeid": "tests/researcher/bibliography/test_formatter.py::TestReferenceFormatter::test_ieee_formatting", "type": "Function", "lineno": 170}, {"nodeid": "tests/researcher/bibliography/test_formatter.py::TestReferenceFormatter::test_in_text_citations", "type": "Function", "lineno": 182}, {"nodeid": "tests/researcher/bibliography/test_formatter.py::TestReferenceFormatter::test_generate_bibliography", "type": "Function", "lineno": 209}, {"nodeid": "tests/researcher/bibliography/test_formatter.py::TestReferenceFormatter::test_author_formatting", "type": "Function", "lineno": 238}]}, {"nodeid": "tests/researcher/bibliography/test_formatter.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/bibliography/test_formatter.py::TestReferenceFormatter", "type": "Class"}]}, {"nodeid": "tests/researcher/bibliography/test_importer.py::TestBibliographyImporter", "outcome": "passed", "result": [{"nodeid": "tests/researcher/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_json_single_reference", "type": "Function", "lineno": 10}, {"nodeid": "tests/researcher/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_json_multiple_references", "type": "Function", "lineno": 71}, {"nodeid": "tests/researcher/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_json_string", "type": "Function", "lineno": 143}, {"nodeid": "tests/researcher/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_invalid_json", "type": "Function", "lineno": 165}, {"nodeid": "tests/researcher/bibliography/test_importer.py::TestBibliographyImporter::test_import_handles_missing_fields", "type": "Function", "lineno": 170}, {"nodeid": "tests/researcher/bibliography/test_importer.py::TestBibliographyImporter::test_export_to_json", "type": "Function", "lineno": 186}, {"nodeid": "tests/researcher/bibliography/test_importer.py::TestBibliographyImporter::test_import_export_roundtrip", "type": "Function", "lineno": 262}, {"nodeid": "tests/researcher/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_bibtex_basic", "type": "Function", "lineno": 307}]}, {"nodeid": "tests/researcher/bibliography/test_importer.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/bibliography/test_importer.py::TestBibliographyImporter", "type": "Class"}]}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestAuthor", "outcome": "passed", "result": [{"nodeid": "tests/researcher/bibliography/test_models.py::TestAuthor::test_create_person_author", "type": "Function", "lineno": 15}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestAuthor::test_create_organization_author", "type": "Function", "lineno": 31}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestAuthor::test_author_full_name_person", "type": "Function", "lineno": 45}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestAuthor::test_author_full_name_organization", "type": "Function", "lineno": 76}]}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference", "outcome": "passed", "result": [{"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_create_journal_article", "type": "Function", "lineno": 92}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_create_book", "type": "Function", "lineno": 137}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_create_website", "type": "Function", "lineno": 164}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_update_reference", "type": "Function", "lineno": 190}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_add_author", "type": "Function", "lineno": 215}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_remove_author", "type": "Function", "lineno": 245}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_keywords", "type": "Function", "lineno": 280}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_notes", "type": "Function", "lineno": 313}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_custom_fields", "type": "Function", "lineno": 331}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_author_names_formatted", "type": "Function", "lineno": 366}]}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestTaskReferenceLink", "outcome": "passed", "result": [{"nodeid": "tests/researcher/bibliography/test_models.py::TestTaskReferenceLink::test_create_task_reference_link", "type": "Function", "lineno": 416}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestTaskReferenceLink::test_update_link", "type": "Function", "lineno": 435}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestTaskReferenceLink::test_add_note", "type": "Function", "lineno": 453}]}, {"nodeid": "tests/researcher/bibliography/test_models.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/bibliography/test_models.py::TestAuthor", "type": "Class"}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference", "type": "Class"}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestTaskReferenceLink", "type": "Class"}]}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService", "outcome": "passed", "result": [{"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_create_author_methods", "type": "Function", "lineno": 26}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_create_journal_article", "type": "Function", "lineno": 49}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_create_book", "type": "Function", "lineno": 82}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_create_website", "type": "Function", "lineno": 111}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_create_generic_reference", "type": "Function", "lineno": 139}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_update_reference", "type": "Function", "lineno": 166}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_update_nonexistent_reference", "type": "Function", "lineno": 193}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_delete_reference", "type": "Function", "lineno": 205}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_search_references", "type": "Function", "lineno": 224}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_reference_modification_methods", "type": "Function", "lineno": 289}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_link_task_to_reference", "type": "Function", "lineno": 326}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_link_to_nonexistent_reference", "type": "Function", "lineno": 352}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_update_task_reference_link", "type": "Function", "lineno": 360}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_add_note_to_link", "type": "Function", "lineno": 388}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_get_references_by_task", "type": "Function", "lineno": 412}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_get_tasks_by_reference", "type": "Function", "lineno": 448}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_delete_task_reference_link", "type": "Function", "lineno": 468}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_citation_formatting", "type": "Function", "lineno": 490}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_in_text_citation_formatting", "type": "Function", "lineno": 524}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_generate_task_bibliography", "type": "Function", "lineno": 548}]}, {"nodeid": "tests/researcher/bibliography/test_service.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService", "type": "Class"}]}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage", "outcome": "passed", "result": [{"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_create_and_get_reference", "type": "Function", "lineno": 53}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_update_reference", "type": "Function", "lineno": 64}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_update_nonexistent_reference", "type": "Function", "lineno": 79}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_delete_reference", "type": "Function", "lineno": 91}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_delete_nonexistent_reference", "type": "Function", "lineno": 111}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_list_references_empty", "type": "Function", "lineno": 116}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_list_references_with_filters", "type": "Function", "lineno": 121}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_task_reference_link_operations", "type": "Function", "lineno": 165}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_get_references_by_task", "type": "Function", "lineno": 217}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_get_links_by_task", "type": "Function", "lineno": 252}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_get_tasks_by_reference", "type": "Function", "lineno": 282}]}, {"nodeid": "tests/researcher/bibliography/test_storage.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage", "type": "Class"}]}, {"nodeid": "tests/researcher/bibliography", "outcome": "passed", "result": [{"nodeid": "tests/researcher/bibliography/test_formatter.py", "type": "Module"}, {"nodeid": "tests/researcher/bibliography/test_importer.py", "type": "Module"}, {"nodeid": "tests/researcher/bibliography/test_models.py", "type": "Module"}, {"nodeid": "tests/researcher/bibliography/test_service.py", "type": "Module"}, {"nodeid": "tests/researcher/bibliography/test_storage.py", "type": "Module"}]}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataset", "outcome": "passed", "result": [{"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataset::test_create_dataset", "type": "Function", "lineno": 17}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataset::test_update_dataset", "type": "Function", "lineno": 61}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataset::test_dataset_tags", "type": "Function", "lineno": 88}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataset::test_dataset_custom_metadata", "type": "Function", "lineno": 121}]}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDatasetVersion", "outcome": "passed", "result": [{"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDatasetVersion::test_create_dataset_version", "type": "Function", "lineno": 167}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDatasetVersion::test_update_version", "type": "Function", "lineno": 212}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDatasetVersion::test_version_custom_metadata", "type": "Function", "lineno": 234}]}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataTransformation", "outcome": "passed", "result": [{"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataTransformation::test_create_data_transformation", "type": "Function", "lineno": 267}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataTransformation::test_update_transformation", "type": "Function", "lineno": 302}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataTransformation::test_transformation_tags", "type": "Function", "lineno": 327}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataTransformation::test_transformation_notes", "type": "Function", "lineno": 357}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataTransformation::test_transformation_parameters", "type": "Function", "lineno": 376}]}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestTaskDatasetLink", "outcome": "passed", "result": [{"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestTaskDatasetLink::test_create_task_dataset_link", "type": "Function", "lineno": 411}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestTaskDatasetLink::test_update_link", "type": "Function", "lineno": 432}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestTaskDatasetLink::test_link_notes", "type": "Function", "lineno": 455}]}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataset", "type": "Class"}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDatasetVersion", "type": "Class"}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataTransformation", "type": "Class"}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestTaskDatasetLink", "type": "Class"}]}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService", "outcome": "passed", "result": [{"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_dataset", "type": "Function", "lineno": 23}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_update_dataset", "type": "Function", "lineno": 58}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_update_nonexistent_dataset", "type": "Function", "lineno": 86}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_delete_dataset", "type": "Function", "lineno": 94}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_list_datasets", "type": "Function", "lineno": 112}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_dataset_tags", "type": "Function", "lineno": 167}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_dataset_custom_metadata", "type": "Function", "lineno": 189}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_dataset_version", "type": "Function", "lineno": 214}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_dataset_version_with_parent", "type": "Function", "lineno": 253}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_version_nonexistent_dataset", "type": "Function", "lineno": 284}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_version_nonexistent_parent", "type": "Function", "lineno": 293}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_update_dataset_version", "type": "Function", "lineno": 310}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_version_operations", "type": "Function", "lineno": 348}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_data_transformation", "type": "Function", "lineno": 402}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_transformation_nonexistent_version", "type": "Function", "lineno": 455}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_transformation_operations", "type": "Function", "lineno": 465}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_link_task_to_dataset_version", "type": "Function", "lineno": 551}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_link_to_nonexistent_version", "type": "Function", "lineno": 582}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_task_dataset_link_operations", "type": "Function", "lineno": 590}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_dataset_lineage", "type": "Function", "lineno": 661}]}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService", "type": "Class"}]}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage", "outcome": "passed", "result": [{"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_create_and_get_dataset", "type": "Function", "lineno": 43}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_update_dataset", "type": "Function", "lineno": 55}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_update_nonexistent_dataset", "type": "Function", "lineno": 70}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_delete_dataset", "type": "Function", "lineno": 83}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_delete_nonexistent_dataset", "type": "Function", "lineno": 114}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_list_datasets_empty", "type": "Function", "lineno": 119}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_list_datasets_with_filters", "type": "Function", "lineno": 124}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_dataset_version_operations", "type": "Function", "lineno": 160}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_version_lineage_operations", "type": "Function", "lineno": 223}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_data_transformation_operations", "type": "Function", "lineno": 266}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_task_dataset_link_operations", "type": "Function", "lineno": 344}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_get_lineage", "type": "Function", "lineno": 415}]}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage", "type": "Class"}]}, {"nodeid": "tests/researcher/dataset_versioning", "outcome": "passed", "result": [{"nodeid": "tests/researcher/dataset_versioning/test_models.py", "type": "Module"}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py", "type": "Module"}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py", "type": "Module"}]}, {"nodeid": "tests/researcher/environment/test_models.py::TestPackageInfo", "outcome": "passed", "result": [{"nodeid": "tests/researcher/environment/test_models.py::TestPackageInfo::test_create_package_info", "type": "Function", "lineno": 18}]}, {"nodeid": "tests/researcher/environment/test_models.py::TestComputeResource", "outcome": "passed", "result": [{"nodeid": "tests/researcher/environment/test_models.py::TestComputeResource::test_create_compute_resource", "type": "Function", "lineno": 52}]}, {"nodeid": "tests/researcher/environment/test_models.py::TestEnvironmentSnapshot", "outcome": "passed", "result": [{"nodeid": "tests/researcher/environment/test_models.py::TestEnvironmentSnapshot::test_create_environment_snapshot", "type": "Function", "lineno": 82}, {"nodeid": "tests/researcher/environment/test_models.py::TestEnvironmentSnapshot::test_update_environment_snapshot", "type": "Function", "lineno": 181}, {"nodeid": "tests/researcher/environment/test_models.py::TestEnvironmentSnapshot::test_package_management", "type": "Function", "lineno": 206}, {"nodeid": "tests/researcher/environment/test_models.py::TestEnvironmentSnapshot::test_compute_resource_management", "type": "Function", "lineno": 253}, {"nodeid": "tests/researcher/environment/test_models.py::TestEnvironmentSnapshot::test_environment_variable_management", "type": "Function", "lineno": 293}, {"nodeid": "tests/researcher/environment/test_models.py::TestEnvironmentSnapshot::test_config_file_management", "type": "Function", "lineno": 327}, {"nodeid": "tests/researcher/environment/test_models.py::TestEnvironmentSnapshot::test_tag_management", "type": "Function", "lineno": 370}, {"nodeid": "tests/researcher/environment/test_models.py::TestEnvironmentSnapshot::test_custom_metadata_management", "type": "Function", "lineno": 403}]}, {"nodeid": "tests/researcher/environment/test_models.py::TestTaskEnvironmentLink", "outcome": "passed", "result": [{"nodeid": "tests/researcher/environment/test_models.py::TestTaskEnvironmentLink::test_create_task_environment_link", "type": "Function", "lineno": 447}, {"nodeid": "tests/researcher/environment/test_models.py::TestTaskEnvironmentLink::test_update_link", "type": "Function", "lineno": 468}, {"nodeid": "tests/researcher/environment/test_models.py::TestTaskEnvironmentLink::test_add_note", "type": "Function", "lineno": 491}]}, {"nodeid": "tests/researcher/environment/test_models.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/environment/test_models.py::TestPackageInfo", "type": "Class"}, {"nodeid": "tests/researcher/environment/test_models.py::TestComputeResource", "type": "Class"}, {"nodeid": "tests/researcher/environment/test_models.py::TestEnvironmentSnapshot", "type": "Class"}, {"nodeid": "tests/researcher/environment/test_models.py::TestTaskEnvironmentLink", "type": "Class"}]}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService", "outcome": "passed", "result": [{"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_create_environment_snapshot", "type": "Function", "lineno": 26}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_create_environment_with_packages_and_resources", "type": "Function", "lineno": 55}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_capture_current_environment", "type": "Function", "lineno": 140}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_update_environment", "type": "Function", "lineno": 169}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_update_nonexistent_environment", "type": "Function", "lineno": 206}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_delete_environment", "type": "Function", "lineno": 214}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_list_environments", "type": "Function", "lineno": 230}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_environment_tag_operations", "type": "Function", "lineno": 284}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_package_operations", "type": "Function", "lineno": 313}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_compute_resource_operations", "type": "Function", "lineno": 362}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_environment_variable_operations", "type": "Function", "lineno": 407}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_config_file_operations", "type": "Function", "lineno": 448}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_custom_metadata_operations", "type": "Function", "lineno": 501}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_compare_environments", "type": "Function", "lineno": 550}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_link_task_to_environment", "type": "Function", "lineno": 658}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_link_to_nonexistent_environment", "type": "Function", "lineno": 681}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_task_environment_link_operations", "type": "Function", "lineno": 689}]}, {"nodeid": "tests/researcher/environment/test_service.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService", "type": "Class"}]}, {"nodeid": "tests/researcher/environment/test_storage.py::TestInMemoryEnvironmentStorage", "outcome": "passed", "result": [{"nodeid": "tests/researcher/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_create_and_get_environment", "type": "Function", "lineno": 63}, {"nodeid": "tests/researcher/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_update_environment", "type": "Function", "lineno": 76}, {"nodeid": "tests/researcher/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_update_nonexistent_environment", "type": "Function", "lineno": 91}, {"nodeid": "tests/researcher/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_delete_environment", "type": "Function", "lineno": 102}, {"nodeid": "tests/researcher/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_delete_nonexistent_environment", "type": "Function", "lineno": 122}, {"nodeid": "tests/researcher/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_list_environments_empty", "type": "Function", "lineno": 127}, {"nodeid": "tests/researcher/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_list_environments_with_filters", "type": "Function", "lineno": 132}, {"nodeid": "tests/researcher/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_task_environment_link_operations", "type": "Function", "lineno": 163}]}, {"nodeid": "tests/researcher/environment/test_storage.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/environment/test_storage.py::TestInMemoryEnvironmentStorage", "type": "Class"}]}, {"nodeid": "tests/researcher/environment", "outcome": "passed", "result": [{"nodeid": "tests/researcher/environment/test_models.py", "type": "Module"}, {"nodeid": "tests/researcher/environment/test_service.py", "type": "Module"}, {"nodeid": "tests/researcher/environment/test_storage.py", "type": "Module"}]}, {"nodeid": "tests/researcher/experiment", "outcome": "passed", "result": []}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_parameter_creation", "type": "Function", "lineno": 10}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_metric_creation", "type": "Function", "lineno": 26}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_experiment_run_creation", "type": "Function", "lineno": 43}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_experiment_run_duration", "type": "Function", "lineno": 68}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_experiment_creation", "type": "Function", "lineno": 91}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_experiment_add_run", "type": "Function", "lineno": 111}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_experiment_get_run", "type": "Function", "lineno": 132}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_experiment_get_best_run", "type": "Function", "lineno": 152}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_experiment_comparison_creation", "type": "Function", "lineno": 191}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_experiment_comparison_add_methods", "type": "Function", "lineno": 210}]}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_create_experiment", "type": "Function", "lineno": 21}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_get_experiment", "type": "Function", "lineno": 36}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_get_experiment_by_name", "type": "Function", "lineno": 46}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_update_experiment", "type": "Function", "lineno": 58}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_delete_experiment", "type": "Function", "lineno": 71}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_list_experiments", "type": "Function", "lineno": 80}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_list_experiments_by_task", "type": "Function", "lineno": 92}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_add_parameter", "type": "Function", "lineno": 104}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_add_metric", "type": "Function", "lineno": 120}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_create_experiment_run", "type": "Function", "lineno": 136}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_create_experiment_run_nonexistent_experiment", "type": "Function", "lineno": 155}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_get_experiment_run", "type": "Function", "lineno": 163}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_run_lifecycle", "type": "Function", "lineno": 175}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_failed_and_aborted_runs", "type": "Function", "lineno": 212}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_get_best_run", "type": "Function", "lineno": 233}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_create_comparison", "type": "Function", "lineno": 261}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_get_comparison", "type": "Function", "lineno": 282}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_update_comparison", "type": "Function", "lineno": 292}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_delete_comparison", "type": "Function", "lineno": 305}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_list_comparisons", "type": "Function", "lineno": 314}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_get_comparison_data", "type": "Function", "lineno": 326}]}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_create_experiment", "type": "Function", "lineno": 48}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_get_experiment", "type": "Function", "lineno": 58}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_get_nonexistent_experiment", "type": "Function", "lineno": 68}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_update_experiment", "type": "Function", "lineno": 76}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_update_nonexistent_experiment", "type": "Function", "lineno": 89}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_delete_experiment", "type": "Function", "lineno": 97}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_delete_nonexistent_experiment", "type": "Function", "lineno": 106}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_list_experiments", "type": "Function", "lineno": 114}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_list_experiments_by_task", "type": "Function", "lineno": 127}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_get_experiment_by_name", "type": "Function", "lineno": 148}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_create_run", "type": "Function", "lineno": 160}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_create_run_nonexistent_experiment", "type": "Function", "lineno": 175}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_get_run", "type": "Function", "lineno": 183}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_update_run", "type": "Function", "lineno": 194}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_update_nonexistent_run", "type": "Function", "lineno": 214}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_delete_run", "type": "Function", "lineno": 222}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_delete_nonexistent_run", "type": "Function", "lineno": 236}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_create_comparison", "type": "Function", "lineno": 244}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_get_comparison", "type": "Function", "lineno": 254}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_update_comparison", "type": "Function", "lineno": 264}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_update_nonexistent_comparison", "type": "Function", "lineno": 279}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_delete_comparison", "type": "Function", "lineno": 287}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_delete_nonexistent_comparison", "type": "Function", "lineno": 296}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_list_comparisons", "type": "Function", "lineno": 304}]}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_parameter_table", "type": "Function", "lineno": 130}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_empty_parameter_table", "type": "Function", "lineno": 140}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_metric_table", "type": "Function", "lineno": 148}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_empty_metric_table", "type": "Function", "lineno": 160}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_artifact_table", "type": "Function", "lineno": 168}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_empty_artifact_table", "type": "Function", "lineno": 177}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_run_summary", "type": "Function", "lineno": 185}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_experiment_summary", "type": "Function", "lineno": 210}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_comparison_table", "type": "Function", "lineno": 229}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_empty_comparison_table", "type": "Function", "lineno": 286}]}, {"nodeid": "tests/researcher/experiment_tracking", "outcome": "passed", "result": [{"nodeid": "tests/researcher/experiment_tracking/test_models.py", "type": "Module"}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py", "type": "Module"}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py", "type": "Module"}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py", "type": "Module"}]}, {"nodeid": "tests/researcher/export/test_formatter.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/export/test_formatter.py::test_format_document_default", "type": "Function", "lineno": 51}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_document_nature", "type": "Function", "lineno": 89}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_document_science", "type": "Function", "lineno": 100}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_document_plos", "type": "Function", "lineno": 109}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_section", "type": "Function", "lineno": 118}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_text_block", "type": "Function", "lineno": 133}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_image_block", "type": "Function", "lineno": 141}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_table_block", "type": "Function", "lineno": 153}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_code_block", "type": "Function", "lineno": 171}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_equation_block", "type": "Function", "lineno": 186}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_citation_block", "type": "Function", "lineno": 194}]}, {"nodeid": "tests/researcher/export/test_models.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/export/test_models.py::test_document_creation", "type": "Function", "lineno": 10}, {"nodeid": "tests/researcher/export/test_models.py::test_section_creation", "type": "Function", "lineno": 32}, {"nodeid": "tests/researcher/export/test_models.py::test_text_block", "type": "Function", "lineno": 49}, {"nodeid": "tests/researcher/export/test_models.py::test_image_block", "type": "Function", "lineno": 58}, {"nodeid": "tests/researcher/export/test_models.py::test_table_block", "type": "Function", "lineno": 73}, {"nodeid": "tests/researcher/export/test_models.py::test_code_block", "type": "Function", "lineno": 93}, {"nodeid": "tests/researcher/export/test_models.py::test_equation_block", "type": "Function", "lineno": 107}, {"nodeid": "tests/researcher/export/test_models.py::test_citation_block", "type": "Function", "lineno": 117}, {"nodeid": "tests/researcher/export/test_models.py::test_document_with_sections_and_blocks", "type": "Function", "lineno": 129}]}, {"nodeid": "tests/researcher/export/test_service.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/export/test_service.py::test_create_document", "type": "Function", "lineno": 22}, {"nodeid": "tests/researcher/export/test_service.py::test_get_document", "type": "Function", "lineno": 42}, {"nodeid": "tests/researcher/export/test_service.py::test_update_document", "type": "Function", "lineno": 52}, {"nodeid": "tests/researcher/export/test_service.py::test_delete_document", "type": "Function", "lineno": 65}, {"nodeid": "tests/researcher/export/test_service.py::test_add_section", "type": "Function", "lineno": 74}, {"nodeid": "tests/researcher/export/test_service.py::test_add_section_with_order", "type": "Function", "lineno": 88}, {"nodeid": "tests/researcher/export/test_service.py::test_add_content_block", "type": "Function", "lineno": 105}, {"nodeid": "tests/researcher/export/test_service.py::test_create_content_blocks", "type": "Function", "lineno": 122}, {"nodeid": "tests/researcher/export/test_service.py::test_generate_markdown", "type": "Function", "lineno": 163}, {"nodeid": "tests/researcher/export/test_service.py::test_export_to_file", "type": "Function", "lineno": 183}]}, {"nodeid": "tests/researcher/export/test_storage.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/export/test_storage.py::test_create_document", "type": "Function", "lineno": 30}, {"nodeid": "tests/researcher/export/test_storage.py::test_get_document", "type": "Function", "lineno": 40}, {"nodeid": "tests/researcher/export/test_storage.py::test_get_nonexistent_document", "type": "Function", "lineno": 50}, {"nodeid": "tests/researcher/export/test_storage.py::test_update_document", "type": "Function", "lineno": 59}, {"nodeid": "tests/researcher/export/test_storage.py::test_update_nonexistent_document", "type": "Function", "lineno": 72}, {"nodeid": "tests/researcher/export/test_storage.py::test_delete_document", "type": "Function", "lineno": 80}, {"nodeid": "tests/researcher/export/test_storage.py::test_delete_nonexistent_document", "type": "Function", "lineno": 89}, {"nodeid": "tests/researcher/export/test_storage.py::test_list_documents", "type": "Function", "lineno": 98}]}, {"nodeid": "tests/researcher/export", "outcome": "passed", "result": [{"nodeid": "tests/researcher/export/test_formatter.py", "type": "Module"}, {"nodeid": "tests/researcher/export/test_models.py", "type": "Module"}, {"nodeid": "tests/researcher/export/test_service.py", "type": "Module"}, {"nodeid": "tests/researcher/export/test_storage.py", "type": "Module"}]}, {"nodeid": "tests/researcher/integration/test_multitask_workflow.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/integration/test_multitask_workflow.py::test_multitask_research_project", "type": "Function", "lineno": 58}]}, {"nodeid": "tests/researcher/integration/test_research_workflow.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/integration/test_research_workflow.py::test_complete_research_workflow", "type": "Function", "lineno": 39}]}, {"nodeid": "tests/researcher/integration", "outcome": "passed", "result": [{"nodeid": "tests/researcher/integration/test_multitask_workflow.py", "type": "Module"}, {"nodeid": "tests/researcher/integration/test_research_workflow.py", "type": "Module"}]}, {"nodeid": "tests/researcher/performance/test_bibliography_performance.py::TestBibliographyPerformance", "outcome": "passed", "result": [{"nodeid": "tests/researcher/performance/test_bibliography_performance.py::TestBibliographyPerformance::test_large_bibliography_operations", "type": "Function", "lineno": 23}, {"nodeid": "tests/researcher/performance/test_bibliography_performance.py::TestBibliographyPerformance::test_task_reference_link_performance", "type": "Function", "lineno": 160}]}, {"nodeid": "tests/researcher/performance/test_bibliography_performance.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/performance/test_bibliography_performance.py::TestBibliographyPerformance", "type": "Class"}]}, {"nodeid": "tests/researcher/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance", "outcome": "passed", "result": [{"nodeid": "tests/researcher/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_dataset_operations_performance", "type": "Function", "lineno": 20}, {"nodeid": "tests/researcher/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_handle_large_dataset_catalog", "type": "Function", "lineno": 57}, {"nodeid": "tests/researcher/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_handle_100gb_dataset_metadata", "type": "Function", "lineno": 110}, {"nodeid": "tests/researcher/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_complex_transformation_chain_performance", "type": "Function", "lineno": 166}, {"nodeid": "tests/researcher/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_task_dataset_link_performance", "type": "Function", "lineno": 237}]}, {"nodeid": "tests/researcher/performance/test_dataset_versioning_performance.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance", "type": "Class"}]}, {"nodeid": "tests/researcher/performance/test_environment_performance.py::TestEnvironmentPerformance", "outcome": "passed", "result": [{"nodeid": "tests/researcher/performance/test_environment_performance.py::TestEnvironmentPerformance::test_environment_operations_performance", "type": "Function", "lineno": 21}, {"nodeid": "tests/researcher/performance/test_environment_performance.py::TestEnvironmentPerformance::test_environment_snapshot_generation_time", "type": "Function", "lineno": 57}, {"nodeid": "tests/researcher/performance/test_environment_performance.py::TestEnvironmentPerformance::test_large_environment_catalog_performance", "type": "Function", "lineno": 82}, {"nodeid": "tests/researcher/performance/test_environment_performance.py::TestEnvironmentPerformance::test_complex_environment_performance", "type": "Function", "lineno": 161}, {"nodeid": "tests/researcher/performance/test_environment_performance.py::TestEnvironmentPerformance::test_task_environment_link_performance", "type": "Function", "lineno": 211}]}, {"nodeid": "tests/researcher/performance/test_environment_performance.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/performance/test_environment_performance.py::TestEnvironmentPerformance", "type": "Class"}]}, {"nodeid": "tests/researcher/performance/test_experiment_tracking_performance.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/performance/test_experiment_tracking_performance.py::test_experiment_creation_performance", "type": "Function", "lineno": 121}, {"nodeid": "tests/researcher/performance/test_experiment_tracking_performance.py::test_best_run_query_performance", "type": "Function", "lineno": 145}, {"nodeid": "tests/researcher/performance/test_experiment_tracking_performance.py::test_comparison_performance", "type": "Function", "lineno": 181}, {"nodeid": "tests/researcher/performance/test_experiment_tracking_performance.py::test_large_experiment_performance", "type": "Function", "lineno": 235}]}, {"nodeid": "tests/researcher/performance/test_export_performance.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/performance/test_export_performance.py::test_document_creation_performance", "type": "Function", "lineno": 94}, {"nodeid": "tests/researcher/performance/test_export_performance.py::test_markdown_generation_performance", "type": "Function", "lineno": 116}, {"nodeid": "tests/researcher/performance/test_export_performance.py::test_file_export_performance", "type": "Function", "lineno": 142}, {"nodeid": "tests/researcher/performance/test_export_performance.py::test_large_document_performance", "type": "Function", "lineno": 173}]}, {"nodeid": "tests/researcher/performance/test_integration_performance.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/performance/test_integration_performance.py::test_large_research_project_performance", "type": "Function", "lineno": 46}]}, {"nodeid": "tests/researcher/performance/test_task_management_performance.py::TestTaskManagementPerformance", "outcome": "passed", "result": [{"nodeid": "tests/researcher/performance/test_task_management_performance.py::TestTaskManagementPerformance::test_task_operation_speed", "type": "Function", "lineno": 16}, {"nodeid": "tests/researcher/performance/test_task_management_performance.py::TestTaskManagementPerformance::test_large_task_list_performance", "type": "Function", "lineno": 51}, {"nodeid": "tests/researcher/performance/test_task_management_performance.py::TestTaskManagementPerformance::test_research_question_hierarchy_performance", "type": "Function", "lineno": 135}, {"nodeid": "tests/researcher/performance/test_task_management_performance.py::TestTaskManagementPerformance::test_task_question_association_performance", "type": "Function", "lineno": 202}]}, {"nodeid": "tests/researcher/performance/test_task_management_performance.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/performance/test_task_management_performance.py::TestTaskManagementPerformance", "type": "Class"}]}, {"nodeid": "tests/researcher/performance", "outcome": "passed", "result": [{"nodeid": "tests/researcher/performance/test_bibliography_performance.py", "type": "Module"}, {"nodeid": "tests/researcher/performance/test_dataset_versioning_performance.py", "type": "Module"}, {"nodeid": "tests/researcher/performance/test_environment_performance.py", "type": "Module"}, {"nodeid": "tests/researcher/performance/test_experiment_tracking_performance.py", "type": "Module"}, {"nodeid": "tests/researcher/performance/test_export_performance.py", "type": "Module"}, {"nodeid": "tests/researcher/performance/test_integration_performance.py", "type": "Module"}, {"nodeid": "tests/researcher/performance/test_task_management_performance.py", "type": "Module"}]}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchQuestion", "outcome": "passed", "result": [{"nodeid": "tests/researcher/task_management/test_models.py::TestResearchQuestion::test_create_research_question", "type": "Function", "lineno": 14}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchQuestion::test_create_with_parent", "type": "Function", "lineno": 28}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchQuestion::test_update_question", "type": "Function", "lineno": 39}]}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask", "outcome": "passed", "result": [{"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_create_research_task", "type": "Function", "lineno": 60}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_task_with_due_date", "type": "Function", "lineno": 88}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_create_subtask", "type": "Function", "lineno": 99}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_update_task", "type": "Function", "lineno": 110}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_complete_task", "type": "Function", "lineno": 140}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_add_note", "type": "Function", "lineno": 155}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_manage_tags", "type": "Function", "lineno": 172}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_research_question_association", "type": "Function", "lineno": 199}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_subtask_management", "type": "Function", "lineno": 222}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_custom_metadata", "type": "Function", "lineno": 245}]}, {"nodeid": "tests/researcher/task_management/test_models.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/task_management/test_models.py::TestResearchQuestion", "type": "Class"}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask", "type": "Class"}]}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService", "outcome": "passed", "result": [{"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_create_task", "type": "Function", "lineno": 16}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_create_task_with_parent", "type": "Function", "lineno": 35}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_create_task_invalid_parent", "type": "Function", "lineno": 54}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_create_task_with_research_questions", "type": "Function", "lineno": 63}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_create_task_invalid_question", "type": "Function", "lineno": 83}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_update_task", "type": "Function", "lineno": 92}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_update_nonexistent_task", "type": "Function", "lineno": 121}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_delete_task", "type": "Function", "lineno": 129}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_add_task_note", "type": "Function", "lineno": 143}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_add_note_to_nonexistent_task", "type": "Function", "lineno": 159}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_tag_management", "type": "Function", "lineno": 164}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_custom_metadata", "type": "Function", "lineno": 189}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_filter_tasks", "type": "Function", "lineno": 206}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_research_question_operations", "type": "Function", "lineno": 264}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_research_question_hierarchy", "type": "Function", "lineno": 293}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_task_question_association", "type": "Function", "lineno": 325}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_associate_with_nonexistent_task", "type": "Function", "lineno": 359}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_associate_with_nonexistent_question", "type": "Function", "lineno": 368}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_get_subtasks", "type": "Function", "lineno": 378}]}, {"nodeid": "tests/researcher/task_management/test_service.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService", "type": "Class"}]}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage", "outcome": "passed", "result": [{"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_create_and_get_task", "type": "Function", "lineno": 13}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_update_task", "type": "Function", "lineno": 30}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_update_nonexistent_task", "type": "Function", "lineno": 54}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_task", "type": "Function", "lineno": 66}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_nonexistent_task", "type": "Function", "lineno": 82}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_list_tasks_empty", "type": "Function", "lineno": 89}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_list_tasks_with_filters", "type": "Function", "lineno": 96}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_research_question_operations", "type": "Function", "lineno": 170}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_update_nonexistent_question", "type": "Function", "lineno": 204}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_nonexistent_question", "type": "Function", "lineno": 216}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_list_research_questions", "type": "Function", "lineno": 223}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_task_question_associations", "type": "Function", "lineno": 270}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_subtask_relationships", "type": "Function", "lineno": 316}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_task_subtask_cleanup", "type": "Function", "lineno": 359}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_question_cleanup", "type": "Function", "lineno": 386}]}, {"nodeid": "tests/researcher/task_management/test_storage.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage", "type": "Class"}]}, {"nodeid": "tests/researcher/task_management", "outcome": "passed", "result": [{"nodeid": "tests/researcher/task_management/test_models.py", "type": "Module"}, {"nodeid": "tests/researcher/task_management/test_service.py", "type": "Module"}, {"nodeid": "tests/researcher/task_management/test_storage.py", "type": "Module"}]}, {"nodeid": "tests/researcher", "outcome": "passed", "result": [{"nodeid": "tests/researcher/bibliography", "type": "Package"}, {"nodeid": "tests/researcher/dataset_versioning", "type": "Package"}, {"nodeid": "tests/researcher/environment", "type": "Package"}, {"nodeid": "tests/researcher/experiment", "type": "Package"}, {"nodeid": "tests/researcher/experiment_tracking", "type": "Package"}, {"nodeid": "tests/researcher/export", "type": "Package"}, {"nodeid": "tests/researcher/integration", "type": "Package"}, {"nodeid": "tests/researcher/performance", "type": "Package"}, {"nodeid": "tests/researcher/task_management", "type": "Package"}]}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py", "outcome": "passed", "result": [{"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_models", "type": "Function", "lineno": 19}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_mapping", "type": "Function", "lineno": 86}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_repository_create_framework", "type": "Function", "lineno": 225}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_repository_add_controls", "type": "Function", "lineno": 264}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_repository_mappings", "type": "Function", "lineno": 346}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_repository_update_framework", "type": "Function", "lineno": 458}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_repository_delete_framework", "type": "Function", "lineno": 497}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_repository_list_and_count", "type": "Function", "lineno": 527}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_repository_import_framework", "type": "Function", "lineno": 585}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_performance", "type": "Function", "lineno": 650}]}, {"nodeid": "tests/security_analyst/compliance", "outcome": "passed", "result": [{"nodeid": "tests/security_analyst/compliance/test_compliance.py", "type": "Module"}]}, {"nodeid": "tests/security_analyst/cvss/test_cvss.py", "outcome": "passed", "result": [{"nodeid": "tests/security_analyst/cvss/test_cvss.py::test_cvss_vector_validation", "type": "Function", "lineno": 13}, {"nodeid": "tests/security_analyst/cvss/test_cvss.py::test_cvss_vector_string_conversion", "type": "Function", "lineno": 57}, {"nodeid": "tests/security_analyst/cvss/test_cvss.py::test_cvss_score_calculation", "type": "Function", "lineno": 128}, {"nodeid": "tests/security_analyst/cvss/test_cvss.py::test_cvss_calculation_with_scope_change", "type": "Function", "lineno": 216}, {"nodeid": "tests/security_analyst/cvss/test_cvss.py::test_cvss_calculation_with_temporal_metrics", "type": "Function", "lineno": 272}, {"nodeid": "tests/security_analyst/cvss/test_cvss.py::test_cvss_vector_string_parsing", "type": "Function", "lineno": 328}, {"nodeid": "tests/security_analyst/cvss/test_cvss.py::test_cvss_performance", "type": "Function", "lineno": 361}, {"nodeid": "tests/security_analyst/cvss/test_cvss.py::test_cvss_edge_cases", "type": "Function", "lineno": 403}]}, {"nodeid": "tests/security_analyst/cvss", "outcome": "passed", "result": [{"nodeid": "tests/security_analyst/cvss/test_cvss.py", "type": "Module"}]}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py", "outcome": "passed", "result": [{"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_model_validation", "type": "Function", "lineno": 28}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_store", "type": "Function", "lineno": 98}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_get_metadata", "type": "Function", "lineno": 151}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_retrieve", "type": "Function", "lineno": 215}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_update_metadata", "type": "Function", "lineno": 271}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_delete", "type": "Function", "lineno": 314}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_list_and_filter", "type": "Function", "lineno": 353}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_integrity", "type": "Function", "lineno": 434}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_store_oversized_file", "type": "Function", "lineno": 468}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_performance_benchmark", "type": "Function", "lineno": 488}]}, {"nodeid": "tests/security_analyst/evidence", "outcome": "passed", "result": [{"nodeid": "tests/security_analyst/evidence/test_evidence.py", "type": "Module"}]}, {"nodeid": "tests/security_analyst/findings/test_findings.py", "outcome": "passed", "result": [{"nodeid": "tests/security_analyst/findings/test_findings.py::test_finding_model_validation", "type": "Function", "lineno": 16}, {"nodeid": "tests/security_analyst/findings/test_findings.py::test_finding_create", "type": "Function", "lineno": 46}, {"nodeid": "tests/security_analyst/findings/test_findings.py::test_finding_get", "type": "Function", "lineno": 71}, {"nodeid": "tests/security_analyst/findings/test_findings.py::test_finding_update", "type": "Function", "lineno": 97}, {"nodeid": "tests/security_analyst/findings/test_findings.py::test_finding_delete", "type": "Function", "lineno": 132}, {"nodeid": "tests/security_analyst/findings/test_findings.py::test_finding_list_and_filter", "type": "Function", "lineno": 166}, {"nodeid": "tests/security_analyst/findings/test_findings.py::test_finding_crypto_integrity", "type": "Function", "lineno": 239}, {"nodeid": "tests/security_analyst/findings/test_findings.py::test_finding_performance_benchmark", "type": "Function", "lineno": 275}]}, {"nodeid": "tests/security_analyst/findings", "outcome": "passed", "result": [{"nodeid": "tests/security_analyst/findings/test_findings.py", "type": "Module"}]}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py", "outcome": "passed", "result": [{"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_task_model", "type": "Function", "lineno": 20}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_task_steps", "type": "Function", "lineno": 62}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_workflow_engine", "type": "Function", "lineno": 117}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_tracker_create_task", "type": "Function", "lineno": 199}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_tracker_get_task", "type": "Function", "lineno": 260}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_tracker_update_task", "type": "Function", "lineno": 289}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_tracker_transition_task", "type": "Function", "lineno": 327}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_tracker_get_transition_history", "type": "Function", "lineno": 412}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_tracker_list_and_filter", "type": "Function", "lineno": 462}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_tracker_delete_task", "type": "Function", "lineno": 536}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_tracker_metrics", "type": "Function", "lineno": 576}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_performance", "type": "Function", "lineno": 735}]}, {"nodeid": "tests/security_analyst/remediation", "outcome": "passed", "result": [{"nodeid": "tests/security_analyst/remediation/test_remediation.py", "type": "Module"}]}, {"nodeid": "tests/security_analyst/reporting/test_redaction.py", "outcome": "passed", "result": [{"nodeid": "tests/security_analyst/reporting/test_redaction.py::test_redaction_pattern_complex", "type": "Function", "lineno": 14}, {"nodeid": "tests/security_analyst/reporting/test_redaction.py::test_redaction_engine_comprehensive", "type": "Function", "lineno": 133}, {"nodeid": "tests/security_analyst/reporting/test_redaction.py::test_redaction_pattern_basic", "type": "Function", "lineno": 214}, {"nodeid": "tests/security_analyst/reporting/test_redaction.py::test_redaction_engine_basic", "type": "Function", "lineno": 244}, {"nodeid": "tests/security_analyst/reporting/test_redaction.py::test_redaction_engine_custom_patterns", "type": "Function", "lineno": 280}, {"nodeid": "tests/security_analyst/reporting/test_redaction.py::test_redaction_with_json_and_xml", "type": "Function", "lineno": 312}, {"nodeid": "tests/security_analyst/reporting/test_redaction.py::test_redaction_edge_cases", "type": "Function", "lineno": 377}, {"nodeid": "tests/security_analyst/reporting/test_redaction.py::test_redaction_patterns_builtin", "type": "Function", "lineno": 452}]}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py", "outcome": "passed", "result": [{"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_redaction_pattern", "type": "Function", "lineno": 46}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_redaction_engine", "type": "Function", "lineno": 79}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_report_model", "type": "Function", "lineno": 158}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_report_generator_integration", "type": "Function", "lineno": 201}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_evidence_report_template", "type": "Function", "lineno": 477}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_status_update_template", "type": "Function", "lineno": 658}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_evidence_report_access_levels", "type": "Function", "lineno": 856}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_status_update_with_no_findings", "type": "Function", "lineno": 1052}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_report_formats_rendering", "type": "Function", "lineno": 1115}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_report_generator_performance", "type": "Function", "lineno": 1220}]}, {"nodeid": "tests/security_analyst/reporting", "outcome": "passed", "result": [{"nodeid": "tests/security_analyst/reporting/test_redaction.py", "type": "Module"}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py", "type": "Module"}]}, {"nodeid": "tests/security_analyst/test_integration.py", "outcome": "passed", "result": [{"nodeid": "tests/security_analyst/test_integration.py::test_complete_security_assessment_workflow", "type": "Function", "lineno": 71}, {"nodeid": "tests/security_analyst/test_integration.py::test_integrity_checks_simple", "type": "Function", "lineno": 149}, {"nodeid": "tests/security_analyst/test_integration.py::test_redaction_basic", "type": "Function", "lineno": 172}]}, {"nodeid": "tests/security_analyst/test_stress.py", "outcome": "passed", "result": [{"nodeid": "tests/security_analyst/test_stress.py::test_large_findings_repository", "type": "Function", "lineno": 195}, {"nodeid": "tests/security_analyst/test_stress.py::test_large_evidence_vault", "type": "Function", "lineno": 257}, {"nodeid": "tests/security_analyst/test_stress.py::test_large_remediation_tracking", "type": "Function", "lineno": 334}, {"nodeid": "tests/security_analyst/test_stress.py::test_large_compliance_framework", "type": "Function", "lineno": 434}, {"nodeid": "tests/security_analyst/test_stress.py::test_large_report_generation", "type": "Function", "lineno": 564}, {"nodeid": "tests/security_analyst/test_stress.py::test_redaction_performance_large_data", "type": "Function", "lineno": 744}]}, {"nodeid": "tests/security_analyst/utils/test_crypto.py", "outcome": "passed", "result": [{"nodeid": "tests/security_analyst/utils/test_crypto.py::test_crypto_manager_init", "type": "Function", "lineno": 17}, {"nodeid": "tests/security_analyst/utils/test_crypto.py::test_encrypt_decrypt", "type": "Function", "lineno": 33}, {"nodeid": "tests/security_analyst/utils/test_crypto.py::test_integrity_verification", "type": "Function", "lineno": 66}, {"nodeid": "tests/security_analyst/utils/test_crypto.py::test_derive_key_from_password", "type": "Function", "lineno": 95}, {"nodeid": "tests/security_analyst/utils/test_crypto.py::test_hash_data", "type": "Function", "lineno": 128}, {"nodeid": "tests/security_analyst/utils/test_crypto.py::test_generate_random_id", "type": "Function", "lineno": 154}, {"nodeid": "tests/security_analyst/utils/test_crypto.py::test_encrypt_decrypt_performance", "type": "Function", "lineno": 176}, {"nodeid": "tests/security_analyst/utils/test_crypto.py::test_key_reuse", "type": "Function", "lineno": 213}, {"nodeid": "tests/security_analyst/utils/test_crypto.py::test_different_keys", "type": "Function", "lineno": 244}]}, {"nodeid": "tests/security_analyst/utils/test_validation.py", "outcome": "passed", "result": [{"nodeid": "tests/security_analyst/utils/test_validation.py::test_validation_error", "type": "Function", "lineno": 10}, {"nodeid": "tests/security_analyst/utils/test_validation.py::test_validate_file_size", "type": "Function", "lineno": 25}, {"nodeid": "tests/security_analyst/utils/test_validation.py::test_validate_cvss_metric", "type": "Function", "lineno": 53}, {"nodeid": "tests/security_analyst/utils/test_validation.py::test_validation_with_pydantic", "type": "Function", "lineno": 76}, {"nodeid": "tests/security_analyst/utils/test_validation.py::test_validate_file_size_edge_cases", "type": "Function", "lineno": 99}, {"nodeid": "tests/security_analyst/utils/test_validation.py::test_validate_cvss_metric_performance", "type": "Function", "lineno": 129}, {"nodeid": "tests/security_analyst/utils/test_validation.py::test_validation_error_inheritance", "type": "Function", "lineno": 149}]}, {"nodeid": "tests/security_analyst/utils", "outcome": "passed", "result": [{"nodeid": "tests/security_analyst/utils/test_crypto.py", "type": "Module"}, {"nodeid": "tests/security_analyst/utils/test_validation.py", "type": "Module"}]}, {"nodeid": "tests/security_analyst", "outcome": "passed", "result": [{"nodeid": "tests/security_analyst/compliance", "type": "Package"}, {"nodeid": "tests/security_analyst/cvss", "type": "Package"}, {"nodeid": "tests/security_analyst/evidence", "type": "Package"}, {"nodeid": "tests/security_analyst/findings", "type": "Package"}, {"nodeid": "tests/security_analyst/remediation", "type": "Package"}, {"nodeid": "tests/security_analyst/reporting", "type": "Package"}, {"nodeid": "tests/security_analyst/test_integration.py", "type": "Module"}, {"nodeid": "tests/security_analyst/test_stress.py", "type": "Module"}, {"nodeid": "tests/security_analyst/utils", "type": "Package"}]}, {"nodeid": "tests", "outcome": "passed", "result": [{"nodeid": "tests/researcher", "type": "Package"}, {"nodeid": "tests/security_analyst", "type": "Package"}]}], "tests": [{"nodeid": "tests/researcher/bibliography/test_formatter.py::TestReferenceFormatter::test_apa_formatting", "lineno": 101, "outcome": "passed", "keywords": ["test_apa_formatting", "TestReferenceFormatter", "test_formatter.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.000874845078215003, "outcome": "passed"}, "call": {"duration": 0.00022145616821944714, "outcome": "passed"}, "teardown": {"duration": 0.0001616920344531536, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_formatter.py::TestReferenceFormatter::test_mla_formatting", "lineno": 133, "outcome": "passed", "keywords": ["test_mla_formatting", "TestReferenceFormatter", "test_formatter.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00032171490602195263, "outcome": "passed"}, "call": {"duration": 0.00016496400348842144, "outcome": "passed"}, "teardown": {"duration": 0.00013675191439688206, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_formatter.py::TestReferenceFormatter::test_harvard_formatting", "lineno": 156, "outcome": "passed", "keywords": ["test_harvard_formatting", "TestReferenceFormatter", "test_formatter.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00029497919604182243, "outcome": "passed"}, "call": {"duration": 0.00015102815814316273, "outcome": "passed"}, "teardown": {"duration": 0.00013274699449539185, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_formatter.py::TestReferenceFormatter::test_ieee_formatting", "lineno": 170, "outcome": "passed", "keywords": ["test_ieee_formatting", "TestReferenceFormatter", "test_formatter.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002880420070141554, "outcome": "passed"}, "call": {"duration": 0.00014281785115599632, "outcome": "passed"}, "teardown": {"duration": 0.00013053999282419682, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_formatter.py::TestReferenceFormatter::test_in_text_citations", "lineno": 182, "outcome": "passed", "keywords": ["test_in_text_citations", "TestReferenceFormatter", "test_formatter.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0003041601739823818, "outcome": "passed"}, "call": {"duration": 0.00015187892131507397, "outcome": "passed"}, "teardown": {"duration": 0.00015015993267297745, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_formatter.py::TestReferenceFormatter::test_generate_bibliography", "lineno": 209, "outcome": "passed", "keywords": ["test_generate_bibliography", "TestReferenceFormatter", "test_formatter.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0004111221060156822, "outcome": "passed"}, "call": {"duration": 0.00018772599287331104, "outcome": "passed"}, "teardown": {"duration": 0.000147518003359437, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_formatter.py::TestReferenceFormatter::test_author_formatting", "lineno": 238, "outcome": "passed", "keywords": ["test_author_formatting", "TestReferenceFormatter", "test_formatter.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002822231035679579, "outcome": "passed"}, "call": {"duration": 0.00021471898071467876, "outcome": "passed"}, "teardown": {"duration": 0.00014002900570631027, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_json_single_reference", "lineno": 10, "outcome": "passed", "keywords": ["test_import_from_json_single_reference", "TestBibliographyImporter", "test_importer.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011691218242049217, "outcome": "passed"}, "call": {"duration": 0.0002073200885206461, "outcome": "passed"}, "teardown": {"duration": 0.0001182348933070898, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_json_multiple_references", "lineno": 71, "outcome": "passed", "keywords": ["test_import_from_json_multiple_references", "TestBibliographyImporter", "test_importer.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011022388935089111, "outcome": "passed"}, "call": {"duration": 0.00026813498698174953, "outcome": "passed"}, "teardown": {"duration": 0.00011377292685210705, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_json_string", "lineno": 143, "outcome": "passed", "keywords": ["test_import_from_json_string", "TestBibliographyImporter", "test_importer.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010843295603990555, "outcome": "passed"}, "call": {"duration": 0.00021941796876490116, "outcome": "passed"}, "teardown": {"duration": 0.00012246007099747658, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_invalid_json", "lineno": 165, "outcome": "passed", "keywords": ["test_import_from_invalid_json", "TestBibliographyImporter", "test_importer.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011328211985528469, "outcome": "passed"}, "call": {"duration": 0.00031761988066136837, "outcome": "passed"}, "teardown": {"duration": 0.00011310004629194736, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_importer.py::TestBibliographyImporter::test_import_handles_missing_fields", "lineno": 170, "outcome": "passed", "keywords": ["test_import_handles_missing_fields", "TestBibliographyImporter", "test_importer.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001099549699574709, "outcome": "passed"}, "call": {"duration": 0.00017196382395923138, "outcome": "passed"}, "teardown": {"duration": 0.00013948907144367695, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_importer.py::TestBibliographyImporter::test_export_to_json", "lineno": 186, "outcome": "passed", "keywords": ["test_export_to_json", "TestBibliographyImporter", "test_importer.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00012065190821886063, "outcome": "passed"}, "call": {"duration": 0.00031913211569190025, "outcome": "passed"}, "teardown": {"duration": 0.00019927090033888817, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_importer.py::TestBibliographyImporter::test_import_export_roundtrip", "lineno": 262, "outcome": "passed", "keywords": ["test_import_export_roundtrip", "TestBibliographyImporter", "test_importer.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00012709200382232666, "outcome": "passed"}, "call": {"duration": 0.0003192031290382147, "outcome": "passed"}, "teardown": {"duration": 0.00011479388922452927, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_importer.py::TestBibliographyImporter::test_import_from_bibtex_basic", "lineno": 307, "outcome": "passed", "keywords": ["test_import_from_bibtex_basic", "TestBibliographyImporter", "test_importer.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011269282549619675, "outcome": "passed"}, "call": {"duration": 0.0008669930975884199, "outcome": "passed"}, "teardown": {"duration": 0.00013531791046261787, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestAuthor::test_create_person_author", "lineno": 15, "outcome": "passed", "keywords": ["test_create_person_author", "TestAuthor", "test_models.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001187820453196764, "outcome": "passed"}, "call": {"duration": 0.0001485717948526144, "outcome": "passed"}, "teardown": {"duration": 0.00011303904466331005, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestAuthor::test_create_organization_author", "lineno": 31, "outcome": "passed", "keywords": ["test_create_organization_author", "TestAuthor", "test_models.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011786608956754208, "outcome": "passed"}, "call": {"duration": 0.000147378072142601, "outcome": "passed"}, "teardown": {"duration": 0.00010612490586936474, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestAuthor::test_author_full_name_person", "lineno": 45, "outcome": "passed", "keywords": ["test_author_full_name_person", "TestAuthor", "test_models.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011142902076244354, "outcome": "passed"}, "call": {"duration": 0.00016432208940386772, "outcome": "passed"}, "teardown": {"duration": 0.00010459800250828266, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestAuthor::test_author_full_name_organization", "lineno": 76, "outcome": "passed", "keywords": ["test_author_full_name_organization", "TestAuthor", "test_models.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011247000657022, "outcome": "passed"}, "call": {"duration": 0.0001523259561508894, "outcome": "passed"}, "teardown": {"duration": 0.00011048000305891037, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_create_journal_article", "lineno": 92, "outcome": "passed", "keywords": ["test_create_journal_article", "TestReference", "test_models.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011152680963277817, "outcome": "passed"}, "call": {"duration": 0.00018333201296627522, "outcome": "passed"}, "teardown": {"duration": 0.00010462198406457901, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_create_book", "lineno": 137, "outcome": "passed", "keywords": ["test_create_book", "TestReference", "test_models.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010640989057719707, "outcome": "passed"}, "call": {"duration": 0.00016461312770843506, "outcome": "passed"}, "teardown": {"duration": 0.00010458310134708881, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_create_website", "lineno": 164, "outcome": "passed", "keywords": ["test_create_website", "TestReference", "test_models.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010572001338005066, "outcome": "passed"}, "call": {"duration": 0.00015752296894788742, "outcome": "passed"}, "teardown": {"duration": 0.00011408701539039612, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_update_reference", "lineno": 190, "outcome": "passed", "keywords": ["test_update_reference", "TestReference", "test_models.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010912399739027023, "outcome": "passed"}, "call": {"duration": 0.00019702105782926083, "outcome": "passed"}, "teardown": {"duration": 0.00010555097833275795, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_add_author", "lineno": 215, "outcome": "passed", "keywords": ["test_add_author", "TestReference", "test_models.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010701315477490425, "outcome": "passed"}, "call": {"duration": 0.0002538170665502548, "outcome": "passed"}, "teardown": {"duration": 0.0001147598959505558, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_remove_author", "lineno": 245, "outcome": "passed", "keywords": ["test_remove_author", "TestReference", "test_models.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011335802264511585, "outcome": "passed"}, "call": {"duration": 0.0001877888571470976, "outcome": "passed"}, "teardown": {"duration": 0.00011981395073235035, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_keywords", "lineno": 280, "outcome": "passed", "keywords": ["test_keywords", "TestReference", "test_models.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010984507389366627, "outcome": "passed"}, "call": {"duration": 0.00016051414422690868, "outcome": "passed"}, "teardown": {"duration": 0.00010687694884836674, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_notes", "lineno": 313, "outcome": "passed", "keywords": ["test_notes", "TestReference", "test_models.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010688602924346924, "outcome": "passed"}, "call": {"duration": 0.000151726882904768, "outcome": "passed"}, "teardown": {"duration": 0.00010117399506270885, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_custom_fields", "lineno": 331, "outcome": "passed", "keywords": ["test_custom_fields", "TestReference", "test_models.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001079400535672903, "outcome": "passed"}, "call": {"duration": 0.00016730790957808495, "outcome": "passed"}, "teardown": {"duration": 0.00010820594616234303, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestReference::test_author_names_formatted", "lineno": 366, "outcome": "passed", "keywords": ["test_author_names_formatted", "TestReference", "test_models.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001048678532242775, "outcome": "passed"}, "call": {"duration": 0.00020884699188172817, "outcome": "passed"}, "teardown": {"duration": 0.00010874215513467789, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestTaskReferenceLink::test_create_task_reference_link", "lineno": 416, "outcome": "passed", "keywords": ["test_create_task_reference_link", "TestTaskReferenceLink", "test_models.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010663503780961037, "outcome": "passed"}, "call": {"duration": 0.00017218198627233505, "outcome": "passed"}, "teardown": {"duration": 0.00011419388465583324, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestTaskReferenceLink::test_update_link", "lineno": 435, "outcome": "passed", "keywords": ["test_update_link", "TestTaskReferenceLink", "test_models.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010710977949202061, "outcome": "passed"}, "call": {"duration": 0.0001705510076135397, "outcome": "passed"}, "teardown": {"duration": 0.00010467995889484882, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_models.py::TestTaskReferenceLink::test_add_note", "lineno": 453, "outcome": "passed", "keywords": ["test_add_note", "TestTaskReferenceLink", "test_models.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001073228195309639, "outcome": "passed"}, "call": {"duration": 0.00015573506243526936, "outcome": "passed"}, "teardown": {"duration": 0.00010637403465807438, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_create_author_methods", "lineno": 26, "outcome": "passed", "keywords": ["test_create_author_methods", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021437089890241623, "outcome": "passed"}, "call": {"duration": 0.0001629760954529047, "outcome": "passed"}, "teardown": {"duration": 0.00013084313832223415, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_create_journal_article", "lineno": 49, "outcome": "passed", "keywords": ["test_create_journal_article", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021044397726655006, "outcome": "passed"}, "call": {"duration": 0.0001759701408445835, "outcome": "passed"}, "teardown": {"duration": 0.00012932298704981804, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_create_book", "lineno": 82, "outcome": "passed", "keywords": ["test_create_book", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020276405848562717, "outcome": "passed"}, "call": {"duration": 0.00017769797705113888, "outcome": "passed"}, "teardown": {"duration": 0.00012837001122534275, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_create_website", "lineno": 111, "outcome": "passed", "keywords": ["test_create_website", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021617300808429718, "outcome": "passed"}, "call": {"duration": 0.0001857229508459568, "outcome": "passed"}, "teardown": {"duration": 0.0001306920312345028, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_create_generic_reference", "lineno": 139, "outcome": "passed", "keywords": ["test_create_generic_reference", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020338711328804493, "outcome": "passed"}, "call": {"duration": 0.00020171096548438072, "outcome": "passed"}, "teardown": {"duration": 0.00013121007941663265, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_update_reference", "lineno": 166, "outcome": "passed", "keywords": ["test_update_reference", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020672287791967392, "outcome": "passed"}, "call": {"duration": 0.00018859421834349632, "outcome": "passed"}, "teardown": {"duration": 0.00013894611038267612, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_update_nonexistent_reference", "lineno": 193, "outcome": "passed", "keywords": ["test_update_nonexistent_reference", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020226417109370232, "outcome": "passed"}, "call": {"duration": 0.00029368000105023384, "outcome": "passed"}, "teardown": {"duration": 0.00013980991207063198, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_delete_reference", "lineno": 205, "outcome": "passed", "keywords": ["test_delete_reference", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021105282939970493, "outcome": "passed"}, "call": {"duration": 0.00017082993872463703, "outcome": "passed"}, "teardown": {"duration": 0.0001282310113310814, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_search_references", "lineno": 224, "outcome": "passed", "keywords": ["test_search_references", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.000194573774933815, "outcome": "passed"}, "call": {"duration": 0.0003186610992997885, "outcome": "passed"}, "teardown": {"duration": 0.00015241093933582306, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_reference_modification_methods", "lineno": 289, "outcome": "passed", "keywords": ["test_reference_modification_methods", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020611588843166828, "outcome": "passed"}, "call": {"duration": 0.00021117297001183033, "outcome": "passed"}, "teardown": {"duration": 0.00014162110164761543, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_link_task_to_reference", "lineno": 326, "outcome": "passed", "keywords": ["test_link_task_to_reference", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019815796986222267, "outcome": "passed"}, "call": {"duration": 0.00018102512694895267, "outcome": "passed"}, "teardown": {"duration": 0.00014292518608272076, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_link_to_nonexistent_reference", "lineno": 352, "outcome": "passed", "keywords": ["test_link_to_nonexistent_reference", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002024979330599308, "outcome": "passed"}, "call": {"duration": 0.0001691649667918682, "outcome": "passed"}, "teardown": {"duration": 0.000136462040245533, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_update_task_reference_link", "lineno": 360, "outcome": "passed", "keywords": ["test_update_task_reference_link", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019597518257796764, "outcome": "passed"}, "call": {"duration": 0.00018257787451148033, "outcome": "passed"}, "teardown": {"duration": 0.0001467971596866846, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_add_note_to_link", "lineno": 388, "outcome": "passed", "keywords": ["test_add_note_to_link", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019847601652145386, "outcome": "passed"}, "call": {"duration": 0.00019418797455728054, "outcome": "passed"}, "teardown": {"duration": 0.00014275405555963516, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_get_references_by_task", "lineno": 412, "outcome": "passed", "keywords": ["test_get_references_by_task", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020599504932761192, "outcome": "passed"}, "call": {"duration": 0.00022091111168265343, "outcome": "passed"}, "teardown": {"duration": 0.00013209902681410313, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_get_tasks_by_reference", "lineno": 448, "outcome": "passed", "keywords": ["test_get_tasks_by_reference", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019232393242418766, "outcome": "passed"}, "call": {"duration": 0.00018752506002783775, "outcome": "passed"}, "teardown": {"duration": 0.00013676495291292667, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_delete_task_reference_link", "lineno": 468, "outcome": "passed", "keywords": ["test_delete_task_reference_link", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019790302030742168, "outcome": "passed"}, "call": {"duration": 0.00018000882118940353, "outcome": "passed"}, "teardown": {"duration": 0.00013729208149015903, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_citation_formatting", "lineno": 490, "outcome": "passed", "keywords": ["test_citation_formatting", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019551115110516548, "outcome": "passed"}, "call": {"duration": 0.00021748896688222885, "outcome": "passed"}, "teardown": {"duration": 0.00012956606224179268, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_in_text_citation_formatting", "lineno": 524, "outcome": "passed", "keywords": ["test_in_text_citation_formatting", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019532605074346066, "outcome": "passed"}, "call": {"duration": 0.0001780430320650339, "outcome": "passed"}, "teardown": {"duration": 0.000138081144541502, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_service.py::TestBibliographyService::test_generate_task_bibliography", "lineno": 548, "outcome": "passed", "keywords": ["test_generate_task_bibliography", "TestBibliographyService", "test_service.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019235513173043728, "outcome": "passed"}, "call": {"duration": 0.00026318710297346115, "outcome": "passed"}, "teardown": {"duration": 0.00013238214887678623, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_create_and_get_reference", "lineno": 53, "outcome": "passed", "keywords": ["test_create_and_get_reference", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0003233260940760374, "outcome": "passed"}, "call": {"duration": 0.00013415096327662468, "outcome": "passed"}, "teardown": {"duration": 0.00013101007789373398, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_update_reference", "lineno": 64, "outcome": "passed", "keywords": ["test_update_reference", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00023843091912567616, "outcome": "passed"}, "call": {"duration": 0.0001368809025734663, "outcome": "passed"}, "teardown": {"duration": 0.00013036001473665237, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_update_nonexistent_reference", "lineno": 79, "outcome": "passed", "keywords": ["test_update_nonexistent_reference", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.000250489916652441, "outcome": "passed"}, "call": {"duration": 0.00014410610310733318, "outcome": "passed"}, "teardown": {"duration": 0.00012907898053526878, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_delete_reference", "lineno": 91, "outcome": "passed", "keywords": ["test_delete_reference", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00023651611991226673, "outcome": "passed"}, "call": {"duration": 0.00014322088100016117, "outcome": "passed"}, "teardown": {"duration": 0.0001274759415537119, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_delete_nonexistent_reference", "lineno": 111, "outcome": "passed", "keywords": ["test_delete_nonexistent_reference", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00024007889442145824, "outcome": "passed"}, "call": {"duration": 0.0001335740089416504, "outcome": "passed"}, "teardown": {"duration": 0.00013023917563259602, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_list_references_empty", "lineno": 116, "outcome": "passed", "keywords": ["test_list_references_empty", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00023450003936886787, "outcome": "passed"}, "call": {"duration": 0.00012657279148697853, "outcome": "passed"}, "teardown": {"duration": 0.00020252191461622715, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_list_references_with_filters", "lineno": 121, "outcome": "passed", "keywords": ["test_list_references_with_filters", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00029268511570990086, "outcome": "passed"}, "call": {"duration": 0.00017889682203531265, "outcome": "passed"}, "teardown": {"duration": 0.0001436891034245491, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_task_reference_link_operations", "lineno": 165, "outcome": "passed", "keywords": ["test_task_reference_link_operations", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002748621627688408, "outcome": "passed"}, "call": {"duration": 0.00018606893718242645, "outcome": "passed"}, "teardown": {"duration": 0.00013626599684357643, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_get_references_by_task", "lineno": 217, "outcome": "passed", "keywords": ["test_get_references_by_task", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002591430675238371, "outcome": "passed"}, "call": {"duration": 0.0001723680179566145, "outcome": "passed"}, "teardown": {"duration": 0.00016101496294140816, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_get_links_by_task", "lineno": 252, "outcome": "passed", "keywords": ["test_get_links_by_task", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00025091320276260376, "outcome": "passed"}, "call": {"duration": 0.00016361195594072342, "outcome": "passed"}, "teardown": {"duration": 0.0001315867993980646, "outcome": "passed"}}, {"nodeid": "tests/researcher/bibliography/test_storage.py::TestInMemoryBibliographyStorage::test_get_tasks_by_reference", "lineno": 282, "outcome": "passed", "keywords": ["test_get_tasks_by_reference", "TestInMemoryBibliographyStorage", "test_storage.py", "bibliography", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00024637789465487003, "outcome": "passed"}, "call": {"duration": 0.00015700305812060833, "outcome": "passed"}, "teardown": {"duration": 0.0001337430439889431, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataset::test_create_dataset", "lineno": 17, "outcome": "passed", "keywords": ["test_create_dataset", "TestDataset", "test_models.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0003076428547501564, "outcome": "passed"}, "call": {"duration": 0.00018221302889287472, "outcome": "passed"}, "teardown": {"duration": 0.00012022792361676693, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataset::test_update_dataset", "lineno": 61, "outcome": "passed", "keywords": ["test_update_dataset", "TestDataset", "test_models.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011278106831014156, "outcome": "passed"}, "call": {"duration": 0.0002752668224275112, "outcome": "passed"}, "teardown": {"duration": 0.00012194388546049595, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataset::test_dataset_tags", "lineno": 88, "outcome": "passed", "keywords": ["test_dataset_tags", "TestDataset", "test_models.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011642114259302616, "outcome": "passed"}, "call": {"duration": 0.0001634419895708561, "outcome": "passed"}, "teardown": {"duration": 0.00010890187695622444, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataset::test_dataset_custom_metadata", "lineno": 121, "outcome": "passed", "keywords": ["test_dataset_custom_metadata", "TestDataset", "test_models.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011053495109081268, "outcome": "passed"}, "call": {"duration": 0.00016175187192857265, "outcome": "passed"}, "teardown": {"duration": 0.00010563409887254238, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDatasetVersion::test_create_dataset_version", "lineno": 167, "outcome": "passed", "keywords": ["test_create_dataset_version", "TestDatasetVersion", "test_models.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011628912761807442, "outcome": "passed"}, "call": {"duration": 0.00018069404177367687, "outcome": "passed"}, "teardown": {"duration": 0.00011343997903168201, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDatasetVersion::test_update_version", "lineno": 212, "outcome": "passed", "keywords": ["test_update_version", "TestDatasetVersion", "test_models.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011041504330933094, "outcome": "passed"}, "call": {"duration": 0.00018371082842350006, "outcome": "passed"}, "teardown": {"duration": 0.00010673492215573788, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDatasetVersion::test_version_custom_metadata", "lineno": 234, "outcome": "passed", "keywords": ["test_version_custom_metadata", "TestDatasetVersion", "test_models.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011384603567421436, "outcome": "passed"}, "call": {"duration": 0.00015858490951359272, "outcome": "passed"}, "teardown": {"duration": 0.00010487786494195461, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataTransformation::test_create_data_transformation", "lineno": 267, "outcome": "passed", "keywords": ["test_create_data_transformation", "TestDataTransformation", "test_models.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010812701657414436, "outcome": "passed"}, "call": {"duration": 0.00018717395141720772, "outcome": "passed"}, "teardown": {"duration": 0.00010791188105940819, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataTransformation::test_update_transformation", "lineno": 302, "outcome": "passed", "keywords": ["test_update_transformation", "TestDataTransformation", "test_models.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00012732786126434803, "outcome": "passed"}, "call": {"duration": 0.00019043590873479843, "outcome": "passed"}, "teardown": {"duration": 0.00010782084427773952, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataTransformation::test_transformation_tags", "lineno": 327, "outcome": "passed", "keywords": ["test_transformation_tags", "TestDataTransformation", "test_models.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010793493129312992, "outcome": "passed"}, "call": {"duration": 0.00015475205145776272, "outcome": "passed"}, "teardown": {"duration": 0.0001042420044541359, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataTransformation::test_transformation_notes", "lineno": 357, "outcome": "passed", "keywords": ["test_transformation_notes", "TestDataTransformation", "test_models.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011090794578194618, "outcome": "passed"}, "call": {"duration": 0.00015128706581890583, "outcome": "passed"}, "teardown": {"duration": 0.0001186891458928585, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestDataTransformation::test_transformation_parameters", "lineno": 376, "outcome": "passed", "keywords": ["test_transformation_parameters", "TestDataTransformation", "test_models.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011162296868860722, "outcome": "passed"}, "call": {"duration": 0.000164389843121171, "outcome": "passed"}, "teardown": {"duration": 0.00011010188609361649, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestTaskDatasetLink::test_create_task_dataset_link", "lineno": 411, "outcome": "passed", "keywords": ["test_create_task_dataset_link", "TestTaskDatasetLink", "test_models.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010721385478973389, "outcome": "passed"}, "call": {"duration": 0.0001820400357246399, "outcome": "passed"}, "teardown": {"duration": 0.00011176499538123608, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestTaskDatasetLink::test_update_link", "lineno": 432, "outcome": "passed", "keywords": ["test_update_link", "TestTaskDatasetLink", "test_models.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001109871082007885, "outcome": "passed"}, "call": {"duration": 0.00018435204401612282, "outcome": "passed"}, "teardown": {"duration": 0.00012367311865091324, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_models.py::TestTaskDatasetLink::test_link_notes", "lineno": 455, "outcome": "passed", "keywords": ["test_link_notes", "TestTaskDatasetLink", "test_models.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010896986350417137, "outcome": "passed"}, "call": {"duration": 0.000152326887473464, "outcome": "passed"}, "teardown": {"duration": 0.00011265696957707405, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_dataset", "lineno": 23, "outcome": "passed", "keywords": ["test_create_dataset", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002220049500465393, "outcome": "passed"}, "call": {"duration": 0.00016833399422466755, "outcome": "passed"}, "teardown": {"duration": 0.00012749293819069862, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_update_dataset", "lineno": 58, "outcome": "passed", "keywords": ["test_update_dataset", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021039508283138275, "outcome": "passed"}, "call": {"duration": 0.00016663200221955776, "outcome": "passed"}, "teardown": {"duration": 0.0001415889710187912, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_update_nonexistent_dataset", "lineno": 86, "outcome": "passed", "keywords": ["test_update_nonexistent_dataset", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020953314378857613, "outcome": "passed"}, "call": {"duration": 0.0002548841293901205, "outcome": "passed"}, "teardown": {"duration": 0.00013721291907131672, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_delete_dataset", "lineno": 94, "outcome": "passed", "keywords": ["test_delete_dataset", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020326999947428703, "outcome": "passed"}, "call": {"duration": 0.00017428211867809296, "outcome": "passed"}, "teardown": {"duration": 0.00013908394612371922, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_list_datasets", "lineno": 112, "outcome": "passed", "keywords": ["test_list_datasets", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020202714949846268, "outcome": "passed"}, "call": {"duration": 0.00022220495156943798, "outcome": "passed"}, "teardown": {"duration": 0.00014197197742760181, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_dataset_tags", "lineno": 167, "outcome": "passed", "keywords": ["test_dataset_tags", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019959593191742897, "outcome": "passed"}, "call": {"duration": 0.0001710259821265936, "outcome": "passed"}, "teardown": {"duration": 0.00013805599883198738, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_dataset_custom_metadata", "lineno": 189, "outcome": "passed", "keywords": ["test_dataset_custom_metadata", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002728579565882683, "outcome": "passed"}, "call": {"duration": 0.00018561002798378468, "outcome": "passed"}, "teardown": {"duration": 0.00013832584954798222, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_dataset_version", "lineno": 214, "outcome": "passed", "keywords": ["test_create_dataset_version", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002008611336350441, "outcome": "passed"}, "call": {"duration": 0.00020433589816093445, "outcome": "passed"}, "teardown": {"duration": 0.00013404479250311852, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_dataset_version_with_parent", "lineno": 253, "outcome": "passed", "keywords": ["test_create_dataset_version_with_parent", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021116016432642937, "outcome": "passed"}, "call": {"duration": 0.00018753483891487122, "outcome": "passed"}, "teardown": {"duration": 0.0001392001286149025, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_version_nonexistent_dataset", "lineno": 284, "outcome": "passed", "keywords": ["test_create_version_nonexistent_dataset", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002002629917114973, "outcome": "passed"}, "call": {"duration": 0.0001648769248276949, "outcome": "passed"}, "teardown": {"duration": 0.00013279682025313377, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_version_nonexistent_parent", "lineno": 293, "outcome": "passed", "keywords": ["test_create_version_nonexistent_parent", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019429298117756844, "outcome": "passed"}, "call": {"duration": 0.00031598983332514763, "outcome": "passed"}, "teardown": {"duration": 0.00014267303049564362, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_update_dataset_version", "lineno": 310, "outcome": "passed", "keywords": ["test_update_dataset_version", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022352999076247215, "outcome": "passed"}, "call": {"duration": 0.00022042985074222088, "outcome": "passed"}, "teardown": {"duration": 0.0001361318863928318, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_version_operations", "lineno": 348, "outcome": "passed", "keywords": ["test_version_operations", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001989689189940691, "outcome": "passed"}, "call": {"duration": 0.00024025095626711845, "outcome": "passed"}, "teardown": {"duration": 0.0001401090994477272, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_data_transformation", "lineno": 402, "outcome": "passed", "keywords": ["test_create_data_transformation", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020465999841690063, "outcome": "passed"}, "call": {"duration": 0.0002080099657177925, "outcome": "passed"}, "teardown": {"duration": 0.00013326294720172882, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_create_transformation_nonexistent_version", "lineno": 455, "outcome": "passed", "keywords": ["test_create_transformation_nonexistent_version", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019889092072844505, "outcome": "passed"}, "call": {"duration": 0.0002876059152185917, "outcome": "passed"}, "teardown": {"duration": 0.00013932888396084309, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_transformation_operations", "lineno": 465, "outcome": "passed", "keywords": ["test_transformation_operations", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002191639505326748, "outcome": "passed"}, "call": {"duration": 0.00023687793873250484, "outcome": "passed"}, "teardown": {"duration": 0.00013415003195405006, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_link_task_to_dataset_version", "lineno": 551, "outcome": "passed", "keywords": ["test_link_task_to_dataset_version", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002411198802292347, "outcome": "passed"}, "call": {"duration": 0.00019298307597637177, "outcome": "passed"}, "teardown": {"duration": 0.0001336971763521433, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_link_to_nonexistent_version", "lineno": 582, "outcome": "passed", "keywords": ["test_link_to_nonexistent_version", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019999593496322632, "outcome": "passed"}, "call": {"duration": 0.0002619801089167595, "outcome": "passed"}, "teardown": {"duration": 0.0001348468940705061, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_task_dataset_link_operations", "lineno": 590, "outcome": "passed", "keywords": ["test_task_dataset_link_operations", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001999950036406517, "outcome": "passed"}, "call": {"duration": 0.0010463329963386059, "outcome": "passed"}, "teardown": {"duration": 0.00016178609803318977, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_service.py::TestDatasetVersioningService::test_dataset_lineage", "lineno": 661, "outcome": "passed", "keywords": ["test_dataset_lineage", "TestDatasetVersioningService", "test_service.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022588390856981277, "outcome": "passed"}, "call": {"duration": 0.0002651058603078127, "outcome": "passed"}, "teardown": {"duration": 0.00015131989493966103, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_create_and_get_dataset", "lineno": 43, "outcome": "passed", "keywords": ["test_create_and_get_dataset", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002546070609241724, "outcome": "passed"}, "call": {"duration": 0.00013322406448423862, "outcome": "passed"}, "teardown": {"duration": 0.00013890303671360016, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_update_dataset", "lineno": 55, "outcome": "passed", "keywords": ["test_update_dataset", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002341759391129017, "outcome": "passed"}, "call": {"duration": 0.00014396989718079567, "outcome": "passed"}, "teardown": {"duration": 0.00014460692182183266, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_update_nonexistent_dataset", "lineno": 70, "outcome": "passed", "keywords": ["test_update_nonexistent_dataset", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00023523089475929737, "outcome": "passed"}, "call": {"duration": 0.00014794198796153069, "outcome": "passed"}, "teardown": {"duration": 0.00013509206473827362, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_delete_dataset", "lineno": 83, "outcome": "passed", "keywords": ["test_delete_dataset", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021931598894298077, "outcome": "passed"}, "call": {"duration": 0.00016593211330473423, "outcome": "passed"}, "teardown": {"duration": 0.0001349709928035736, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_delete_nonexistent_dataset", "lineno": 114, "outcome": "passed", "keywords": ["test_delete_nonexistent_dataset", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002223269548267126, "outcome": "passed"}, "call": {"duration": 0.00013660499826073647, "outcome": "passed"}, "teardown": {"duration": 0.00013548298738896847, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_list_datasets_empty", "lineno": 119, "outcome": "passed", "keywords": ["test_list_datasets_empty", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00023197592236101627, "outcome": "passed"}, "call": {"duration": 0.00013156398199498653, "outcome": "passed"}, "teardown": {"duration": 0.00013699010014533997, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_list_datasets_with_filters", "lineno": 124, "outcome": "passed", "keywords": ["test_list_datasets_with_filters", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022065709345042706, "outcome": "passed"}, "call": {"duration": 0.00014577293768525124, "outcome": "passed"}, "teardown": {"duration": 0.00012975605204701424, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_dataset_version_operations", "lineno": 160, "outcome": "passed", "keywords": ["test_dataset_version_operations", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022312509827315807, "outcome": "passed"}, "call": {"duration": 0.00017863791435956955, "outcome": "passed"}, "teardown": {"duration": 0.00013077608309686184, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_version_lineage_operations", "lineno": 223, "outcome": "passed", "keywords": ["test_version_lineage_operations", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00023030885495245457, "outcome": "passed"}, "call": {"duration": 0.00016496912576258183, "outcome": "passed"}, "teardown": {"duration": 0.0001267299521714449, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_data_transformation_operations", "lineno": 266, "outcome": "passed", "keywords": ["test_data_transformation_operations", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002278950996696949, "outcome": "passed"}, "call": {"duration": 0.00018887617625296116, "outcome": "passed"}, "teardown": {"duration": 0.00014229398220777512, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_task_dataset_link_operations", "lineno": 344, "outcome": "passed", "keywords": ["test_task_dataset_link_operations", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022417493164539337, "outcome": "passed"}, "call": {"duration": 0.00026023387908935547, "outcome": "passed"}, "teardown": {"duration": 0.00014766398817300797, "outcome": "passed"}}, {"nodeid": "tests/researcher/dataset_versioning/test_storage.py::TestInMemoryDatasetStorage::test_get_lineage", "lineno": 415, "outcome": "passed", "keywords": ["test_get_lineage", "TestInMemoryDatasetStorage", "test_storage.py", "dataset_versioning", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00023821601644158363, "outcome": "passed"}, "call": {"duration": 0.00021363189443945885, "outcome": "passed"}, "teardown": {"duration": 0.00013894797302782536, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_models.py::TestPackageInfo::test_create_package_info", "lineno": 18, "outcome": "passed", "keywords": ["test_create_package_info", "TestPackageInfo", "test_models.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0003089010715484619, "outcome": "passed"}, "call": {"duration": 0.00016684294678270817, "outcome": "passed"}, "teardown": {"duration": 0.00011257315054535866, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_models.py::TestComputeResource::test_create_compute_resource", "lineno": 52, "outcome": "passed", "keywords": ["test_create_compute_resource", "TestComputeResource", "test_models.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011131307110190392, "outcome": "passed"}, "call": {"duration": 0.0001521729864180088, "outcome": "passed"}, "teardown": {"duration": 0.000112572917714715, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_models.py::TestEnvironmentSnapshot::test_create_environment_snapshot", "lineno": 82, "outcome": "passed", "keywords": ["test_create_environment_snapshot", "TestEnvironmentSnapshot", "test_models.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011469307355582714, "outcome": "passed"}, "call": {"duration": 0.0001980240922421217, "outcome": "passed"}, "teardown": {"duration": 0.00011728983372449875, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_models.py::TestEnvironmentSnapshot::test_update_environment_snapshot", "lineno": 181, "outcome": "passed", "keywords": ["test_update_environment_snapshot", "TestEnvironmentSnapshot", "test_models.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001137761864811182, "outcome": "passed"}, "call": {"duration": 0.00019524013623595238, "outcome": "passed"}, "teardown": {"duration": 0.00011943303979933262, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_models.py::TestEnvironmentSnapshot::test_package_management", "lineno": 206, "outcome": "passed", "keywords": ["test_package_management", "TestEnvironmentSnapshot", "test_models.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010794284753501415, "outcome": "passed"}, "call": {"duration": 0.00018131802789866924, "outcome": "passed"}, "teardown": {"duration": 0.00010520103387534618, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_models.py::TestEnvironmentSnapshot::test_compute_resource_management", "lineno": 253, "outcome": "passed", "keywords": ["test_compute_resource_management", "TestEnvironmentSnapshot", "test_models.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010671094059944153, "outcome": "passed"}, "call": {"duration": 0.00015973090194165707, "outcome": "passed"}, "teardown": {"duration": 0.00011798785999417305, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_models.py::TestEnvironmentSnapshot::test_environment_variable_management", "lineno": 293, "outcome": "passed", "keywords": ["test_environment_variable_management", "TestEnvironmentSnapshot", "test_models.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011995108798146248, "outcome": "passed"}, "call": {"duration": 0.00016072695143520832, "outcome": "passed"}, "teardown": {"duration": 0.00010670186020433903, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_models.py::TestEnvironmentSnapshot::test_config_file_management", "lineno": 327, "outcome": "passed", "keywords": ["test_config_file_management", "TestEnvironmentSnapshot", "test_models.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010574399493634701, "outcome": "passed"}, "call": {"duration": 0.00015788991004228592, "outcome": "passed"}, "teardown": {"duration": 0.00010274187661707401, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_models.py::TestEnvironmentSnapshot::test_tag_management", "lineno": 370, "outcome": "passed", "keywords": ["test_tag_management", "TestEnvironmentSnapshot", "test_models.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010576401837170124, "outcome": "passed"}, "call": {"duration": 0.00016779894940555096, "outcome": "passed"}, "teardown": {"duration": 0.00010853982530534267, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_models.py::TestEnvironmentSnapshot::test_custom_metadata_management", "lineno": 403, "outcome": "passed", "keywords": ["test_custom_metadata_management", "TestEnvironmentSnapshot", "test_models.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010672397911548615, "outcome": "passed"}, "call": {"duration": 0.0001620010007172823, "outcome": "passed"}, "teardown": {"duration": 0.00011037616059184074, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_models.py::TestTaskEnvironmentLink::test_create_task_environment_link", "lineno": 447, "outcome": "passed", "keywords": ["test_create_task_environment_link", "TestTaskEnvironmentLink", "test_models.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011658808216452599, "outcome": "passed"}, "call": {"duration": 0.00015529990196228027, "outcome": "passed"}, "teardown": {"duration": 0.0001073919702321291, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_models.py::TestTaskEnvironmentLink::test_update_link", "lineno": 468, "outcome": "passed", "keywords": ["test_update_link", "TestTaskEnvironmentLink", "test_models.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010695494711399078, "outcome": "passed"}, "call": {"duration": 0.000174596905708313, "outcome": "passed"}, "teardown": {"duration": 0.00010597007349133492, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_models.py::TestTaskEnvironmentLink::test_add_note", "lineno": 491, "outcome": "passed", "keywords": ["test_add_note", "TestTaskEnvironmentLink", "test_models.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010660500265657902, "outcome": "passed"}, "call": {"duration": 0.00015428289771080017, "outcome": "passed"}, "teardown": {"duration": 0.0001038331538438797, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_create_environment_snapshot", "lineno": 26, "outcome": "passed", "keywords": ["test_create_environment_snapshot", "TestEnvironmentService", "test_service.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00023357803001999855, "outcome": "passed"}, "call": {"duration": 0.00017955806106328964, "outcome": "passed"}, "teardown": {"duration": 0.00013263709843158722, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_create_environment_with_packages_and_resources", "lineno": 55, "outcome": "passed", "keywords": ["test_create_environment_with_packages_and_resources", "TestEnvironmentService", "test_service.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020371400751173496, "outcome": "passed"}, "call": {"duration": 0.0001948629505932331, "outcome": "passed"}, "teardown": {"duration": 0.00012953300029039383, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_capture_current_environment", "lineno": 140, "outcome": "passed", "keywords": ["test_capture_current_environment", "TestEnvironmentService", "test_service.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002183739561587572, "outcome": "passed"}, "call": {"duration": 0.15087320609018207, "outcome": "passed"}, "teardown": {"duration": 0.00018358509987592697, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_update_environment", "lineno": 169, "outcome": "passed", "keywords": ["test_update_environment", "TestEnvironmentService", "test_service.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002603998873382807, "outcome": "passed"}, "call": {"duration": 0.0002447548322379589, "outcome": "passed"}, "teardown": {"duration": 0.00014321599155664444, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_update_nonexistent_environment", "lineno": 206, "outcome": "passed", "keywords": ["test_update_nonexistent_environment", "TestEnvironmentService", "test_service.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022275792434811592, "outcome": "passed"}, "call": {"duration": 0.000296521931886673, "outcome": "passed"}, "teardown": {"duration": 0.00013686204329133034, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_delete_environment", "lineno": 214, "outcome": "passed", "keywords": ["test_delete_environment", "TestEnvironmentService", "test_service.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021048798225820065, "outcome": "passed"}, "call": {"duration": 0.000260351924225688, "outcome": "passed"}, "teardown": {"duration": 0.00014466210268437862, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_list_environments", "lineno": 230, "outcome": "passed", "keywords": ["test_list_environments", "TestEnvironmentService", "test_service.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020439596846699715, "outcome": "passed"}, "call": {"duration": 0.00025729089975357056, "outcome": "passed"}, "teardown": {"duration": 0.0001451179850846529, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_environment_tag_operations", "lineno": 284, "outcome": "passed", "keywords": ["test_environment_tag_operations", "TestEnvironmentService", "test_service.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020381994545459747, "outcome": "passed"}, "call": {"duration": 0.00018398603424429893, "outcome": "passed"}, "teardown": {"duration": 0.00013575982302427292, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_package_operations", "lineno": 313, "outcome": "passed", "keywords": ["test_package_operations", "TestEnvironmentService", "test_service.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020036310888826847, "outcome": "passed"}, "call": {"duration": 0.00019809696823358536, "outcome": "passed"}, "teardown": {"duration": 0.0001317120622843504, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_compute_resource_operations", "lineno": 362, "outcome": "passed", "keywords": ["test_compute_resource_operations", "TestEnvironmentService", "test_service.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020131608471274376, "outcome": "passed"}, "call": {"duration": 0.00018547987565398216, "outcome": "passed"}, "teardown": {"duration": 0.00013748998753726482, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_environment_variable_operations", "lineno": 407, "outcome": "passed", "keywords": ["test_environment_variable_operations", "TestEnvironmentService", "test_service.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020443391986191273, "outcome": "passed"}, "call": {"duration": 0.00020685605704784393, "outcome": "passed"}, "teardown": {"duration": 0.00013204198330640793, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_config_file_operations", "lineno": 448, "outcome": "passed", "keywords": ["test_config_file_operations", "TestEnvironmentService", "test_service.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019834283739328384, "outcome": "passed"}, "call": {"duration": 0.0001841699704527855, "outcome": "passed"}, "teardown": {"duration": 0.00013067317195236683, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_custom_metadata_operations", "lineno": 501, "outcome": "passed", "keywords": ["test_custom_metadata_operations", "TestEnvironmentService", "test_service.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001949518918991089, "outcome": "passed"}, "call": {"duration": 0.00018853088840842247, "outcome": "passed"}, "teardown": {"duration": 0.00013473001308739185, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_compare_environments", "lineno": 550, "outcome": "passed", "keywords": ["test_compare_environments", "TestEnvironmentService", "test_service.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020354287698864937, "outcome": "passed"}, "call": {"duration": 0.00024410011246800423, "outcome": "passed"}, "teardown": {"duration": 0.0001314319670200348, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_link_task_to_environment", "lineno": 658, "outcome": "passed", "keywords": ["test_link_task_to_environment", "TestEnvironmentService", "test_service.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002010201569646597, "outcome": "passed"}, "call": {"duration": 0.00018756208010017872, "outcome": "passed"}, "teardown": {"duration": 0.0001348771620541811, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_link_to_nonexistent_environment", "lineno": 681, "outcome": "passed", "keywords": ["test_link_to_nonexistent_environment", "TestEnvironmentService", "test_service.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002045349683612585, "outcome": "passed"}, "call": {"duration": 0.00016554584726691246, "outcome": "passed"}, "teardown": {"duration": 0.0001275849062949419, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_service.py::TestEnvironmentService::test_task_environment_link_operations", "lineno": 689, "outcome": "passed", "keywords": ["test_task_environment_link_operations", "TestEnvironmentService", "test_service.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019670999608933926, "outcome": "passed"}, "call": {"duration": 0.0002763490192592144, "outcome": "passed"}, "teardown": {"duration": 0.00014301692135632038, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_create_and_get_environment", "lineno": 63, "outcome": "passed", "keywords": ["test_create_and_get_environment", "TestInMemoryEnvironmentStorage", "test_storage.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0003292681649327278, "outcome": "passed"}, "call": {"duration": 0.00014352984726428986, "outcome": "passed"}, "teardown": {"duration": 0.0001295739784836769, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_update_environment", "lineno": 76, "outcome": "passed", "keywords": ["test_update_environment", "TestInMemoryEnvironmentStorage", "test_storage.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002661519683897495, "outcome": "passed"}, "call": {"duration": 0.00014209095388650894, "outcome": "passed"}, "teardown": {"duration": 0.0001342578325420618, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_update_nonexistent_environment", "lineno": 91, "outcome": "passed", "keywords": ["test_update_nonexistent_environment", "TestInMemoryEnvironmentStorage", "test_storage.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00026263901963829994, "outcome": "passed"}, "call": {"duration": 0.00015059206634759903, "outcome": "passed"}, "teardown": {"duration": 0.00013023382052779198, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_delete_environment", "lineno": 102, "outcome": "passed", "keywords": ["test_delete_environment", "TestInMemoryEnvironmentStorage", "test_storage.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00024591386318206787, "outcome": "passed"}, "call": {"duration": 0.00015352689661085606, "outcome": "passed"}, "teardown": {"duration": 0.00012904498726129532, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_delete_nonexistent_environment", "lineno": 122, "outcome": "passed", "keywords": ["test_delete_nonexistent_environment", "TestInMemoryEnvironmentStorage", "test_storage.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00024559698067605495, "outcome": "passed"}, "call": {"duration": 0.00013252999633550644, "outcome": "passed"}, "teardown": {"duration": 0.00012771203182637691, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_list_environments_empty", "lineno": 127, "outcome": "passed", "keywords": ["test_list_environments_empty", "TestInMemoryEnvironmentStorage", "test_storage.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002471150364726782, "outcome": "passed"}, "call": {"duration": 0.0001298920251429081, "outcome": "passed"}, "teardown": {"duration": 0.00012868712656199932, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_list_environments_with_filters", "lineno": 132, "outcome": "passed", "keywords": ["test_list_environments_with_filters", "TestInMemoryEnvironmentStorage", "test_storage.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00025311578065156937, "outcome": "passed"}, "call": {"duration": 0.00014850590378046036, "outcome": "passed"}, "teardown": {"duration": 0.0001274379901587963, "outcome": "passed"}}, {"nodeid": "tests/researcher/environment/test_storage.py::TestInMemoryEnvironmentStorage::test_task_environment_link_operations", "lineno": 163, "outcome": "passed", "keywords": ["test_task_environment_link_operations", "TestInMemoryEnvironmentStorage", "test_storage.py", "environment", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002472950145602226, "outcome": "passed"}, "call": {"duration": 0.00019072205759584904, "outcome": "passed"}, "teardown": {"duration": 0.00014006998389959335, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_parameter_creation", "lineno": 10, "outcome": "passed", "keywords": ["test_parameter_creation", "test_models.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0003278949297964573, "outcome": "passed"}, "call": {"duration": 0.00015237904153764248, "outcome": "passed"}, "teardown": {"duration": 0.00012378999963402748, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_metric_creation", "lineno": 26, "outcome": "passed", "keywords": ["test_metric_creation", "test_models.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00012050499208271503, "outcome": "passed"}, "call": {"duration": 0.0001504488755017519, "outcome": "passed"}, "teardown": {"duration": 0.0001049430575221777, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_experiment_run_creation", "lineno": 43, "outcome": "passed", "keywords": ["test_experiment_run_creation", "test_models.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011341809295117855, "outcome": "passed"}, "call": {"duration": 0.00017278012819588184, "outcome": "passed"}, "teardown": {"duration": 0.00010597007349133492, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_experiment_run_duration", "lineno": 68, "outcome": "passed", "keywords": ["test_experiment_run_duration", "test_models.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010772794485092163, "outcome": "passed"}, "call": {"duration": 0.00018185703083872795, "outcome": "passed"}, "teardown": {"duration": 0.0001070790458470583, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_experiment_creation", "lineno": 91, "outcome": "passed", "keywords": ["test_experiment_creation", "test_models.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011253799311816692, "outcome": "passed"}, "call": {"duration": 0.00015212781727313995, "outcome": "passed"}, "teardown": {"duration": 0.00010861479677259922, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_experiment_add_run", "lineno": 111, "outcome": "passed", "keywords": ["test_experiment_add_run", "test_models.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001117270439863205, "outcome": "passed"}, "call": {"duration": 0.0002965258900076151, "outcome": "passed"}, "teardown": {"duration": 0.00011159898713231087, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_experiment_get_run", "lineno": 132, "outcome": "passed", "keywords": ["test_experiment_get_run", "test_models.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010707485489547253, "outcome": "passed"}, "call": {"duration": 0.0001656541135162115, "outcome": "passed"}, "teardown": {"duration": 0.00011758203618228436, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_experiment_get_best_run", "lineno": 152, "outcome": "passed", "keywords": ["test_experiment_get_best_run", "test_models.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011361506767570972, "outcome": "passed"}, "call": {"duration": 0.00023417011834681034, "outcome": "passed"}, "teardown": {"duration": 0.0001084750983864069, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_experiment_comparison_creation", "lineno": 191, "outcome": "passed", "keywords": ["test_experiment_comparison_creation", "test_models.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010908395051956177, "outcome": "passed"}, "call": {"duration": 0.00016335793770849705, "outcome": "passed"}, "teardown": {"duration": 0.00010385783389210701, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_models.py::test_experiment_comparison_add_methods", "lineno": 210, "outcome": "passed", "keywords": ["test_experiment_comparison_add_methods", "test_models.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010763201862573624, "outcome": "passed"}, "call": {"duration": 0.00016535306349396706, "outcome": "passed"}, "teardown": {"duration": 0.00010809209197759628, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_create_experiment", "lineno": 21, "outcome": "passed", "keywords": ["test_create_experiment", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00024272711016237736, "outcome": "passed"}, "call": {"duration": 0.0001472120638936758, "outcome": "passed"}, "teardown": {"duration": 0.0001523531973361969, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_get_experiment", "lineno": 36, "outcome": "passed", "keywords": ["test_get_experiment", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002240778412669897, "outcome": "passed"}, "call": {"duration": 0.00014978204853832722, "outcome": "passed"}, "teardown": {"duration": 0.00015286891721189022, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_get_experiment_by_name", "lineno": 46, "outcome": "passed", "keywords": ["test_get_experiment_by_name", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002261749468743801, "outcome": "passed"}, "call": {"duration": 0.000149240018799901, "outcome": "passed"}, "teardown": {"duration": 0.0001493419986218214, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_update_experiment", "lineno": 58, "outcome": "passed", "keywords": ["test_update_experiment", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022310414351522923, "outcome": "passed"}, "call": {"duration": 0.00015976582653820515, "outcome": "passed"}, "teardown": {"duration": 0.00014925003051757812, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_delete_experiment", "lineno": 71, "outcome": "passed", "keywords": ["test_delete_experiment", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022148899734020233, "outcome": "passed"}, "call": {"duration": 0.00015609106048941612, "outcome": "passed"}, "teardown": {"duration": 0.00015632808208465576, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_list_experiments", "lineno": 80, "outcome": "passed", "keywords": ["test_list_experiments", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002309330739080906, "outcome": "passed"}, "call": {"duration": 0.00015833904035389423, "outcome": "passed"}, "teardown": {"duration": 0.00015347497537732124, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_list_experiments_by_task", "lineno": 92, "outcome": "passed", "keywords": ["test_list_experiments_by_task", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022016698494553566, "outcome": "passed"}, "call": {"duration": 0.00015659094788134098, "outcome": "passed"}, "teardown": {"duration": 0.0001463869120925665, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_add_parameter", "lineno": 104, "outcome": "passed", "keywords": ["test_add_parameter", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002234899438917637, "outcome": "passed"}, "call": {"duration": 0.00015342095866799355, "outcome": "passed"}, "teardown": {"duration": 0.0001558009535074234, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_add_metric", "lineno": 120, "outcome": "passed", "keywords": ["test_add_metric", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002262729685753584, "outcome": "passed"}, "call": {"duration": 0.00014557014219462872, "outcome": "passed"}, "teardown": {"duration": 0.00014770706184208393, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_create_experiment_run", "lineno": 136, "outcome": "passed", "keywords": ["test_create_experiment_run", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021441001445055008, "outcome": "passed"}, "call": {"duration": 0.00019153417088091373, "outcome": "passed"}, "teardown": {"duration": 0.00015563098713755608, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_create_experiment_run_nonexistent_experiment", "lineno": 155, "outcome": "passed", "keywords": ["test_create_experiment_run_nonexistent_experiment", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021974998526275158, "outcome": "passed"}, "call": {"duration": 0.0001486288383603096, "outcome": "passed"}, "teardown": {"duration": 0.00014888099394738674, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_get_experiment_run", "lineno": 163, "outcome": "passed", "keywords": ["test_get_experiment_run", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021530594676733017, "outcome": "passed"}, "call": {"duration": 0.00016314187087118626, "outcome": "passed"}, "teardown": {"duration": 0.00017503299750387669, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_run_lifecycle", "lineno": 175, "outcome": "passed", "keywords": ["test_run_lifecycle", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022983807139098644, "outcome": "passed"}, "call": {"duration": 0.0002347300760447979, "outcome": "passed"}, "teardown": {"duration": 0.00015566707588732243, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_failed_and_aborted_runs", "lineno": 212, "outcome": "passed", "keywords": ["test_failed_and_aborted_runs", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022529205307364464, "outcome": "passed"}, "call": {"duration": 0.00021024886518716812, "outcome": "passed"}, "teardown": {"duration": 0.00015386799350380898, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_get_best_run", "lineno": 233, "outcome": "passed", "keywords": ["test_get_best_run", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021900399588048458, "outcome": "passed"}, "call": {"duration": 0.00028121680952608585, "outcome": "passed"}, "teardown": {"duration": 0.00017279991880059242, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_create_comparison", "lineno": 261, "outcome": "passed", "keywords": ["test_create_comparison", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021939584985375404, "outcome": "passed"}, "call": {"duration": 0.00018809805624186993, "outcome": "passed"}, "teardown": {"duration": 0.0001509718131273985, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_get_comparison", "lineno": 282, "outcome": "passed", "keywords": ["test_get_comparison", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021313992328941822, "outcome": "passed"}, "call": {"duration": 0.00014779996126890182, "outcome": "passed"}, "teardown": {"duration": 0.00014900905080139637, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_update_comparison", "lineno": 292, "outcome": "passed", "keywords": ["test_update_comparison", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021850294433534145, "outcome": "passed"}, "call": {"duration": 0.00016277492977678776, "outcome": "passed"}, "teardown": {"duration": 0.00015957397408783436, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_delete_comparison", "lineno": 305, "outcome": "passed", "keywords": ["test_delete_comparison", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021100789308547974, "outcome": "passed"}, "call": {"duration": 0.0001449170522391796, "outcome": "passed"}, "teardown": {"duration": 0.0001515829935669899, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_list_comparisons", "lineno": 314, "outcome": "passed", "keywords": ["test_list_comparisons", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00027707312256097794, "outcome": "passed"}, "call": {"duration": 0.00018508010543882847, "outcome": "passed"}, "teardown": {"duration": 0.00015797605738043785, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_service.py::test_get_comparison_data", "lineno": 326, "outcome": "passed", "keywords": ["test_get_comparison_data", "test_service.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021616695448756218, "outcome": "passed"}, "call": {"duration": 0.0002742609940469265, "outcome": "passed"}, "teardown": {"duration": 0.0001602929551154375, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_create_experiment", "lineno": 48, "outcome": "passed", "keywords": ["test_create_experiment", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00023457198403775692, "outcome": "passed"}, "call": {"duration": 0.00012943497858941555, "outcome": "passed"}, "teardown": {"duration": 0.0001374881248921156, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_get_experiment", "lineno": 58, "outcome": "passed", "keywords": ["test_get_experiment", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022329413332045078, "outcome": "passed"}, "call": {"duration": 0.0001263988669961691, "outcome": "passed"}, "teardown": {"duration": 0.000136188929900527, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_get_nonexistent_experiment", "lineno": 68, "outcome": "passed", "keywords": ["test_get_nonexistent_experiment", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00018288404680788517, "outcome": "passed"}, "call": {"duration": 0.00014133797958493233, "outcome": "passed"}, "teardown": {"duration": 0.0001271180808544159, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_update_experiment", "lineno": 76, "outcome": "passed", "keywords": ["test_update_experiment", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.000225533964112401, "outcome": "passed"}, "call": {"duration": 0.0001448509283363819, "outcome": "passed"}, "teardown": {"duration": 0.0001374639105051756, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_update_nonexistent_experiment", "lineno": 89, "outcome": "passed", "keywords": ["test_update_nonexistent_experiment", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001597111113369465, "outcome": "passed"}, "call": {"duration": 0.00014054705388844013, "outcome": "passed"}, "teardown": {"duration": 0.00012389011681079865, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_delete_experiment", "lineno": 97, "outcome": "passed", "keywords": ["test_delete_experiment", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021930597722530365, "outcome": "passed"}, "call": {"duration": 0.00012302701361477375, "outcome": "passed"}, "teardown": {"duration": 0.0001446239184588194, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_delete_nonexistent_experiment", "lineno": 106, "outcome": "passed", "keywords": ["test_delete_nonexistent_experiment", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.000165147939696908, "outcome": "passed"}, "call": {"duration": 0.0001597630325704813, "outcome": "passed"}, "teardown": {"duration": 0.000125254038721323, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_list_experiments", "lineno": 114, "outcome": "passed", "keywords": ["test_list_experiments", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022860500030219555, "outcome": "passed"}, "call": {"duration": 0.00014226394705474377, "outcome": "passed"}, "teardown": {"duration": 0.0001505089458078146, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_list_experiments_by_task", "lineno": 127, "outcome": "passed", "keywords": ["test_list_experiments_by_task", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022733001969754696, "outcome": "passed"}, "call": {"duration": 0.00016780500300228596, "outcome": "passed"}, "teardown": {"duration": 0.00014764303341507912, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_get_experiment_by_name", "lineno": 148, "outcome": "passed", "keywords": ["test_get_experiment_by_name", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002212580293416977, "outcome": "passed"}, "call": {"duration": 0.0001246039755642414, "outcome": "passed"}, "teardown": {"duration": 0.00015191081911325455, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_create_run", "lineno": 160, "outcome": "passed", "keywords": ["test_create_run", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00030303606763482094, "outcome": "passed"}, "call": {"duration": 0.00013893120922148228, "outcome": "passed"}, "teardown": {"duration": 0.00016365805640816689, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_create_run_nonexistent_experiment", "lineno": 175, "outcome": "passed", "keywords": ["test_create_run_nonexistent_experiment", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.000281699001789093, "outcome": "passed"}, "call": {"duration": 0.00012829387560486794, "outcome": "passed"}, "teardown": {"duration": 0.00017017987556755543, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_get_run", "lineno": 183, "outcome": "passed", "keywords": ["test_get_run", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002923461142927408, "outcome": "passed"}, "call": {"duration": 0.00013943598605692387, "outcome": "passed"}, "teardown": {"duration": 0.00016427296213805676, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_update_run", "lineno": 194, "outcome": "passed", "keywords": ["test_update_run", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.000293482793495059, "outcome": "passed"}, "call": {"duration": 0.00014793290756642818, "outcome": "passed"}, "teardown": {"duration": 0.00016031996347010136, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_update_nonexistent_run", "lineno": 214, "outcome": "passed", "keywords": ["test_update_nonexistent_run", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00018158415332436562, "outcome": "passed"}, "call": {"duration": 0.0001542700920253992, "outcome": "passed"}, "teardown": {"duration": 0.00012552505359053612, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_delete_run", "lineno": 222, "outcome": "passed", "keywords": ["test_delete_run", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002946488093584776, "outcome": "passed"}, "call": {"duration": 0.00014913803897798061, "outcome": "passed"}, "teardown": {"duration": 0.00016054697334766388, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_delete_nonexistent_run", "lineno": 236, "outcome": "passed", "keywords": ["test_delete_nonexistent_run", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00016352697275578976, "outcome": "passed"}, "call": {"duration": 0.00013689696788787842, "outcome": "passed"}, "teardown": {"duration": 0.00012785685248672962, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_create_comparison", "lineno": 244, "outcome": "passed", "keywords": ["test_create_comparison", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002215709537267685, "outcome": "passed"}, "call": {"duration": 0.0001316398847848177, "outcome": "passed"}, "teardown": {"duration": 0.00013386690989136696, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_get_comparison", "lineno": 254, "outcome": "passed", "keywords": ["test_get_comparison", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002334991004317999, "outcome": "passed"}, "call": {"duration": 0.0001306449994444847, "outcome": "passed"}, "teardown": {"duration": 0.00014374707825481892, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_update_comparison", "lineno": 264, "outcome": "passed", "keywords": ["test_update_comparison", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002269688993692398, "outcome": "passed"}, "call": {"duration": 0.00012485613115131855, "outcome": "passed"}, "teardown": {"duration": 0.00013654003851115704, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_update_nonexistent_comparison", "lineno": 279, "outcome": "passed", "keywords": ["test_update_nonexistent_comparison", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00016443897038698196, "outcome": "passed"}, "call": {"duration": 0.00014060107059776783, "outcome": "passed"}, "teardown": {"duration": 0.00012465007603168488, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_delete_comparison", "lineno": 287, "outcome": "passed", "keywords": ["test_delete_comparison", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022335699759423733, "outcome": "passed"}, "call": {"duration": 0.0001274577807635069, "outcome": "passed"}, "teardown": {"duration": 0.0001484400127083063, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_delete_nonexistent_comparison", "lineno": 296, "outcome": "passed", "keywords": ["test_delete_nonexistent_comparison", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00016307109035551548, "outcome": "passed"}, "call": {"duration": 0.00013739895075559616, "outcome": "passed"}, "teardown": {"duration": 0.00013259006664156914, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_storage.py::test_list_comparisons", "lineno": 304, "outcome": "passed", "keywords": ["test_list_comparisons", "test_storage.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002242040354758501, "outcome": "passed"}, "call": {"duration": 0.00020931707695126534, "outcome": "passed"}, "teardown": {"duration": 0.00017255102284252644, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_parameter_table", "lineno": 130, "outcome": "passed", "keywords": ["test_format_parameter_table", "test_visualizer.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00029557314701378345, "outcome": "passed"}, "call": {"duration": 0.00014715990982949734, "outcome": "passed"}, "teardown": {"duration": 0.00014225300401449203, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_empty_parameter_table", "lineno": 140, "outcome": "passed", "keywords": ["test_format_empty_parameter_table", "test_visualizer.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00016477983444929123, "outcome": "passed"}, "call": {"duration": 0.0001415042206645012, "outcome": "passed"}, "teardown": {"duration": 0.0001274759415537119, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_metric_table", "lineno": 148, "outcome": "passed", "keywords": ["test_format_metric_table", "test_visualizer.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002744668163359165, "outcome": "passed"}, "call": {"duration": 0.0001790798269212246, "outcome": "passed"}, "teardown": {"duration": 0.00014225812628865242, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_empty_metric_table", "lineno": 160, "outcome": "passed", "keywords": ["test_format_empty_metric_table", "test_visualizer.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001616219524294138, "outcome": "passed"}, "call": {"duration": 0.0001403351780027151, "outcome": "passed"}, "teardown": {"duration": 0.00012584193609654903, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_artifact_table", "lineno": 168, "outcome": "passed", "keywords": ["test_format_artifact_table", "test_visualizer.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00026121712289750576, "outcome": "passed"}, "call": {"duration": 0.00012922589667141438, "outcome": "passed"}, "teardown": {"duration": 0.00015177088789641857, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_empty_artifact_table", "lineno": 177, "outcome": "passed", "keywords": ["test_format_empty_artifact_table", "test_visualizer.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00016576703637838364, "outcome": "passed"}, "call": {"duration": 0.00014015310443937778, "outcome": "passed"}, "teardown": {"duration": 0.00013425410725176334, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_run_summary", "lineno": 185, "outcome": "passed", "keywords": ["test_format_run_summary", "test_visualizer.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00026467908173799515, "outcome": "passed"}, "call": {"duration": 0.00021049496717751026, "outcome": "passed"}, "teardown": {"duration": 0.00014697900041937828, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_experiment_summary", "lineno": 210, "outcome": "passed", "keywords": ["test_format_experiment_summary", "test_visualizer.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.000277835875749588, "outcome": "passed"}, "call": {"duration": 0.00018246006220579147, "outcome": "passed"}, "teardown": {"duration": 0.00015242001973092556, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_comparison_table", "lineno": 229, "outcome": "passed", "keywords": ["test_format_comparison_table", "test_visualizer.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001708250492811203, "outcome": "passed"}, "call": {"duration": 0.00013188202865421772, "outcome": "passed"}, "teardown": {"duration": 0.00012327800504863262, "outcome": "passed"}}, {"nodeid": "tests/researcher/experiment_tracking/test_visualizer.py::test_format_empty_comparison_table", "lineno": 286, "outcome": "passed", "keywords": ["test_format_empty_comparison_table", "test_visualizer.py", "experiment_tracking", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001634450163692236, "outcome": "passed"}, "call": {"duration": 0.00011778599582612514, "outcome": "passed"}, "teardown": {"duration": 0.00013151695020496845, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_document_default", "lineno": 51, "outcome": "passed", "keywords": ["test_format_document_default", "test_formatter.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0005229120142757893, "outcome": "passed"}, "call": {"duration": 0.00023710005916655064, "outcome": "passed"}, "teardown": {"duration": 0.00015155994333326817, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_document_nature", "lineno": 89, "outcome": "passed", "keywords": ["test_format_document_nature", "test_formatter.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002911640331149101, "outcome": "passed"}, "call": {"duration": 0.00031313998624682426, "outcome": "passed"}, "teardown": {"duration": 0.00014986214227974415, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_document_science", "lineno": 100, "outcome": "passed", "keywords": ["test_format_document_science", "test_formatter.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00029623997397720814, "outcome": "passed"}, "call": {"duration": 0.00016431394033133984, "outcome": "passed"}, "teardown": {"duration": 0.00014231493696570396, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_document_plos", "lineno": 109, "outcome": "passed", "keywords": ["test_format_document_plos", "test_formatter.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002753851003944874, "outcome": "passed"}, "call": {"duration": 0.00015787780284881592, "outcome": "passed"}, "teardown": {"duration": 0.00014606607146561146, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_section", "lineno": 118, "outcome": "passed", "keywords": ["test_format_section", "test_formatter.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001714811660349369, "outcome": "passed"}, "call": {"duration": 0.00014760298654437065, "outcome": "passed"}, "teardown": {"duration": 0.00012583681382238865, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_text_block", "lineno": 133, "outcome": "passed", "keywords": ["test_format_text_block", "test_formatter.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00016263010911643505, "outcome": "passed"}, "call": {"duration": 0.00013421615585684776, "outcome": "passed"}, "teardown": {"duration": 0.0001254160888493061, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_image_block", "lineno": 141, "outcome": "passed", "keywords": ["test_format_image_block", "test_formatter.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00016686320304870605, "outcome": "passed"}, "call": {"duration": 0.00013503991067409515, "outcome": "passed"}, "teardown": {"duration": 0.00012634997256100178, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_table_block", "lineno": 153, "outcome": "passed", "keywords": ["test_format_table_block", "test_formatter.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00017224112525582314, "outcome": "passed"}, "call": {"duration": 0.00014901906251907349, "outcome": "passed"}, "teardown": {"duration": 0.00012176390737295151, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_code_block", "lineno": 171, "outcome": "passed", "keywords": ["test_format_code_block", "test_formatter.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00016366085037589073, "outcome": "passed"}, "call": {"duration": 0.00013616797514259815, "outcome": "passed"}, "teardown": {"duration": 0.00012388383038342, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_equation_block", "lineno": 186, "outcome": "passed", "keywords": ["test_format_equation_block", "test_formatter.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00017514312639832497, "outcome": "passed"}, "call": {"duration": 0.0006795630324631929, "outcome": "passed"}, "teardown": {"duration": 0.00012913602404296398, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_formatter.py::test_format_citation_block", "lineno": 194, "outcome": "passed", "keywords": ["test_format_citation_block", "test_formatter.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001628671307116747, "outcome": "passed"}, "call": {"duration": 0.0001423920039087534, "outcome": "passed"}, "teardown": {"duration": 0.00012431596405804157, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_models.py::test_document_creation", "lineno": 10, "outcome": "passed", "keywords": ["test_document_creation", "test_models.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010997895151376724, "outcome": "passed"}, "call": {"duration": 0.00014888704754412174, "outcome": "passed"}, "teardown": {"duration": 0.00010575703345239162, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_models.py::test_section_creation", "lineno": 32, "outcome": "passed", "keywords": ["test_section_creation", "test_models.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010821502655744553, "outcome": "passed"}, "call": {"duration": 0.0001503049861639738, "outcome": "passed"}, "teardown": {"duration": 0.00010224198922514915, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_models.py::test_text_block", "lineno": 49, "outcome": "passed", "keywords": ["test_text_block", "test_models.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010502408258616924, "outcome": "passed"}, "call": {"duration": 0.0001416429877281189, "outcome": "passed"}, "teardown": {"duration": 0.00010240403935313225, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_models.py::test_image_block", "lineno": 58, "outcome": "passed", "keywords": ["test_image_block", "test_models.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010577100329101086, "outcome": "passed"}, "call": {"duration": 0.00019956892356276512, "outcome": "passed"}, "teardown": {"duration": 0.00010755099356174469, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_models.py::test_table_block", "lineno": 73, "outcome": "passed", "keywords": ["test_table_block", "test_models.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010417494922876358, "outcome": "passed"}, "call": {"duration": 0.0001411831472069025, "outcome": "passed"}, "teardown": {"duration": 0.00010184408165514469, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_models.py::test_code_block", "lineno": 93, "outcome": "passed", "keywords": ["test_code_block", "test_models.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010431907139718533, "outcome": "passed"}, "call": {"duration": 0.00013965903781354427, "outcome": "passed"}, "teardown": {"duration": 0.00011718086898326874, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_models.py::test_equation_block", "lineno": 107, "outcome": "passed", "keywords": ["test_equation_block", "test_models.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011456897482275963, "outcome": "passed"}, "call": {"duration": 0.00013496004976332188, "outcome": "passed"}, "teardown": {"duration": 0.00010229810141026974, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_models.py::test_citation_block", "lineno": 117, "outcome": "passed", "keywords": ["test_citation_block", "test_models.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010277191177010536, "outcome": "passed"}, "call": {"duration": 0.0001470788847655058, "outcome": "passed"}, "teardown": {"duration": 9.906291961669922e-05, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_models.py::test_document_with_sections_and_blocks", "lineno": 129, "outcome": "passed", "keywords": ["test_document_with_sections_and_blocks", "test_models.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001025248784571886, "outcome": "passed"}, "call": {"duration": 0.00017864000983536243, "outcome": "passed"}, "teardown": {"duration": 0.00011288910172879696, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_service.py::test_create_document", "lineno": 22, "outcome": "passed", "keywords": ["test_create_document", "test_service.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022978917695581913, "outcome": "passed"}, "call": {"duration": 0.00015091104432940483, "outcome": "passed"}, "teardown": {"duration": 0.00015031802468001842, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_service.py::test_get_document", "lineno": 42, "outcome": "passed", "keywords": ["test_get_document", "test_service.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021207588724792004, "outcome": "passed"}, "call": {"duration": 0.00015163212083280087, "outcome": "passed"}, "teardown": {"duration": 0.0001604030840098858, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_service.py::test_update_document", "lineno": 52, "outcome": "passed", "keywords": ["test_update_document", "test_service.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021759793162345886, "outcome": "passed"}, "call": {"duration": 0.00016280612908303738, "outcome": "passed"}, "teardown": {"duration": 0.0001490290742367506, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_service.py::test_delete_document", "lineno": 65, "outcome": "passed", "keywords": ["test_delete_document", "test_service.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021153991110622883, "outcome": "passed"}, "call": {"duration": 0.00014475197531282902, "outcome": "passed"}, "teardown": {"duration": 0.00015005096793174744, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_service.py::test_add_section", "lineno": 74, "outcome": "passed", "keywords": ["test_add_section", "test_service.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002168728969991207, "outcome": "passed"}, "call": {"duration": 0.00015839608386158943, "outcome": "passed"}, "teardown": {"duration": 0.00015281490050256252, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_service.py::test_add_section_with_order", "lineno": 88, "outcome": "passed", "keywords": ["test_add_section_with_order", "test_service.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020967796444892883, "outcome": "passed"}, "call": {"duration": 0.00017089792527258396, "outcome": "passed"}, "teardown": {"duration": 0.0001514300238341093, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_service.py::test_add_content_block", "lineno": 105, "outcome": "passed", "keywords": ["test_add_content_block", "test_service.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021646497771143913, "outcome": "passed"}, "call": {"duration": 0.0001639870461076498, "outcome": "passed"}, "teardown": {"duration": 0.00015152199193835258, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_service.py::test_create_content_blocks", "lineno": 122, "outcome": "passed", "keywords": ["test_create_content_blocks", "test_service.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002113759983330965, "outcome": "passed"}, "call": {"duration": 0.00017772288993000984, "outcome": "passed"}, "teardown": {"duration": 0.00015412806533277035, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_service.py::test_generate_markdown", "lineno": 163, "outcome": "passed", "keywords": ["test_generate_markdown", "test_service.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002161830198019743, "outcome": "passed"}, "call": {"duration": 0.00017940299585461617, "outcome": "passed"}, "teardown": {"duration": 0.00015006586909294128, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_service.py::test_export_to_file", "lineno": 183, "outcome": "passed", "keywords": ["test_export_to_file", "test_service.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022949185222387314, "outcome": "passed"}, "call": {"duration": 0.0010868110693991184, "outcome": "passed"}, "teardown": {"duration": 0.000178077956661582, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_storage.py::test_create_document", "lineno": 30, "outcome": "passed", "keywords": ["test_create_document", "test_storage.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002584110479801893, "outcome": "passed"}, "call": {"duration": 0.0001422350760549307, "outcome": "passed"}, "teardown": {"duration": 0.0001442008651793003, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_storage.py::test_get_document", "lineno": 40, "outcome": "passed", "keywords": ["test_get_document", "test_storage.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00023865397088229656, "outcome": "passed"}, "call": {"duration": 0.000133848050609231, "outcome": "passed"}, "teardown": {"duration": 0.00014013214968144894, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_storage.py::test_get_nonexistent_document", "lineno": 50, "outcome": "passed", "keywords": ["test_get_nonexistent_document", "test_storage.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001866889651864767, "outcome": "passed"}, "call": {"duration": 0.00014745607040822506, "outcome": "passed"}, "teardown": {"duration": 0.00012553506530821323, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_storage.py::test_update_document", "lineno": 59, "outcome": "passed", "keywords": ["test_update_document", "test_storage.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00024147005751729012, "outcome": "passed"}, "call": {"duration": 0.00014653196558356285, "outcome": "passed"}, "teardown": {"duration": 0.00013737590052187443, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_storage.py::test_update_nonexistent_document", "lineno": 72, "outcome": "passed", "keywords": ["test_update_nonexistent_document", "test_storage.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00016334489919245243, "outcome": "passed"}, "call": {"duration": 0.00014081085100769997, "outcome": "passed"}, "teardown": {"duration": 0.0001276899129152298, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_storage.py::test_delete_document", "lineno": 80, "outcome": "passed", "keywords": ["test_delete_document", "test_storage.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002362038940191269, "outcome": "passed"}, "call": {"duration": 0.00012723496183753014, "outcome": "passed"}, "teardown": {"duration": 0.00014075101353228092, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_storage.py::test_delete_nonexistent_document", "lineno": 89, "outcome": "passed", "keywords": ["test_delete_nonexistent_document", "test_storage.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001618380192667246, "outcome": "passed"}, "call": {"duration": 0.00014883605763316154, "outcome": "passed"}, "teardown": {"duration": 0.0001295730471611023, "outcome": "passed"}}, {"nodeid": "tests/researcher/export/test_storage.py::test_list_documents", "lineno": 98, "outcome": "passed", "keywords": ["test_list_documents", "test_storage.py", "export", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002364697866141796, "outcome": "passed"}, "call": {"duration": 0.0001428648829460144, "outcome": "passed"}, "teardown": {"duration": 0.00020761904306709766, "outcome": "passed"}}, {"nodeid": "tests/researcher/integration/test_multitask_workflow.py::test_multitask_research_project", "lineno": 58, "outcome": "failed", "keywords": ["test_multitask_research_project", "test_multitask_workflow.py", "integration", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0004119020886719227, "outcome": "passed"}, "call": {"duration": 0.0003423909656703472, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/researchtrack/task_management/service.py", "lineno": 685, "message": "AttributeError: 'TaskManagementService' object has no attribute 'get_task'"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/integration/test_multitask_workflow.py", "lineno": 71, "message": ""}, {"path": "researchtrack/task_management/service.py", "lineno": 685, "message": "AttributeError"}], "longrepr": "services = {'bibliography': <researchtrack.bibliography.service.BibliographyService object at 0x7f634726e1d0>, 'dataset': <resear...634726e2f0>, 'experiment': <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f634726e350>, ...}\n\n    def test_multitask_research_project(services):\n        \"\"\"\n        Test a research project with multiple interconnected tasks.\n    \n        This test simulates a complex research project with:\n        1. A main research task with subtasks\n        2. Shared bibliographic references\n        3. Datasets that evolve across tasks\n        4. Multiple experiment runs with comparisons\n        5. Consolidated reporting\n        \"\"\"\n        # 1. Create main research task\n>       main_task = services[\"task\"].create_task(\n            title=\"Improving NLP Models for Scientific Literature\",\n            description=\"Research project to improve NLP models for scientific literature analysis\",\n            tags=[\"nlp\", \"science\", \"literature\"]\n        )\n\n../command_line_task_manager_researcher/tests/integration/test_multitask_workflow.py:71: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <researchtrack.task_management.service.TaskService object at 0x7f634726e140>\ntitle = 'Improving NLP Models for Scientific Literature'\ndescription = 'Research project to improve NLP models for scientific literature analysis'\nstatus = <TaskStatus.PLANNED: 'planned'>\npriority = <TaskPriority.MEDIUM: 'medium'>, estimated_hours = None\ndue_date = None, parent_id = None, research_question_ids = None\ntags = ['nlp', 'science', 'literature'], custom_metadata = None\n\n    def create_task(\n        self,\n        title: str,\n        description: str,\n        status: TaskStatus = TaskStatus.PLANNED,\n        priority: TaskPriority = TaskPriority.MEDIUM,\n        estimated_hours: Optional[float] = None,\n        due_date: Optional[datetime] = None,\n        parent_id: Optional[UUID] = None,  # Different parameter name from TaskManagementService\n        research_question_ids: Optional[Set[UUID]] = None,\n        tags: Optional[Set[str]] = None,\n        custom_metadata: Optional[Dict[str, Union[str, int, float, bool, list, dict]]] = None,\n    ) -> ResearchTask:\n        \"\"\"\n        Create a new research task.\n    \n        Args:\n            title: Task title\n            description: Task description\n            status: Task status\n            priority: Task priority\n            estimated_hours: Estimated hours to complete the task\n            due_date: Task due date\n            parent_id: Parent task ID if this is a subtask (note: different from parent_task_id)\n            research_question_ids: Associated research question IDs\n            tags: Task tags\n            custom_metadata: Custom metadata key-value pairs\n    \n        Returns:\n            ResearchTask: The created task (not just the ID)\n    \n        Raises:\n            ValueError: If parent task doesn't exist\n        \"\"\"\n        task_id = self._service.create_task(\n            title=title,\n            description=description,\n            status=status,\n            priority=priority,\n            estimated_hours=estimated_hours,\n            due_date=due_date,\n            parent_task_id=parent_id,  # Map parent_id to parent_task_id\n            research_question_ids=research_question_ids,\n            tags=tags,\n            custom_metadata=custom_metadata,\n        )\n    \n        # Return the task object, not just the ID\n>       return self._service.get_task(task_id)\nE       AttributeError: 'TaskManagementService' object has no attribute 'get_task'\n\nresearchtrack/task_management/service.py:685: AttributeError"}, "teardown": {"duration": 0.00019701500423252583, "outcome": "passed"}}, {"nodeid": "tests/researcher/integration/test_research_workflow.py::test_complete_research_workflow", "lineno": 39, "outcome": "failed", "keywords": ["test_complete_research_workflow", "test_research_workflow.py", "integration", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021357391960918903, "outcome": "passed"}, "call": {"duration": 0.00018537510186433792, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/researchtrack/task_management/service.py", "lineno": 685, "message": "AttributeError: 'TaskManagementService' object has no attribute 'get_task'"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/integration/test_research_workflow.py", "lineno": 53, "message": ""}, {"path": "researchtrack/task_management/service.py", "lineno": 685, "message": "AttributeError"}], "longrepr": "services = {'bibliography': <researchtrack.bibliography.service.BibliographyService object at 0x7f6347187610>, 'dataset': <resear...6347187dc0>, 'experiment': <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f6347187d60>, ...}\n\n    def test_complete_research_workflow(services):\n        \"\"\"\n        Test a complete research workflow from task creation to publication.\n    \n        This test simulates a research workflow where:\n        1. A research task is created\n        2. Bibliographic references are added\n        3. A dataset is versioned\n        4. The computational environment is captured\n        5. Experiments are run\n        6. Results are exported as an academic document\n        \"\"\"\n        # 1. Create a research task\n>       task = services[\"task\"].create_task(\n            title=\"Investigate Neural Network Performance\",\n            description=\"Investigate performance of different neural network architectures on image classification\"\n        )\n\n../command_line_task_manager_researcher/tests/integration/test_research_workflow.py:53: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <researchtrack.task_management.service.TaskService object at 0x7f63471877f0>\ntitle = 'Investigate Neural Network Performance'\ndescription = 'Investigate performance of different neural network architectures on image classification'\nstatus = <TaskStatus.PLANNED: 'planned'>\npriority = <TaskPriority.MEDIUM: 'medium'>, estimated_hours = None\ndue_date = None, parent_id = None, research_question_ids = None, tags = None\ncustom_metadata = None\n\n    def create_task(\n        self,\n        title: str,\n        description: str,\n        status: TaskStatus = TaskStatus.PLANNED,\n        priority: TaskPriority = TaskPriority.MEDIUM,\n        estimated_hours: Optional[float] = None,\n        due_date: Optional[datetime] = None,\n        parent_id: Optional[UUID] = None,  # Different parameter name from TaskManagementService\n        research_question_ids: Optional[Set[UUID]] = None,\n        tags: Optional[Set[str]] = None,\n        custom_metadata: Optional[Dict[str, Union[str, int, float, bool, list, dict]]] = None,\n    ) -> ResearchTask:\n        \"\"\"\n        Create a new research task.\n    \n        Args:\n            title: Task title\n            description: Task description\n            status: Task status\n            priority: Task priority\n            estimated_hours: Estimated hours to complete the task\n            due_date: Task due date\n            parent_id: Parent task ID if this is a subtask (note: different from parent_task_id)\n            research_question_ids: Associated research question IDs\n            tags: Task tags\n            custom_metadata: Custom metadata key-value pairs\n    \n        Returns:\n            ResearchTask: The created task (not just the ID)\n    \n        Raises:\n            ValueError: If parent task doesn't exist\n        \"\"\"\n        task_id = self._service.create_task(\n            title=title,\n            description=description,\n            status=status,\n            priority=priority,\n            estimated_hours=estimated_hours,\n            due_date=due_date,\n            parent_task_id=parent_id,  # Map parent_id to parent_task_id\n            research_question_ids=research_question_ids,\n            tags=tags,\n            custom_metadata=custom_metadata,\n        )\n    \n        # Return the task object, not just the ID\n>       return self._service.get_task(task_id)\nE       AttributeError: 'TaskManagementService' object has no attribute 'get_task'\n\nresearchtrack/task_management/service.py:685: AttributeError"}, "teardown": {"duration": 0.0001818658784031868, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_bibliography_performance.py::TestBibliographyPerformance::test_large_bibliography_operations", "lineno": 23, "outcome": "passed", "keywords": ["test_large_bibliography_operations", "TestBibliographyPerformance", "test_bibliography_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0004032410215586424, "outcome": "passed"}, "call": {"duration": 0.202692240010947, "outcome": "passed"}, "teardown": {"duration": 0.00021483306773006916, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_bibliography_performance.py::TestBibliographyPerformance::test_task_reference_link_performance", "lineno": 160, "outcome": "passed", "keywords": ["test_task_reference_link_performance", "TestBibliographyPerformance", "test_bibliography_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00025285198353230953, "outcome": "passed"}, "call": {"duration": 1.3936135210096836, "outcome": "passed"}, "teardown": {"duration": 0.00021438812837004662, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_dataset_operations_performance", "lineno": 20, "outcome": "passed", "keywords": ["test_dataset_operations_performance", "TestDatasetVersioningPerformance", "test_dataset_versioning_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00027605309151113033, "outcome": "passed"}, "call": {"duration": 0.00021232711151242256, "outcome": "passed"}, "teardown": {"duration": 0.00014141714200377464, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_handle_large_dataset_catalog", "lineno": 57, "outcome": "passed", "keywords": ["test_handle_large_dataset_catalog", "TestDatasetVersioningPerformance", "test_dataset_versioning_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002085329033434391, "outcome": "passed"}, "call": {"duration": 0.012784263119101524, "outcome": "passed"}, "teardown": {"duration": 0.00015936209820210934, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_handle_100gb_dataset_metadata", "lineno": 110, "outcome": "passed", "keywords": ["test_handle_100gb_dataset_metadata", "TestDatasetVersioningPerformance", "test_dataset_versioning_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020750192925333977, "outcome": "passed"}, "call": {"duration": 0.0005416239146143198, "outcome": "passed"}, "teardown": {"duration": 0.00014655105769634247, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_complex_transformation_chain_performance", "lineno": 166, "outcome": "passed", "keywords": ["test_complex_transformation_chain_performance", "TestDatasetVersioningPerformance", "test_dataset_versioning_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.000201815040782094, "outcome": "passed"}, "call": {"duration": 0.0010399401653558016, "outcome": "passed"}, "teardown": {"duration": 0.0001638280227780342, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_dataset_versioning_performance.py::TestDatasetVersioningPerformance::test_task_dataset_link_performance", "lineno": 237, "outcome": "passed", "keywords": ["test_task_dataset_link_performance", "TestDatasetVersioningPerformance", "test_dataset_versioning_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002812060993164778, "outcome": "passed"}, "call": {"duration": 0.06053208094090223, "outcome": "passed"}, "teardown": {"duration": 0.00015616696327924728, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_environment_performance.py::TestEnvironmentPerformance::test_environment_operations_performance", "lineno": 21, "outcome": "passed", "keywords": ["test_environment_operations_performance", "TestEnvironmentPerformance", "test_environment_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020923116244375706, "outcome": "passed"}, "call": {"duration": 0.00021558883599936962, "outcome": "passed"}, "teardown": {"duration": 0.00013852701522409916, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_environment_performance.py::TestEnvironmentPerformance::test_environment_snapshot_generation_time", "lineno": 57, "outcome": "passed", "keywords": ["test_environment_snapshot_generation_time", "TestEnvironmentPerformance", "test_environment_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019428296945989132, "outcome": "passed"}, "call": {"duration": 0.14601828181184828, "outcome": "passed"}, "teardown": {"duration": 0.00015972903929650784, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_environment_performance.py::TestEnvironmentPerformance::test_large_environment_catalog_performance", "lineno": 82, "outcome": "passed", "keywords": ["test_large_environment_catalog_performance", "TestEnvironmentPerformance", "test_environment_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021068518981337547, "outcome": "passed"}, "call": {"duration": 0.0038384839426726103, "outcome": "passed"}, "teardown": {"duration": 0.00015972508117556572, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_environment_performance.py::TestEnvironmentPerformance::test_complex_environment_performance", "lineno": 161, "outcome": "passed", "keywords": ["test_complex_environment_performance", "TestEnvironmentPerformance", "test_environment_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002100788988173008, "outcome": "passed"}, "call": {"duration": 0.0016413521952927113, "outcome": "passed"}, "teardown": {"duration": 0.00014428398571908474, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_environment_performance.py::TestEnvironmentPerformance::test_task_environment_link_performance", "lineno": 211, "outcome": "passed", "keywords": ["test_task_environment_link_performance", "TestEnvironmentPerformance", "test_environment_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020930590108036995, "outcome": "passed"}, "call": {"duration": 0.0068460681941360235, "outcome": "passed"}, "teardown": {"duration": 0.00015566195361316204, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_experiment_tracking_performance.py::test_experiment_creation_performance", "lineno": 121, "outcome": "passed", "keywords": ["test_experiment_creation_performance", "test_experiment_tracking_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00018939189612865448, "outcome": "passed"}, "call": {"duration": 0.006173823960125446, "outcome": "passed"}, "teardown": {"duration": 0.00015465705655515194, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_experiment_tracking_performance.py::test_best_run_query_performance", "lineno": 145, "outcome": "passed", "keywords": ["test_best_run_query_performance", "test_experiment_tracking_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020887190476059914, "outcome": "passed"}, "call": {"duration": 0.01985132019035518, "outcome": "passed", "stdout": "Best run query time for 50 runs: 0.000022s\n"}, "teardown": {"duration": 0.00015334086492657661, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_experiment_tracking_performance.py::test_comparison_performance", "lineno": 181, "outcome": "passed", "keywords": ["test_comparison_performance", "test_experiment_tracking_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001966638956218958, "outcome": "passed"}, "call": {"duration": 0.003947227029129863, "outcome": "passed"}, "teardown": {"duration": 0.00014690589159727097, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_experiment_tracking_performance.py::test_large_experiment_performance", "lineno": 235, "outcome": "passed", "keywords": ["test_large_experiment_performance", "test_experiment_tracking_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019208109006285667, "outcome": "passed"}, "call": {"duration": 0.08105055405758321, "outcome": "passed", "stdout": "Large experiment creation time: 0.08s\nLarge experiment retrieval time: 0.000001s\nLarge experiment update time: 0.000046s\nTotal runs: 100\nTotal parameters: 2000\nTotal metrics: 2000\n"}, "teardown": {"duration": 0.00015619699843227863, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_export_performance.py::test_document_creation_performance", "lineno": 94, "outcome": "passed", "keywords": ["test_document_creation_performance", "test_export_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021255412138998508, "outcome": "passed"}, "call": {"duration": 0.0032225660979747772, "outcome": "passed"}, "teardown": {"duration": 0.00014488189481198788, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_export_performance.py::test_markdown_generation_performance", "lineno": 116, "outcome": "passed", "keywords": ["test_markdown_generation_performance", "test_export_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00018571480177342892, "outcome": "passed"}, "call": {"duration": 0.0037528688553720713, "outcome": "passed"}, "teardown": {"duration": 0.00014438200742006302, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_export_performance.py::test_file_export_performance", "lineno": 142, "outcome": "passed", "keywords": ["test_file_export_performance", "test_export_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0015120899770408869, "outcome": "passed"}, "call": {"duration": 0.0038489620201289654, "outcome": "passed"}, "teardown": {"duration": 0.00017967796884477139, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_export_performance.py::test_large_document_performance", "lineno": 173, "outcome": "passed", "keywords": ["test_large_document_performance", "test_export_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00018769712187349796, "outcome": "passed"}, "call": {"duration": 0.017541039967909455, "outcome": "passed", "stdout": "Large document creation time: 0.02s\nLarge document markdown generation time: 0.00s\nTotal content blocks: 1000\n"}, "teardown": {"duration": 0.0001492369920015335, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_integration_performance.py::test_large_research_project_performance", "lineno": 46, "outcome": "failed", "keywords": ["test_large_research_project_performance", "test_integration_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022411905229091644, "outcome": "passed"}, "call": {"duration": 0.00021524401381611824, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/researchtrack/task_management/service.py", "lineno": 685, "message": "AttributeError: 'TaskManagementService' object has no attribute 'get_task'"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/performance/test_integration_performance.py", "lineno": 64, "message": ""}, {"path": "researchtrack/task_management/service.py", "lineno": 685, "message": "AttributeError"}], "longrepr": "services = {'bibliography': <researchtrack.bibliography.service.BibliographyService object at 0x7f63453ac1c0>, 'dataset': <resear...63453acca0>, 'experiment': <researchtrack.experiment_tracking.service.ExperimentService object at 0x7f63453aca30>, ...}\n\n    def test_large_research_project_performance(services):\n        \"\"\"\n        Test the performance of a large-scale research project workflow.\n    \n        This test simulates a complex research project with:\n        - Multiple research tasks and questions\n        - Many bibliographic references\n        - Multiple datasets with versions\n        - Several environment snapshots\n        - Multiple experiments with many runs\n        - Document generation with the results\n        \"\"\"\n        start_time = time.time()\n    \n        # 1. Create research tasks and questions\n        tasks = []\n        for i in range(10):\n>           task = services[\"task\"].create_task(\n                title=f\"Research Task {i+1}: {random_string(20)}\",\n                description=f\"Description for task {i+1}: {random_string(100)}\",\n                tags=[f\"tag{i+1}\", \"research\", random_string(8)]\n            )\n\n../command_line_task_manager_researcher/tests/performance/test_integration_performance.py:64: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <researchtrack.task_management.service.TaskService object at 0x7f63453ad510>\ntitle = 'Research Task 1: kzgjRvVFujCiWyjirUKr'\ndescription = 'Description for task 1: UQvFGpiwbScdQgoBQDcUiGUkvzryogxjPRyBrLQbTTncRTdpklnWDdZWAxGJOViPinqCsslTtcKspouGyvdvhAdkEUUXmHEUgxsU'\nstatus = <TaskStatus.PLANNED: 'planned'>\npriority = <TaskPriority.MEDIUM: 'medium'>, estimated_hours = None\ndue_date = None, parent_id = None, research_question_ids = None\ntags = ['tag1', 'research', 'LHPjLjQO'], custom_metadata = None\n\n    def create_task(\n        self,\n        title: str,\n        description: str,\n        status: TaskStatus = TaskStatus.PLANNED,\n        priority: TaskPriority = TaskPriority.MEDIUM,\n        estimated_hours: Optional[float] = None,\n        due_date: Optional[datetime] = None,\n        parent_id: Optional[UUID] = None,  # Different parameter name from TaskManagementService\n        research_question_ids: Optional[Set[UUID]] = None,\n        tags: Optional[Set[str]] = None,\n        custom_metadata: Optional[Dict[str, Union[str, int, float, bool, list, dict]]] = None,\n    ) -> ResearchTask:\n        \"\"\"\n        Create a new research task.\n    \n        Args:\n            title: Task title\n            description: Task description\n            status: Task status\n            priority: Task priority\n            estimated_hours: Estimated hours to complete the task\n            due_date: Task due date\n            parent_id: Parent task ID if this is a subtask (note: different from parent_task_id)\n            research_question_ids: Associated research question IDs\n            tags: Task tags\n            custom_metadata: Custom metadata key-value pairs\n    \n        Returns:\n            ResearchTask: The created task (not just the ID)\n    \n        Raises:\n            ValueError: If parent task doesn't exist\n        \"\"\"\n        task_id = self._service.create_task(\n            title=title,\n            description=description,\n            status=status,\n            priority=priority,\n            estimated_hours=estimated_hours,\n            due_date=due_date,\n            parent_task_id=parent_id,  # Map parent_id to parent_task_id\n            research_question_ids=research_question_ids,\n            tags=tags,\n            custom_metadata=custom_metadata,\n        )\n    \n        # Return the task object, not just the ID\n>       return self._service.get_task(task_id)\nE       AttributeError: 'TaskManagementService' object has no attribute 'get_task'\n\nresearchtrack/task_management/service.py:685: AttributeError"}, "teardown": {"duration": 0.00018048984929919243, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_task_management_performance.py::TestTaskManagementPerformance::test_task_operation_speed", "lineno": 16, "outcome": "failed", "keywords": ["test_task_operation_speed", "TestTaskManagementPerformance", "test_task_management_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021530385129153728, "outcome": "passed"}, "call": {"duration": 0.00019723805598914623, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/performance/test_task_management_performance.py", "lineno": 29, "message": "AttributeError: 'TaskManagementService' object has no attribute 'get_task'"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/performance/test_task_management_performance.py", "lineno": 29, "message": "AttributeError"}], "longrepr": "self = <tests.researcher.performance.test_task_management_performance.TestTaskManagementPerformance object at 0x7f63480c9c90>\n\n    def test_task_operation_speed(self):\n        \"\"\"Test that individual task operations complete within 50ms.\"\"\"\n        # Create task\n        start_time = time.time()\n        task_id = self.service.create_task(\n            title=\"Performance test task\",\n            description=\"Testing performance of task operations\",\n        )\n        create_time = time.time() - start_time\n    \n        # Get task\n        start_time = time.time()\n>       self.service.get_task(task_id)\nE       AttributeError: 'TaskManagementService' object has no attribute 'get_task'\n\n../command_line_task_manager_researcher/tests/performance/test_task_management_performance.py:29: AttributeError"}, "teardown": {"duration": 0.00017262902110815048, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_task_management_performance.py::TestTaskManagementPerformance::test_large_task_list_performance", "lineno": 51, "outcome": "failed", "keywords": ["test_large_task_list_performance", "TestTaskManagementPerformance", "test_task_management_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021188287064433098, "outcome": "passed"}, "call": {"duration": 0.04985724715515971, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/performance/test_task_management_performance.py", "lineno": 86, "message": "AttributeError: 'TaskManagementService' object has no attribute 'list_tasks'"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/performance/test_task_management_performance.py", "lineno": 86, "message": "AttributeError"}], "longrepr": "self = <tests.researcher.performance.test_task_management_performance.TestTaskManagementPerformance object at 0x7f63480c9e40>\n\n    def test_large_task_list_performance(self):\n        \"\"\"Test performance with 1000+ tasks.\"\"\"\n        # Create 1000 tasks\n        task_ids = []\n    \n        start_time = time.time()\n        for i in range(1000):\n            task_id = self.service.create_task(\n                title=f\"Task {i}\",\n                description=f\"Description for task {i}\",\n                status=TaskStatus.PLANNED if i % 3 == 0 else (\n                    TaskStatus.IN_PROGRESS if i % 3 == 1 else TaskStatus.COMPLETED\n                ),\n                priority=TaskPriority.LOW if i % 4 == 0 else (\n                    TaskPriority.MEDIUM if i % 4 == 1 else (\n                        TaskPriority.HIGH if i % 4 == 2 else TaskPriority.CRITICAL\n                    )\n                ),\n            )\n            task_ids.append(task_id)\n    \n            # Add tags to some tasks\n            if i % 5 == 0:\n                self.service.add_task_tag(task_id, \"tag1\")\n            if i % 7 == 0:\n                self.service.add_task_tag(task_id, \"tag2\")\n            if i % 11 == 0:\n                self.service.add_task_tag(task_id, \"tag3\")\n    \n        creation_time = time.time() - start_time\n        avg_creation_time = creation_time / 1000\n    \n        # Test listing with various filters\n        start_time = time.time()\n>       planned_tasks = self.service.list_tasks(status=TaskStatus.PLANNED)\nE       AttributeError: 'TaskManagementService' object has no attribute 'list_tasks'\n\n../command_line_task_manager_researcher/tests/performance/test_task_management_performance.py:86: AttributeError"}, "teardown": {"duration": 0.0002050700131803751, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_task_management_performance.py::TestTaskManagementPerformance::test_research_question_hierarchy_performance", "lineno": 135, "outcome": "failed", "keywords": ["test_research_question_hierarchy_performance", "TestTaskManagementPerformance", "test_task_management_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00023345905356109142, "outcome": "passed"}, "call": {"duration": 0.0018150461837649345, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/performance/test_task_management_performance.py", "lineno": 184, "message": "assert 0 == 5\n +  where 0 = len([])"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/performance/test_task_management_performance.py", "lineno": 184, "message": "AssertionError"}], "longrepr": "self = <tests.researcher.performance.test_task_management_performance.TestTaskManagementPerformance object at 0x7f63480c9ff0>\n\n    def test_research_question_hierarchy_performance(self):\n        \"\"\"Test performance with complex research question hierarchies.\"\"\"\n        # Create a tree of research questions (3 levels, branching factor of 5)\n        start_time = time.time()\n    \n        # Create root questions\n        root_ids = []\n        for i in range(5):\n            root_id = self.service.create_research_question(\n                text=f\"Root question {i}\",\n                description=f\"Top-level research question {i}\",\n            )\n            root_ids.append(root_id)\n    \n        # Create level 2 questions (children of root)\n        level2_ids = []\n        for root_id in root_ids:\n            for i in range(5):\n                level2_id = self.service.create_research_question(\n                    text=f\"Level 2 question under {root_id} - {i}\",\n                    description=f\"Second-level research question {i}\",\n                    parent_question_id=root_id,\n                )\n                level2_ids.append(level2_id)\n    \n        # Create level 3 questions (children of level 2)\n        level3_ids = []\n        for level2_id in level2_ids:\n            for i in range(5):\n                level3_id = self.service.create_research_question(\n                    text=f\"Level 3 question under {level2_id} - {i}\",\n                    description=f\"Third-level research question {i}\",\n                    parent_question_id=level2_id,\n                )\n                level3_ids.append(level3_id)\n    \n        # Total: 5 + 25 + 125 = 155 questions\n        creation_time = time.time() - start_time\n        avg_question_creation_time = creation_time / 155\n    \n        # Test querying the hierarchy\n        query_times = []\n        for root_id in root_ids:\n            start_time = time.time()\n            level2_children = self.service.list_research_questions(parent_question_id=root_id)\n            query_times.append(time.time() - start_time)\n    \n            # Verify each root has 5 children\n>           assert len(level2_children) == 5\nE           assert 0 == 5\nE            +  where 0 = len([])\n\n../command_line_task_manager_researcher/tests/performance/test_task_management_performance.py:184: AssertionError"}, "teardown": {"duration": 0.00017831404693424702, "outcome": "passed"}}, {"nodeid": "tests/researcher/performance/test_task_management_performance.py::TestTaskManagementPerformance::test_task_question_association_performance", "lineno": 202, "outcome": "failed", "keywords": ["test_task_question_association_performance", "TestTaskManagementPerformance", "test_task_management_performance.py", "performance", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021573901176452637, "outcome": "passed"}, "call": {"duration": 0.013501600129529834, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/performance/test_task_management_performance.py", "lineno": 254, "message": "AttributeError: 'TaskManagementService' object has no attribute 'list_tasks'"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/performance/test_task_management_performance.py", "lineno": 254, "message": "AttributeError"}], "longrepr": "self = <tests.researcher.performance.test_task_management_performance.TestTaskManagementPerformance object at 0x7f63480ca1a0>\n\n    def test_task_question_association_performance(self):\n        \"\"\"Test performance with many task-question associations.\"\"\"\n        # Create 100 questions and 500 tasks, with multiple associations\n        questions = []\n        tasks = []\n    \n        start_time = time.time()\n    \n        # Create questions\n        for i in range(100):\n            question_id = self.service.create_research_question(\n                text=f\"Research question {i}\",\n                description=f\"Description for question {i}\",\n            )\n            questions.append(question_id)\n    \n        # Create tasks with multiple question associations\n        for i in range(500):\n            task_id = self.service.create_task(\n                title=f\"Task {i}\",\n                description=f\"Description for task {i}\",\n            )\n            tasks.append(task_id)\n    \n            # Associate each task with 1-5 questions\n            num_associations = (i % 5) + 1\n            for j in range(num_associations):\n                # Pick a question based on a formula to ensure distribution\n                question_index = (i + j * 17) % 100  # Use a prime number for better distribution\n                question_id = questions[question_index]\n                self.service.associate_task_with_research_question(task_id, question_id)\n    \n        setup_time = time.time() - start_time\n    \n        # Test query performance\n        query_times = []\n        for i in range(20):  # Test with 20 random questions\n            question_id = questions[i * 5]\n    \n            start_time = time.time()\n            related_tasks = self.service.get_tasks_by_research_question(question_id)\n            query_times.append(time.time() - start_time)\n    \n        avg_query_time = sum(query_times) / len(query_times)\n    \n        # Test filtering tasks by question\n        filter_times = []\n        for i in range(20):  # Test with 20 random questions\n            question_id = questions[i * 5]\n    \n            start_time = time.time()\n>           filtered_tasks = self.service.list_tasks(research_question_id=question_id)\nE           AttributeError: 'TaskManagementService' object has no attribute 'list_tasks'\n\n../command_line_task_manager_researcher/tests/performance/test_task_management_performance.py:254: AttributeError"}, "teardown": {"duration": 0.0001755841076374054, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchQuestion::test_create_research_question", "lineno": 14, "outcome": "passed", "keywords": ["test_create_research_question", "TestResearchQuestion", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0003297780640423298, "outcome": "passed"}, "call": {"duration": 0.00016293395310640335, "outcome": "passed"}, "teardown": {"duration": 0.00011092796921730042, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchQuestion::test_create_with_parent", "lineno": 28, "outcome": "passed", "keywords": ["test_create_with_parent", "TestResearchQuestion", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011549494229257107, "outcome": "passed"}, "call": {"duration": 0.00015075993724167347, "outcome": "passed"}, "teardown": {"duration": 0.00010565691627562046, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchQuestion::test_update_question", "lineno": 39, "outcome": "passed", "keywords": ["test_update_question", "TestResearchQuestion", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010583200491964817, "outcome": "passed"}, "call": {"duration": 0.00017114519141614437, "outcome": "passed"}, "teardown": {"duration": 0.00010500708594918251, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_create_research_task", "lineno": 60, "outcome": "failed", "keywords": ["test_create_research_task", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011879811063408852, "outcome": "passed"}, "call": {"duration": 0.00018049892969429493, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/.pyenv/versions/3.10.11/lib/python3.10/site-packages/pydantic/main.py", "lineno": 989, "message": "AttributeError: 'ResearchTask' object has no attribute 'parent_task_id'"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 83, "message": ""}, {"path": "../../../../.pyenv/versions/3.10.11/lib/python3.10/site-packages/pydantic/main.py", "lineno": 989, "message": "AttributeError"}], "longrepr": "self = <tests.researcher.task_management.test_models.TestResearchTask object at 0x7f63480c9ba0>\n\n    def test_create_research_task(self):\n        # Test basic creation\n        task = ResearchTask(\n            title=\"Analyze climate data from 1950-2020\",\n            description=\"Perform time series analysis on global temperature data\",\n            status=TaskStatus.PLANNED,\n            priority=TaskPriority.HIGH,\n            estimated_hours=8.5,\n        )\n    \n        assert isinstance(task.id, UUID)\n        assert task.title == \"Analyze climate data from 1950-2020\"\n        assert task.description == \"Perform time series analysis on global temperature data\"\n        assert task.status == TaskStatus.PLANNED\n        assert task.priority == TaskPriority.HIGH\n        assert task.estimated_hours == 8.5\n        assert task.actual_hours is None\n        assert task.due_date is None\n        assert task.completed_at is None\n        assert isinstance(task.created_at, datetime)\n        assert isinstance(task.updated_at, datetime)\n        assert len(task.research_question_ids) == 0\n>       assert task.parent_task_id is None\n\n../command_line_task_manager_researcher/tests/task_management/test_models.py:83: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = ResearchTask(id=UUID('79206e57-f342-406f-aed8-afe3ed622ffb'), created_at=datetime.datetime(2025, 5, 15, 23, 15, 13, 28...nt_ids=set(), experiment_ids=set(), research_questions=[], references=[], datasets=[], environments=[], experiments=[])\nitem = 'parent_task_id'\n\n    def __getattr__(self, item: str) -> Any:\n        private_attributes = object.__getattribute__(self, '__private_attributes__')\n        if item in private_attributes:\n            attribute = private_attributes[item]\n            if hasattr(attribute, '__get__'):\n                return attribute.__get__(self, type(self))  # type: ignore\n    \n            try:\n                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items\n                return self.__pydantic_private__[item]  # type: ignore\n            except KeyError as exc:\n                raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc\n        else:\n            # `__pydantic_extra__` can fail to be set if the model is not yet fully initialized.\n            # See `BaseModel.__repr_args__` for more details\n            try:\n                pydantic_extra = object.__getattribute__(self, '__pydantic_extra__')\n            except AttributeError:\n                pydantic_extra = None\n    \n            if pydantic_extra:\n                try:\n                    return pydantic_extra[item]\n                except KeyError as exc:\n                    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc\n            else:\n                if hasattr(self.__class__, item):\n                    return super().__getattribute__(item)  # Raises AttributeError if appropriate\n                else:\n                    # this is the current error\n>                   raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')\nE                   AttributeError: 'ResearchTask' object has no attribute 'parent_task_id'\n\n../../../../.pyenv/versions/3.10.11/lib/python3.10/site-packages/pydantic/main.py:989: AttributeError"}, "teardown": {"duration": 0.000158434035256505, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_task_with_due_date", "lineno": 88, "outcome": "failed", "keywords": ["test_task_with_due_date", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00012679491192102432, "outcome": "passed"}, "call": {"duration": 0.00017991801723837852, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 92, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nstatus\n  Field required [type=missing, input_value={'title': 'Submit prelimi...22, 23, 15, 13, 316746)}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'Submit prelimi...22, 23, 15, 13, 316746)}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 92, "message": "ValidationError"}], "longrepr": "self = <tests.researcher.task_management.test_models.TestResearchTask object at 0x7f63480c8490>\n\n    def test_task_with_due_date(self):\n        # Test creation with due date\n        due_date = datetime.now() + timedelta(days=7)\n>       task = ResearchTask(\n            title=\"Submit preliminary findings\",\n            description=\"Prepare and submit initial findings report\",\n            due_date=due_date,\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nE       status\nE         Field required [type=missing, input_value={'title': 'Submit prelimi...22, 23, 15, 13, 316746)}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'Submit prelimi...22, 23, 15, 13, 316746)}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\n../command_line_task_manager_researcher/tests/task_management/test_models.py:92: ValidationError"}, "teardown": {"duration": 0.0001533010508865118, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_create_subtask", "lineno": 99, "outcome": "failed", "keywords": ["test_create_subtask", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00012159394100308418, "outcome": "passed"}, "call": {"duration": 0.0001688420306891203, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 103, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nstatus\n  Field required [type=missing, input_value={'title': 'Data cleaning ...cb9-8ae5-d0f77b54aa2f')}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'Data cleaning ...cb9-8ae5-d0f77b54aa2f')}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 103, "message": "ValidationError"}], "longrepr": "self = <tests.researcher.task_management.test_models.TestResearchTask object at 0x7f63480cb2b0>\n\n    def test_create_subtask(self):\n        # Test creation with parent task\n        parent_id = uuid4()\n>       task = ResearchTask(\n            title=\"Data cleaning subtask\",\n            description=\"Clean and normalize the temperature dataset\",\n            parent_task_id=parent_id,\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nE       status\nE         Field required [type=missing, input_value={'title': 'Data cleaning ...cb9-8ae5-d0f77b54aa2f')}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'Data cleaning ...cb9-8ae5-d0f77b54aa2f')}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\n../command_line_task_manager_researcher/tests/task_management/test_models.py:103: ValidationError"}, "teardown": {"duration": 0.00014579016715288162, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_update_task", "lineno": 110, "outcome": "passed", "keywords": ["test_update_task", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011924607679247856, "outcome": "passed"}, "call": {"duration": 0.0002039570827037096, "outcome": "passed"}, "teardown": {"duration": 0.00011078105308115482, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_complete_task", "lineno": 140, "outcome": "failed", "keywords": ["test_complete_task", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010857381857931614, "outcome": "passed"}, "call": {"duration": 0.00015685404650866985, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 143, "message": "pydantic_core._pydantic_core.ValidationError: 1 validation error for ResearchTask\npriority\n  Field required [type=missing, input_value={'title': 'Task to comple...ROGRESS: 'in_progress'>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 143, "message": "ValidationError"}], "longrepr": "self = <tests.researcher.task_management.test_models.TestResearchTask object at 0x7f63480cb5b0>\n\n    def test_complete_task(self):\n        # Test completing a task\n>       task = ResearchTask(\n            title=\"Task to complete\",\n            description=\"This task will be marked as completed\",\n            status=TaskStatus.IN_PROGRESS,\n        )\nE       pydantic_core._pydantic_core.ValidationError: 1 validation error for ResearchTask\nE       priority\nE         Field required [type=missing, input_value={'title': 'Task to comple...ROGRESS: 'in_progress'>}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\n../command_line_task_manager_researcher/tests/task_management/test_models.py:143: ValidationError"}, "teardown": {"duration": 0.0001436891034245491, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_add_note", "lineno": 155, "outcome": "failed", "keywords": ["test_add_note", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00012087100185453892, "outcome": "passed"}, "call": {"duration": 0.00016670208424329758, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 158, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nstatus\n  Field required [type=missing, input_value={'title': 'Task with note...ing note functionality'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'Task with note...ing note functionality'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 158, "message": "ValidationError"}], "longrepr": "self = <tests.researcher.task_management.test_models.TestResearchTask object at 0x7f63480c8340>\n\n    def test_add_note(self):\n        # Test adding notes\n>       task = ResearchTask(\n            title=\"Task with notes\",\n            description=\"Testing note functionality\",\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nE       status\nE         Field required [type=missing, input_value={'title': 'Task with note...ing note functionality'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'Task with note...ing note functionality'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\n../command_line_task_manager_researcher/tests/task_management/test_models.py:158: ValidationError"}, "teardown": {"duration": 0.00014588492922484875, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_manage_tags", "lineno": 172, "outcome": "failed", "keywords": ["test_manage_tags", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00012240512296557426, "outcome": "passed"}, "call": {"duration": 0.00016537494957447052, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 175, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nstatus\n  Field required [type=missing, input_value={'title': 'Task with tags...ting tag functionality'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'Task with tags...ting tag functionality'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 175, "message": "ValidationError"}], "longrepr": "self = <tests.researcher.task_management.test_models.TestResearchTask object at 0x7f63480c81c0>\n\n    def test_manage_tags(self):\n        # Test adding and removing tags\n>       task = ResearchTask(\n            title=\"Task with tags\",\n            description=\"Testing tag functionality\",\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nE       status\nE         Field required [type=missing, input_value={'title': 'Task with tags...ting tag functionality'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'Task with tags...ting tag functionality'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\n../command_line_task_manager_researcher/tests/task_management/test_models.py:175: ValidationError"}, "teardown": {"duration": 0.00014783721417188644, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_research_question_association", "lineno": 199, "outcome": "failed", "keywords": ["test_research_question_association", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00012131896801292896, "outcome": "passed"}, "call": {"duration": 0.00016459706239402294, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 202, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nstatus\n  Field required [type=missing, input_value={'title': 'Task with rese... question associations'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'Task with rese... question associations'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 202, "message": "ValidationError"}], "longrepr": "self = <tests.researcher.task_management.test_models.TestResearchTask object at 0x7f63480c8040>\n\n    def test_research_question_association(self):\n        # Test associating with research questions\n>       task = ResearchTask(\n            title=\"Task with research questions\",\n            description=\"Testing research question associations\",\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nE       status\nE         Field required [type=missing, input_value={'title': 'Task with rese... question associations'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'Task with rese... question associations'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\n../command_line_task_manager_researcher/tests/task_management/test_models.py:202: ValidationError"}, "teardown": {"duration": 0.00014438503421843052, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_subtask_management", "lineno": 222, "outcome": "failed", "keywords": ["test_subtask_management", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.000130724860355258, "outcome": "passed"}, "call": {"duration": 0.0001761200837790966, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 225, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nstatus\n  Field required [type=missing, input_value={'title': 'Parent task', ...': 'Task with subtasks'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'Parent task', ...': 'Task with subtasks'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 225, "message": "ValidationError"}], "longrepr": "self = <tests.researcher.task_management.test_models.TestResearchTask object at 0x7f63480cb850>\n\n    def test_subtask_management(self):\n        # Test subtask management\n>       task = ResearchTask(\n            title=\"Parent task\",\n            description=\"Task with subtasks\",\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nE       status\nE         Field required [type=missing, input_value={'title': 'Parent task', ...': 'Task with subtasks'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'Parent task', ...': 'Task with subtasks'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\n../command_line_task_manager_researcher/tests/task_management/test_models.py:225: ValidationError"}, "teardown": {"duration": 0.00014525721780955791, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_custom_metadata", "lineno": 245, "outcome": "failed", "keywords": ["test_custom_metadata", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00012074294500052929, "outcome": "passed"}, "call": {"duration": 0.00017218501307070255, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 248, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nstatus\n  Field required [type=missing, input_value={'title': 'Task with meta...metadata functionality'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'Task with meta...metadata functionality'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 248, "message": "ValidationError"}], "longrepr": "self = <tests.researcher.task_management.test_models.TestResearchTask object at 0x7f63480cb9d0>\n\n    def test_custom_metadata(self):\n        # Test custom metadata functionality\n>       task = ResearchTask(\n            title=\"Task with metadata\",\n            description=\"Testing custom metadata functionality\",\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nE       status\nE         Field required [type=missing, input_value={'title': 'Task with meta...metadata functionality'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'Task with meta...metadata functionality'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\n../command_line_task_manager_researcher/tests/task_management/test_models.py:248: ValidationError"}, "teardown": {"duration": 0.00014815200120210648, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_create_task", "lineno": 16, "outcome": "failed", "keywords": ["test_create_task", "TestTaskManagementService", "test_service.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021798303350806236, "outcome": "passed"}, "call": {"duration": 0.00017759902402758598, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 27, "message": "AttributeError: 'TaskManagementService' object has no attribute 'get_task'"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 27, "message": "AttributeError"}], "longrepr": "self = <tests.researcher.task_management.test_service.TestTaskManagementService object at 0x7f63480f9bd0>\n\n    def test_create_task(self):\n        # Test creating a basic task\n        task_id = self.service.create_task(\n            title=\"Analyze gene expression data\",\n            description=\"Run differential expression analysis on RNA-seq data\",\n            status=TaskStatus.PLANNED,\n            priority=TaskPriority.HIGH,\n            estimated_hours=6.0,\n        )\n    \n>       task = self.service.get_task(task_id)\nE       AttributeError: 'TaskManagementService' object has no attribute 'get_task'\n\n../command_line_task_manager_researcher/tests/task_management/test_service.py:27: AttributeError"}, "teardown": {"duration": 0.000173595966771245, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_create_task_with_parent", "lineno": 35, "outcome": "failed", "keywords": ["test_create_task_with_parent", "TestTaskManagementService", "test_service.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021606404334306717, "outcome": "passed"}, "call": {"duration": 0.00019903294742107391, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 49, "message": "AttributeError: 'TaskManagementService' object has no attribute 'get_task'"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 49, "message": "AttributeError"}], "longrepr": "self = <tests.researcher.task_management.test_service.TestTaskManagementService object at 0x7f63480f9d80>\n\n    def test_create_task_with_parent(self):\n        # Test creating a task with a parent task\n        parent_id = self.service.create_task(\n            title=\"Main analysis project\",\n            description=\"Parent task for gene expression analysis\",\n        )\n    \n        subtask_id = self.service.create_task(\n            title=\"Data preprocessing\",\n            description=\"Preprocess raw sequencing data\",\n            parent_task_id=parent_id,\n        )\n    \n>       parent_task = self.service.get_task(parent_id)\nE       AttributeError: 'TaskManagementService' object has no attribute 'get_task'\n\n../command_line_task_manager_researcher/tests/task_management/test_service.py:49: AttributeError"}, "teardown": {"duration": 0.00017123203724622726, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_create_task_invalid_parent", "lineno": 54, "outcome": "passed", "keywords": ["test_create_task_invalid_parent", "TestTaskManagementService", "test_service.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002074160147458315, "outcome": "passed"}, "call": {"duration": 0.0002908168826252222, "outcome": "passed"}, "teardown": {"duration": 0.00014316197484731674, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_create_task_with_research_questions", "lineno": 63, "outcome": "failed", "keywords": ["test_create_task_with_research_questions", "TestTaskManagementService", "test_service.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020410004071891308, "outcome": "passed"}, "call": {"duration": 0.00019591907039284706, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 79, "message": "AttributeError: 'TaskManagementService' object has no attribute 'get_task'"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 79, "message": "AttributeError"}], "longrepr": "self = <tests.researcher.task_management.test_service.TestTaskManagementService object at 0x7f63480fa0e0>\n\n    def test_create_task_with_research_questions(self):\n        # Test creating a task with research questions\n        question_id1 = self.service.create_research_question(\n            text=\"How does gene A influence phenotype B?\",\n        )\n        question_id2 = self.service.create_research_question(\n            text=\"What pathways are affected by gene A?\",\n        )\n    \n        task_id = self.service.create_task(\n            title=\"Investigate gene A effects\",\n            description=\"Comprehensive analysis of gene A effects\",\n            research_question_ids={question_id1, question_id2},\n        )\n    \n>       task = self.service.get_task(task_id)\nE       AttributeError: 'TaskManagementService' object has no attribute 'get_task'\n\n../command_line_task_manager_researcher/tests/task_management/test_service.py:79: AttributeError"}, "teardown": {"duration": 0.00017158198170363903, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_create_task_invalid_question", "lineno": 83, "outcome": "passed", "keywords": ["test_create_task_invalid_question", "TestTaskManagementService", "test_service.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002067270688712597, "outcome": "passed"}, "call": {"duration": 0.00028939894400537014, "outcome": "passed"}, "teardown": {"duration": 0.00013833609409630299, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_update_task", "lineno": 92, "outcome": "failed", "keywords": ["test_update_task", "TestTaskManagementService", "test_service.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021161511540412903, "outcome": "passed"}, "call": {"duration": 0.00017553893849253654, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 102, "message": "TypeError: BaseTaskService.update_task() got an unexpected keyword argument 'estimated_hours'"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 102, "message": "TypeError"}], "longrepr": "self = <tests.researcher.task_management.test_service.TestTaskManagementService object at 0x7f63480cb2e0>\n\n    def test_update_task(self):\n        # Test updating a task\n        task_id = self.service.create_task(\n            title=\"Original title\",\n            description=\"Original description\",\n            status=TaskStatus.PLANNED,\n            priority=TaskPriority.MEDIUM,\n        )\n    \n>       result = self.service.update_task(\n            task_id=task_id,\n            title=\"Updated title\",\n            description=\"Updated description\",\n            status=TaskStatus.IN_PROGRESS,\n            priority=TaskPriority.HIGH,\n            estimated_hours=10.0,\n            actual_hours=2.5,\n        )\nE       TypeError: BaseTaskService.update_task() got an unexpected keyword argument 'estimated_hours'\n\n../command_line_task_manager_researcher/tests/task_management/test_service.py:102: TypeError"}, "teardown": {"duration": 0.00017752498388290405, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_update_nonexistent_task", "lineno": 121, "outcome": "passed", "keywords": ["test_update_nonexistent_task", "TestTaskManagementService", "test_service.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002187010832130909, "outcome": "passed"}, "call": {"duration": 0.00027712411247193813, "outcome": "passed"}, "teardown": {"duration": 0.00013834284618496895, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_delete_task", "lineno": 129, "outcome": "failed", "keywords": ["test_delete_task", "TestTaskManagementService", "test_service.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00020734197460114956, "outcome": "passed"}, "call": {"duration": 0.0001721449661999941, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 137, "message": "AttributeError: 'TaskManagementService' object has no attribute 'get_task'"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 137, "message": "AttributeError"}], "longrepr": "self = <tests.researcher.task_management.test_service.TestTaskManagementService object at 0x7f63480f9a80>\n\n    def test_delete_task(self):\n        # Test deleting a task\n        task_id = self.service.create_task(\n            title=\"Task to delete\",\n            description=\"This task will be deleted\",\n        )\n    \n>       assert self.service.get_task(task_id) is not None\nE       AttributeError: 'TaskManagementService' object has no attribute 'get_task'\n\n../command_line_task_manager_researcher/tests/task_management/test_service.py:137: AttributeError"}, "teardown": {"duration": 0.00017081922851502895, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_add_task_note", "lineno": 143, "outcome": "failed", "keywords": ["test_add_task_note", "TestTaskManagementService", "test_service.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022358703427016735, "outcome": "passed"}, "call": {"duration": 0.00018767896108329296, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 154, "message": "AttributeError: 'TaskManagementService' object has no attribute 'get_task'"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 154, "message": "AttributeError"}], "longrepr": "self = <tests.researcher.task_management.test_service.TestTaskManagementService object at 0x7f63480f9d20>\n\n    def test_add_task_note(self):\n        # Test adding a note to a task\n        task_id = self.service.create_task(\n            title=\"Task with notes\",\n            description=\"Testing note functionality\",\n        )\n    \n        self.service.add_task_note(task_id, \"First research note\")\n        self.service.add_task_note(task_id, \"Follow-up observation\")\n    \n>       task = self.service.get_task(task_id)\nE       AttributeError: 'TaskManagementService' object has no attribute 'get_task'\n\n../command_line_task_manager_researcher/tests/task_management/test_service.py:154: AttributeError"}, "teardown": {"duration": 0.00016967696137726307, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_add_note_to_nonexistent_task", "lineno": 159, "outcome": "passed", "keywords": ["test_add_note_to_nonexistent_task", "TestTaskManagementService", "test_service.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00022106198593974113, "outcome": "passed"}, "call": {"duration": 0.00018406403250992298, "outcome": "passed"}, "teardown": {"duration": 0.00013474281877279282, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_tag_management", "lineno": 164, "outcome": "failed", "keywords": ["test_tag_management", "TestTaskManagementService", "test_service.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019453885033726692, "outcome": "passed"}, "call": {"duration": 0.0001905788667500019, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 176, "message": "AttributeError: 'TaskManagementService' object has no attribute 'get_task'"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 176, "message": "AttributeError"}], "longrepr": "self = <tests.researcher.task_management.test_service.TestTaskManagementService object at 0x7f63480f8070>\n\n    def test_tag_management(self):\n        # Test adding and removing tags\n        task_id = self.service.create_task(\n            title=\"Task with tags\",\n            description=\"Testing tag functionality\",\n        )\n    \n        self.service.add_task_tag(task_id, \"genomics\")\n        self.service.add_task_tag(task_id, \"bioinformatics\")\n        self.service.add_task_tag(task_id, \"rnaseq\")\n    \n>       task = self.service.get_task(task_id)\nE       AttributeError: 'TaskManagementService' object has no attribute 'get_task'\n\n../command_line_task_manager_researcher/tests/task_management/test_service.py:176: AttributeError"}, "teardown": {"duration": 0.0001709910575300455, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_custom_metadata", "lineno": 189, "outcome": "failed", "keywords": ["test_custom_metadata", "TestTaskManagementService", "test_service.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021075690165162086, "outcome": "passed"}, "call": {"duration": 0.00019705388695001602, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 201, "message": "AttributeError: 'TaskManagementService' object has no attribute 'get_task'"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 201, "message": "AttributeError"}], "longrepr": "self = <tests.researcher.task_management.test_service.TestTaskManagementService object at 0x7f63480f8670>\n\n    def test_custom_metadata(self):\n        # Test updating custom metadata\n        task_id = self.service.create_task(\n            title=\"Task with metadata\",\n            description=\"Testing metadata functionality\",\n        )\n    \n        self.service.update_task_custom_metadata(task_id, \"dataset_source\", \"EBI ArrayExpress\")\n        self.service.update_task_custom_metadata(task_id, \"sample_count\", 48)\n        self.service.update_task_custom_metadata(task_id, \"includes_controls\", True)\n    \n>       task = self.service.get_task(task_id)\nE       AttributeError: 'TaskManagementService' object has no attribute 'get_task'\n\n../command_line_task_manager_researcher/tests/task_management/test_service.py:201: AttributeError"}, "teardown": {"duration": 0.00017222901806235313, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_filter_tasks", "lineno": 206, "outcome": "failed", "keywords": ["test_filter_tasks", "TestTaskManagementService", "test_service.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002084698062390089, "outcome": "passed"}, "call": {"duration": 0.00020969612523913383, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 243, "message": "AttributeError: 'TaskManagementService' object has no attribute 'list_tasks'"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 243, "message": "AttributeError"}], "longrepr": "self = <tests.researcher.task_management.test_service.TestTaskManagementService object at 0x7f63480f8820>\n\n    def test_filter_tasks(self):\n        # Test filtering tasks\n        # Create tasks with different properties\n        self.service.create_task(\n            title=\"Task 1\",\n            description=\"First task\",\n            status=TaskStatus.PLANNED,\n            priority=TaskPriority.LOW,\n            tags={\"literature\", \"planning\"},\n        )\n    \n        self.service.create_task(\n            title=\"Task 2\",\n            description=\"Second task\",\n            status=TaskStatus.IN_PROGRESS,\n            priority=TaskPriority.MEDIUM,\n            tags={\"experiment\", \"analysis\"},\n        )\n    \n        self.service.create_task(\n            title=\"Task 3\",\n            description=\"Third task\",\n            status=TaskStatus.IN_PROGRESS,\n            priority=TaskPriority.HIGH,\n            tags={\"analysis\", \"computation\"},\n        )\n    \n        self.service.create_task(\n            title=\"Task 4\",\n            description=\"Fourth task\",\n            status=TaskStatus.COMPLETED,\n            priority=TaskPriority.MEDIUM,\n            tags={\"reporting\", \"analysis\"},\n        )\n    \n        # Test different filters\n>       planned_tasks = self.service.list_tasks(status=TaskStatus.PLANNED)\nE       AttributeError: 'TaskManagementService' object has no attribute 'list_tasks'\n\n../command_line_task_manager_researcher/tests/task_management/test_service.py:243: AttributeError"}, "teardown": {"duration": 0.00017033121548593044, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_research_question_operations", "lineno": 264, "outcome": "passed", "keywords": ["test_research_question_operations", "TestTaskManagementService", "test_service.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002106900792568922, "outcome": "passed"}, "call": {"duration": 0.00018611084669828415, "outcome": "passed"}, "teardown": {"duration": 0.00014696596190333366, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_research_question_hierarchy", "lineno": 293, "outcome": "failed", "keywords": ["test_research_question_hierarchy", "TestTaskManagementService", "test_service.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019478402100503445, "outcome": "passed"}, "call": {"duration": 0.0002834449987858534, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 315, "message": "assert 0 == 2\n +  where 0 = len([])"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 315, "message": "AssertionError"}], "longrepr": "self = <tests.researcher.task_management.test_service.TestTaskManagementService object at 0x7f63480f8b80>\n\n    def test_research_question_hierarchy(self):\n        # Test creating a hierarchy of research questions\n        parent_id = self.service.create_research_question(\n            text=\"How do climate factors affect agricultural yields?\",\n            description=\"Main research area\",\n        )\n    \n        sub_id1 = self.service.create_research_question(\n            text=\"How does temperature variation impact wheat production?\",\n            description=\"Temperature sub-question\",\n            parent_question_id=parent_id,\n        )\n    \n        sub_id2 = self.service.create_research_question(\n            text=\"How does precipitation pattern affect corn yields?\",\n            description=\"Precipitation sub-question\",\n            parent_question_id=parent_id,\n        )\n    \n        # List sub-questions\n        sub_questions = self.service.list_research_questions(parent_question_id=parent_id)\n>       assert len(sub_questions) == 2\nE       assert 0 == 2\nE        +  where 0 = len([])\n\n../command_line_task_manager_researcher/tests/task_management/test_service.py:315: AssertionError"}, "teardown": {"duration": 0.00016899616457521915, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_task_question_association", "lineno": 325, "outcome": "failed", "keywords": ["test_task_question_association", "TestTaskManagementService", "test_service.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00021808594465255737, "outcome": "passed"}, "call": {"duration": 0.0002009449526667595, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 342, "message": "AttributeError: 'TaskManagementService' object has no attribute 'get_task'"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_service.py", "lineno": 342, "message": "AttributeError"}], "longrepr": "self = <tests.researcher.task_management.test_service.TestTaskManagementService object at 0x7f63480fa4a0>\n\n    def test_task_question_association(self):\n        # Test associating tasks with research questions\n        question_id = self.service.create_research_question(\n            text=\"How effective is treatment X for condition Y?\",\n        )\n    \n        task_id = self.service.create_task(\n            title=\"Literature review on treatment X\",\n            description=\"Comprehensive review of existing studies\",\n        )\n    \n        # Associate task with question\n        result = self.service.associate_task_with_research_question(task_id, question_id)\n        assert result is True\n    \n        # Check association exists\n>       task = self.service.get_task(task_id)\nE       AttributeError: 'TaskManagementService' object has no attribute 'get_task'\n\n../command_line_task_manager_researcher/tests/task_management/test_service.py:342: AttributeError"}, "teardown": {"duration": 0.00017407513223588467, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_associate_with_nonexistent_task", "lineno": 359, "outcome": "passed", "keywords": ["test_associate_with_nonexistent_task", "TestTaskManagementService", "test_service.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0002142100129276514, "outcome": "passed"}, "call": {"duration": 0.00019441312178969383, "outcome": "passed"}, "teardown": {"duration": 0.00013401894830167294, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_associate_with_nonexistent_question", "lineno": 368, "outcome": "passed", "keywords": ["test_associate_with_nonexistent_question", "TestTaskManagementService", "test_service.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019987020641565323, "outcome": "passed"}, "call": {"duration": 0.0001920289359986782, "outcome": "passed"}, "teardown": {"duration": 0.00013046013191342354, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_service.py::TestTaskManagementService::test_get_subtasks", "lineno": 378, "outcome": "passed", "keywords": ["test_get_subtasks", "TestTaskManagementService", "test_service.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00019364198669791222, "outcome": "passed"}, "call": {"duration": 0.00019294396042823792, "outcome": "passed"}, "teardown": {"duration": 0.00013571209274232388, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_create_and_get_task", "lineno": 13, "outcome": "failed", "keywords": ["test_create_and_get_task", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011697993613779545, "outcome": "passed"}, "call": {"duration": 0.00016129110008478165, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 18, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nstatus\n  Field required [type=missing, input_value={'title': 'Analyze neural...ctures on climate data'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'Analyze neural...ctures on climate data'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 18, "message": "ValidationError"}], "longrepr": "self = <tests.researcher.task_management.test_storage.TestInMemoryTaskStorage object at 0x7f63480fb2b0>\n\n    def test_create_and_get_task(self):\n        # Test creating and retrieving a task\n        storage = InMemoryTaskStorage()\n    \n>       task = ResearchTask(\n            title=\"Analyze neural network architecture effectiveness\",\n            description=\"Compare performance of different NN architectures on climate data\",\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nE       status\nE         Field required [type=missing, input_value={'title': 'Analyze neural...ctures on climate data'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'Analyze neural...ctures on climate data'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\n../command_line_task_manager_researcher/tests/task_management/test_storage.py:18: ValidationError"}, "teardown": {"duration": 0.00015236996114253998, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_update_task", "lineno": 30, "outcome": "failed", "keywords": ["test_update_task", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00012023304589092731, "outcome": "passed"}, "call": {"duration": 0.00016900687478482723, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 35, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nstatus\n  Field required [type=missing, input_value={'title': 'Original title... 'Original description'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'Original title... 'Original description'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 35, "message": "ValidationError"}], "longrepr": "self = <tests.researcher.task_management.test_storage.TestInMemoryTaskStorage object at 0x7f63480fb430>\n\n    def test_update_task(self):\n        # Test updating a task\n        storage = InMemoryTaskStorage()\n    \n>       task = ResearchTask(\n            title=\"Original title\",\n            description=\"Original description\",\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nE       status\nE         Field required [type=missing, input_value={'title': 'Original title... 'Original description'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'Original title... 'Original description'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\n../command_line_task_manager_researcher/tests/task_management/test_storage.py:35: ValidationError"}, "teardown": {"duration": 0.0001426509115844965, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_update_nonexistent_task", "lineno": 54, "outcome": "failed", "keywords": ["test_update_nonexistent_task", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00013755704276263714, "outcome": "passed"}, "call": {"duration": 0.00017429888248443604, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 59, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nstatus\n  Field required [type=missing, input_value={'title': 'Nonexistent ta...een created in storage\"}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'Nonexistent ta...een created in storage\"}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 59, "message": "ValidationError"}], "longrepr": "self = <tests.researcher.task_management.test_storage.TestInMemoryTaskStorage object at 0x7f63480fb190>\n\n    def test_update_nonexistent_task(self):\n        # Test updating a task that doesn't exist\n        storage = InMemoryTaskStorage()\n    \n>       task = ResearchTask(\n            title=\"Nonexistent task\",\n            description=\"This task hasn't been created in storage\",\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nE       status\nE         Field required [type=missing, input_value={'title': 'Nonexistent ta...een created in storage\"}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'Nonexistent ta...een created in storage\"}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\n../command_line_task_manager_researcher/tests/task_management/test_storage.py:59: ValidationError"}, "teardown": {"duration": 0.0001510479487478733, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_task", "lineno": 66, "outcome": "failed", "keywords": ["test_delete_task", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00012077414430677891, "outcome": "passed"}, "call": {"duration": 0.00016684690490365028, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 71, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nstatus\n  Field required [type=missing, input_value={'title': 'Task to delete...s task will be deleted'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'Task to delete...s task will be deleted'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 71, "message": "ValidationError"}], "longrepr": "self = <tests.researcher.task_management.test_storage.TestInMemoryTaskStorage object at 0x7f63480fa8f0>\n\n    def test_delete_task(self):\n        # Test deleting a task\n        storage = InMemoryTaskStorage()\n    \n>       task = ResearchTask(\n            title=\"Task to delete\",\n            description=\"This task will be deleted\",\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nE       status\nE         Field required [type=missing, input_value={'title': 'Task to delete...s task will be deleted'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'Task to delete...s task will be deleted'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\n../command_line_task_manager_researcher/tests/task_management/test_storage.py:71: ValidationError"}, "teardown": {"duration": 0.00014505116268992424, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_nonexistent_task", "lineno": 82, "outcome": "passed", "keywords": ["test_delete_nonexistent_task", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011938298121094704, "outcome": "passed"}, "call": {"duration": 0.00015183608047664165, "outcome": "passed"}, "teardown": {"duration": 0.00010925508104264736, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_list_tasks_empty", "lineno": 89, "outcome": "passed", "keywords": ["test_list_tasks_empty", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010959990322589874, "outcome": "passed"}, "call": {"duration": 0.00012535997666418552, "outcome": "passed"}, "teardown": {"duration": 0.00010344688780605793, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_list_tasks_with_filters", "lineno": 96, "outcome": "failed", "keywords": ["test_list_tasks_with_filters", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010605505667626858, "outcome": "passed"}, "call": {"duration": 0.0004554570186883211, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 143, "message": "AssertionError: assert 4 == 1\n +  where 4 = len([ResearchTask(id=UUID('e879ac2c-dd7b-4c1b-becb-b477ebde7e5c'), created_at=datetime.datetime(2025, 5, 15, 23, 15, 13, 480009), updated_at=datetime.datetime(2025, 5, 15, 23, 15, 13, 480022), title='Task 1', description='First task', status='planned', priority='low', due_date=None, completed_at=None, tags={'data', 'planning'}, notes=[], parent_id=None, subtask_ids=set(), custom_metadata={}, estimated_hours=None, actual_hours=None, research_question_ids=set(), reference_ids=set(), dataset_ids=set(), environment_ids=set(), experiment_ids=set(), research_questions=[], references=[], datasets=[], environments=[], experiments=[]), ResearchTask(id=UUID('5d6a12a0-d547-423b-9882-35da69e7b69c'), created_at=datetime.datetime(2025, 5, 15, 23, 15, 13, 480028), updated_at=datetime.datetime(2025, 5, 15, 23, 15, 13, 480034), title='Task 2', description='Second task', status='in_progress', priority='medium', due_date=None, completed_at=None, tags={'analysis'}, notes=[], parent_id=None, subtask_ids=set(), custom_metadata={}, estimated_hours=None, actual_hours=None, research_question_ids=set(), reference_ids=set(), dataset_ids=set(), environment_ids=set(), experiment_ids=set(), research_questions=[],...eated_at=datetime.datetime(2025, 5, 15, 23, 15, 13, 480039), updated_at=datetime.datetime(2025, 5, 15, 23, 15, 13, 480044), title='Task 3', description='Third task', status='in_progress', priority='high', due_date=None, completed_at=None, tags={'data', 'analysis'}, notes=[], parent_id=None, subtask_ids=set(), custom_metadata={}, estimated_hours=None, actual_hours=None, research_question_ids=set(), reference_ids=set(), dataset_ids=set(), environment_ids=set(), experiment_ids=set(), research_questions=[], references=[], datasets=[], environments=[], experiments=[]), ResearchTask(id=UUID('b0da4b3f-38ae-49f7-84b0-b225b0cbb672'), created_at=datetime.datetime(2025, 5, 15, 23, 15, 13, 480061), updated_at=datetime.datetime(2025, 5, 15, 23, 15, 13, 480065), title='Task 4', description='Fourth task', status='completed', priority='medium', due_date=None, completed_at=None, tags={'reporting'}, notes=[], parent_id=None, subtask_ids=set(), custom_metadata={}, estimated_hours=None, actual_hours=None, research_question_ids=set(), reference_ids=set(), dataset_ids=set(), environment_ids=set(), experiment_ids=set(), research_questions=[], references=[], datasets=[], environments=[], experiments=[])])"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 143, "message": "AssertionError"}], "longrepr": "self = <tests.researcher.task_management.test_storage.TestInMemoryTaskStorage object at 0x7f63480fa380>\n\n    def test_list_tasks_with_filters(self):\n        # Test listing tasks with various filters\n        storage = InMemoryTaskStorage()\n    \n        # Create tasks with different statuses, priorities, and tags\n        task1 = ResearchTask(\n            title=\"Task 1\",\n            description=\"First task\",\n            status=TaskStatus.PLANNED,\n            priority=TaskPriority.LOW,\n        )\n        task1.add_tag(\"data\")\n        task1.add_tag(\"planning\")\n    \n        task2 = ResearchTask(\n            title=\"Task 2\",\n            description=\"Second task\",\n            status=TaskStatus.IN_PROGRESS,\n            priority=TaskPriority.MEDIUM,\n        )\n        task2.add_tag(\"analysis\")\n    \n        task3 = ResearchTask(\n            title=\"Task 3\",\n            description=\"Third task\",\n            status=TaskStatus.IN_PROGRESS,\n            priority=TaskPriority.HIGH,\n        )\n        task3.add_tag(\"data\")\n        task3.add_tag(\"analysis\")\n    \n        task4 = ResearchTask(\n            title=\"Task 4\",\n            description=\"Fourth task\",\n            status=TaskStatus.COMPLETED,\n            priority=TaskPriority.MEDIUM,\n        )\n        task4.add_tag(\"reporting\")\n    \n        storage.create_task(task1)\n        storage.create_task(task2)\n        storage.create_task(task3)\n        storage.create_task(task4)\n    \n        # Test filtering by status\n        planned_tasks = storage.list_tasks(status=TaskStatus.PLANNED)\n>       assert len(planned_tasks) == 1\nE       AssertionError: assert 4 == 1\nE        +  where 4 = len([ResearchTask(id=UUID('e879ac2c-dd7b-4c1b-becb-b477ebde7e5c'), created_at=datetime.datetime(2025, 5, 15, 23, 15, 13, 480009), updated_at=datetime.datetime(2025, 5, 15, 23, 15, 13, 480022), title='Task 1', description='First task', status='planned', priority='low', due_date=None, completed_at=None, tags={'data', 'planning'}, notes=[], parent_id=None, subtask_ids=set(), custom_metadata={}, estimated_hours=None, actual_hours=None, research_question_ids=set(), reference_ids=set(), dataset_ids=set(), environment_ids=set(), experiment_ids=set(), research_questions=[], references=[], datasets=[], environments=[], experiments=[]), ResearchTask(id=UUID('5d6a12a0-d547-423b-9882-35da69e7b69c'), created_at=datetime.datetime(2025, 5, 15, 23, 15, 13, 480028), updated_at=datetime.datetime(2025, 5, 15, 23, 15, 13, 480034), title='Task 2', description='Second task', status='in_progress', priority='medium', due_date=None, completed_at=None, tags={'analysis'}, notes=[], parent_id=None, subtask_ids=set(), custom_metadata={}, estimated_hours=None, actual_hours=None, research_question_ids=set(), reference_ids=set(), dataset_ids=set(), environment_ids=set(), experiment_ids=set(), research_questions=[],...eated_at=datetime.datetime(2025, 5, 15, 23, 15, 13, 480039), updated_at=datetime.datetime(2025, 5, 15, 23, 15, 13, 480044), title='Task 3', description='Third task', status='in_progress', priority='high', due_date=None, completed_at=None, tags={'data', 'analysis'}, notes=[], parent_id=None, subtask_ids=set(), custom_metadata={}, estimated_hours=None, actual_hours=None, research_question_ids=set(), reference_ids=set(), dataset_ids=set(), environment_ids=set(), experiment_ids=set(), research_questions=[], references=[], datasets=[], environments=[], experiments=[]), ResearchTask(id=UUID('b0da4b3f-38ae-49f7-84b0-b225b0cbb672'), created_at=datetime.datetime(2025, 5, 15, 23, 15, 13, 480061), updated_at=datetime.datetime(2025, 5, 15, 23, 15, 13, 480065), title='Task 4', description='Fourth task', status='completed', priority='medium', due_date=None, completed_at=None, tags={'reporting'}, notes=[], parent_id=None, subtask_ids=set(), custom_metadata={}, estimated_hours=None, actual_hours=None, research_question_ids=set(), reference_ids=set(), dataset_ids=set(), environment_ids=set(), experiment_ids=set(), research_questions=[], references=[], datasets=[], environments=[], experiments=[])])\n\n../command_line_task_manager_researcher/tests/task_management/test_storage.py:143: AssertionError"}, "teardown": {"duration": 0.00014540390111505985, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_research_question_operations", "lineno": 170, "outcome": "passed", "keywords": ["test_research_question_operations", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001249699853360653, "outcome": "passed"}, "call": {"duration": 0.0001741258893162012, "outcome": "passed"}, "teardown": {"duration": 0.00011263694614171982, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_update_nonexistent_question", "lineno": 204, "outcome": "passed", "keywords": ["test_update_nonexistent_question", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010822084732353687, "outcome": "passed"}, "call": {"duration": 0.000161399831995368, "outcome": "passed"}, "teardown": {"duration": 0.00011362018994987011, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_nonexistent_question", "lineno": 216, "outcome": "passed", "keywords": ["test_delete_nonexistent_question", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00010814517736434937, "outcome": "passed"}, "call": {"duration": 0.00013397913426160812, "outcome": "passed"}, "teardown": {"duration": 0.00010528601706027985, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_list_research_questions", "lineno": 223, "outcome": "failed", "keywords": ["test_list_research_questions", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011109095066785812, "outcome": "passed"}, "call": {"duration": 0.00027948198840022087, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 259, "message": "assert 0 == 4\n +  where 0 = len([])"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 259, "message": "AssertionError"}], "longrepr": "self = <tests.researcher.task_management.test_storage.TestInMemoryTaskStorage object at 0x7f63480fb940>\n\n    def test_list_research_questions(self):\n        # Test listing research questions\n        storage = InMemoryTaskStorage()\n    \n        # Create parent question\n        parent_question = ResearchQuestion(\n            text=\"Main research question\",\n            description=\"The main area of investigation\",\n        )\n        parent_id = storage.create_research_question(parent_question)\n    \n        # Create sub-questions\n        sub_question1 = ResearchQuestion(\n            text=\"Sub-question 1\",\n            description=\"First sub-area\",\n            parent_question_id=parent_id,\n        )\n        sub_question2 = ResearchQuestion(\n            text=\"Sub-question 2\",\n            description=\"Second sub-area\",\n            parent_question_id=parent_id,\n        )\n    \n        # Create unrelated question\n        unrelated_question = ResearchQuestion(\n            text=\"Unrelated question\",\n            description=\"Different research area\",\n        )\n    \n        sub_id1 = storage.create_research_question(sub_question1)\n        sub_id2 = storage.create_research_question(sub_question2)\n        unrelated_id = storage.create_research_question(unrelated_question)\n    \n        # List all questions\n        all_questions = storage.list_research_questions()\n>       assert len(all_questions) == 4\nE       assert 0 == 4\nE        +  where 0 = len([])\n\n../command_line_task_manager_researcher/tests/task_management/test_storage.py:259: AssertionError"}, "teardown": {"duration": 0.0001448560506105423, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_task_question_associations", "lineno": 270, "outcome": "failed", "keywords": ["test_task_question_associations", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00013414700515568256, "outcome": "passed"}, "call": {"duration": 0.0002059401012957096, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 285, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nstatus\n  Field required [type=missing, input_value={'title': 'Task 1', 'description': 'First task'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'Task 1', 'description': 'First task'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 285, "message": "ValidationError"}], "longrepr": "self = <tests.researcher.task_management.test_storage.TestInMemoryTaskStorage object at 0x7f63480fbac0>\n\n    def test_task_question_associations(self):\n        # Test associations between tasks and research questions\n        storage = InMemoryTaskStorage()\n    \n        # Create questions\n        question1 = ResearchQuestion(text=\"Question 1\")\n        question2 = ResearchQuestion(text=\"Question 2\")\n        question3 = ResearchQuestion(text=\"Question 3\")\n    \n        q1_id = storage.create_research_question(question1)\n        q2_id = storage.create_research_question(question2)\n        q3_id = storage.create_research_question(question3)\n    \n        # Create tasks with associations\n>       task1 = ResearchTask(title=\"Task 1\", description=\"First task\")\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nE       status\nE         Field required [type=missing, input_value={'title': 'Task 1', 'description': 'First task'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'Task 1', 'description': 'First task'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\n../command_line_task_manager_researcher/tests/task_management/test_storage.py:285: ValidationError"}, "teardown": {"duration": 0.00015127495862543583, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_subtask_relationships", "lineno": 316, "outcome": "failed", "keywords": ["test_subtask_relationships", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0001215140800923109, "outcome": "passed"}, "call": {"duration": 0.00016482011415064335, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 322, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nstatus\n  Field required [type=missing, input_value={'title': 'Parent task', ...': 'Main research task'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'Parent task', ...': 'Main research task'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 322, "message": "ValidationError"}], "longrepr": "self = <tests.researcher.task_management.test_storage.TestInMemoryTaskStorage object at 0x7f63480fbc40>\n\n    def test_subtask_relationships(self):\n        # Test parent-child task relationships\n        storage = InMemoryTaskStorage()\n    \n        # Create parent task\n>       parent_task = ResearchTask(\n            title=\"Parent task\",\n            description=\"Main research task\",\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nE       status\nE         Field required [type=missing, input_value={'title': 'Parent task', ...': 'Main research task'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'Parent task', ...': 'Main research task'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\n../command_line_task_manager_researcher/tests/task_management/test_storage.py:322: ValidationError"}, "teardown": {"duration": 0.00014521507546305656, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_task_subtask_cleanup", "lineno": 359, "outcome": "failed", "keywords": ["test_delete_task_subtask_cleanup", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011966004967689514, "outcome": "passed"}, "call": {"duration": 0.00018542795442044735, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 365, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nstatus\n  Field required [type=missing, input_value={'title': 'Parent task', ...scription': 'Main task'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'Parent task', ...scription': 'Main task'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 365, "message": "ValidationError"}], "longrepr": "self = <tests.researcher.task_management.test_storage.TestInMemoryTaskStorage object at 0x7f63480fbdc0>\n\n    def test_delete_task_subtask_cleanup(self):\n        # Test that deleting a task also cleans up references from parent tasks\n        storage = InMemoryTaskStorage()\n    \n        # Create parent and subtask\n>       parent_task = ResearchTask(title=\"Parent task\", description=\"Main task\")\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nE       status\nE         Field required [type=missing, input_value={'title': 'Parent task', ...scription': 'Main task'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'Parent task', ...scription': 'Main task'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\n../command_line_task_manager_researcher/tests/task_management/test_storage.py:365: ValidationError"}, "teardown": {"duration": 0.00014568399637937546, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_storage.py::TestInMemoryTaskStorage::test_delete_question_cleanup", "lineno": 386, "outcome": "failed", "keywords": ["test_delete_question_cleanup", "TestInMemoryTaskStorage", "test_storage.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00012168916873633862, "outcome": "passed"}, "call": {"duration": 0.00019897986203432083, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 402, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nstatus\n  Field required [type=missing, input_value={'title': 'Related task',...elated to the question'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'Related task',...elated to the question'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_storage.py", "lineno": 402, "message": "ValidationError"}], "longrepr": "self = <tests.researcher.task_management.test_storage.TestInMemoryTaskStorage object at 0x7f63480fbf40>\n\n    def test_delete_question_cleanup(self):\n        # Test that deleting a question cleans up references\n        storage = InMemoryTaskStorage()\n    \n        # Create parent and child questions\n        parent_question = ResearchQuestion(text=\"Parent question\")\n        child_question = ResearchQuestion(text=\"Child question\")\n    \n        parent_id = storage.create_research_question(parent_question)\n    \n        # Set parent relationship\n        child_question.parent_question_id = parent_id\n        child_id = storage.create_research_question(child_question)\n    \n        # Create task with reference to the question\n>       task = ResearchTask(title=\"Related task\", description=\"Task related to the question\")\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for ResearchTask\nE       status\nE         Field required [type=missing, input_value={'title': 'Related task',...elated to the question'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'Related task',...elated to the question'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\n../command_line_task_manager_researcher/tests/task_management/test_storage.py:402: ValidationError"}, "teardown": {"duration": 0.00014982791617512703, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_models", "lineno": 19, "outcome": "passed", "keywords": ["test_compliance_models", "test_compliance.py", "compliance", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0004422839265316725, "outcome": "passed"}, "call": {"duration": 0.00021727196872234344, "outcome": "passed"}, "teardown": {"duration": 0.00011196383275091648, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_mapping", "lineno": 86, "outcome": "passed", "keywords": ["test_compliance_mapping", "test_compliance.py", "compliance", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00011718389578163624, "outcome": "passed"}, "call": {"duration": 0.0002443899866193533, "outcome": "passed"}, "teardown": {"duration": 0.00011336407624185085, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_repository_create_framework", "lineno": 225, "outcome": "passed", "keywords": ["test_compliance_repository_create_framework", "test_compliance.py", "compliance", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00031379307620227337, "outcome": "passed"}, "call": {"duration": 0.0016738399863243103, "outcome": "passed"}, "teardown": {"duration": 0.00028575584292411804, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_repository_add_controls", "lineno": 264, "outcome": "passed", "keywords": ["test_compliance_repository_add_controls", "test_compliance.py", "compliance", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00025924202054739, "outcome": "passed"}, "call": {"duration": 0.0025329759810119867, "outcome": "passed"}, "teardown": {"duration": 0.0002703468780964613, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_repository_mappings", "lineno": 346, "outcome": "passed", "keywords": ["test_compliance_repository_mappings", "test_compliance.py", "compliance", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0002525730524212122, "outcome": "passed"}, "call": {"duration": 0.002616293029859662, "outcome": "passed"}, "teardown": {"duration": 0.00027381605468690395, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_repository_update_framework", "lineno": 458, "outcome": "passed", "keywords": ["test_compliance_repository_update_framework", "test_compliance.py", "compliance", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00025464408099651337, "outcome": "passed"}, "call": {"duration": 0.0006625319365411997, "outcome": "passed"}, "teardown": {"duration": 0.0002528328914195299, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_repository_delete_framework", "lineno": 497, "outcome": "passed", "keywords": ["test_compliance_repository_delete_framework", "test_compliance.py", "compliance", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00026370701380074024, "outcome": "passed"}, "call": {"duration": 0.00040800590068101883, "outcome": "passed"}, "teardown": {"duration": 0.00022126687690615654, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_repository_list_and_count", "lineno": 527, "outcome": "passed", "keywords": ["test_compliance_repository_list_and_count", "test_compliance.py", "compliance", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0002501681447029114, "outcome": "passed"}, "call": {"duration": 0.001812497153878212, "outcome": "passed"}, "teardown": {"duration": 0.0002970658242702484, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_repository_import_framework", "lineno": 585, "outcome": "passed", "keywords": ["test_compliance_repository_import_framework", "test_compliance.py", "compliance", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0002473930362612009, "outcome": "passed"}, "call": {"duration": 0.0006029920186847448, "outcome": "passed"}, "teardown": {"duration": 0.00025666598230600357, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/compliance/test_compliance.py::test_compliance_performance", "lineno": 650, "outcome": "passed", "keywords": ["test_compliance_performance", "test_compliance.py", "compliance", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00025645713321864605, "outcome": "passed"}, "call": {"duration": 0.02333863591775298, "outcome": "passed"}, "teardown": {"duration": 0.00028247712180018425, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/cvss/test_cvss.py::test_cvss_vector_validation", "lineno": 13, "outcome": "passed", "keywords": ["test_cvss_vector_validation", "test_cvss.py", "cvss", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00031688506714999676, "outcome": "passed"}, "call": {"duration": 0.0002924420405179262, "outcome": "passed"}, "teardown": {"duration": 0.0001186169683933258, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/cvss/test_cvss.py::test_cvss_vector_string_conversion", "lineno": 57, "outcome": "passed", "keywords": ["test_cvss_vector_string_conversion", "test_cvss.py", "cvss", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00011315988376736641, "outcome": "passed"}, "call": {"duration": 0.00039937812834978104, "outcome": "passed"}, "teardown": {"duration": 0.00011243484914302826, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/cvss/test_cvss.py::test_cvss_score_calculation", "lineno": 128, "outcome": "passed", "keywords": ["test_cvss_score_calculation", "test_cvss.py", "cvss", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00011140992864966393, "outcome": "passed"}, "call": {"duration": 0.0003331198822706938, "outcome": "passed"}, "teardown": {"duration": 0.00010951794683933258, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/cvss/test_cvss.py::test_cvss_calculation_with_scope_change", "lineno": 216, "outcome": "passed", "keywords": ["test_cvss_calculation_with_scope_change", "test_cvss.py", "cvss", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00010822201147675514, "outcome": "passed"}, "call": {"duration": 0.0002580669242888689, "outcome": "passed"}, "teardown": {"duration": 0.00010528299026191235, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/cvss/test_cvss.py::test_cvss_calculation_with_temporal_metrics", "lineno": 272, "outcome": "passed", "keywords": ["test_cvss_calculation_with_temporal_metrics", "test_cvss.py", "cvss", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00010909000411629677, "outcome": "passed"}, "call": {"duration": 0.0002519648987799883, "outcome": "passed"}, "teardown": {"duration": 0.00010944204404950142, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/cvss/test_cvss.py::test_cvss_vector_string_parsing", "lineno": 328, "outcome": "passed", "keywords": ["test_cvss_vector_string_parsing", "test_cvss.py", "cvss", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00010736100375652313, "outcome": "passed"}, "call": {"duration": 0.0003653347957879305, "outcome": "passed"}, "teardown": {"duration": 0.00010611698962748051, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/cvss/test_cvss.py::test_cvss_performance", "lineno": 361, "outcome": "passed", "keywords": ["test_cvss_performance", "test_cvss.py", "cvss", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00010804389603435993, "outcome": "passed"}, "call": {"duration": 0.039477002806961536, "outcome": "passed", "stdout": "CVSS Performance: 25597.81 calculations/second\n"}, "teardown": {"duration": 0.00011660996824502945, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/cvss/test_cvss.py::test_cvss_edge_cases", "lineno": 403, "outcome": "passed", "keywords": ["test_cvss_edge_cases", "test_cvss.py", "cvss", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00011245696805417538, "outcome": "passed"}, "call": {"duration": 0.00028395699337124825, "outcome": "passed"}, "teardown": {"duration": 0.0001091130543500185, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_model_validation", "lineno": 28, "outcome": "passed", "keywords": ["test_evidence_model_validation", "test_evidence.py", "evidence", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0003018230199813843, "outcome": "passed"}, "call": {"duration": 0.0002512370701879263, "outcome": "passed"}, "teardown": {"duration": 0.00011053704656660557, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_store", "lineno": 98, "outcome": "passed", "keywords": ["test_evidence_store", "test_evidence.py", "evidence", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0002503548748791218, "outcome": "passed"}, "call": {"duration": 0.012704686028882861, "outcome": "passed"}, "teardown": {"duration": 0.0006404139567166567, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_get_metadata", "lineno": 151, "outcome": "passed", "keywords": ["test_evidence_get_metadata", "test_evidence.py", "evidence", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0002567400224506855, "outcome": "passed"}, "call": {"duration": 0.0015891960356384516, "outcome": "passed"}, "teardown": {"duration": 0.0003404179587960243, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_retrieve", "lineno": 215, "outcome": "passed", "keywords": ["test_evidence_retrieve", "test_evidence.py", "evidence", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00026211305521428585, "outcome": "passed"}, "call": {"duration": 0.0013864331413060427, "outcome": "passed"}, "teardown": {"duration": 0.0003419280983507633, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_update_metadata", "lineno": 271, "outcome": "passed", "keywords": ["test_evidence_update_metadata", "test_evidence.py", "evidence", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00024725310504436493, "outcome": "passed"}, "call": {"duration": 0.0008525529410690069, "outcome": "passed"}, "teardown": {"duration": 0.0003019168507307768, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_delete", "lineno": 314, "outcome": "passed", "keywords": ["test_evidence_delete", "test_evidence.py", "evidence", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00024603400379419327, "outcome": "passed"}, "call": {"duration": 0.0007682570721954107, "outcome": "passed"}, "teardown": {"duration": 0.0002466121222823858, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_list_and_filter", "lineno": 353, "outcome": "passed", "keywords": ["test_evidence_list_and_filter", "test_evidence.py", "evidence", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.000247306190431118, "outcome": "passed"}, "call": {"duration": 0.003316180082038045, "outcome": "passed"}, "teardown": {"duration": 0.00035305600613355637, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_integrity", "lineno": 434, "outcome": "passed", "keywords": ["test_evidence_integrity", "test_evidence.py", "evidence", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00024880701676011086, "outcome": "passed"}, "call": {"duration": 0.0010878921020776033, "outcome": "passed"}, "teardown": {"duration": 0.0002898599486798048, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_store_oversized_file", "lineno": 468, "outcome": "passed", "keywords": ["test_evidence_store_oversized_file", "test_evidence.py", "evidence", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00024285097606480122, "outcome": "passed"}, "call": {"duration": 0.0008323909714818001, "outcome": "passed"}, "teardown": {"duration": 0.00036079389974474907, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/evidence/test_evidence.py::test_evidence_performance_benchmark", "lineno": 488, "outcome": "passed", "keywords": ["test_evidence_performance_benchmark", "test_evidence.py", "evidence", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0002460908144712448, "outcome": "passed"}, "call": {"duration": 0.02002324187196791, "outcome": "passed"}, "teardown": {"duration": 0.0008164800237864256, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/findings/test_findings.py::test_finding_model_validation", "lineno": 16, "outcome": "failed", "keywords": ["test_finding_model_validation", "test_findings.py", "findings", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0003097918815910816, "outcome": "passed"}, "call": {"duration": 0.00017576408572494984, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/tests/security_analyst/findings/test_findings.py", "lineno": 20, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for Finding\nstatus\n  Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "tests/security_analyst/findings/test_findings.py", "lineno": 20, "message": "ValidationError"}], "longrepr": "def test_finding_model_validation():\n        \"\"\"Test that finding model validation works correctly.\"\"\"\n        # Valid finding\n>       finding = Finding(\n            title=\"SQL Injection in Login Form\",\n            description=\"The login form is vulnerable to SQL injection\",\n            affected_systems=[\"web-app-01\", \"web-app-02\"],\n            discovered_by=\"security-analyst\",\n            severity=\"high\"\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Finding\nE       status\nE         Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests/security_analyst/findings/test_findings.py:20: ValidationError"}, "teardown": {"duration": 0.00014066905714571476, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/findings/test_findings.py::test_finding_create", "lineno": 46, "outcome": "failed", "keywords": ["test_finding_create", "test_findings.py", "findings", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0002639919985085726, "outcome": "passed"}, "call": {"duration": 0.00022693793289363384, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/tests/security_analyst/findings/test_findings.py", "lineno": 51, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for Finding\nstatus\n  Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "tests/security_analyst/findings/test_findings.py", "lineno": 51, "message": "ValidationError"}], "longrepr": "temp_dir = '/tmp/tmpb3xhgb50'\n\n    def test_finding_create(temp_dir):\n        \"\"\"Test creating and retrieving security findings.\"\"\"\n        repo = FindingRepository(temp_dir)\n    \n>       finding = Finding(\n            title=\"SQL Injection in Login Form\",\n            description=\"The login form is vulnerable to SQL injection\",\n            affected_systems=[\"web-app-01\", \"web-app-02\"],\n            discovered_by=\"security-analyst\",\n            severity=\"high\"\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Finding\nE       status\nE         Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests/security_analyst/findings/test_findings.py:51: ValidationError"}, "teardown": {"duration": 0.00024815998040139675, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/findings/test_findings.py::test_finding_get", "lineno": 71, "outcome": "failed", "keywords": ["test_finding_get", "test_findings.py", "findings", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0002521991264075041, "outcome": "passed"}, "call": {"duration": 0.0002193839754909277, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/tests/security_analyst/findings/test_findings.py", "lineno": 77, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for Finding\nstatus\n  Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "tests/security_analyst/findings/test_findings.py", "lineno": 77, "message": "ValidationError"}], "longrepr": "temp_dir = '/tmp/tmpvwaytiaz'\n\n    def test_finding_get(temp_dir):\n        \"\"\"Test retrieving a security finding.\"\"\"\n        repo = FindingRepository(temp_dir)\n    \n        # Create a finding to retrieve\n>       finding = Finding(\n            title=\"SQL Injection in Login Form\",\n            description=\"The login form is vulnerable to SQL injection\",\n            affected_systems=[\"web-app-01\", \"web-app-02\"],\n            discovered_by=\"security-analyst\",\n            severity=\"high\"\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Finding\nE       status\nE         Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests/security_analyst/findings/test_findings.py:77: ValidationError"}, "teardown": {"duration": 0.00025464408099651337, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/findings/test_findings.py::test_finding_update", "lineno": 97, "outcome": "failed", "keywords": ["test_finding_update", "test_findings.py", "findings", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0002532221842557192, "outcome": "passed"}, "call": {"duration": 0.00023788097314536572, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/tests/security_analyst/findings/test_findings.py", "lineno": 103, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for Finding\nstatus\n  Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "tests/security_analyst/findings/test_findings.py", "lineno": 103, "message": "ValidationError"}], "longrepr": "temp_dir = '/tmp/tmp21tf0pe1'\n\n    def test_finding_update(temp_dir):\n        \"\"\"Test updating a security finding.\"\"\"\n        repo = FindingRepository(temp_dir)\n    \n        # Create a finding to update\n>       finding = Finding(\n            title=\"SQL Injection in Login Form\",\n            description=\"The login form is vulnerable to SQL injection\",\n            affected_systems=[\"web-app-01\"],\n            discovered_by=\"security-analyst\",\n            severity=\"high\"\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Finding\nE       status\nE         Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests/security_analyst/findings/test_findings.py:103: ValidationError"}, "teardown": {"duration": 0.0002467681188136339, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/findings/test_findings.py::test_finding_delete", "lineno": 132, "outcome": "failed", "keywords": ["test_finding_delete", "test_findings.py", "findings", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00025595189072191715, "outcome": "passed"}, "call": {"duration": 0.00022339308634400368, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/tests/security_analyst/findings/test_findings.py", "lineno": 138, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for Finding\nstatus\n  Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "tests/security_analyst/findings/test_findings.py", "lineno": 138, "message": "ValidationError"}], "longrepr": "temp_dir = '/tmp/tmp7yd904ag'\n\n    def test_finding_delete(temp_dir):\n        \"\"\"Test deleting a security finding.\"\"\"\n        repo = FindingRepository(temp_dir)\n    \n        # Create a finding to delete\n>       finding = Finding(\n            title=\"SQL Injection in Login Form\",\n            description=\"The login form is vulnerable to SQL injection\",\n            affected_systems=[\"web-app-01\"],\n            discovered_by=\"security-analyst\",\n            severity=\"high\"\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Finding\nE       status\nE         Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests/security_analyst/findings/test_findings.py:138: ValidationError"}, "teardown": {"duration": 0.0002594129182398319, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/findings/test_findings.py::test_finding_list_and_filter", "lineno": 166, "outcome": "failed", "keywords": ["test_finding_list_and_filter", "test_findings.py", "findings", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0002558410633355379, "outcome": "passed"}, "call": {"duration": 0.00023459410294890404, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/tests/security_analyst/findings/test_findings.py", "lineno": 172, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for Finding\nstatus\n  Field required [type=missing, input_value={'title': 'SQL Injection ...t1', 'severity': 'high'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'SQL Injection ...t1', 'severity': 'high'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "tests/security_analyst/findings/test_findings.py", "lineno": 172, "message": "ValidationError"}], "longrepr": "temp_dir = '/tmp/tmps72esj2q'\n\n    def test_finding_list_and_filter(temp_dir):\n        \"\"\"Test listing and filtering security findings.\"\"\"\n        repo = FindingRepository(temp_dir)\n    \n        # Create multiple findings\n>       finding1 = Finding(\n            title=\"SQL Injection in Login Form\",\n            description=\"The login form is vulnerable to SQL injection\",\n            affected_systems=[\"web-app-01\"],\n            discovered_by=\"analyst1\",\n            severity=\"high\"\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Finding\nE       status\nE         Field required [type=missing, input_value={'title': 'SQL Injection ...t1', 'severity': 'high'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'SQL Injection ...t1', 'severity': 'high'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests/security_analyst/findings/test_findings.py:172: ValidationError"}, "teardown": {"duration": 0.00024716416373848915, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/findings/test_findings.py::test_finding_crypto_integrity", "lineno": 239, "outcome": "failed", "keywords": ["test_finding_crypto_integrity", "test_findings.py", "findings", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00025750487111508846, "outcome": "passed"}, "call": {"duration": 0.00022133789025247097, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/tests/security_analyst/findings/test_findings.py", "lineno": 245, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for Finding\nstatus\n  Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "tests/security_analyst/findings/test_findings.py", "lineno": 245, "message": "ValidationError"}], "longrepr": "temp_dir = '/tmp/tmpali6ns3m'\n\n    def test_finding_crypto_integrity(temp_dir):\n        \"\"\"Test cryptographic integrity protection of findings.\"\"\"\n        crypto_manager = CryptoManager()\n        repo = FindingRepository(temp_dir, crypto_manager)\n    \n>       finding = Finding(\n            title=\"SQL Injection in Login Form\",\n            description=\"The login form is vulnerable to SQL injection\",\n            affected_systems=[\"web-app-01\"],\n            discovered_by=\"security-analyst\",\n            severity=\"high\"\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Finding\nE       status\nE         Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'SQL Injection ...st', 'severity': 'high'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests/security_analyst/findings/test_findings.py:245: ValidationError"}, "teardown": {"duration": 0.00024707289412617683, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/findings/test_findings.py::test_finding_performance_benchmark", "lineno": 275, "outcome": "failed", "keywords": ["test_finding_performance_benchmark", "test_findings.py", "findings", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0002535239327698946, "outcome": "passed"}, "call": {"duration": 0.00021832017228007317, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/tests/security_analyst/findings/test_findings.py", "lineno": 283, "message": "pydantic_core._pydantic_core.ValidationError: 2 validation errors for Finding\nstatus\n  Field required [type=missing, input_value={'title': 'Performance Te...', 'severity': 'medium'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\npriority\n  Field required [type=missing, input_value={'title': 'Performance Te...', 'severity': 'medium'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "tests/security_analyst/findings/test_findings.py", "lineno": 283, "message": "ValidationError"}], "longrepr": "temp_dir = '/tmp/tmptsahsh32'\n\n    def test_finding_performance_benchmark(temp_dir):\n        \"\"\"Test performance of finding operations.\"\"\"\n        repo = FindingRepository(temp_dir)\n    \n        # Time the creation of a finding\n        start_time = time.time()\n    \n>       finding = Finding(\n            title=\"Performance Test Finding\",\n            description=\"Testing performance of finding operations\",\n            affected_systems=[\"system-1\", \"system-2\", \"system-3\"],\n            discovered_by=\"performance-tester\",\n            severity=\"medium\"\n        )\nE       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Finding\nE       status\nE         Field required [type=missing, input_value={'title': 'Performance Te...', 'severity': 'medium'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\nE       priority\nE         Field required [type=missing, input_value={'title': 'Performance Te...', 'severity': 'medium'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests/security_analyst/findings/test_findings.py:283: ValidationError"}, "teardown": {"duration": 0.00024997699074447155, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_task_model", "lineno": 20, "outcome": "passed", "keywords": ["test_remediation_task_model", "test_remediation.py", "remediation", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00031729182228446007, "outcome": "passed"}, "call": {"duration": 0.0002101450227200985, "outcome": "passed"}, "teardown": {"duration": 0.00011391402222216129, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_task_steps", "lineno": 62, "outcome": "passed", "keywords": ["test_remediation_task_steps", "test_remediation.py", "remediation", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00011112214997410774, "outcome": "passed"}, "call": {"duration": 0.00020654406398534775, "outcome": "passed"}, "teardown": {"duration": 0.00010627484880387783, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_workflow_engine", "lineno": 117, "outcome": "passed", "keywords": ["test_workflow_engine", "test_remediation.py", "remediation", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0001058459747582674, "outcome": "passed"}, "call": {"duration": 0.00030703702941536903, "outcome": "passed"}, "teardown": {"duration": 0.00010806997306644917, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_tracker_create_task", "lineno": 199, "outcome": "passed", "keywords": ["test_remediation_tracker_create_task", "test_remediation.py", "remediation", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00024238694459199905, "outcome": "passed"}, "call": {"duration": 0.0010433578863739967, "outcome": "passed"}, "teardown": {"duration": 0.0003031918313354254, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_tracker_get_task", "lineno": 260, "outcome": "passed", "keywords": ["test_remediation_tracker_get_task", "test_remediation.py", "remediation", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0002592839300632477, "outcome": "passed"}, "call": {"duration": 0.0005552829243242741, "outcome": "passed"}, "teardown": {"duration": 0.00026737689040601254, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_tracker_update_task", "lineno": 289, "outcome": "passed", "keywords": ["test_remediation_tracker_update_task", "test_remediation.py", "remediation", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00024538207799196243, "outcome": "passed"}, "call": {"duration": 0.0007227899041026831, "outcome": "passed"}, "teardown": {"duration": 0.00027727195993065834, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_tracker_transition_task", "lineno": 327, "outcome": "passed", "keywords": ["test_remediation_tracker_transition_task", "test_remediation.py", "remediation", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0002414090558886528, "outcome": "passed"}, "call": {"duration": 0.002539337845519185, "outcome": "passed"}, "teardown": {"duration": 0.0003464601468294859, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_tracker_get_transition_history", "lineno": 412, "outcome": "passed", "keywords": ["test_remediation_tracker_get_transition_history", "test_remediation.py", "remediation", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0002547570038586855, "outcome": "passed"}, "call": {"duration": 0.0019875781144946814, "outcome": "passed"}, "teardown": {"duration": 0.0003123912028968334, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_tracker_list_and_filter", "lineno": 462, "outcome": "passed", "keywords": ["test_remediation_tracker_list_and_filter", "test_remediation.py", "remediation", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00025631184689700603, "outcome": "passed"}, "call": {"duration": 0.003026996972039342, "outcome": "passed"}, "teardown": {"duration": 0.00031425803899765015, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_tracker_delete_task", "lineno": 536, "outcome": "passed", "keywords": ["test_remediation_tracker_delete_task", "test_remediation.py", "remediation", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00025103497318923473, "outcome": "passed"}, "call": {"duration": 0.0015437561087310314, "outcome": "passed"}, "teardown": {"duration": 0.0002841409295797348, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_tracker_metrics", "lineno": 576, "outcome": "passed", "keywords": ["test_remediation_tracker_metrics", "test_remediation.py", "remediation", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0003554190043359995, "outcome": "passed"}, "call": {"duration": 0.011458833003416657, "outcome": "passed"}, "teardown": {"duration": 0.0005145850591361523, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/remediation/test_remediation.py::test_remediation_performance", "lineno": 735, "outcome": "passed", "keywords": ["test_remediation_performance", "test_remediation.py", "remediation", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0002571060322225094, "outcome": "passed"}, "call": {"duration": 0.05236799898557365, "outcome": "passed", "stdout": "Remediation Performance: 2624.52 transitions/second\n"}, "teardown": {"duration": 0.0037251091562211514, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/reporting/test_redaction.py::test_redaction_pattern_complex", "lineno": 14, "outcome": "passed", "keywords": ["test_redaction_pattern_complex", "test_redaction.py", "reporting", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00032628700137138367, "outcome": "passed"}, "call": {"duration": 0.0015003259759396315, "outcome": "passed"}, "teardown": {"duration": 0.00012141792103648186, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/reporting/test_redaction.py::test_redaction_engine_comprehensive", "lineno": 133, "outcome": "passed", "keywords": ["test_redaction_engine_comprehensive", "test_redaction.py", "reporting", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00011415593326091766, "outcome": "passed"}, "call": {"duration": 0.0037089430261403322, "outcome": "passed"}, "teardown": {"duration": 0.00012161093764007092, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/reporting/test_redaction.py::test_redaction_pattern_basic", "lineno": 214, "outcome": "passed", "keywords": ["test_redaction_pattern_basic", "test_redaction.py", "reporting", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0001129640731960535, "outcome": "passed"}, "call": {"duration": 0.00022862199693918228, "outcome": "passed"}, "teardown": {"duration": 0.0001070038415491581, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/reporting/test_redaction.py::test_redaction_engine_basic", "lineno": 244, "outcome": "passed", "keywords": ["test_redaction_engine_basic", "test_redaction.py", "reporting", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00011110003106296062, "outcome": "passed"}, "call": {"duration": 0.000290911877527833, "outcome": "passed"}, "teardown": {"duration": 0.00010540895164012909, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/reporting/test_redaction.py::test_redaction_engine_custom_patterns", "lineno": 280, "outcome": "passed", "keywords": ["test_redaction_engine_custom_patterns", "test_redaction.py", "reporting", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0001045640092343092, "outcome": "passed"}, "call": {"duration": 0.00037581613287329674, "outcome": "passed"}, "teardown": {"duration": 0.00010505807586014271, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/reporting/test_redaction.py::test_redaction_with_json_and_xml", "lineno": 312, "outcome": "passed", "keywords": ["test_redaction_with_json_and_xml", "test_redaction.py", "reporting", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00010410696268081665, "outcome": "passed"}, "call": {"duration": 0.000562586123123765, "outcome": "passed"}, "teardown": {"duration": 0.00011480296961963177, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/reporting/test_redaction.py::test_redaction_edge_cases", "lineno": 377, "outcome": "passed", "keywords": ["test_redaction_edge_cases", "test_redaction.py", "reporting", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00011029490269720554, "outcome": "passed"}, "call": {"duration": 0.0004159619566053152, "outcome": "passed"}, "teardown": {"duration": 0.00011649494990706444, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/reporting/test_redaction.py::test_redaction_patterns_builtin", "lineno": 452, "outcome": "passed", "keywords": ["test_redaction_patterns_builtin", "test_redaction.py", "reporting", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00010736705735325813, "outcome": "passed"}, "call": {"duration": 0.00039920490235090256, "outcome": "passed"}, "teardown": {"duration": 0.00010833400301635265, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_redaction_pattern", "lineno": 46, "outcome": "passed", "keywords": ["test_redaction_pattern", "test_reporting.py", "reporting", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00010842690244317055, "outcome": "passed"}, "call": {"duration": 0.0001410690601915121, "outcome": "passed"}, "teardown": {"duration": 9.998888708651066e-05, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_redaction_engine", "lineno": 79, "outcome": "passed", "keywords": ["test_redaction_engine", "test_reporting.py", "reporting", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00010924809612333775, "outcome": "passed"}, "call": {"duration": 0.0008093600627034903, "outcome": "passed"}, "teardown": {"duration": 0.00011674105189740658, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_report_model", "lineno": 158, "outcome": "passed", "keywords": ["test_report_model", "test_reporting.py", "reporting", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00011070701293647289, "outcome": "passed"}, "call": {"duration": 0.00025050691328942776, "outcome": "passed"}, "teardown": {"duration": 0.0001095880288630724, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_report_generator_integration", "lineno": 201, "outcome": "failed", "keywords": ["test_report_generator_integration", "test_reporting.py", "reporting", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0002419990487396717, "outcome": "passed"}, "call": {"duration": 0.0005596729461103678, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/tests/security_analyst/reporting/test_reporting.py", "lineno": 233, "message": "pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\npriority\n  Field required [type=missing, input_value={'id': '666a52d5-9a55-462... string concatenation.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "tests/security_analyst/reporting/test_reporting.py", "lineno": 233, "message": "ValidationError"}], "longrepr": "temp_dir = '/tmp/tmpwvmfp2z_'\n\n    def test_report_generator_integration(temp_dir):\n        \"\"\"Test report generator integration with other components.\"\"\"\n        # Create crypto manager for all components\n        crypto_manager = CryptoManager()\n    \n        # Setup findings repository\n        findings_dir = os.path.join(temp_dir, \"findings\")\n        findings_repo = FindingRepository(findings_dir, crypto_manager)\n    \n        # Setup evidence vault\n        evidence_dir = os.path.join(temp_dir, \"evidence\")\n        evidence_vault = EvidenceVault(evidence_dir, crypto_manager)\n    \n        # Setup remediation tracker\n        remediation_dir = os.path.join(temp_dir, \"remediation\")\n        remediation_tracker = RemediationTracker(remediation_dir, crypto_manager)\n    \n        # Setup compliance repository\n        compliance_dir = os.path.join(temp_dir, \"compliance\")\n        compliance_repo = ComplianceRepository(compliance_dir, crypto_manager)\n    \n        # Setup report generator\n        report_generator = ReportGenerator(\n            findings_repo=findings_repo,\n            evidence_vault=evidence_vault,\n            remediation_tracker=remediation_tracker,\n            compliance_repo=compliance_repo\n        )\n    \n        # Create test data\n        # 1. Create findings\n>       finding1 = Finding(\n            id=str(uuid.uuid4()),\n            title=\"SQL Injection in Login Form\",\n            description=\"The login form at example.com/login.php is vulnerable to SQL injection via the 'username' parameter. This allows attackers to bypass authentication.\",\n            affected_systems=[\"web-01.example.com\", \"web-02.example.com\"],\n            discovered_date=datetime.now() - timedelta(days=7),\n            discovered_by=\"security_analyst\",\n            status=\"open\",\n            severity=\"high\",\n            cvss_vector=\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\",\n            cvss_score=9.8,\n            cvss_severity=\"Critical\",\n            remediation_plan=\"Update login.php to use parameterized queries instead of string concatenation.\"\n        )\nE       pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\nE       priority\nE         Field required [type=missing, input_value={'id': '666a52d5-9a55-462... string concatenation.'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests/security_analyst/reporting/test_reporting.py:233: ValidationError"}, "teardown": {"duration": 0.0004362801555544138, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_evidence_report_template", "lineno": 477, "outcome": "failed", "keywords": ["test_evidence_report_template", "test_reporting.py", "reporting", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0002597880084067583, "outcome": "passed"}, "call": {"duration": 0.0005280179902911186, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/tests/security_analyst/reporting/test_reporting.py", "lineno": 508, "message": "pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\npriority\n  Field required [type=missing, input_value={'id': '9e17c6cd-eb4f-45e...s_severity': 'Critical'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "tests/security_analyst/reporting/test_reporting.py", "lineno": 508, "message": "ValidationError"}], "longrepr": "temp_dir = '/tmp/tmptb9nyazi'\n\n    def test_evidence_report_template(temp_dir):\n        \"\"\"Test the Evidence Report template specifically.\"\"\"\n        # Create crypto manager for components\n        crypto_manager = CryptoManager()\n    \n        # Setup findings repository\n        findings_dir = os.path.join(temp_dir, \"findings_ev\")\n        findings_repo = FindingRepository(findings_dir, crypto_manager)\n    \n        # Setup evidence vault\n        evidence_dir = os.path.join(temp_dir, \"evidence_ev\")\n        evidence_vault = EvidenceVault(evidence_dir, crypto_manager)\n    \n        # Setup remediation tracker\n        remediation_dir = os.path.join(temp_dir, \"remediation_ev\")\n        remediation_tracker = RemediationTracker(remediation_dir, crypto_manager)\n    \n        # Setup compliance repository\n        compliance_dir = os.path.join(temp_dir, \"compliance_ev\")\n        compliance_repo = ComplianceRepository(compliance_dir, crypto_manager)\n    \n        # Setup report generator\n        report_generator = ReportGenerator(\n            findings_repo=findings_repo,\n            evidence_vault=evidence_vault,\n            remediation_tracker=remediation_tracker,\n            compliance_repo=compliance_repo\n        )\n    \n        # Create test finding with multiple evidence items\n>       finding = Finding(\n            id=str(uuid.uuid4()),\n            title=\"Remote Code Execution in API Endpoint\",\n            description=\"The /api/execute endpoint allows arbitrary code execution due to improper input validation.\",\n            affected_systems=[\"api-server-01.example.com\", \"api-server-02.example.com\"],\n            discovered_date=datetime.now() - timedelta(days=3),\n            discovered_by=\"security_tester\",\n            status=\"open\",\n            severity=\"critical\",\n            cvss_vector=\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:H\",\n            cvss_score=10.0,\n            cvss_severity=\"Critical\"\n        )\nE       pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\nE       priority\nE         Field required [type=missing, input_value={'id': '9e17c6cd-eb4f-45e...s_severity': 'Critical'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests/security_analyst/reporting/test_reporting.py:508: ValidationError"}, "teardown": {"duration": 0.0005532260984182358, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_status_update_template", "lineno": 658, "outcome": "failed", "keywords": ["test_status_update_template", "test_reporting.py", "reporting", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0003239619545638561, "outcome": "passed"}, "call": {"duration": 0.0005736211314797401, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/tests/security_analyst/reporting/test_reporting.py", "lineno": 691, "message": "pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\npriority\n  Field required [type=missing, input_value={'id': '9bad681d-a270-49d...A:N', 'cvss_score': 6.1}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "tests/security_analyst/reporting/test_reporting.py", "lineno": 691, "message": "ValidationError"}], "longrepr": "temp_dir = '/tmp/tmpi7perqq6'\n\n    def test_status_update_template(temp_dir):\n        \"\"\"Test the Status Update template specifically.\"\"\"\n        # Create crypto manager for components\n        crypto_manager = CryptoManager()\n    \n        # Setup findings repository\n        findings_dir = os.path.join(temp_dir, \"findings_st\")\n        findings_repo = FindingRepository(findings_dir, crypto_manager)\n    \n        # Setup evidence vault\n        evidence_dir = os.path.join(temp_dir, \"evidence_st\")\n        evidence_vault = EvidenceVault(evidence_dir, crypto_manager)\n    \n        # Setup remediation tracker\n        remediation_dir = os.path.join(temp_dir, \"remediation_st\")\n        remediation_tracker = RemediationTracker(remediation_dir, crypto_manager)\n    \n        # Setup compliance repository\n        compliance_dir = os.path.join(temp_dir, \"compliance_st\")\n        compliance_repo = ComplianceRepository(compliance_dir, crypto_manager)\n    \n        # Setup report generator\n        report_generator = ReportGenerator(\n            findings_repo=findings_repo,\n            evidence_vault=evidence_vault,\n            remediation_tracker=remediation_tracker,\n            compliance_repo=compliance_repo\n        )\n    \n        # Create test findings with different statuses\n        findings = []\n    \n>       finding1 = Finding(\n            id=str(uuid.uuid4()),\n            title=\"Cross-Site Scripting in Profile Page\",\n            description=\"The profile page is vulnerable to reflected XSS via the 'name' parameter.\",\n            affected_systems=[\"web-frontend-01\"],\n            discovered_date=datetime.now() - timedelta(days=30),\n            discovered_by=\"security_analyst\",\n            status=\"open\",  # Still open\n            severity=\"medium\",\n            cvss_vector=\"CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N\",\n            cvss_score=6.1\n        )\nE       pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\nE       priority\nE         Field required [type=missing, input_value={'id': '9bad681d-a270-49d...A:N', 'cvss_score': 6.1}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests/security_analyst/reporting/test_reporting.py:691: ValidationError"}, "teardown": {"duration": 0.0004395239520817995, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_evidence_report_access_levels", "lineno": 856, "outcome": "failed", "keywords": ["test_evidence_report_access_levels", "test_reporting.py", "reporting", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.000266568036749959, "outcome": "passed"}, "call": {"duration": 0.0005579909775406122, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/tests/security_analyst/reporting/test_reporting.py", "lineno": 884, "message": "pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\npriority\n  Field required [type=missing, input_value={'id': '89585302-5cc9-43f...:H', 'cvss_score': 10.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "tests/security_analyst/reporting/test_reporting.py", "lineno": 884, "message": "ValidationError"}], "longrepr": "temp_dir = '/tmp/tmp618w16c0'\n\n    def test_evidence_report_access_levels(temp_dir):\n        \"\"\"Test how evidence report handles different access levels.\"\"\"\n        # Create crypto manager for components\n        crypto_manager = CryptoManager()\n    \n        # Setup minimal components\n        findings_dir = os.path.join(temp_dir, \"findings_access\")\n        findings_repo = FindingRepository(findings_dir, crypto_manager)\n    \n        evidence_dir = os.path.join(temp_dir, \"evidence_access\")\n        evidence_vault = EvidenceVault(evidence_dir, crypto_manager)\n    \n        remediation_dir = os.path.join(temp_dir, \"remediation_access\")\n        remediation_tracker = RemediationTracker(remediation_dir, crypto_manager)\n    \n        compliance_dir = os.path.join(temp_dir, \"compliance_access\")\n        compliance_repo = ComplianceRepository(compliance_dir, crypto_manager)\n    \n        # Setup report generator\n        report_generator = ReportGenerator(\n            findings_repo=findings_repo,\n            evidence_vault=evidence_vault,\n            remediation_tracker=remediation_tracker,\n            compliance_repo=compliance_repo\n        )\n    \n        # Create a finding with evidence of different access levels\n>       finding = Finding(\n            id=str(uuid.uuid4()),\n            title=\"Database Credential Exposure\",\n            description=\"Database credentials are exposed in plaintext in configuration files.\",\n            affected_systems=[\"database-server-01\", \"application-server-02\"],\n            discovered_date=datetime.now() - timedelta(days=1),\n            discovered_by=\"security_analyst\",\n            status=\"open\",\n            severity=\"critical\",\n            cvss_vector=\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:H\",\n            cvss_score=10.0\n        )\nE       pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\nE       priority\nE         Field required [type=missing, input_value={'id': '89585302-5cc9-43f...:H', 'cvss_score': 10.0}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests/security_analyst/reporting/test_reporting.py:884: ValidationError"}, "teardown": {"duration": 0.0004362131003290415, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_status_update_with_no_findings", "lineno": 1052, "outcome": "passed", "keywords": ["test_status_update_with_no_findings", "test_reporting.py", "reporting", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0002609139773994684, "outcome": "passed"}, "call": {"duration": 0.016313513973727822, "outcome": "passed"}, "teardown": {"duration": 0.0004125298000872135, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_report_formats_rendering", "lineno": 1115, "outcome": "failed", "keywords": ["test_report_formats_rendering", "test_reporting.py", "reporting", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00027145608328282833, "outcome": "passed"}, "call": {"duration": 0.0005174549296498299, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/tests/security_analyst/reporting/test_reporting.py", "lineno": 1143, "message": "pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\npriority\n  Field required [type=missing, input_value={'id': '3c558635-2efd-425...igh', 'cvss_score': 8.5}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "tests/security_analyst/reporting/test_reporting.py", "lineno": 1143, "message": "ValidationError"}], "longrepr": "temp_dir = '/tmp/tmpt63us_6x'\n\n    def test_report_formats_rendering(temp_dir):\n        \"\"\"Test report rendering in different formats.\"\"\"\n        # Create crypto manager for components\n        crypto_manager = CryptoManager()\n    \n        # Setup minimal components\n        findings_dir = os.path.join(temp_dir, \"findings_format\")\n        findings_repo = FindingRepository(findings_dir, crypto_manager)\n    \n        evidence_dir = os.path.join(temp_dir, \"evidence_format\")\n        evidence_vault = EvidenceVault(evidence_dir, crypto_manager)\n    \n        remediation_dir = os.path.join(temp_dir, \"remediation_format\")\n        remediation_tracker = RemediationTracker(remediation_dir, crypto_manager)\n    \n        compliance_dir = os.path.join(temp_dir, \"compliance_format\")\n        compliance_repo = ComplianceRepository(compliance_dir, crypto_manager)\n    \n        # Setup report generator\n        report_generator = ReportGenerator(\n            findings_repo=findings_repo,\n            evidence_vault=evidence_vault,\n            remediation_tracker=remediation_tracker,\n            compliance_repo=compliance_repo\n        )\n    \n        # Create a test finding\n>       finding = Finding(\n            id=str(uuid.uuid4()),\n            title=\"Example Security Finding\",\n            description=\"This is an example security finding for testing report formats.\",\n            affected_systems=[\"test-system\"],\n            discovered_date=datetime.now(),\n            discovered_by=\"test_user\",\n            status=\"open\",\n            severity=\"high\",\n            cvss_score=8.5\n        )\nE       pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\nE       priority\nE         Field required [type=missing, input_value={'id': '3c558635-2efd-425...igh', 'cvss_score': 8.5}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests/security_analyst/reporting/test_reporting.py:1143: ValidationError"}, "teardown": {"duration": 0.0004262879956513643, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/reporting/test_reporting.py::test_report_generator_performance", "lineno": 1220, "outcome": "failed", "keywords": ["test_report_generator_performance", "test_reporting.py", "reporting", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0002586368937045336, "outcome": "passed"}, "call": {"duration": 0.0005544619634747505, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/tests/security_analyst/reporting/test_reporting.py", "lineno": 1250, "message": "pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\npriority\n  Field required [type=missing, input_value={'id': '00f77fff-bd91-41f...en', 'severity': 'high'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "tests/security_analyst/reporting/test_reporting.py", "lineno": 1250, "message": "ValidationError"}], "longrepr": "temp_dir = '/tmp/tmp8r0vvfbb'\n\n    def test_report_generator_performance(temp_dir):\n        \"\"\"Test performance of report generation.\"\"\"\n        # Create crypto manager for all components\n        crypto_manager = CryptoManager()\n    \n        # Setup minimal components for performance testing\n        findings_dir = os.path.join(temp_dir, \"findings\")\n        findings_repo = FindingRepository(findings_dir, crypto_manager)\n    \n        evidence_dir = os.path.join(temp_dir, \"evidence\")\n        evidence_vault = EvidenceVault(evidence_dir, crypto_manager)\n    \n        remediation_dir = os.path.join(temp_dir, \"remediation\")\n        remediation_tracker = RemediationTracker(remediation_dir, crypto_manager)\n    \n        compliance_dir = os.path.join(temp_dir, \"compliance\")\n        compliance_repo = ComplianceRepository(compliance_dir, crypto_manager)\n    \n        # Setup report generator\n        report_generator = ReportGenerator(\n            findings_repo=findings_repo,\n            evidence_vault=evidence_vault,\n            remediation_tracker=remediation_tracker,\n            compliance_repo=compliance_repo\n        )\n    \n        # Create 510 findings (requirement: process 500+ findings in <30 seconds)\n        finding_ids = []\n        for i in range(510):\n>           finding = Finding(\n                id=str(uuid.uuid4()),\n                title=f\"Test Finding {i+1}\",\n                description=f\"Description for test finding {i+1}\",\n                affected_systems=[f\"system-{i+1}\"],\n                discovered_date=datetime.now() - timedelta(days=i % 30),\n                discovered_by=\"performance-tester\",\n                status=\"open\",\n                severity=\"high\" if i % 5 == 0 else \"medium\" if i % 5 == 1 else \"low\" if i % 5 == 2 else \"critical\" if i % 5 == 3 else \"info\"\n            )\nE           pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\nE           priority\nE             Field required [type=missing, input_value={'id': '00f77fff-bd91-41f...en', 'severity': 'high'}, input_type=dict]\nE               For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests/security_analyst/reporting/test_reporting.py:1250: ValidationError"}, "teardown": {"duration": 0.0004360619932413101, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/test_integration.py::test_complete_security_assessment_workflow", "lineno": 71, "outcome": "failed", "keywords": ["test_complete_security_assessment_workflow", "test_integration.py", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0005866680294275284, "outcome": "passed"}, "call": {"duration": 0.00020279595628380775, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/tests/security_analyst/test_integration.py", "lineno": 92, "message": "pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\npriority\n  Field required [type=missing, input_value={'id': '1ace59a4-4bef-444... Add input validation.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "tests/security_analyst/test_integration.py", "lineno": 92, "message": "ValidationError"}], "longrepr": "security_assessment_environment = {'base_dir': '/tmp/tmptuqxuhuf', 'compliance_repo': <securetask.compliance.repository.ComplianceRepository object at 0...r object at 0x7f6344beb220>, 'evidence_vault': <securetask.evidence.vault.EvidenceVault object at 0x7f6344beb340>, ...}\n\n    def test_complete_security_assessment_workflow(security_assessment_environment):\n        \"\"\"\n        Test the complete security assessment workflow from finding creation to final report.\n    \n        This integration test verifies that all components of the SecureTask system\n        work together correctly through a complete security assessment lifecycle:\n    \n        1. Create security findings\n        2. Add evidence to findings\n        3. Create compliance framework and map findings\n        4. Create and update remediation tasks\n        5. Generate different types of reports\n        6. Verify encryption and integrity throughout the process\n        \"\"\"\n        env = security_assessment_environment\n    \n        # Step 1: Create security findings\n        findings = []\n    \n        # SQL Injection finding\n>       sql_injection = Finding(\n            id=str(uuid.uuid4()),\n            title=\"SQL Injection in Login Form\",\n            description=\"The login form is vulnerable to SQL injection via the 'username' parameter, allowing authentication bypass.\",\n            affected_systems=[\"web-01.example.com\", \"web-02.example.com\"],\n            discovered_date=datetime.now() - timedelta(days=14),\n            discovered_by=\"security_analyst\",\n            status=\"open\",\n            severity=\"high\",\n            cvss_vector=\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:L\",\n            cvss_score=9.4,\n            cvss_severity=\"Critical\",\n            remediation_plan=\"Implement prepared statements for all database queries. Add input validation.\"\n        )\nE       pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\nE       priority\nE         Field required [type=missing, input_value={'id': '1ace59a4-4bef-444... Add input validation.'}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests/security_analyst/test_integration.py:92: ValidationError"}, "teardown": {"duration": 0.00044216285459697247, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/test_integration.py::test_integrity_checks_simple", "lineno": 149, "outcome": "passed", "keywords": ["test_integrity_checks_simple", "test_integration.py", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00012767617590725422, "outcome": "passed"}, "call": {"duration": 0.0004787561483681202, "outcome": "passed"}, "teardown": {"duration": 0.00011423998512327671, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/test_integration.py::test_redaction_basic", "lineno": 172, "outcome": "passed", "keywords": ["test_redaction_basic", "test_integration.py", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0001099130604416132, "outcome": "passed"}, "call": {"duration": 0.0003488610964268446, "outcome": "passed"}, "teardown": {"duration": 0.00011399597860872746, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/test_stress.py::test_large_findings_repository", "lineno": 195, "outcome": "failed", "keywords": ["test_large_findings_repository", "test_stress.py", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0005572298541665077, "outcome": "passed"}, "call": {"duration": 0.00038359686732292175, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/tests/security_analyst/test_stress.py", "lineno": 192, "message": "pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\npriority\n  Field required [type=missing, input_value={'id': '7a8ab581-76cc-4e3...ompliance_controls': []}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "tests/security_analyst/test_stress.py", "lineno": 208, "message": ""}, {"path": "tests/security_analyst/test_stress.py", "lineno": 192, "message": "ValidationError"}], "longrepr": "stress_test_env = {'base_dir': '/tmp/tmpbib7abnx', 'compliance_repo': <securetask.compliance.repository.ComplianceRepository object at 0...r object at 0x7f6344d38fa0>, 'evidence_vault': <securetask.evidence.vault.EvidenceVault object at 0x7f6344d38250>, ...}\n\n    def test_large_findings_repository(stress_test_env):\n        \"\"\"Test repository performance with a large number of findings.\"\"\"\n        env = stress_test_env\n        findings_count = 1000\n        findings = []\n        finding_ids = []\n    \n        # Measure creation time\n        start_time = time.time()\n    \n        # Create 1000 findings\n        for i in range(findings_count):\n>           finding = create_random_finding(i)\n\ntests/security_analyst/test_stress.py:208: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nindex = 0, created_days_ago = 16\n\n    def create_random_finding(index: int, created_days_ago: Optional[int] = None) -> Finding:\n        \"\"\"Create a random finding for stress testing.\"\"\"\n        severities = [\"critical\", \"high\", \"medium\", \"low\", \"info\"]\n        statuses = [\"open\", \"in_progress\", \"remediated\", \"false_positive\", \"closed\"]\n    \n        affected_systems = []\n        system_count = random.randint(1, 5)\n        for i in range(system_count):\n            system_type = random.choice([\"web\", \"app\", \"db\", \"api\", \"auth\", \"proxy\", \"storage\"])\n            system_id = random.randint(1, 20)\n            affected_systems.append(f\"{system_type}-server-{system_id}.example.com\")\n    \n        # Generate discovery date\n        if created_days_ago is None:\n            created_days_ago = random.randint(1, 365)\n        discovered_date = datetime.now() - timedelta(days=created_days_ago)\n    \n        # Random CVSS score\n        cvss_score = round(random.uniform(0.1, 10.0), 1)\n    \n        # Determine CVSS severity based on score\n        if cvss_score >= 9.0:\n            cvss_severity = \"Critical\"\n        elif cvss_score >= 7.0:\n            cvss_severity = \"High\"\n        elif cvss_score >= 4.0:\n            cvss_severity = \"Medium\"\n        elif cvss_score >= 0.1:\n            cvss_severity = \"Low\"\n        else:\n            cvss_severity = \"None\"\n    \n        # Generate a somewhat realistic finding with template\n        finding_types = [\n            \"SQL Injection\", \"Cross-Site Scripting\", \"Cross-Site Request Forgery\",\n            \"Server Misconfiguration\", \"Insecure Direct Object Reference\", \"Authentication Bypass\",\n            \"Authorization Bypass\", \"Information Disclosure\", \"Remote Code Execution\",\n            \"Command Injection\", \"Insecure Cryptography\", \"Insecure Communication\",\n            \"Improper Access Control\", \"Default Credentials\", \"Session Fixation\",\n            \"Business Logic Vulnerability\", \"Race Condition\", \"Integer Overflow\",\n            \"Unvalidated Redirect\", \"Insecure Deserialization\"\n        ]\n    \n        vulnerability_type = random.choice(finding_types)\n        title = f\"{vulnerability_type} in {random.choice(['Login', 'Search', 'Admin', 'User', 'Payment', 'API', 'Profile', 'Settings', 'Checkout'])} {random.choice(['Page', 'Module', 'Function', 'Feature', 'Service', 'Endpoint'])}\"\n    \n        # Generate a more detailed description\n        description = generate_lorem_ipsum(paragraphs=random.randint(2, 5), sentences_per_paragraph=random.randint(3, 8))\n    \n        # Generate remediation details if status is remediated\n        remediation_details = None\n        remediation_date = None\n        if random.choice(statuses) == \"remediated\":\n            remediation_details = generate_lorem_ipsum(paragraphs=1, sentences_per_paragraph=random.randint(2, 5))\n            remediation_date = discovered_date + timedelta(days=random.randint(1, 90))\n    \n        # Create a remediation plan for most findings\n        remediation_plan = None\n        if random.random() > 0.2:  # 80% chance to have a remediation plan\n            remediation_plan = generate_lorem_ipsum(paragraphs=1, sentences_per_paragraph=random.randint(2, 5))\n    \n        # Build the finding with valid fields\n        finding_data = {\n            \"id\": str(uuid.uuid4()),\n            \"title\": title,\n            \"description\": description,\n            \"affected_systems\": affected_systems,\n            \"discovered_date\": discovered_date,\n            \"discovered_by\": random.choice([\"security_analyst\", \"penetration_tester\", \"security_scanner\", \"developer\", \"auditor\"]),\n            \"status\": random.choice(statuses),\n            \"severity\": random.choice(severities),\n            \"cvss_vector\": f\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\",  # Simplified for tests\n            \"cvss_score\": cvss_score,\n            \"cvss_severity\": cvss_severity,\n            \"remediation_plan\": remediation_plan,\n            \"tags\": [random.choice([\"web\", \"api\", \"database\", \"network\", \"authentication\", \"authorization\", \"input-validation\"])\n                    for _ in range(random.randint(1, 5))],\n            \"references\": [],\n            \"notes\": [],\n            \"evidence_ids\": [],\n            \"compliance_controls\": []\n        }\n    \n        # Add optional fields if they have values\n        if remediation_date:\n            finding_data[\"remediation_date\"] = remediation_date\n            finding_data[\"remediated_by\"] = \"remediation_engineer\"\n    \n>       return Finding(**finding_data)\nE       pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\nE       priority\nE         Field required [type=missing, input_value={'id': '7a8ab581-76cc-4e3...ompliance_controls': []}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests/security_analyst/test_stress.py:192: ValidationError"}, "teardown": {"duration": 0.00046251690946519375, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/test_stress.py::test_large_evidence_vault", "lineno": 257, "outcome": "passed", "keywords": ["test_large_evidence_vault", "test_stress.py", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0005721200723201036, "outcome": "passed"}, "call": {"duration": 1.2688205919694155, "outcome": "passed", "stdout": "Stored 20/100 evidence files\nStored 40/100 evidence files\nStored 60/100 evidence files\nStored 80/100 evidence files\nStored 100/100 evidence files\nStored 100 evidence files in 0.13 seconds (799.34 files/second)\nRetrieved 20 random evidence items in 0.00 seconds (11199.74 items/second)\nListed all 100 evidence items in 0.01 seconds\nListed 16 filtered evidence items in 0.01 seconds\n"}, "teardown": {"duration": 0.007925669895485044, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/test_stress.py::test_large_remediation_tracking", "lineno": 334, "outcome": "failed", "keywords": ["test_large_remediation_tracking", "test_stress.py", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0006787569727748632, "outcome": "passed"}, "call": {"duration": 0.000411792891100049, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/tests/security_analyst/test_stress.py", "lineno": 192, "message": "pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\npriority\n  Field required [type=missing, input_value={'id': 'd990da88-edec-4bd...ompliance_controls': []}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "tests/security_analyst/test_stress.py", "lineno": 344, "message": ""}, {"path": "tests/security_analyst/test_stress.py", "lineno": 192, "message": "ValidationError"}], "longrepr": "stress_test_env = {'base_dir': '/tmp/tmpuf0m7x0c', 'compliance_repo': <securetask.compliance.repository.ComplianceRepository object at 0...r object at 0x7f6344d4aa70>, 'evidence_vault': <securetask.evidence.vault.EvidenceVault object at 0x7f6344d4be20>, ...}\n\n    def test_large_remediation_tracking(stress_test_env):\n        \"\"\"Test remediation tracking with a large number of tasks and updates.\"\"\"\n        env = stress_test_env\n        findings_count = 200\n        findings = []\n        finding_ids = []\n    \n        # Create findings first\n        for i in range(findings_count):\n>           finding = create_random_finding(i)\n\ntests/security_analyst/test_stress.py:344: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nindex = 0, created_days_ago = 177\n\n    def create_random_finding(index: int, created_days_ago: Optional[int] = None) -> Finding:\n        \"\"\"Create a random finding for stress testing.\"\"\"\n        severities = [\"critical\", \"high\", \"medium\", \"low\", \"info\"]\n        statuses = [\"open\", \"in_progress\", \"remediated\", \"false_positive\", \"closed\"]\n    \n        affected_systems = []\n        system_count = random.randint(1, 5)\n        for i in range(system_count):\n            system_type = random.choice([\"web\", \"app\", \"db\", \"api\", \"auth\", \"proxy\", \"storage\"])\n            system_id = random.randint(1, 20)\n            affected_systems.append(f\"{system_type}-server-{system_id}.example.com\")\n    \n        # Generate discovery date\n        if created_days_ago is None:\n            created_days_ago = random.randint(1, 365)\n        discovered_date = datetime.now() - timedelta(days=created_days_ago)\n    \n        # Random CVSS score\n        cvss_score = round(random.uniform(0.1, 10.0), 1)\n    \n        # Determine CVSS severity based on score\n        if cvss_score >= 9.0:\n            cvss_severity = \"Critical\"\n        elif cvss_score >= 7.0:\n            cvss_severity = \"High\"\n        elif cvss_score >= 4.0:\n            cvss_severity = \"Medium\"\n        elif cvss_score >= 0.1:\n            cvss_severity = \"Low\"\n        else:\n            cvss_severity = \"None\"\n    \n        # Generate a somewhat realistic finding with template\n        finding_types = [\n            \"SQL Injection\", \"Cross-Site Scripting\", \"Cross-Site Request Forgery\",\n            \"Server Misconfiguration\", \"Insecure Direct Object Reference\", \"Authentication Bypass\",\n            \"Authorization Bypass\", \"Information Disclosure\", \"Remote Code Execution\",\n            \"Command Injection\", \"Insecure Cryptography\", \"Insecure Communication\",\n            \"Improper Access Control\", \"Default Credentials\", \"Session Fixation\",\n            \"Business Logic Vulnerability\", \"Race Condition\", \"Integer Overflow\",\n            \"Unvalidated Redirect\", \"Insecure Deserialization\"\n        ]\n    \n        vulnerability_type = random.choice(finding_types)\n        title = f\"{vulnerability_type} in {random.choice(['Login', 'Search', 'Admin', 'User', 'Payment', 'API', 'Profile', 'Settings', 'Checkout'])} {random.choice(['Page', 'Module', 'Function', 'Feature', 'Service', 'Endpoint'])}\"\n    \n        # Generate a more detailed description\n        description = generate_lorem_ipsum(paragraphs=random.randint(2, 5), sentences_per_paragraph=random.randint(3, 8))\n    \n        # Generate remediation details if status is remediated\n        remediation_details = None\n        remediation_date = None\n        if random.choice(statuses) == \"remediated\":\n            remediation_details = generate_lorem_ipsum(paragraphs=1, sentences_per_paragraph=random.randint(2, 5))\n            remediation_date = discovered_date + timedelta(days=random.randint(1, 90))\n    \n        # Create a remediation plan for most findings\n        remediation_plan = None\n        if random.random() > 0.2:  # 80% chance to have a remediation plan\n            remediation_plan = generate_lorem_ipsum(paragraphs=1, sentences_per_paragraph=random.randint(2, 5))\n    \n        # Build the finding with valid fields\n        finding_data = {\n            \"id\": str(uuid.uuid4()),\n            \"title\": title,\n            \"description\": description,\n            \"affected_systems\": affected_systems,\n            \"discovered_date\": discovered_date,\n            \"discovered_by\": random.choice([\"security_analyst\", \"penetration_tester\", \"security_scanner\", \"developer\", \"auditor\"]),\n            \"status\": random.choice(statuses),\n            \"severity\": random.choice(severities),\n            \"cvss_vector\": f\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\",  # Simplified for tests\n            \"cvss_score\": cvss_score,\n            \"cvss_severity\": cvss_severity,\n            \"remediation_plan\": remediation_plan,\n            \"tags\": [random.choice([\"web\", \"api\", \"database\", \"network\", \"authentication\", \"authorization\", \"input-validation\"])\n                    for _ in range(random.randint(1, 5))],\n            \"references\": [],\n            \"notes\": [],\n            \"evidence_ids\": [],\n            \"compliance_controls\": []\n        }\n    \n        # Add optional fields if they have values\n        if remediation_date:\n            finding_data[\"remediation_date\"] = remediation_date\n            finding_data[\"remediated_by\"] = \"remediation_engineer\"\n    \n>       return Finding(**finding_data)\nE       pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\nE       priority\nE         Field required [type=missing, input_value={'id': 'd990da88-edec-4bd...ompliance_controls': []}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests/security_analyst/test_stress.py:192: ValidationError"}, "teardown": {"duration": 0.000471693929284811, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/test_stress.py::test_large_compliance_framework", "lineno": 434, "outcome": "failed", "keywords": ["test_large_compliance_framework", "test_stress.py", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0006068700458854437, "outcome": "passed"}, "call": {"duration": 0.0004358319565653801, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/tests/security_analyst/test_stress.py", "lineno": 192, "message": "pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\npriority\n  Field required [type=missing, input_value={'id': '214db504-74eb-447...ompliance_controls': []}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "tests/security_analyst/test_stress.py", "lineno": 447, "message": ""}, {"path": "tests/security_analyst/test_stress.py", "lineno": 192, "message": "ValidationError"}], "longrepr": "stress_test_env = {'base_dir': '/tmp/tmp4owjbtym', 'compliance_repo': <securetask.compliance.repository.ComplianceRepository object at 0...r object at 0x7f6344c8d8d0>, 'evidence_vault': <securetask.evidence.vault.EvidenceVault object at 0x7f6344c8da20>, ...}\n\n    def test_large_compliance_framework(stress_test_env):\n        \"\"\"Test compliance framework with many controls, frameworks, and mappings.\"\"\"\n        env = stress_test_env\n        framework_count = 5\n        controls_per_framework = 50\n        findings_count = 100\n    \n        # Create findings first\n        findings = []\n        finding_ids = []\n    \n        for i in range(findings_count):\n>           finding = create_random_finding(i)\n\ntests/security_analyst/test_stress.py:447: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nindex = 0, created_days_ago = 35\n\n    def create_random_finding(index: int, created_days_ago: Optional[int] = None) -> Finding:\n        \"\"\"Create a random finding for stress testing.\"\"\"\n        severities = [\"critical\", \"high\", \"medium\", \"low\", \"info\"]\n        statuses = [\"open\", \"in_progress\", \"remediated\", \"false_positive\", \"closed\"]\n    \n        affected_systems = []\n        system_count = random.randint(1, 5)\n        for i in range(system_count):\n            system_type = random.choice([\"web\", \"app\", \"db\", \"api\", \"auth\", \"proxy\", \"storage\"])\n            system_id = random.randint(1, 20)\n            affected_systems.append(f\"{system_type}-server-{system_id}.example.com\")\n    \n        # Generate discovery date\n        if created_days_ago is None:\n            created_days_ago = random.randint(1, 365)\n        discovered_date = datetime.now() - timedelta(days=created_days_ago)\n    \n        # Random CVSS score\n        cvss_score = round(random.uniform(0.1, 10.0), 1)\n    \n        # Determine CVSS severity based on score\n        if cvss_score >= 9.0:\n            cvss_severity = \"Critical\"\n        elif cvss_score >= 7.0:\n            cvss_severity = \"High\"\n        elif cvss_score >= 4.0:\n            cvss_severity = \"Medium\"\n        elif cvss_score >= 0.1:\n            cvss_severity = \"Low\"\n        else:\n            cvss_severity = \"None\"\n    \n        # Generate a somewhat realistic finding with template\n        finding_types = [\n            \"SQL Injection\", \"Cross-Site Scripting\", \"Cross-Site Request Forgery\",\n            \"Server Misconfiguration\", \"Insecure Direct Object Reference\", \"Authentication Bypass\",\n            \"Authorization Bypass\", \"Information Disclosure\", \"Remote Code Execution\",\n            \"Command Injection\", \"Insecure Cryptography\", \"Insecure Communication\",\n            \"Improper Access Control\", \"Default Credentials\", \"Session Fixation\",\n            \"Business Logic Vulnerability\", \"Race Condition\", \"Integer Overflow\",\n            \"Unvalidated Redirect\", \"Insecure Deserialization\"\n        ]\n    \n        vulnerability_type = random.choice(finding_types)\n        title = f\"{vulnerability_type} in {random.choice(['Login', 'Search', 'Admin', 'User', 'Payment', 'API', 'Profile', 'Settings', 'Checkout'])} {random.choice(['Page', 'Module', 'Function', 'Feature', 'Service', 'Endpoint'])}\"\n    \n        # Generate a more detailed description\n        description = generate_lorem_ipsum(paragraphs=random.randint(2, 5), sentences_per_paragraph=random.randint(3, 8))\n    \n        # Generate remediation details if status is remediated\n        remediation_details = None\n        remediation_date = None\n        if random.choice(statuses) == \"remediated\":\n            remediation_details = generate_lorem_ipsum(paragraphs=1, sentences_per_paragraph=random.randint(2, 5))\n            remediation_date = discovered_date + timedelta(days=random.randint(1, 90))\n    \n        # Create a remediation plan for most findings\n        remediation_plan = None\n        if random.random() > 0.2:  # 80% chance to have a remediation plan\n            remediation_plan = generate_lorem_ipsum(paragraphs=1, sentences_per_paragraph=random.randint(2, 5))\n    \n        # Build the finding with valid fields\n        finding_data = {\n            \"id\": str(uuid.uuid4()),\n            \"title\": title,\n            \"description\": description,\n            \"affected_systems\": affected_systems,\n            \"discovered_date\": discovered_date,\n            \"discovered_by\": random.choice([\"security_analyst\", \"penetration_tester\", \"security_scanner\", \"developer\", \"auditor\"]),\n            \"status\": random.choice(statuses),\n            \"severity\": random.choice(severities),\n            \"cvss_vector\": f\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\",  # Simplified for tests\n            \"cvss_score\": cvss_score,\n            \"cvss_severity\": cvss_severity,\n            \"remediation_plan\": remediation_plan,\n            \"tags\": [random.choice([\"web\", \"api\", \"database\", \"network\", \"authentication\", \"authorization\", \"input-validation\"])\n                    for _ in range(random.randint(1, 5))],\n            \"references\": [],\n            \"notes\": [],\n            \"evidence_ids\": [],\n            \"compliance_controls\": []\n        }\n    \n        # Add optional fields if they have values\n        if remediation_date:\n            finding_data[\"remediation_date\"] = remediation_date\n            finding_data[\"remediated_by\"] = \"remediation_engineer\"\n    \n>       return Finding(**finding_data)\nE       pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\nE       priority\nE         Field required [type=missing, input_value={'id': '214db504-74eb-447...ompliance_controls': []}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests/security_analyst/test_stress.py:192: ValidationError"}, "teardown": {"duration": 0.0004433628637343645, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/test_stress.py::test_large_report_generation", "lineno": 564, "outcome": "failed", "keywords": ["test_large_report_generation", "test_stress.py", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.000599452992901206, "outcome": "passed"}, "call": {"duration": 0.0005036930087953806, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/tests/security_analyst/test_stress.py", "lineno": 192, "message": "pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\npriority\n  Field required [type=missing, input_value={'id': '3f3cb175-12a9-44f...ompliance_controls': []}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"}, "traceback": [{"path": "tests/security_analyst/test_stress.py", "lineno": 575, "message": ""}, {"path": "tests/security_analyst/test_stress.py", "lineno": 192, "message": "ValidationError"}], "longrepr": "stress_test_env = {'base_dir': '/tmp/tmpmd829ai0', 'compliance_repo': <securetask.compliance.repository.ComplianceRepository object at 0...r object at 0x7f6344ae50c0>, 'evidence_vault': <securetask.evidence.vault.EvidenceVault object at 0x7f6344ae5180>, ...}\n\n    def test_large_report_generation(stress_test_env):\n        \"\"\"Test report generation with a large number of findings and evidence.\"\"\"\n        env = stress_test_env\n    \n        # Create a large set of findings\n        findings_count = 200\n        findings = []\n        finding_ids = []\n    \n        for i in range(findings_count):\n>           finding = create_random_finding(i)\n\ntests/security_analyst/test_stress.py:575: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nindex = 0, created_days_ago = 355\n\n    def create_random_finding(index: int, created_days_ago: Optional[int] = None) -> Finding:\n        \"\"\"Create a random finding for stress testing.\"\"\"\n        severities = [\"critical\", \"high\", \"medium\", \"low\", \"info\"]\n        statuses = [\"open\", \"in_progress\", \"remediated\", \"false_positive\", \"closed\"]\n    \n        affected_systems = []\n        system_count = random.randint(1, 5)\n        for i in range(system_count):\n            system_type = random.choice([\"web\", \"app\", \"db\", \"api\", \"auth\", \"proxy\", \"storage\"])\n            system_id = random.randint(1, 20)\n            affected_systems.append(f\"{system_type}-server-{system_id}.example.com\")\n    \n        # Generate discovery date\n        if created_days_ago is None:\n            created_days_ago = random.randint(1, 365)\n        discovered_date = datetime.now() - timedelta(days=created_days_ago)\n    \n        # Random CVSS score\n        cvss_score = round(random.uniform(0.1, 10.0), 1)\n    \n        # Determine CVSS severity based on score\n        if cvss_score >= 9.0:\n            cvss_severity = \"Critical\"\n        elif cvss_score >= 7.0:\n            cvss_severity = \"High\"\n        elif cvss_score >= 4.0:\n            cvss_severity = \"Medium\"\n        elif cvss_score >= 0.1:\n            cvss_severity = \"Low\"\n        else:\n            cvss_severity = \"None\"\n    \n        # Generate a somewhat realistic finding with template\n        finding_types = [\n            \"SQL Injection\", \"Cross-Site Scripting\", \"Cross-Site Request Forgery\",\n            \"Server Misconfiguration\", \"Insecure Direct Object Reference\", \"Authentication Bypass\",\n            \"Authorization Bypass\", \"Information Disclosure\", \"Remote Code Execution\",\n            \"Command Injection\", \"Insecure Cryptography\", \"Insecure Communication\",\n            \"Improper Access Control\", \"Default Credentials\", \"Session Fixation\",\n            \"Business Logic Vulnerability\", \"Race Condition\", \"Integer Overflow\",\n            \"Unvalidated Redirect\", \"Insecure Deserialization\"\n        ]\n    \n        vulnerability_type = random.choice(finding_types)\n        title = f\"{vulnerability_type} in {random.choice(['Login', 'Search', 'Admin', 'User', 'Payment', 'API', 'Profile', 'Settings', 'Checkout'])} {random.choice(['Page', 'Module', 'Function', 'Feature', 'Service', 'Endpoint'])}\"\n    \n        # Generate a more detailed description\n        description = generate_lorem_ipsum(paragraphs=random.randint(2, 5), sentences_per_paragraph=random.randint(3, 8))\n    \n        # Generate remediation details if status is remediated\n        remediation_details = None\n        remediation_date = None\n        if random.choice(statuses) == \"remediated\":\n            remediation_details = generate_lorem_ipsum(paragraphs=1, sentences_per_paragraph=random.randint(2, 5))\n            remediation_date = discovered_date + timedelta(days=random.randint(1, 90))\n    \n        # Create a remediation plan for most findings\n        remediation_plan = None\n        if random.random() > 0.2:  # 80% chance to have a remediation plan\n            remediation_plan = generate_lorem_ipsum(paragraphs=1, sentences_per_paragraph=random.randint(2, 5))\n    \n        # Build the finding with valid fields\n        finding_data = {\n            \"id\": str(uuid.uuid4()),\n            \"title\": title,\n            \"description\": description,\n            \"affected_systems\": affected_systems,\n            \"discovered_date\": discovered_date,\n            \"discovered_by\": random.choice([\"security_analyst\", \"penetration_tester\", \"security_scanner\", \"developer\", \"auditor\"]),\n            \"status\": random.choice(statuses),\n            \"severity\": random.choice(severities),\n            \"cvss_vector\": f\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\",  # Simplified for tests\n            \"cvss_score\": cvss_score,\n            \"cvss_severity\": cvss_severity,\n            \"remediation_plan\": remediation_plan,\n            \"tags\": [random.choice([\"web\", \"api\", \"database\", \"network\", \"authentication\", \"authorization\", \"input-validation\"])\n                    for _ in range(random.randint(1, 5))],\n            \"references\": [],\n            \"notes\": [],\n            \"evidence_ids\": [],\n            \"compliance_controls\": []\n        }\n    \n        # Add optional fields if they have values\n        if remediation_date:\n            finding_data[\"remediation_date\"] = remediation_date\n            finding_data[\"remediated_by\"] = \"remediation_engineer\"\n    \n>       return Finding(**finding_data)\nE       pydantic_core._pydantic_core.ValidationError: 1 validation error for Finding\nE       priority\nE         Field required [type=missing, input_value={'id': '3f3cb175-12a9-44f...ompliance_controls': []}, input_type=dict]\nE           For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests/security_analyst/test_stress.py:192: ValidationError"}, "teardown": {"duration": 0.000449249055236578, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/test_stress.py::test_redaction_performance_large_data", "lineno": 744, "outcome": "passed", "keywords": ["test_redaction_performance_large_data", "test_stress.py", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0005811650771647692, "outcome": "passed"}, "call": {"duration": 5.249871996929869, "outcome": "passed", "stdout": "Redacted 100KB of data in 0.11 seconds (883.12 KB/second)\nRedacted 500KB of data in 0.30 seconds (1667.79 KB/second)\nRedacted 1000KB of data in 0.40 seconds (2525.01 KB/second)\nRedacted 5000KB of data in 1.52 seconds (3300.20 KB/second)\n"}, "teardown": {"duration": 0.0006031980738043785, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/utils/test_crypto.py::test_crypto_manager_init", "lineno": 17, "outcome": "passed", "keywords": ["test_crypto_manager_init", "test_crypto.py", "utils", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.0003939620219171047, "outcome": "passed"}, "call": {"duration": 0.0001879851333796978, "outcome": "passed"}, "teardown": {"duration": 0.00011516502127051353, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/utils/test_crypto.py::test_encrypt_decrypt", "lineno": 33, "outcome": "passed", "keywords": ["test_encrypt_decrypt", "test_crypto.py", "utils", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00011452985927462578, "outcome": "passed"}, "call": {"duration": 0.0005148840136826038, "outcome": "passed"}, "teardown": {"duration": 0.0001358608715236187, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/utils/test_crypto.py::test_integrity_verification", "lineno": 66, "outcome": "passed", "keywords": ["test_integrity_verification", "test_crypto.py", "utils", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00011314707808196545, "outcome": "passed"}, "call": {"duration": 0.0003667001146823168, "outcome": "passed"}, "teardown": {"duration": 0.00011275196447968483, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/utils/test_crypto.py::test_derive_key_from_password", "lineno": 95, "outcome": "passed", "keywords": ["test_derive_key_from_password", "test_crypto.py", "utils", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00011133193038403988, "outcome": "passed"}, "call": {"duration": 0.12214692891575396, "outcome": "passed"}, "teardown": {"duration": 0.00013701803982257843, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/utils/test_crypto.py::test_hash_data", "lineno": 128, "outcome": "passed", "keywords": ["test_hash_data", "test_crypto.py", "utils", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00012057996354997158, "outcome": "passed"}, "call": {"duration": 0.0001457291655242443, "outcome": "passed"}, "teardown": {"duration": 0.00011186907067894936, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/utils/test_crypto.py::test_generate_random_id", "lineno": 154, "outcome": "passed", "keywords": ["test_generate_random_id", "test_crypto.py", "utils", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00011759600602090359, "outcome": "passed"}, "call": {"duration": 0.00013190205208957195, "outcome": "passed"}, "teardown": {"duration": 0.00010234187357127666, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/utils/test_crypto.py::test_encrypt_decrypt_performance", "lineno": 176, "outcome": "passed", "keywords": ["test_encrypt_decrypt_performance", "test_crypto.py", "utils", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00010539498180150986, "outcome": "passed"}, "call": {"duration": 0.0017208671197295189, "outcome": "passed"}, "teardown": {"duration": 0.0001233210787177086, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/utils/test_crypto.py::test_key_reuse", "lineno": 213, "outcome": "passed", "keywords": ["test_key_reuse", "test_crypto.py", "utils", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00011260109022259712, "outcome": "passed"}, "call": {"duration": 0.0003322309348732233, "outcome": "passed"}, "teardown": {"duration": 0.00011615804396569729, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/utils/test_crypto.py::test_different_keys", "lineno": 244, "outcome": "passed", "keywords": ["test_different_keys", "test_crypto.py", "utils", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00010787299834191799, "outcome": "passed"}, "call": {"duration": 0.00023732404224574566, "outcome": "passed"}, "teardown": {"duration": 0.00010774494148790836, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/utils/test_validation.py::test_validation_error", "lineno": 10, "outcome": "passed", "keywords": ["test_validation_error", "test_validation.py", "utils", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00010929605923593044, "outcome": "passed"}, "call": {"duration": 0.0001322778407484293, "outcome": "passed"}, "teardown": {"duration": 0.0001008850522339344, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/utils/test_validation.py::test_validate_file_size", "lineno": 25, "outcome": "passed", "keywords": ["test_validate_file_size", "test_validation.py", "utils", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00011413311585783958, "outcome": "passed"}, "call": {"duration": 0.0008295939769595861, "outcome": "passed"}, "teardown": {"duration": 0.0001115170307457447, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/utils/test_validation.py::test_validate_cvss_metric", "lineno": 53, "outcome": "passed", "keywords": ["test_validate_cvss_metric", "test_validation.py", "utils", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00010622479021549225, "outcome": "passed"}, "call": {"duration": 0.0003567079547792673, "outcome": "passed"}, "teardown": {"duration": 0.00010597379878163338, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/utils/test_validation.py::test_validation_with_pydantic", "lineno": 76, "outcome": "passed", "keywords": ["test_validation_with_pydantic", "test_validation.py", "utils", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00010407110676169395, "outcome": "passed"}, "call": {"duration": 0.000918832141906023, "outcome": "passed"}, "teardown": {"duration": 0.0001157829537987709, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/utils/test_validation.py::test_validate_file_size_edge_cases", "lineno": 99, "outcome": "passed", "keywords": ["test_validate_file_size_edge_cases", "test_validation.py", "utils", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00010814983397722244, "outcome": "passed"}, "call": {"duration": 0.00036226888187229633, "outcome": "passed"}, "teardown": {"duration": 0.00012502004392445087, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/utils/test_validation.py::test_validate_cvss_metric_performance", "lineno": 129, "outcome": "passed", "keywords": ["test_validate_cvss_metric_performance", "test_validation.py", "utils", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00011121598072350025, "outcome": "passed"}, "call": {"duration": 0.00023496500216424465, "outcome": "passed"}, "teardown": {"duration": 0.00010221591219305992, "outcome": "passed"}}, {"nodeid": "tests/security_analyst/utils/test_validation.py::test_validation_error_inheritance", "lineno": 149, "outcome": "passed", "keywords": ["test_validation_error_inheritance", "test_validation.py", "utils", "security_analyst", "tests", "unified", ""], "setup": {"duration": 0.00010559801012277603, "outcome": "passed"}, "call": {"duration": 0.0003259279765188694, "outcome": "passed"}, "teardown": {"duration": 0.00019688298925757408, "outcome": "passed"}}], "warnings": [{"message": "Field name \"schema\" in \"Dataset\" shadows an attribute in parent \"BaseModel\"", "category": "UserWarning", "when": "collect", "filename": "/home/justinchiu_cohere_com/.pyenv/versions/3.10.11/lib/python3.10/site-packages/pydantic/_internal/_fields.py", "lineno": 198}, {"message": "Field name \"schema\" in \"DatasetVersion\" shadows an attribute in parent \"BaseModel\"", "category": "UserWarning", "when": "collect", "filename": "/home/justinchiu_cohere_com/.pyenv/versions/3.10.11/lib/python3.10/site-packages/pydantic/_internal/_fields.py", "lineno": 198}]}