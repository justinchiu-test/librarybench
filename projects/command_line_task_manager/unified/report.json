{"created": 1747353298.3515043, "duration": 0.15021300315856934, "exitcode": 1, "root": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified", "environment": {}, "summary": {"failed": 5, "passed": 8, "total": 13, "collected": 13}, "collectors": [{"nodeid": "", "outcome": "passed", "result": [{"nodeid": "tests/researcher/task_management/test_models.py", "type": "Module"}]}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchQuestion", "outcome": "passed", "result": [{"nodeid": "tests/researcher/task_management/test_models.py::TestResearchQuestion::test_create_research_question", "type": "Function", "lineno": 14}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchQuestion::test_create_with_parent", "type": "Function", "lineno": 28}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchQuestion::test_update_question", "type": "Function", "lineno": 39}]}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask", "outcome": "passed", "result": [{"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_create_research_task", "type": "Function", "lineno": 60}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_task_with_due_date", "type": "Function", "lineno": 88}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_create_subtask", "type": "Function", "lineno": 99}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_update_task", "type": "Function", "lineno": 110}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_complete_task", "type": "Function", "lineno": 140}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_add_note", "type": "Function", "lineno": 155}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_manage_tags", "type": "Function", "lineno": 172}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_research_question_association", "type": "Function", "lineno": 199}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_subtask_management", "type": "Function", "lineno": 222}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_custom_metadata", "type": "Function", "lineno": 245}]}, {"nodeid": "tests/researcher/task_management/test_models.py", "outcome": "passed", "result": [{"nodeid": "tests/researcher/task_management/test_models.py::TestResearchQuestion", "type": "Class"}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask", "type": "Class"}]}], "tests": [{"nodeid": "tests/researcher/task_management/test_models.py::TestResearchQuestion::test_create_research_question", "lineno": 14, "outcome": "failed", "keywords": ["test_create_research_question", "TestResearchQuestion", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.0006974120624363422, "outcome": "passed"}, "call": {"duration": 0.00028652697801589966, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 22, "message": "AssertionError: assert False\n +  where False = isinstance('6371e994-d594-4702-912d-92d2123efca9', UUID)\n +    where '6371e994-d594-4702-912d-92d2123efca9' = ResearchQuestion(id='6371e994-d594-4702-912d-92d2123efca9', created_at=datetime.datetime(2025, 5, 15, 23, 54, 58, 308551), updated_at=datetime.datetime(2025, 5, 15, 23, 54, 58, 308553), text='What factors influence climate model accuracy?', description='Investigating the key factors that affect predictive accuracy of climate models', parent_question_id=None).id"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 22, "message": "AssertionError"}], "longrepr": "self = <tests.researcher.task_management.test_models.TestResearchQuestion object at 0x7f4837342e70>\n\n    def test_create_research_question(self):\n        # Test basic creation\n        question = ResearchQuestion(\n            text=\"What factors influence climate model accuracy?\",\n            description=\"Investigating the key factors that affect predictive accuracy of climate models\",\n        )\n    \n>       assert isinstance(question.id, UUID)\nE       AssertionError: assert False\nE        +  where False = isinstance('6371e994-d594-4702-912d-92d2123efca9', UUID)\nE        +    where '6371e994-d594-4702-912d-92d2123efca9' = ResearchQuestion(id='6371e994-d594-4702-912d-92d2123efca9', created_at=datetime.datetime(2025, 5, 15, 23, 54, 58, 308551), updated_at=datetime.datetime(2025, 5, 15, 23, 54, 58, 308553), text='What factors influence climate model accuracy?', description='Investigating the key factors that affect predictive accuracy of climate models', parent_question_id=None).id\n\n../command_line_task_manager_researcher/tests/task_management/test_models.py:22: AssertionError"}, "teardown": {"duration": 0.00013049808330833912, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchQuestion::test_create_with_parent", "lineno": 28, "outcome": "passed", "keywords": ["test_create_with_parent", "TestResearchQuestion", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 9.591295383870602e-05, "outcome": "passed"}, "call": {"duration": 0.00013875705190002918, "outcome": "passed"}, "teardown": {"duration": 9.227893315255642e-05, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchQuestion::test_update_question", "lineno": 39, "outcome": "passed", "keywords": ["test_update_question", "TestResearchQuestion", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 7.940595969557762e-05, "outcome": "passed"}, "call": {"duration": 0.00013633910566568375, "outcome": "passed"}, "teardown": {"duration": 7.899804040789604e-05, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_create_research_task", "lineno": 60, "outcome": "failed", "keywords": ["test_create_research_task", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 7.571396417915821e-05, "outcome": "passed"}, "call": {"duration": 0.000381645979359746, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 71, "message": "AssertionError: assert False\n +  where False = isinstance('29ce5e59-fe3f-452c-9925-52e97e11ca48', UUID)\n +    where '29ce5e59-fe3f-452c-9925-52e97e11ca48' = ResearchTask(id='29ce5e59-fe3f-452c-9925-52e97e11ca48', created_at=datetime.datetime(2025, 5, 15, 23, 54, 58, 329348), updated_at=datetime.datetime(2025, 5, 15, 23, 54, 58, 329349), title='Analyze climate data from 1950-2020', description='Perform time series analysis on global temperature data', status='planned', priority='high', due_date=None, completed_at=None, tags=set(), notes=[], parent_id=None, subtask_ids=set(), custom_metadata={}, estimated_hours=8.5, actual_hours=None, research_question_ids=set(), reference_ids=set(), dataset_ids=set(), environment_ids=set(), experiment_ids=set(), research_questions=[], references=[], datasets=[], environments=[], experiments=[]).id"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 71, "message": "AssertionError"}], "longrepr": "self = <tests.researcher.task_management.test_models.TestResearchTask object at 0x7f48370204d0>\n\n    def test_create_research_task(self):\n        # Test basic creation\n        task = ResearchTask(\n            title=\"Analyze climate data from 1950-2020\",\n            description=\"Perform time series analysis on global temperature data\",\n            status=TaskStatus.PLANNED,\n            priority=TaskPriority.HIGH,\n            estimated_hours=8.5,\n        )\n    \n>       assert isinstance(task.id, UUID)\nE       AssertionError: assert False\nE        +  where False = isinstance('29ce5e59-fe3f-452c-9925-52e97e11ca48', UUID)\nE        +    where '29ce5e59-fe3f-452c-9925-52e97e11ca48' = ResearchTask(id='29ce5e59-fe3f-452c-9925-52e97e11ca48', created_at=datetime.datetime(2025, 5, 15, 23, 54, 58, 329348), updated_at=datetime.datetime(2025, 5, 15, 23, 54, 58, 329349), title='Analyze climate data from 1950-2020', description='Perform time series analysis on global temperature data', status='planned', priority='high', due_date=None, completed_at=None, tags=set(), notes=[], parent_id=None, subtask_ids=set(), custom_metadata={}, estimated_hours=8.5, actual_hours=None, research_question_ids=set(), reference_ids=set(), dataset_ids=set(), environment_ids=set(), experiment_ids=set(), research_questions=[], references=[], datasets=[], environments=[], experiments=[]).id\n\n../command_line_task_manager_researcher/tests/task_management/test_models.py:71: AssertionError"}, "teardown": {"duration": 0.00011650798842310905, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_task_with_due_date", "lineno": 88, "outcome": "passed", "keywords": ["test_task_with_due_date", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 9.792391210794449e-05, "outcome": "passed"}, "call": {"duration": 0.00016026291996240616, "outcome": "passed"}, "teardown": {"duration": 8.488702587783337e-05, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_create_subtask", "lineno": 99, "outcome": "failed", "keywords": ["test_create_subtask", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 8.093100041151047e-05, "outcome": "passed"}, "call": {"duration": 0.00014263507910072803, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/researchtrack/task_management/models.py", "lineno": 76, "message": "pydantic_core._pydantic_core.ValidationError: 1 validation error for ResearchTask\nparent_id\n  Input should be a valid string [type=string_type, input_value=UUID('d861559f-93f9-4e1a-80a9-88d4e016381b'), input_type=UUID]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 103, "message": ""}, {"path": "researchtrack/task_management/models.py", "lineno": 76, "message": "ValidationError"}], "longrepr": "self = <tests.researcher.task_management.test_models.TestResearchTask object at 0x7f48370205c0>\n\n    def test_create_subtask(self):\n        # Test creation with parent task\n        parent_id = uuid4()\n>       task = ResearchTask(\n            title=\"Data cleaning subtask\",\n            description=\"Clean and normalize the temperature dataset\",\n            parent_task_id=parent_id,\n        )\n\n../command_line_task_manager_researcher/tests/task_management/test_models.py:103: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = ResearchTask()\ndata = {'description': 'Clean and normalize the temperature dataset', 'parent_id': UUID('d861559f-93f9-4e1a-80a9-88d4e016381b'), 'title': 'Data cleaning subtask'}\n\n    def __init__(self, **data):\n        if 'parent_task_id' in data and 'parent_id' not in data:\n            data['parent_id'] = data.pop('parent_task_id')\n>       super().__init__(**data)\nE       pydantic_core._pydantic_core.ValidationError: 1 validation error for ResearchTask\nE       parent_id\nE         Input should be a valid string [type=string_type, input_value=UUID('d861559f-93f9-4e1a-80a9-88d4e016381b'), input_type=UUID]\nE           For further information visit https://errors.pydantic.dev/2.11/v/string_type\n\nresearchtrack/task_management/models.py:76: ValidationError"}, "teardown": {"duration": 0.00011456990614533424, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_update_task", "lineno": 110, "outcome": "passed", "keywords": ["test_update_task", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00013855798169970512, "outcome": "passed"}, "call": {"duration": 0.00018824194557964802, "outcome": "passed"}, "teardown": {"duration": 7.957499474287033e-05, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_complete_task", "lineno": 140, "outcome": "passed", "keywords": ["test_complete_task", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 7.821014150977135e-05, "outcome": "passed"}, "call": {"duration": 0.00014518015086650848, "outcome": "passed"}, "teardown": {"duration": 7.402501069009304e-05, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_add_note", "lineno": 155, "outcome": "passed", "keywords": ["test_add_note", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 7.500196807086468e-05, "outcome": "passed"}, "call": {"duration": 0.00012548104859888554, "outcome": "passed"}, "teardown": {"duration": 7.937499321997166e-05, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_manage_tags", "lineno": 172, "outcome": "passed", "keywords": ["test_manage_tags", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 8.499389514327049e-05, "outcome": "passed"}, "call": {"duration": 0.0001268319319933653, "outcome": "passed"}, "teardown": {"duration": 7.58699607104063e-05, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_research_question_association", "lineno": 199, "outcome": "failed", "keywords": ["test_research_question_association", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 7.435004226863384e-05, "outcome": "passed"}, "call": {"duration": 0.0002772470470517874, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 214, "message": "AssertionError: assert UUID('7fbff229-07d6-4b03-ab27-06e4d98fdee3') in {'7fbff229-07d6-4b03-ab27-06e4d98fdee3', 'f692e344-f25b-4f50-9938-f99c07ab84d2'}\n +  where {'7fbff229-07d6-4b03-ab27-06e4d98fdee3', 'f692e344-f25b-4f50-9938-f99c07ab84d2'} = ResearchTask(id='ba887f0c-14d7-406e-921e-2ddd0bcc4aec', created_at=datetime.datetime(2025, 5, 15, 23, 54, 58, 343097), updated_at=datetime.datetime(2025, 5, 15, 23, 54, 58, 343125), title='Task with research questions', description='Testing research question associations', status='planned', priority='medium', due_date=None, completed_at=None, tags=set(), notes=[], parent_id=None, subtask_ids=set(), custom_metadata={}, estimated_hours=None, actual_hours=None, research_question_ids={'7fbff229-07d6-4b03-ab27-06e4d98fdee3', 'f692e344-f25b-4f50-9938-f99c07ab84d2'}, reference_ids=set(), dataset_ids=set(), environment_ids=set(), experiment_ids=set(), research_questions=[], references=[], datasets=[], environments=[], experiments=[]).research_question_ids"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 214, "message": "AssertionError"}], "longrepr": "self = <tests.researcher.task_management.test_models.TestResearchTask object at 0x7f4837022f00>\n\n    def test_research_question_association(self):\n        # Test associating with research questions\n        task = ResearchTask(\n            title=\"Task with research questions\",\n            description=\"Testing research question associations\",\n        )\n    \n        question_id1 = uuid4()\n        question_id2 = uuid4()\n    \n        task.add_research_question(question_id1)\n        task.add_research_question(question_id2)\n    \n        assert len(task.research_question_ids) == 2\n>       assert question_id1 in task.research_question_ids\nE       AssertionError: assert UUID('7fbff229-07d6-4b03-ab27-06e4d98fdee3') in {'7fbff229-07d6-4b03-ab27-06e4d98fdee3', 'f692e344-f25b-4f50-9938-f99c07ab84d2'}\nE        +  where {'7fbff229-07d6-4b03-ab27-06e4d98fdee3', 'f692e344-f25b-4f50-9938-f99c07ab84d2'} = ResearchTask(id='ba887f0c-14d7-406e-921e-2ddd0bcc4aec', created_at=datetime.datetime(2025, 5, 15, 23, 54, 58, 343097), updated_at=datetime.datetime(2025, 5, 15, 23, 54, 58, 343125), title='Task with research questions', description='Testing research question associations', status='planned', priority='medium', due_date=None, completed_at=None, tags=set(), notes=[], parent_id=None, subtask_ids=set(), custom_metadata={}, estimated_hours=None, actual_hours=None, research_question_ids={'7fbff229-07d6-4b03-ab27-06e4d98fdee3', 'f692e344-f25b-4f50-9938-f99c07ab84d2'}, reference_ids=set(), dataset_ids=set(), environment_ids=set(), experiment_ids=set(), research_questions=[], references=[], datasets=[], environments=[], experiments=[]).research_question_ids\n\n../command_line_task_manager_researcher/tests/task_management/test_models.py:214: AssertionError"}, "teardown": {"duration": 0.00012537301518023014, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_subtask_management", "lineno": 222, "outcome": "failed", "keywords": ["test_subtask_management", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 9.116600267589092e-05, "outcome": "passed"}, "call": {"duration": 0.0002840789966285229, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 237, "message": "AssertionError: assert UUID('ad0c5f36-2557-4a63-a8c9-a5b946b04d86') in {'a4677bde-fbab-4835-bbae-635af682dfb6', 'ad0c5f36-2557-4a63-a8c9-a5b946b04d86'}\n +  where {'a4677bde-fbab-4835-bbae-635af682dfb6', 'ad0c5f36-2557-4a63-a8c9-a5b946b04d86'} = ResearchTask(id='90c5c72d-e657-4b2f-b54d-e0a58cfec524', created_at=datetime.datetime(2025, 5, 15, 23, 54, 58, 347095), updated_at=datetime.datetime(2025, 5, 15, 23, 54, 58, 347128), title='Parent task', description='Task with subtasks', status='planned', priority='medium', due_date=None, completed_at=None, tags=set(), notes=[], parent_id=None, subtask_ids={'ad0c5f36-2557-4a63-a8c9-a5b946b04d86', 'a4677bde-fbab-4835-bbae-635af682dfb6'}, custom_metadata={}, estimated_hours=None, actual_hours=None, research_question_ids=set(), reference_ids=set(), dataset_ids=set(), environment_ids=set(), experiment_ids=set(), research_questions=[], references=[], datasets=[], environments=[], experiments=[]).subtask_ids"}, "traceback": [{"path": "../command_line_task_manager_researcher/tests/task_management/test_models.py", "lineno": 237, "message": "AssertionError"}], "longrepr": "self = <tests.researcher.task_management.test_models.TestResearchTask object at 0x7f4837023020>\n\n    def test_subtask_management(self):\n        # Test subtask management\n        task = ResearchTask(\n            title=\"Parent task\",\n            description=\"Task with subtasks\",\n        )\n    \n        subtask_id1 = uuid4()\n        subtask_id2 = uuid4()\n    \n        task.add_subtask(subtask_id1)\n        task.add_subtask(subtask_id2)\n    \n        assert len(task.subtask_ids) == 2\n>       assert subtask_id1 in task.subtask_ids\nE       AssertionError: assert UUID('ad0c5f36-2557-4a63-a8c9-a5b946b04d86') in {'a4677bde-fbab-4835-bbae-635af682dfb6', 'ad0c5f36-2557-4a63-a8c9-a5b946b04d86'}\nE        +  where {'a4677bde-fbab-4835-bbae-635af682dfb6', 'ad0c5f36-2557-4a63-a8c9-a5b946b04d86'} = ResearchTask(id='90c5c72d-e657-4b2f-b54d-e0a58cfec524', created_at=datetime.datetime(2025, 5, 15, 23, 54, 58, 347095), updated_at=datetime.datetime(2025, 5, 15, 23, 54, 58, 347128), title='Parent task', description='Task with subtasks', status='planned', priority='medium', due_date=None, completed_at=None, tags=set(), notes=[], parent_id=None, subtask_ids={'ad0c5f36-2557-4a63-a8c9-a5b946b04d86', 'a4677bde-fbab-4835-bbae-635af682dfb6'}, custom_metadata={}, estimated_hours=None, actual_hours=None, research_question_ids=set(), reference_ids=set(), dataset_ids=set(), environment_ids=set(), experiment_ids=set(), research_questions=[], references=[], datasets=[], environments=[], experiments=[]).subtask_ids\n\n../command_line_task_manager_researcher/tests/task_management/test_models.py:237: AssertionError"}, "teardown": {"duration": 0.00011596106924116611, "outcome": "passed"}}, {"nodeid": "tests/researcher/task_management/test_models.py::TestResearchTask::test_custom_metadata", "lineno": 245, "outcome": "passed", "keywords": ["test_custom_metadata", "TestResearchTask", "test_models.py", "task_management", "researcher", "tests", "unified", ""], "setup": {"duration": 0.00011082715354859829, "outcome": "passed"}, "call": {"duration": 0.00014944793656468391, "outcome": "passed"}, "teardown": {"duration": 8.685491047799587e-05, "outcome": "passed"}}], "warnings": [{"message": "Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/", "category": "PydanticDeprecatedSince20", "when": "collect", "filename": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/.venv/lib/python3.12/site-packages/pydantic/_internal/_config.py", "lineno": 323}, {"message": "`json_encoders` is deprecated. See https://docs.pydantic.dev/2.11/concepts/serialization/#custom-serializers for alternatives. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/", "category": "PydanticDeprecatedSince20", "when": "collect", "filename": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py", "lineno": 293}, {"message": "`json_encoders` is deprecated. See https://docs.pydantic.dev/2.11/concepts/serialization/#custom-serializers for alternatives. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/", "category": "PydanticDeprecatedSince20", "when": "collect", "filename": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py", "lineno": 293}, {"message": "`json_encoders` is deprecated. See https://docs.pydantic.dev/2.11/concepts/serialization/#custom-serializers for alternatives. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/", "category": "PydanticDeprecatedSince20", "when": "collect", "filename": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py", "lineno": 293}, {"message": "`json_encoders` is deprecated. See https://docs.pydantic.dev/2.11/concepts/serialization/#custom-serializers for alternatives. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/", "category": "PydanticDeprecatedSince20", "when": "collect", "filename": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py", "lineno": 293}, {"message": "`json_encoders` is deprecated. See https://docs.pydantic.dev/2.11/concepts/serialization/#custom-serializers for alternatives. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/", "category": "PydanticDeprecatedSince20", "when": "collect", "filename": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py", "lineno": 293}, {"message": "`json_encoders` is deprecated. See https://docs.pydantic.dev/2.11/concepts/serialization/#custom-serializers for alternatives. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/", "category": "PydanticDeprecatedSince20", "when": "collect", "filename": "/home/justinchiu_cohere_com/librarybench/projects/command_line_task_manager/unified/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py", "lineno": 293}]}