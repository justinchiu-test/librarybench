{"created": 1747281844.1572862, "duration": 0.7007677555084229, "exitcode": 1, "root": "/home/justinchiu_cohere_com/librarybench/projects/concurrent_task_scheduler/concurrent_task_scheduler_render_farm_manager", "environment": {}, "summary": {"failed": 13, "passed": 76, "total": 89, "collected": 89}, "collectors": [{"nodeid": "", "outcome": "passed", "result": [{"nodeid": ".", "type": "Dir"}]}, {"nodeid": "render_farm_manager/core", "outcome": "passed", "result": []}, {"nodeid": "render_farm_manager/energy_optimization", "outcome": "passed", "result": []}, {"nodeid": "render_farm_manager/node_specialization", "outcome": "passed", "result": []}, {"nodeid": "render_farm_manager/progressive_result", "outcome": "passed", "result": []}, {"nodeid": "render_farm_manager/resource_management", "outcome": "passed", "result": []}, {"nodeid": "render_farm_manager/scheduling", "outcome": "passed", "result": []}, {"nodeid": "render_farm_manager/utils", "outcome": "passed", "result": []}, {"nodeid": "render_farm_manager", "outcome": "passed", "result": [{"nodeid": "render_farm_manager/core", "type": "Package"}, {"nodeid": "render_farm_manager/energy_optimization", "type": "Package"}, {"nodeid": "render_farm_manager/node_specialization", "type": "Package"}, {"nodeid": "render_farm_manager/progressive_result", "type": "Package"}, {"nodeid": "render_farm_manager/resource_management", "type": "Package"}, {"nodeid": "render_farm_manager/scheduling", "type": "Package"}, {"nodeid": "render_farm_manager/utils", "type": "Package"}]}, {"nodeid": "render_farm_manager.egg-info", "outcome": "passed", "result": []}, {"nodeid": "tests/integration/test_audit_logging.py", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_audit_logging.py::test_audit_logging_completeness", "type": "Function", "lineno": 118}, {"nodeid": "tests/integration/test_audit_logging.py::test_audit_log_levels", "type": "Function", "lineno": 186}, {"nodeid": "tests/integration/test_audit_logging.py::test_performance_metrics_tracking", "type": "Function", "lineno": 245}]}, {"nodeid": "tests/integration/test_energy_modes.py", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_energy_modes.py::test_dynamic_energy_mode_switching", "type": "Function", "lineno": 197}, {"nodeid": "tests/integration/test_energy_modes.py::test_night_savings_energy_mode", "type": "Function", "lineno": 289}]}, {"nodeid": "tests/integration/test_energy_modes_fixed.py", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_energy_modes_fixed.py::test_dynamic_energy_mode_switching", "type": "Function", "lineno": 206}, {"nodeid": "tests/integration/test_energy_modes_fixed.py::test_night_savings_energy_mode", "type": "Function", "lineno": 296}]}, {"nodeid": "tests/integration/test_error_recovery.py", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_error_recovery.py::test_error_recovery_checkpoint_resume", "type": "Function", "lineno": 132}, {"nodeid": "tests/integration/test_error_recovery.py::test_multiple_failures_with_checkpoints", "type": "Function", "lineno": 205}, {"nodeid": "tests/integration/test_error_recovery.py::test_error_count_threshold", "type": "Function", "lineno": 267}]}, {"nodeid": "tests/integration/test_fault_tolerance.py", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_fault_tolerance.py::test_fault_tolerance_multiple_node_failures", "type": "Function", "lineno": 266}]}, {"nodeid": "tests/integration/test_fault_tolerance_fixed.py", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_fault_tolerance_fixed.py::test_fault_tolerance_multiple_node_failures", "type": "Function", "lineno": 258}]}, {"nodeid": "tests/integration/test_job_dependencies.py", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_job_dependencies.py::test_job_dependency_scheduling", "type": "Function", "lineno": 211}, {"nodeid": "tests/integration/test_job_dependencies.py::test_dependent_job_priority_inheritance", "type": "Function", "lineno": 302}, {"nodeid": "tests/integration/test_job_dependencies.py::test_circular_dependency_detection", "type": "Function", "lineno": 423}]}, {"nodeid": "tests/integration/test_render_farm_manager.py", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_render_farm_manager.py::test_farm_manager_initialization", "type": "Function", "lineno": 212}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_add_client", "type": "Function", "lineno": 220}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_add_node", "type": "Function", "lineno": 231}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_submit_job", "type": "Function", "lineno": 241}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_scheduling_cycle", "type": "Function", "lineno": 257}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_job_progress_update", "type": "Function", "lineno": 290}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_node_failure", "type": "Function", "lineno": 328}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_cancel_job", "type": "Function", "lineno": 369}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_client_resource_guarantees", "type": "Function", "lineno": 402}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_energy_optimization", "type": "Function", "lineno": 488}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_progressive_output_config", "type": "Function", "lineno": 518}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_full_end_to_end_workflow", "type": "Function", "lineno": 554}]}, {"nodeid": "tests/integration", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_audit_logging.py", "type": "Module"}, {"nodeid": "tests/integration/test_energy_modes.py", "type": "Module"}, {"nodeid": "tests/integration/test_energy_modes_fixed.py", "type": "Module"}, {"nodeid": "tests/integration/test_error_recovery.py", "type": "Module"}, {"nodeid": "tests/integration/test_fault_tolerance.py", "type": "Module"}, {"nodeid": "tests/integration/test_fault_tolerance_fixed.py", "type": "Module"}, {"nodeid": "tests/integration/test_job_dependencies.py", "type": "Module"}, {"nodeid": "tests/integration/test_render_farm_manager.py", "type": "Module"}]}, {"nodeid": "tests/performance/test_performance.py", "outcome": "passed", "result": [{"nodeid": "tests/performance/test_performance.py::test_scheduling_performance", "type": "Function", "lineno": 160}, {"nodeid": "tests/performance/test_performance.py::test_multiple_scheduling_cycles", "type": "Function", "lineno": 195}, {"nodeid": "tests/performance/test_performance.py::test_node_specialization_efficiency", "type": "Function", "lineno": 251}]}, {"nodeid": "tests/performance", "outcome": "passed", "result": [{"nodeid": "tests/performance/test_performance.py", "type": "Module"}]}, {"nodeid": "tests/unit/test_deadline_scheduler.py", "outcome": "passed", "result": [{"nodeid": "tests/unit/test_deadline_scheduler.py::test_scheduler_initialization", "type": "Function", "lineno": 184}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_update_priorities_deadline_approaching", "type": "Function", "lineno": 190}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_update_priorities_job_progress", "type": "Function", "lineno": 211}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_schedule_jobs_priority_order", "type": "Function", "lineno": 228}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_schedule_jobs_resource_requirements", "type": "Function", "lineno": 246}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_preemption", "type": "Function", "lineno": 258}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_preemption_disabled", "type": "Function", "lineno": 285}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_can_meet_deadline", "type": "Function", "lineno": 305}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_should_preempt", "type": "Function", "lineno": 337}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_schedule_with_dependencies", "type": "Function", "lineno": 360}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_rescheduling_failed_job", "type": "Function", "lineno": 425}]}, {"nodeid": "tests/unit/test_energy_optimizer.py", "outcome": "passed", "result": [{"nodeid": "tests/unit/test_energy_optimizer.py::test_energy_optimizer_initialization", "type": "Function", "lineno": 190}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_optimize_energy_usage", "type": "Function", "lineno": 199}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_energy_mode_affects_scheduling", "type": "Function", "lineno": 227}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_calculate_energy_cost", "type": "Function", "lineno": 252}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_time_of_day_energy_price", "type": "Function", "lineno": 282}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_set_energy_mode", "type": "Function", "lineno": 297}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_estimate_energy_savings", "type": "Function", "lineno": 313}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_energy_mode_update_based_on_time", "type": "Function", "lineno": 331}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_node_meets_requirements", "type": "Function", "lineno": 350}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_get_node_type", "type": "Function", "lineno": 368}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_high_priority_jobs_override_energy_considerations", "type": "Function", "lineno": 383}]}, {"nodeid": "tests/unit/test_node_specialization.py", "outcome": "passed", "result": [{"nodeid": "tests/unit/test_node_specialization.py::test_specialization_manager_initialization", "type": "Function", "lineno": 249}, {"nodeid": "tests/unit/test_node_specialization.py::test_match_job_to_node_gpu_job", "type": "Function", "lineno": 258}, {"nodeid": "tests/unit/test_node_specialization.py::test_match_job_to_node_cpu_job", "type": "Function", "lineno": 274}, {"nodeid": "tests/unit/test_node_specialization.py::test_match_job_to_node_memory_job", "type": "Function", "lineno": 290}, {"nodeid": "tests/unit/test_node_specialization.py::test_calculate_performance_score", "type": "Function", "lineno": 306}, {"nodeid": "tests/unit/test_node_specialization.py::test_update_performance_history", "type": "Function", "lineno": 327}, {"nodeid": "tests/unit/test_node_specialization.py::test_performance_history_influence", "type": "Function", "lineno": 361}, {"nodeid": "tests/unit/test_node_specialization.py::test_node_capability_matching", "type": "Function", "lineno": 376}, {"nodeid": "tests/unit/test_node_specialization.py::test_no_suitable_node", "type": "Function", "lineno": 395}, {"nodeid": "tests/unit/test_node_specialization.py::test_specialized_vs_general_nodes", "type": "Function", "lineno": 409}, {"nodeid": "tests/unit/test_node_specialization.py::test_analyze_node_efficiency", "type": "Function", "lineno": 444}]}, {"nodeid": "tests/unit/test_progressive_renderer.py", "outcome": "passed", "result": [{"nodeid": "tests/unit/test_progressive_renderer.py::test_progressive_renderer_initialization", "type": "Function", "lineno": 167}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_schedule_progressive_output_long_job", "type": "Function", "lineno": 175}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_schedule_progressive_output_short_job", "type": "Function", "lineno": 192}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_schedule_progressive_output_disabled_config", "type": "Function", "lineno": 207}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_schedule_progressive_output_unsupported_job", "type": "Function", "lineno": 226}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_generate_progressive_output", "type": "Function", "lineno": 237}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_generate_progressive_output_unsupported_job", "type": "Function", "lineno": 258}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_estimate_overhead", "type": "Function", "lineno": 267}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_process_pending_outputs", "type": "Function", "lineno": 292}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_get_latest_progressive_output", "type": "Function", "lineno": 338}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_quality_overhead_factors", "type": "Function", "lineno": 355}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_max_overhead_limit", "type": "Function", "lineno": 362}]}, {"nodeid": "tests/unit/test_resource_borrowing.py", "outcome": "passed", "result": [{"nodeid": "tests/unit/test_resource_borrowing.py::test_client_resource_borrowing", "type": "Function", "lineno": 174}, {"nodeid": "tests/unit/test_resource_borrowing.py::test_borrowing_limit_variations", "type": "Function", "lineno": 308}]}, {"nodeid": "tests/unit/test_resource_borrowing_fixed.py", "outcome": "passed", "result": [{"nodeid": "tests/unit/test_resource_borrowing_fixed.py::test_client_resource_borrowing", "type": "Function", "lineno": 175}, {"nodeid": "tests/unit/test_resource_borrowing_fixed.py::test_borrowing_limit_variations", "type": "Function", "lineno": 313}]}, {"nodeid": "tests/unit/test_resource_partitioner.py", "outcome": "passed", "result": [{"nodeid": "tests/unit/test_resource_partitioner.py::test_partitioner_initialization", "type": "Function", "lineno": 171}, {"nodeid": "tests/unit/test_resource_partitioner.py::test_allocate_resources_guaranteed_minimums", "type": "Function", "lineno": 177}, {"nodeid": "tests/unit/test_resource_partitioner.py::test_allocate_resources_borrowing", "type": "Function", "lineno": 197}, {"nodeid": "tests/unit/test_resource_partitioner.py::test_can_borrow_resources", "type": "Function", "lineno": 218}, {"nodeid": "tests/unit/test_resource_partitioner.py::test_calculate_resource_usage", "type": "Function", "lineno": 249}, {"nodeid": "tests/unit/test_resource_partitioner.py::test_allocate_resources_with_offline_nodes", "type": "Function", "lineno": 273}, {"nodeid": "tests/unit/test_resource_partitioner.py::test_resource_allocation_scaling", "type": "Function", "lineno": 295}, {"nodeid": "tests/unit/test_resource_partitioner.py::test_resource_allocation_special_hardware", "type": "Function", "lineno": 313}, {"nodeid": "tests/unit/test_resource_partitioner.py::test_allocate_resources_with_no_clients", "type": "Function", "lineno": 334}, {"nodeid": "tests/unit/test_resource_partitioner.py::test_allocate_resources_with_no_nodes", "type": "Function", "lineno": 342}]}, {"nodeid": "tests/unit", "outcome": "passed", "result": [{"nodeid": "tests/unit/test_deadline_scheduler.py", "type": "Module"}, {"nodeid": "tests/unit/test_energy_optimizer.py", "type": "Module"}, {"nodeid": "tests/unit/test_node_specialization.py", "type": "Module"}, {"nodeid": "tests/unit/test_progressive_renderer.py", "type": "Module"}, {"nodeid": "tests/unit/test_resource_borrowing.py", "type": "Module"}, {"nodeid": "tests/unit/test_resource_borrowing_fixed.py", "type": "Module"}, {"nodeid": "tests/unit/test_resource_partitioner.py", "type": "Module"}]}, {"nodeid": "tests", "outcome": "passed", "result": [{"nodeid": "tests/integration", "type": "Package"}, {"nodeid": "tests/performance", "type": "Package"}, {"nodeid": "tests/unit", "type": "Package"}]}, {"nodeid": ".", "outcome": "passed", "result": [{"nodeid": "render_farm_manager", "type": "Package"}, {"nodeid": "render_farm_manager.egg-info", "type": "Dir"}, {"nodeid": "tests", "type": "Package"}]}], "tests": [{"nodeid": "tests/integration/test_audit_logging.py::test_audit_logging_completeness", "lineno": 118, "outcome": "failed", "keywords": ["test_audit_logging_completeness", "test_audit_logging.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.004999564960598946, "outcome": "passed"}, "call": {"duration": 0.00019775994587689638, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/concurrent_task_scheduler/concurrent_task_scheduler_render_farm_manager/tests/integration/test_audit_logging.py", "lineno": 123, "message": "AttributeError: 'RenderFarmManager' object has no attribute 'update_client_tier'"}, "traceback": [{"path": "tests/integration/test_audit_logging.py", "lineno": 123, "message": "AttributeError"}], "longrepr": "farm_manager = <render_farm_manager.core.manager.RenderFarmManager object at 0x7f3b7a916680>\naudit_logger = <MagicMock id='139893438713136'>\nclient = RenderClient(client_id='client1', name='Test Client', service_tier=<ServiceTier.PREMIUM: 'premium'>, guaranteed_resources=0, max_resources=100)\nrender_node = RenderNode(id='node1', name='Test Node', status='online', capabilities=NodeCapabilities(cpu_cores=16, memory_gb=64, gp...ositing']), power_efficiency_rating=75.0, current_job_id=None, performance_history={}, last_error=None, uptime_hours=0)\nrender_job = RenderJob(id='job1', name='Test Job', client_id='client1', status=<RenderJobStatus.PENDING: 'pending'>, job_type='anim...False, supports_checkpoint=False, last_checkpoint_time=None, last_progressive_output_time=None, energy_intensive=False)\n\n    def test_audit_logging_completeness(farm_manager, audit_logger, client, render_node, render_job):\n        \"\"\"Test that all important operations are properly logged to the audit logger.\"\"\"\n        # Client operations\n        farm_manager.add_client(client)\n>       farm_manager.update_client_tier(client.client_id, ServiceTier.STANDARD)\nE       AttributeError: 'RenderFarmManager' object has no attribute 'update_client_tier'\n\ntests/integration/test_audit_logging.py:123: AttributeError"}, "teardown": {"duration": 0.00023309397511184216, "outcome": "passed"}}, {"nodeid": "tests/integration/test_audit_logging.py::test_audit_log_levels", "lineno": 186, "outcome": "failed", "keywords": ["test_audit_log_levels", "test_audit_logging.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.004279239918105304, "outcome": "passed"}, "call": {"duration": 0.0024689199635758996, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/concurrent_task_scheduler/concurrent_task_scheduler_render_farm_manager/tests/integration/test_audit_logging.py", "lineno": 237, "message": "AssertionError: Expected WARNING level audit log entries\nassert 0 > 0\n +  where 0 = len([])"}, "traceback": [{"path": "tests/integration/test_audit_logging.py", "lineno": 237, "message": "AssertionError"}], "longrepr": "farm_manager = <render_farm_manager.core.manager.RenderFarmManager object at 0x7f3b7a9a9090>\naudit_logger = <MagicMock id='139893436292336'>\nclient = RenderClient(client_id='client1', name='Test Client', service_tier=<ServiceTier.PREMIUM: 'premium'>, guaranteed_resources=0, max_resources=100)\nrender_node = RenderNode(id='node1', name='Test Node', status='error', capabilities=NodeCapabilities(cpu_cores=16, memory_gb=64, gpu...cy_rating=75.0, current_job_id=None, performance_history={}, last_error='Hardware failure during test', uptime_hours=0)\nrender_job = RenderJob(id='job1', name='Test Job', client_id='client1', status=<RenderJobStatus.PENDING: 'pending'>, job_type='anim...False, supports_checkpoint=False, last_checkpoint_time=None, last_progressive_output_time=None, energy_intensive=False)\n\n    def test_audit_log_levels(farm_manager, audit_logger, client, render_node, render_job):\n        \"\"\"Test that audit logging respects log level settings.\"\"\"\n        # Setup: configure audit logger with log level filters\n        # In a real implementation, we would set log level on the audit logger\n        # For this test, we'll assume the behavior and verify the mock calls\n    \n        # Add client, node, and job\n        farm_manager.add_client(client)\n        farm_manager.add_node(render_node)\n        farm_manager.submit_job(render_job)\n    \n        # Run operations at different severity levels\n    \n        # INFO level - normal operations\n        farm_manager.run_scheduling_cycle()\n        farm_manager.update_job_progress(render_job.id, 50.0)\n    \n        # WARNING level - anomalies\n        farm_manager.handle_node_failure(render_node.id, error=\"Hardware failure during test\")\n        # Since we're mocking, manually call the methods we expect the manager to call\n        farm_manager.audit_logger.log_node_failure(node_id=render_node.id)\n        farm_manager.performance_monitor.update_node_failure_count()\n    \n        # ERROR level - critical issues\n        # Simulate an error condition by calling audit_logger directly\n        # (since RenderFarmManager might not have explicit error scenarios)\n        farm_manager.audit_logger.log_error(\n            message=\"Critical error detected in node communication\",\n            source=\"NodeCommunicationService\",\n            severity=LogLevel.ERROR\n        )\n    \n        # Verify calls were made with appropriate log levels\n        info_calls = [\n            call for call in audit_logger.log_event.call_args_list\n            if call[1].get('log_level', LogLevel.INFO) == LogLevel.INFO\n        ]\n    \n        warning_calls = [\n            call for call in audit_logger.log_event.call_args_list\n            if call[1].get('log_level', LogLevel.INFO) == LogLevel.WARNING\n        ]\n    \n        error_calls = [\n            call for call in audit_logger.log_event.call_args_list\n            if call[1].get('log_level', LogLevel.INFO) == LogLevel.ERROR\n        ]\n    \n        # There should be calls at all log levels\n        assert len(info_calls) > 0, \"Expected INFO level audit log entries\"\n>       assert len(warning_calls) > 0, \"Expected WARNING level audit log entries\"\nE       AssertionError: Expected WARNING level audit log entries\nE       assert 0 > 0\nE        +  where 0 = len([])\n\ntests/integration/test_audit_logging.py:237: AssertionError"}, "teardown": {"duration": 0.00022086792159825563, "outcome": "passed"}}, {"nodeid": "tests/integration/test_audit_logging.py::test_performance_metrics_tracking", "lineno": 245, "outcome": "failed", "keywords": ["test_performance_metrics_tracking", "test_audit_logging.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.004199092974886298, "outcome": "passed"}, "call": {"duration": 0.0016928859986364841, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/concurrent_task_scheduler/concurrent_task_scheduler_render_farm_manager/tests/integration/test_audit_logging.py", "lineno": 259, "message": "AttributeError: 'RenderFarmManager' object has no attribute 'complete_job'"}, "traceback": [{"path": "tests/integration/test_audit_logging.py", "lineno": 259, "message": "AttributeError"}], "longrepr": "farm_manager = <render_farm_manager.core.manager.RenderFarmManager object at 0x7f3b7a82e0e0>\nperformance_monitor = <MagicMock id='139893435195664'>\nclient = RenderClient(client_id='client1', name='Test Client', service_tier=<ServiceTier.PREMIUM: 'premium'>, guaranteed_resources=0, max_resources=100)\nrender_node = RenderNode(id='node1', name='Test Node', status='online', capabilities=NodeCapabilities(cpu_cores=16, memory_gb=64, gp...ositing']), power_efficiency_rating=75.0, current_job_id=None, performance_history={}, last_error=None, uptime_hours=0)\nrender_job = RenderJob(id='job1', name='Test Job', client_id='client1', status=<RenderJobStatus.COMPLETED: 'completed'>, job_type='...False, supports_checkpoint=False, last_checkpoint_time=None, last_progressive_output_time=None, energy_intensive=False)\n\n    def test_performance_metrics_tracking(farm_manager, performance_monitor, client, render_node, render_job):\n        \"\"\"Test that performance metrics are properly tracked alongside audit logging.\"\"\"\n        # Setup\n        farm_manager.add_client(client)\n        farm_manager.add_node(render_node)\n        farm_manager.submit_job(render_job)\n    \n        # Run scheduling operations\n        farm_manager.run_scheduling_cycle()\n    \n        # Update job progress and complete it\n        farm_manager.update_job_progress(render_job.id, 50.0)\n        farm_manager.update_job_progress(render_job.id, 100.0)\n>       farm_manager.complete_job(render_job.id)\nE       AttributeError: 'RenderFarmManager' object has no attribute 'complete_job'\n\ntests/integration/test_audit_logging.py:259: AttributeError"}, "teardown": {"duration": 0.00023012596648186445, "outcome": "passed"}}, {"nodeid": "tests/integration/test_energy_modes.py::test_dynamic_energy_mode_switching", "lineno": 197, "outcome": "failed", "keywords": ["test_dynamic_energy_mode_switching", "test_energy_modes.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0038279190193861723, "outcome": "passed"}, "call": {"duration": 0.0028267219895496964, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/concurrent_task_scheduler/concurrent_task_scheduler_render_farm_manager/tests/integration/test_energy_modes.py", "lineno": 279, "message": "AssertionError: No jobs assigned to high performance nodes in PERFORMANCE mode\nassert 0 >= 1"}, "traceback": [{"path": "tests/integration/test_energy_modes.py", "lineno": 279, "message": "AssertionError"}], "longrepr": "farm_manager = <render_farm_manager.core.manager.RenderFarmManager object at 0x7f3b7a88fc10>\nclient = RenderClient(client_id='client1', name='Test Client', service_tier=<ServiceTier.PREMIUM: 'premium'>, guaranteed_resources=0, max_resources=100)\nrender_nodes = [RenderNode(id='eff1', name='High Efficiency Node', status='online', capabilities=NodeCapabilities(cpu_cores=16, memor...ndering']), power_efficiency_rating=2.5, current_job_id=None, performance_history={}, last_error=None, uptime_hours=0)]\nrender_jobs = [RenderJob(id='job1', name='High Priority Job', client_id='client1', status=<RenderJobStatus.PENDING: 'pending'>, job_...alse, supports_checkpoint=False, last_checkpoint_time=None, last_progressive_output_time=None, energy_intensive=False)]\n\n    def test_dynamic_energy_mode_switching(farm_manager, client, render_nodes, render_jobs):\n        \"\"\"Test that changing energy modes affects job scheduling and node selection.\"\"\"\n        # Setup: Add client, nodes and jobs\n        farm_manager.add_client(client)\n    \n        for node in render_nodes:\n            farm_manager.add_node(node)\n    \n        for job in render_jobs:\n            farm_manager.submit_job(job)\n    \n        # Start in BALANCED mode (default)\n        farm_manager.set_energy_mode(EnergyMode.BALANCED)\n    \n        # Run first scheduling cycle\n        farm_manager.run_scheduling_cycle()\n    \n        # Store the node assignments in balanced mode\n        balanced_assignments = {}\n        for job_id, job in farm_manager.jobs.items():\n            if job.status == RenderJobStatus.RUNNING:\n                balanced_assignments[job_id] = job.assigned_node_id\n    \n        # Cancel all running jobs to reset\n        for job_id in list(farm_manager.jobs.keys()):\n            if farm_manager.jobs[job_id].status == RenderJobStatus.RUNNING:\n                farm_manager.cancel_job(job_id)\n                # Resubmit the job to reset its state\n                job = render_jobs[int(job_id[-1]) - 1]  # Get the original job definition\n                farm_manager.submit_job(job)\n    \n        # Switch to EFFICIENCY mode\n        farm_manager.set_energy_mode(EnergyMode.EFFICIENCY)\n    \n        # Run scheduling cycle again\n        farm_manager.run_scheduling_cycle()\n    \n        # Store the node assignments in efficiency mode\n        efficiency_assignments = {}\n        for job_id, job in farm_manager.jobs.items():\n            if job.status == RenderJobStatus.RUNNING:\n                efficiency_assignments[job_id] = job.assigned_node_id\n    \n        # Check that job assignments changed due to energy mode switch\n        # In efficiency mode, more efficient nodes should be preferred\n        for job_id, node_id in efficiency_assignments.items():\n            # Get the efficiency rating of the node\n            efficiency_rating = farm_manager.nodes[node_id].power_efficiency_rating\n    \n            # Most jobs should be assigned to high efficiency nodes\n            assert efficiency_rating > 5.0, f\"Job {job_id} was assigned to a low efficiency node in EFFICIENCY mode\"\n    \n        # Cancel all running jobs to reset again\n        for job_id in list(farm_manager.jobs.keys()):\n            if farm_manager.jobs[job_id].status == RenderJobStatus.RUNNING:\n                farm_manager.cancel_job(job_id)\n                # Resubmit the job to reset its state\n                job = render_jobs[int(job_id[-1]) - 1]  # Get the original job definition\n                farm_manager.submit_job(job)\n    \n        # Switch to PERFORMANCE mode\n        farm_manager.set_energy_mode(EnergyMode.PERFORMANCE)\n    \n        # Run scheduling cycle again\n        farm_manager.run_scheduling_cycle()\n    \n        # Store the node assignments in performance mode\n        performance_assignments = {}\n        for job_id, job in farm_manager.jobs.items():\n            if job.status == RenderJobStatus.RUNNING:\n                performance_assignments[job_id] = job.assigned_node_id\n    \n        # Check that in performance mode, more powerful nodes are preferred\n        # (which tend to be less efficient in our test setup)\n        highest_performance_nodes = [\"eff3\", \"eff4\"]  # Our less efficient but more powerful nodes\n        high_perf_assignment_count = sum(\n            1 for node_id in performance_assignments.values()\n            if node_id in highest_performance_nodes\n        )\n    \n        # More jobs should use high performance nodes in PERFORMANCE mode\n>       assert high_perf_assignment_count >= 1, \"No jobs assigned to high performance nodes in PERFORMANCE mode\"\nE       AssertionError: No jobs assigned to high performance nodes in PERFORMANCE mode\nE       assert 0 >= 1\n\ntests/integration/test_energy_modes.py:279: AssertionError"}, "teardown": {"duration": 0.00021869991905987263, "outcome": "passed"}}, {"nodeid": "tests/integration/test_energy_modes.py::test_night_savings_energy_mode", "lineno": 289, "outcome": "failed", "keywords": ["test_night_savings_energy_mode", "test_energy_modes.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0037719820393249393, "outcome": "passed"}, "call": {"duration": 0.002272761077620089, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/concurrent_task_scheduler/concurrent_task_scheduler_render_farm_manager/tests/integration/test_energy_modes.py", "lineno": 338, "message": "AssertionError: Standard job should run during daytime in NIGHT_SAVINGS mode\nassert <RenderJobSta...NG: 'pending'> == <RenderJobSta...NG: 'running'>\n  \n  - running\n  + pending"}, "traceback": [{"path": "tests/integration/test_energy_modes.py", "lineno": 338, "message": "AssertionError"}], "longrepr": "farm_manager = <render_farm_manager.core.manager.RenderFarmManager object at 0x7f3b7a715960>\nclient = RenderClient(client_id='client1', name='Test Client', service_tier=<ServiceTier.PREMIUM: 'premium'>, guaranteed_resources=0, max_resources=100)\nrender_nodes = [RenderNode(id='eff1', name='High Efficiency Node', status='online', capabilities=NodeCapabilities(cpu_cores=16, memor...ndering']), power_efficiency_rating=2.5, current_job_id=None, performance_history={}, last_error=None, uptime_hours=0)]\nrender_jobs = [RenderJob(id='job1', name='High Priority Job', client_id='client1', status=<RenderJobStatus.PENDING: 'pending'>, job_...alse, supports_checkpoint=False, last_checkpoint_time=None, last_progressive_output_time=None, energy_intensive=False)]\n\n    def test_night_savings_energy_mode(farm_manager, client, render_nodes, render_jobs):\n        \"\"\"Test that NIGHT_SAVINGS mode correctly schedules energy-intensive jobs for night execution.\"\"\"\n        # Setup: Add client, nodes and jobs\n        farm_manager.add_client(client)\n    \n        for node in render_nodes:\n            farm_manager.add_node(node)\n    \n        # Set jobs with different energy profiles\n        energy_intensive_job = render_jobs[2]  # The job with highest CPU/GPU requirements\n        # Add energy_intensive attribute if it doesn't exist\n        if not hasattr(energy_intensive_job, 'energy_intensive'):\n            # We'll just use a high scene_complexity as a proxy for energy intensity\n            energy_intensive_job = RenderJob(\n                **energy_intensive_job.model_dump(),\n                scene_complexity=10  # Maximum complexity\n            )\n    \n        standard_job = render_jobs[0]\n        # Add energy_intensive attribute if it doesn't exist\n        if not hasattr(standard_job, 'energy_intensive'):\n            # We'll just use a low scene_complexity as a proxy for lower energy intensity\n            standard_job = RenderJob(\n                **standard_job.model_dump(),\n                scene_complexity=3  # Lower complexity\n            )\n    \n        farm_manager.submit_job(energy_intensive_job)\n        farm_manager.submit_job(standard_job)\n    \n        # Switch to NIGHT_SAVINGS mode\n        farm_manager.set_energy_mode(EnergyMode.NIGHT_SAVINGS)\n    \n        # Set current time to daytime (e.g., 2pm)\n        current_time = datetime.now().replace(hour=14, minute=0, second=0, microsecond=0)\n    \n        # Override the farm manager's datetime.now function to return our fixed time\n        # In a real test, we might use a patch for datetime, but for this example\n        # we're simulating the behavior\n    \n        # Run scheduling cycle\n        farm_manager.run_scheduling_cycle()\n    \n        # Check that energy intensive job is not running (should be scheduled for night)\n        assert farm_manager.jobs[energy_intensive_job.id].status != RenderJobStatus.RUNNING, \\\n            \"Energy intensive job should not run during daytime in NIGHT_SAVINGS mode\"\n    \n        # Check that standard job is running\n>       assert farm_manager.jobs[standard_job.id].status == RenderJobStatus.RUNNING, \\\n            \"Standard job should run during daytime in NIGHT_SAVINGS mode\"\nE       AssertionError: Standard job should run during daytime in NIGHT_SAVINGS mode\nE       assert <RenderJobSta...NG: 'pending'> == <RenderJobSta...NG: 'running'>\nE         \nE         - running\nE         + pending\n\ntests/integration/test_energy_modes.py:338: AssertionError"}, "teardown": {"duration": 0.00022493291180580854, "outcome": "passed"}}, {"nodeid": "tests/integration/test_energy_modes_fixed.py::test_dynamic_energy_mode_switching", "lineno": 206, "outcome": "failed", "keywords": ["test_dynamic_energy_mode_switching", "test_energy_modes_fixed.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.001759951002895832, "outcome": "passed"}, "call": {"duration": 0.0032474519684910774, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/concurrent_task_scheduler/concurrent_task_scheduler_render_farm_manager/tests/integration/test_energy_modes_fixed.py", "lineno": 257, "message": "AssertionError: Job job3 was assigned to a low efficiency node in EFFICIENCY mode\nassert 4.0 > 5.0"}, "traceback": [{"path": "tests/integration/test_energy_modes_fixed.py", "lineno": 257, "message": "AssertionError"}], "longrepr": "farm_manager = <render_farm_manager.core.manager.RenderFarmManager object at 0x7f3b7a785ff0>\nclient = Client(id='client1', name='Test Client', sla_tier='premium', guaranteed_resources=50, max_resources=80)\nrender_nodes = [RenderNode(id='eff1', name='High Efficiency Node', status='online', capabilities=NodeCapabilities(cpu_cores=16, memor...ce']), power_efficiency_rating=2.5, current_job_id=None, performance_history={}, last_error=None, uptime_hours=1000.0)]\nrender_jobs = [RenderJob(id='job1', name='High Priority Job', client_id='client1', status=<RenderJobStatus.CANCELLED: 'cancelled'>, ...alse, supports_checkpoint=False, last_checkpoint_time=None, last_progressive_output_time=None, energy_intensive=False)]\n\n    def test_dynamic_energy_mode_switching(farm_manager, client, render_nodes, render_jobs):\n        \"\"\"Test that changing energy modes affects job scheduling and node selection.\"\"\"\n        # Setup: Add client, nodes and jobs\n        farm_manager.add_client(client)\n    \n        for node in render_nodes:\n            farm_manager.add_node(node)\n    \n        for job in render_jobs:\n            farm_manager.submit_job(job)\n    \n        # Start in BALANCED mode (default)\n        farm_manager.set_energy_mode(EnergyMode.BALANCED)\n    \n        # Run first scheduling cycle\n        farm_manager.run_scheduling_cycle()\n    \n        # Store the node assignments in balanced mode\n        balanced_assignments = {}\n        for job_id, job in farm_manager.jobs.items():\n            if job.status == RenderJobStatus.RUNNING:\n                balanced_assignments[job_id] = job.assigned_node_id\n    \n        # Cancel all running jobs to reset\n        for job_id in list(farm_manager.jobs.keys()):\n            if farm_manager.jobs[job_id].status == RenderJobStatus.RUNNING:\n                farm_manager.cancel_job(job_id)\n                # Resubmit the job to reset its state\n                job = render_jobs[int(job_id[-1]) - 1]  # Get the original job definition\n                farm_manager.submit_job(job)\n    \n        # Switch to EFFICIENCY mode\n        farm_manager.set_energy_mode(EnergyMode.EFFICIENCY)\n    \n        # Run scheduling cycle again\n        farm_manager.run_scheduling_cycle()\n    \n        # Store the node assignments in efficiency mode\n        efficiency_assignments = {}\n        for job_id, job in farm_manager.jobs.items():\n            if job.status == RenderJobStatus.RUNNING:\n                efficiency_assignments[job_id] = job.assigned_node_id\n    \n        # Check that job assignments changed due to energy mode switch\n        # In efficiency mode, more efficient nodes should be preferred\n        for job_id, node_id in efficiency_assignments.items():\n            # Get the efficiency rating of the node\n            efficiency_rating = farm_manager.nodes[node_id].power_efficiency_rating\n    \n            # Most jobs should be assigned to high efficiency nodes\n>           assert efficiency_rating > 5.0, f\"Job {job_id} was assigned to a low efficiency node in EFFICIENCY mode\"\nE           AssertionError: Job job3 was assigned to a low efficiency node in EFFICIENCY mode\nE           assert 4.0 > 5.0\n\ntests/integration/test_energy_modes_fixed.py:257: AssertionError"}, "teardown": {"duration": 0.0002198109868913889, "outcome": "passed"}}, {"nodeid": "tests/integration/test_energy_modes_fixed.py::test_night_savings_energy_mode", "lineno": 296, "outcome": "failed", "keywords": ["test_night_savings_energy_mode", "test_energy_modes_fixed.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0016649989411234856, "outcome": "passed"}, "call": {"duration": 0.0022474039578810334, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/concurrent_task_scheduler/concurrent_task_scheduler_render_farm_manager/tests/integration/test_energy_modes_fixed.py", "lineno": 329, "message": "AssertionError: Energy intensive job should not run during daytime in NIGHT_SAVINGS mode\nassert <RenderJobStatus.RUNNING: 'running'> != <RenderJobStatus.RUNNING: 'running'>\n +  where <RenderJobStatus.RUNNING: 'running'> = RenderJob(id='job3', name='Low Priority Job', client_id='client1', status=<RenderJobStatus.RUNNING: 'running'>, job_ty...=False, supports_checkpoint=False, last_checkpoint_time=None, last_progressive_output_time=None, energy_intensive=True).status\n +  and   <RenderJobStatus.RUNNING: 'running'> = RenderJobStatus.RUNNING"}, "traceback": [{"path": "tests/integration/test_energy_modes_fixed.py", "lineno": 329, "message": "AssertionError"}], "longrepr": "farm_manager = <render_farm_manager.core.manager.RenderFarmManager object at 0x7f3b7a7622c0>\nclient = Client(id='client1', name='Test Client', sla_tier='premium', guaranteed_resources=50, max_resources=80)\nrender_nodes = [RenderNode(id='eff1', name='High Efficiency Node', status='online', capabilities=NodeCapabilities(cpu_cores=16, memor...']), power_efficiency_rating=2.5, current_job_id='job3', performance_history={}, last_error=None, uptime_hours=1000.0)]\nrender_jobs = [RenderJob(id='job1', name='High Priority Job', client_id='client1', status=<RenderJobStatus.RUNNING: 'running'>, job_...False, supports_checkpoint=False, last_checkpoint_time=None, last_progressive_output_time=None, energy_intensive=True)]\n\n    def test_night_savings_energy_mode(farm_manager, client, render_nodes, render_jobs):\n        \"\"\"Test that NIGHT_SAVINGS mode correctly schedules energy-intensive jobs for night execution.\"\"\"\n        # Setup: Add client, nodes and jobs\n        farm_manager.add_client(client)\n    \n        for node in render_nodes:\n            farm_manager.add_node(node)\n    \n        # Set jobs with different energy profiles\n        energy_intensive_job = render_jobs[2]  # The job with highest CPU/GPU requirements\n        energy_intensive_job.energy_intensive = True\n    \n        standard_job = render_jobs[0]\n        standard_job.energy_intensive = False\n    \n        farm_manager.submit_job(energy_intensive_job)\n        farm_manager.submit_job(standard_job)\n    \n        # Switch to NIGHT_SAVINGS mode\n        farm_manager.set_energy_mode(EnergyMode.NIGHT_SAVINGS)\n    \n        # Set current time to daytime (e.g., 2pm)\n        current_time = datetime.now().replace(hour=14, minute=0, second=0, microsecond=0)\n    \n        # Override the farm manager's datetime.now function to return our fixed time\n        # In a real test, we might use a patch for datetime, but for this example\n        # we're simulating the behavior\n    \n        # Run scheduling cycle\n        farm_manager.run_scheduling_cycle()\n    \n        # Check that energy intensive job is not running (should be scheduled for night)\n>       assert farm_manager.jobs[energy_intensive_job.id].status != RenderJobStatus.RUNNING, \\\n            \"Energy intensive job should not run during daytime in NIGHT_SAVINGS mode\"\nE       AssertionError: Energy intensive job should not run during daytime in NIGHT_SAVINGS mode\nE       assert <RenderJobStatus.RUNNING: 'running'> != <RenderJobStatus.RUNNING: 'running'>\nE        +  where <RenderJobStatus.RUNNING: 'running'> = RenderJob(id='job3', name='Low Priority Job', client_id='client1', status=<RenderJobStatus.RUNNING: 'running'>, job_ty...=False, supports_checkpoint=False, last_checkpoint_time=None, last_progressive_output_time=None, energy_intensive=True).status\nE        +  and   <RenderJobStatus.RUNNING: 'running'> = RenderJobStatus.RUNNING\n\ntests/integration/test_energy_modes_fixed.py:329: AssertionError"}, "teardown": {"duration": 0.00021979899611324072, "outcome": "passed"}}, {"nodeid": "tests/integration/test_error_recovery.py::test_error_recovery_checkpoint_resume", "lineno": 132, "outcome": "failed", "keywords": ["test_error_recovery_checkpoint_resume", "test_error_recovery.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.003949453006498516, "outcome": "passed"}, "call": {"duration": 0.0020303240744397044, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/concurrent_task_scheduler/concurrent_task_scheduler_render_farm_manager/tests/integration/test_error_recovery.py", "lineno": 148, "message": "AssertionError: assert <RenderJobSta...NG: 'pending'> == <RenderJobSta...NG: 'running'>\n  \n  - running\n  + pending"}, "traceback": [{"path": "tests/integration/test_error_recovery.py", "lineno": 148, "message": "AssertionError"}], "longrepr": "farm_manager = <render_farm_manager.core.manager.RenderFarmManager object at 0x7f3b7a5faef0>\nclient = RenderClient(client_id='client1', name='Test Client', service_tier=<ServiceTier.PREMIUM: 'premium'>, guaranteed_resources=0, max_resources=100)\nrender_nodes = [RenderNode(id='gpu1', name='GPU Node 1', status='online', capabilities=NodeCapabilities(cpu_cores=16, memory_gb=64, g...dering']), power_efficiency_rating=72.0, current_job_id=None, performance_history={}, last_error=None, uptime_hours=0)]\ncheckpointable_job = RenderJob(id='job1', name='Test Checkpoint Job', client_id='client1', status=<RenderJobStatus.PENDING: 'pending'>, job...=False, supports_checkpoint=True, last_checkpoint_time=None, last_progressive_output_time=None, energy_intensive=False)\n\n    def test_error_recovery_checkpoint_resume(farm_manager, client, render_nodes, checkpointable_job):\n        \"\"\"Test that jobs can properly recover from node failures using checkpoints.\"\"\"\n        # Setup: Add client, nodes and job\n        farm_manager.add_client(client)\n    \n        for node in render_nodes:\n            farm_manager.add_node(node)\n    \n        farm_manager.submit_job(checkpointable_job)\n    \n        # Run first scheduling cycle - job should be assigned to a node\n        farm_manager.run_scheduling_cycle()\n    \n        # Verify job is now running\n        job = farm_manager.jobs[checkpointable_job.id]\n>       assert job.status == RenderJobStatus.RUNNING\nE       AssertionError: assert <RenderJobSta...NG: 'pending'> == <RenderJobSta...NG: 'running'>\nE         \nE         - running\nE         + pending\n\ntests/integration/test_error_recovery.py:148: AssertionError"}, "teardown": {"duration": 0.00022012495901435614, "outcome": "passed"}}, {"nodeid": "tests/integration/test_error_recovery.py::test_multiple_failures_with_checkpoints", "lineno": 205, "outcome": "failed", "keywords": ["test_multiple_failures_with_checkpoints", "test_error_recovery.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0039175390265882015, "outcome": "passed"}, "call": {"duration": 0.002053466043435037, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/concurrent_task_scheduler/concurrent_task_scheduler_render_farm_manager/tests/integration/test_error_recovery.py", "lineno": 217, "message": "AssertionError: assert <RenderJobSta...NG: 'pending'> == <RenderJobSta...NG: 'running'>\n  \n  - running\n  + pending"}, "traceback": [{"path": "tests/integration/test_error_recovery.py", "lineno": 217, "message": "AssertionError"}], "longrepr": "farm_manager = <render_farm_manager.core.manager.RenderFarmManager object at 0x7f3b7a66c4f0>\nclient = RenderClient(client_id='client1', name='Test Client', service_tier=<ServiceTier.PREMIUM: 'premium'>, guaranteed_resources=0, max_resources=100)\nrender_nodes = [RenderNode(id='gpu1', name='GPU Node 1', status='online', capabilities=NodeCapabilities(cpu_cores=16, memory_gb=64, g...dering']), power_efficiency_rating=72.0, current_job_id=None, performance_history={}, last_error=None, uptime_hours=0)]\ncheckpointable_job = RenderJob(id='job1', name='Test Checkpoint Job', client_id='client1', status=<RenderJobStatus.PENDING: 'pending'>, job...=False, supports_checkpoint=True, last_checkpoint_time=None, last_progressive_output_time=None, energy_intensive=False)\n\n    def test_multiple_failures_with_checkpoints(farm_manager, client, render_nodes, checkpointable_job):\n        \"\"\"Test that job can recover from multiple failures with increasing progress.\"\"\"\n        # Setup\n        farm_manager.add_client(client)\n        for node in render_nodes:\n            farm_manager.add_node(node)\n        farm_manager.submit_job(checkpointable_job)\n    \n        # First cycle - initial job assignment\n        farm_manager.run_scheduling_cycle()\n        job = farm_manager.jobs[checkpointable_job.id]\n>       assert job.status == RenderJobStatus.RUNNING\nE       AssertionError: assert <RenderJobSta...NG: 'pending'> == <RenderJobSta...NG: 'running'>\nE         \nE         - running\nE         + pending\n\ntests/integration/test_error_recovery.py:217: AssertionError"}, "teardown": {"duration": 0.00022301299031823874, "outcome": "passed"}}, {"nodeid": "tests/integration/test_error_recovery.py::test_error_count_threshold", "lineno": 267, "outcome": "failed", "keywords": ["test_error_count_threshold", "test_error_recovery.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0036411560140550137, "outcome": "passed"}, "call": {"duration": 0.002401437028311193, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/concurrent_task_scheduler/concurrent_task_scheduler_render_farm_manager/tests/integration/test_error_recovery.py", "lineno": 287, "message": "AssertionError: assert <RenderJobSta...NG: 'pending'> == <RenderJobSta...NG: 'running'>\n  \n  - running\n  + pending"}, "traceback": [{"path": "tests/integration/test_error_recovery.py", "lineno": 287, "message": "AssertionError"}], "longrepr": "farm_manager = <render_farm_manager.core.manager.RenderFarmManager object at 0x7f3b7a4e9a80>\nclient = RenderClient(client_id='client1', name='Test Client', service_tier=<ServiceTier.PREMIUM: 'premium'>, guaranteed_resources=0, max_resources=100)\nrender_nodes = [RenderNode(id='gpu1', name='GPU Node 1', status='online', capabilities=NodeCapabilities(cpu_cores=16, memory_gb=64, g...dering']), power_efficiency_rating=72.0, current_job_id=None, performance_history={}, last_error=None, uptime_hours=0)]\ncheckpointable_job = RenderJob(id='job1', name='Test Checkpoint Job', client_id='client1', status=<RenderJobStatus.PENDING: 'pending'>, job...=False, supports_checkpoint=True, last_checkpoint_time=None, last_progressive_output_time=None, energy_intensive=False)\n\n    def test_error_count_threshold(farm_manager, client, render_nodes, checkpointable_job):\n        \"\"\"Test that jobs with too many errors are handled appropriately.\"\"\"\n        # Setup\n        farm_manager.add_client(client)\n        for node in render_nodes:\n            farm_manager.add_node(node)\n        farm_manager.submit_job(checkpointable_job)\n    \n        # Set a maximum error threshold (this would normally be from config)\n        max_errors = 3\n    \n        # Run job and simulate repeated failures\n        for i in range(max_errors + 1):\n            # Schedule job\n            farm_manager.run_scheduling_cycle()\n            job = farm_manager.jobs[checkpointable_job.id]\n    \n            if i < max_errors:\n                # Job should be scheduled normally for the first max_errors attempts\n>               assert job.status == RenderJobStatus.RUNNING\nE               AssertionError: assert <RenderJobSta...NG: 'pending'> == <RenderJobSta...NG: 'running'>\nE                 \nE                 - running\nE                 + pending\n\ntests/integration/test_error_recovery.py:287: AssertionError"}, "teardown": {"duration": 0.0002270860131829977, "outcome": "passed"}}, {"nodeid": "tests/integration/test_fault_tolerance.py::test_fault_tolerance_multiple_node_failures", "lineno": 266, "outcome": "passed", "keywords": ["test_fault_tolerance_multiple_node_failures", "test_fault_tolerance.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0034629079746082425, "outcome": "passed"}, "call": {"duration": 0.003766882000491023, "outcome": "passed", "stdout": "Affected jobs: 2, Rescheduled: 0\n"}, "teardown": {"duration": 0.0002021979307755828, "outcome": "passed"}}, {"nodeid": "tests/integration/test_fault_tolerance_fixed.py::test_fault_tolerance_multiple_node_failures", "lineno": 258, "outcome": "passed", "keywords": ["test_fault_tolerance_multiple_node_failures", "test_fault_tolerance_fixed.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.003303815028630197, "outcome": "passed"}, "call": {"duration": 0.003627366037108004, "outcome": "passed", "stdout": "Affected jobs: 2, Rescheduled: 0\n"}, "teardown": {"duration": 0.0002044320572167635, "outcome": "passed"}}, {"nodeid": "tests/integration/test_job_dependencies.py::test_job_dependency_scheduling", "lineno": 211, "outcome": "failed", "keywords": ["test_job_dependency_scheduling", "test_job_dependencies.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.003497843979857862, "outcome": "passed"}, "call": {"duration": 0.00276899803429842, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/concurrent_task_scheduler/concurrent_task_scheduler_render_farm_manager/tests/integration/test_job_dependencies.py", "lineno": 236, "message": "AssertionError: assert <RenderJobStatus.PENDING: 'pending'> in [<RenderJobStatus.RUNNING: 'running'>, <RenderJobStatus.QUEUED: 'queued'>]\n +  where <RenderJobStatus.PENDING: 'pending'> = RenderJob(id='parent1', name='Parent Job 1', client_id='client1', status=<RenderJobStatus.PENDING: 'pending'>, job_typ...False, supports_checkpoint=False, last_checkpoint_time=None, last_progressive_output_time=None, energy_intensive=False).status"}, "traceback": [{"path": "tests/integration/test_job_dependencies.py", "lineno": 236, "message": "AssertionError"}], "longrepr": "farm_manager = <render_farm_manager.core.manager.RenderFarmManager object at 0x7f3b7a57ebc0>\nclient = RenderClient(client_id='client1', name='Test Client', service_tier=<ServiceTier.PREMIUM: 'premium'>, guaranteed_resources=50, max_resources=80)\nrender_nodes = [RenderNode(id='node1', name='Node 1', status='online', capabilities=NodeCapabilities(cpu_cores=16, memory_gb=64, gpu_...ng']), power_efficiency_rating=72.0, current_job_id='child1', performance_history={}, last_error=None, uptime_hours=0)]\ndependent_jobs = [RenderJob(id='parent1', name='Parent Job 1', client_id='client1', status=<RenderJobStatus.PENDING: 'pending'>, job_ty...alse, supports_checkpoint=False, last_checkpoint_time=None, last_progressive_output_time=None, energy_intensive=False)]\n\n    def test_job_dependency_scheduling(farm_manager, client, render_nodes, dependent_jobs):\n        \"\"\"Test that jobs with dependencies are scheduled correctly.\"\"\"\n        # Setup: Add client and nodes\n        farm_manager.add_client(client)\n    \n        for node in render_nodes:\n            farm_manager.add_node(node)\n    \n        # Submit all jobs\n        for job in dependent_jobs:\n            farm_manager.submit_job(job)\n    \n        # First scheduling cycle\n        farm_manager.run_scheduling_cycle()\n    \n        # Check that only parent jobs and independent job are running or queued\n        # Child jobs should be pending until dependencies complete\n        parent1 = farm_manager.jobs[\"parent1\"]\n        parent2 = farm_manager.jobs[\"parent2\"]\n        child = farm_manager.jobs[\"child1\"]\n        grandchild = farm_manager.jobs[\"grandchild1\"]\n        independent = farm_manager.jobs[\"independent1\"]\n    \n        # Parents and independent job should be scheduled\n>       assert parent1.status in [RenderJobStatus.RUNNING, RenderJobStatus.QUEUED]\nE       AssertionError: assert <RenderJobStatus.PENDING: 'pending'> in [<RenderJobStatus.RUNNING: 'running'>, <RenderJobStatus.QUEUED: 'queued'>]\nE        +  where <RenderJobStatus.PENDING: 'pending'> = RenderJob(id='parent1', name='Parent Job 1', client_id='client1', status=<RenderJobStatus.PENDING: 'pending'>, job_typ...False, supports_checkpoint=False, last_checkpoint_time=None, last_progressive_output_time=None, energy_intensive=False).status\n\ntests/integration/test_job_dependencies.py:236: AssertionError"}, "teardown": {"duration": 0.0002201040042564273, "outcome": "passed"}}, {"nodeid": "tests/integration/test_job_dependencies.py::test_dependent_job_priority_inheritance", "lineno": 302, "outcome": "failed", "keywords": ["test_dependent_job_priority_inheritance", "test_job_dependencies.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.003376712091267109, "outcome": "passed"}, "call": {"duration": 0.0020781049970537424, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/concurrent_task_scheduler/concurrent_task_scheduler_render_farm_manager/tests/integration/test_job_dependencies.py", "lineno": 387, "message": "AttributeError: 'RenderFarmManager' object has no attribute 'complete_job'"}, "traceback": [{"path": "tests/integration/test_job_dependencies.py", "lineno": 387, "message": "AttributeError"}], "longrepr": "farm_manager = <render_farm_manager.core.manager.RenderFarmManager object at 0x7f3b7a557be0>\nclient = RenderClient(client_id='client1', name='Test Client', service_tier=<ServiceTier.PREMIUM: 'premium'>, guaranteed_resources=50, max_resources=80)\nrender_nodes = [RenderNode(id='node1', name='Node 1', status='online', capabilities=NodeCapabilities(cpu_cores=16, memory_gb=64, gpu_...), power_efficiency_rating=72.0, current_job_id='competing1', performance_history={}, last_error=None, uptime_hours=0)]\n\n    def test_dependent_job_priority_inheritance(farm_manager, client, render_nodes):\n        \"\"\"Test that dependent jobs inherit priority from parent jobs when appropriate.\"\"\"\n        # Setup: Add client and nodes\n        farm_manager.add_client(client)\n    \n        for node in render_nodes:\n            farm_manager.add_node(node)\n    \n        now = datetime.now()\n    \n        # Create a high-priority parent job\n        parent_job = RenderJob(\n            id=\"high_parent\",\n            client_id=\"client1\",\n            name=\"High Priority Parent\",\n            status=RenderJobStatus.PENDING,\n            job_type=\"animation\",\n            priority=JobPriority.CRITICAL,  # Very high priority\n            submission_time=now,\n            deadline=now + timedelta(hours=3),  # Tight deadline\n            estimated_duration_hours=1.0,\n            progress=0.0,\n            requires_gpu=True,\n            memory_requirements_gb=32,\n            cpu_requirements=8,\n            scene_complexity=7,\n            output_path=\"/renders/client1/high_parent/\",\n        )\n    \n        # Create a low-priority child job\n        child_job = RenderJob(\n            id=\"low_child\",\n            client_id=\"client1\",\n            name=\"Low Priority Child\",\n            status=RenderJobStatus.PENDING,\n            job_type=\"composition\",\n            priority=JobPriority.LOW,  # Low priority\n            submission_time=now,\n            deadline=now + timedelta(hours=12),  # Loose deadline\n            estimated_duration_hours=1.0,\n            progress=0.0,\n            requires_gpu=True,\n            memory_requirements_gb=32,\n            cpu_requirements=8,\n            scene_complexity=5,\n            output_path=\"/renders/client1/low_child/\",\n            dependencies=[\"high_parent\"],\n        )\n    \n        # Create competing jobs with medium priority\n        competing_jobs = [\n            RenderJob(\n                id=f\"competing{i}\",\n                client_id=\"client1\",\n                name=f\"Competing Job {i}\",\n                status=RenderJobStatus.PENDING,\n                job_type=\"standalone\",\n                priority=JobPriority.MEDIUM,  # Medium priority\n                submission_time=now,\n                deadline=now + timedelta(hours=6),\n                estimated_duration_hours=1.0,\n                progress=0.0,\n                requires_gpu=True,\n                memory_requirements_gb=32,\n                cpu_requirements=8,\n                scene_complexity=6,\n                output_path=f\"/renders/client1/competing{i}/\",\n            )\n            for i in range(1, 4)\n        ]\n    \n        # Submit all jobs\n        farm_manager.submit_job(parent_job)\n        farm_manager.submit_job(child_job)\n        for job in competing_jobs:\n            farm_manager.submit_job(job)\n    \n        # First scheduling cycle - parent should run\n        farm_manager.run_scheduling_cycle()\n    \n        # Complete the parent job\n        parent = farm_manager.jobs[\"high_parent\"]\n        if parent.status == RenderJobStatus.RUNNING:\n            farm_manager.update_job_progress(parent.id, 100.0)\n>           farm_manager.complete_job(parent.id)\nE           AttributeError: 'RenderFarmManager' object has no attribute 'complete_job'\n\ntests/integration/test_job_dependencies.py:387: AttributeError"}, "teardown": {"duration": 0.0002256130101159215, "outcome": "passed"}}, {"nodeid": "tests/integration/test_job_dependencies.py::test_circular_dependency_detection", "lineno": 423, "outcome": "failed", "keywords": ["test_circular_dependency_detection", "test_job_dependencies.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.003365712007507682, "outcome": "passed"}, "call": {"duration": 0.002044680994004011, "outcome": "failed", "crash": {"path": "/home/justinchiu_cohere_com/librarybench/projects/concurrent_task_scheduler/concurrent_task_scheduler_render_farm_manager/tests/integration/test_job_dependencies.py", "lineno": 508, "message": "AssertionError: Job job_b should not be scheduled due to circular dependency\nassert <RenderJobStatus.RUNNING: 'running'> not in [<RenderJobStatus.RUNNING: 'running'>, <RenderJobStatus.QUEUED: 'queued'>]\n +  where <RenderJobStatus.RUNNING: 'running'> = RenderJob(id='job_b', name='Job B', client_id='client1', status=<RenderJobStatus.RUNNING: 'running'>, job_type='vfx', ...False, supports_checkpoint=False, last_checkpoint_time=None, last_progressive_output_time=None, energy_intensive=False).status"}, "traceback": [{"path": "tests/integration/test_job_dependencies.py", "lineno": 508, "message": "AssertionError"}], "longrepr": "farm_manager = <render_farm_manager.core.manager.RenderFarmManager object at 0x7f3b7a58a320>\nclient = RenderClient(client_id='client1', name='Test Client', service_tier=<ServiceTier.PREMIUM: 'premium'>, guaranteed_resources=50, max_resources=80)\nrender_nodes = [RenderNode(id='node1', name='Node 1', status='online', capabilities=NodeCapabilities(cpu_cores=16, memory_gb=64, gpu_...ing']), power_efficiency_rating=72.0, current_job_id='job_b', performance_history={}, last_error=None, uptime_hours=0)]\n\n    def test_circular_dependency_detection(farm_manager, client, render_nodes):\n        \"\"\"Test that circular dependencies are detected and handled appropriately.\"\"\"\n        # Setup: Add client and nodes\n        farm_manager.add_client(client)\n    \n        for node in render_nodes:\n            farm_manager.add_node(node)\n    \n        now = datetime.now()\n    \n        # Create jobs with circular dependencies\n        job_a = RenderJob(\n            id=\"job_a\",\n            client_id=\"client1\",\n            name=\"Job A\",\n            status=RenderJobStatus.PENDING,\n            job_type=\"animation\",\n            priority=JobPriority.HIGH,\n            submission_time=now,\n            deadline=now + timedelta(hours=4),\n            estimated_duration_hours=1.0,\n            progress=0.0,\n            requires_gpu=True,\n            memory_requirements_gb=32,\n            cpu_requirements=8,\n            scene_complexity=6,\n            output_path=\"/renders/client1/job_a/\",\n            dependencies=[\"job_c\"],  # A depends on C\n        )\n    \n        job_b = RenderJob(\n            id=\"job_b\",\n            client_id=\"client1\",\n            name=\"Job B\",\n            status=RenderJobStatus.PENDING,\n            job_type=\"vfx\",\n            priority=JobPriority.HIGH,\n            submission_time=now,\n            deadline=now + timedelta(hours=5),\n            estimated_duration_hours=1.0,\n            progress=0.0,\n            requires_gpu=True,\n            memory_requirements_gb=32,\n            cpu_requirements=8,\n            scene_complexity=6,\n            output_path=\"/renders/client1/job_b/\",\n            dependencies=[\"job_a\"],  # B depends on A\n        )\n    \n        job_c = RenderJob(\n            id=\"job_c\",\n            client_id=\"client1\",\n            name=\"Job C\",\n            status=RenderJobStatus.PENDING,\n            job_type=\"composition\",\n            priority=JobPriority.MEDIUM,\n            submission_time=now,\n            deadline=now + timedelta(hours=6),\n            estimated_duration_hours=1.0,\n            progress=0.0,\n            requires_gpu=True,\n            memory_requirements_gb=32,\n            cpu_requirements=8,\n            scene_complexity=6,\n            output_path=\"/renders/client1/job_c/\",\n            dependencies=[\"job_b\"],  # C depends on B, creating a cycle: A -> C -> B -> A\n        )\n    \n        # In a real implementation, the farm manager should detect this cycle\n        # during job submission and reject the jobs or mark them as failed\n        # For this test, we'll submit them and check that they aren't scheduled\n    \n        # Submit all jobs\n        farm_manager.submit_job(job_a)\n        farm_manager.submit_job(job_b)\n        farm_manager.submit_job(job_c)\n    \n        # Run scheduling cycle\n        farm_manager.run_scheduling_cycle()\n    \n        # All jobs should be in PENDING or FAILED state due to circular dependencies\n        # None should be RUNNING or QUEUED\n        for job_id in [\"job_a\", \"job_b\", \"job_c\"]:\n            job = farm_manager.jobs[job_id]\n>           assert job.status not in [RenderJobStatus.RUNNING, RenderJobStatus.QUEUED], \\\n                f\"Job {job_id} should not be scheduled due to circular dependency\"\nE           AssertionError: Job job_b should not be scheduled due to circular dependency\nE           assert <RenderJobStatus.RUNNING: 'running'> not in [<RenderJobStatus.RUNNING: 'running'>, <RenderJobStatus.QUEUED: 'queued'>]\nE            +  where <RenderJobStatus.RUNNING: 'running'> = RenderJob(id='job_b', name='Job B', client_id='client1', status=<RenderJobStatus.RUNNING: 'running'>, job_type='vfx', ...False, supports_checkpoint=False, last_checkpoint_time=None, last_progressive_output_time=None, energy_intensive=False).status\n\ntests/integration/test_job_dependencies.py:508: AssertionError"}, "teardown": {"duration": 0.00022179307416081429, "outcome": "passed"}}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_farm_manager_initialization", "lineno": 212, "outcome": "passed", "keywords": ["test_farm_manager_initialization", "test_render_farm_manager.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0002744230441749096, "outcome": "passed"}, "call": {"duration": 0.00012508698273450136, "outcome": "passed"}, "teardown": {"duration": 0.00011925201397389174, "outcome": "passed"}}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_add_client", "lineno": 220, "outcome": "passed", "keywords": ["test_add_client", "test_render_farm_manager.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.00025078398175537586, "outcome": "passed"}, "call": {"duration": 0.00016842794138938189, "outcome": "passed"}, "teardown": {"duration": 0.00012893998064100742, "outcome": "passed"}}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_add_node", "lineno": 231, "outcome": "passed", "keywords": ["test_add_node", "test_render_farm_manager.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0002947840839624405, "outcome": "passed"}, "call": {"duration": 0.00022640300448983908, "outcome": "passed"}, "teardown": {"duration": 0.00012806197628378868, "outcome": "passed"}}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_submit_job", "lineno": 241, "outcome": "passed", "keywords": ["test_submit_job", "test_render_farm_manager.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0003011800581589341, "outcome": "passed"}, "call": {"duration": 0.00028685491997748613, "outcome": "passed"}, "teardown": {"duration": 0.00013795203994959593, "outcome": "passed"}}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_scheduling_cycle", "lineno": 257, "outcome": "passed", "keywords": ["test_scheduling_cycle", "test_render_farm_manager.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0004179560346528888, "outcome": "passed"}, "call": {"duration": 0.0008078229147940874, "outcome": "passed"}, "teardown": {"duration": 0.00015880202408879995, "outcome": "passed"}}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_job_progress_update", "lineno": 290, "outcome": "passed", "keywords": ["test_job_progress_update", "test_render_farm_manager.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0004061110084876418, "outcome": "passed"}, "call": {"duration": 0.0008410559967160225, "outcome": "passed"}, "teardown": {"duration": 0.00015264004468917847, "outcome": "passed"}}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_node_failure", "lineno": 328, "outcome": "passed", "keywords": ["test_node_failure", "test_render_farm_manager.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.000421884935349226, "outcome": "passed"}, "call": {"duration": 0.0008262649644166231, "outcome": "passed"}, "teardown": {"duration": 0.00015329604502767324, "outcome": "passed"}}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_cancel_job", "lineno": 369, "outcome": "passed", "keywords": ["test_cancel_job", "test_render_farm_manager.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.000407590065151453, "outcome": "passed"}, "call": {"duration": 0.0008106259629130363, "outcome": "passed"}, "teardown": {"duration": 0.00015365704894065857, "outcome": "passed"}}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_client_resource_guarantees", "lineno": 402, "outcome": "passed", "keywords": ["test_client_resource_guarantees", "test_render_farm_manager.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.00034847192000597715, "outcome": "passed"}, "call": {"duration": 0.0021045220782980323, "outcome": "passed"}, "teardown": {"duration": 0.00015266507398337126, "outcome": "passed"}}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_energy_optimization", "lineno": 488, "outcome": "passed", "keywords": ["test_energy_optimization", "test_render_farm_manager.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.00042497494723647833, "outcome": "passed"}, "call": {"duration": 0.0008767599938437343, "outcome": "passed"}, "teardown": {"duration": 0.00016598508227616549, "outcome": "passed"}}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_progressive_output_config", "lineno": 518, "outcome": "passed", "keywords": ["test_progressive_output_config", "test_render_farm_manager.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0004122150130569935, "outcome": "passed"}, "call": {"duration": 0.0008355400059372187, "outcome": "passed"}, "teardown": {"duration": 0.0001542039681226015, "outcome": "passed"}}, {"nodeid": "tests/integration/test_render_farm_manager.py::test_full_end_to_end_workflow", "lineno": 554, "outcome": "passed", "keywords": ["test_full_end_to_end_workflow", "test_render_farm_manager.py", "integration", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0004109080182388425, "outcome": "passed"}, "call": {"duration": 0.0013060299679636955, "outcome": "passed"}, "teardown": {"duration": 0.00015790294855833054, "outcome": "passed"}}, {"nodeid": "tests/performance/test_performance.py::test_scheduling_performance", "lineno": 160, "outcome": "passed", "keywords": ["test_scheduling_performance", "test_performance.py", "performance", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0039039079565554857, "outcome": "passed"}, "call": {"duration": 0.07008331001270562, "outcome": "passed", "stdout": "Scheduling time: 25.86ms\nJobs scheduled: 200\nResource utilization: 100.00%\n"}, "teardown": {"duration": 0.00015129393432289362, "outcome": "passed"}}, {"nodeid": "tests/performance/test_performance.py::test_multiple_scheduling_cycles", "lineno": 195, "outcome": "passed", "keywords": ["test_multiple_scheduling_cycles", "test_performance.py", "performance", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0037259020609781146, "outcome": "passed"}, "call": {"duration": 0.0906415618956089, "outcome": "passed", "stdout": "Average cycle time: 11.49ms\nMax cycle time: 20.85ms\nMin cycle time: 9.02ms\nFinal resource utilization: 98.00%\n"}, "teardown": {"duration": 0.00014264299534261227, "outcome": "passed"}}, {"nodeid": "tests/performance/test_performance.py::test_node_specialization_efficiency", "lineno": 251, "outcome": "passed", "keywords": ["test_node_specialization_efficiency", "test_performance.py", "performance", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0037338099209591746, "outcome": "passed"}, "call": {"duration": 0.030690337996929884, "outcome": "passed", "stdout": "Specialization efficiency: 83.54%\nGPU jobs on GPU nodes: 56\nCPU jobs on CPU nodes: 60\nMemory jobs on Memory nodes: 16\nTotal assigned: 158\nScheduling time: 21.48ms\n"}, "teardown": {"duration": 0.00014540296979248524, "outcome": "passed"}}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_scheduler_initialization", "lineno": 184, "outcome": "passed", "keywords": ["test_scheduler_initialization", "test_deadline_scheduler.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0012135260039940476, "outcome": "passed"}, "call": {"duration": 0.0001432780409231782, "outcome": "passed"}, "teardown": {"duration": 0.00014917505905032158, "outcome": "passed"}}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_update_priorities_deadline_approaching", "lineno": 190, "outcome": "passed", "keywords": ["test_update_priorities_deadline_approaching", "test_deadline_scheduler.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.001024144934490323, "outcome": "passed"}, "call": {"duration": 0.0015681990189477801, "outcome": "passed"}, "teardown": {"duration": 0.00017288594972342253, "outcome": "passed"}}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_update_priorities_job_progress", "lineno": 211, "outcome": "passed", "keywords": ["test_update_priorities_job_progress", "test_deadline_scheduler.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0010118240024894476, "outcome": "passed"}, "call": {"duration": 0.0015009730122983456, "outcome": "passed"}, "teardown": {"duration": 0.00018610595725476742, "outcome": "passed"}}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_schedule_jobs_priority_order", "lineno": 228, "outcome": "passed", "keywords": ["test_schedule_jobs_priority_order", "test_deadline_scheduler.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0011099230032414198, "outcome": "passed"}, "call": {"duration": 0.001654081977903843, "outcome": "passed"}, "teardown": {"duration": 0.00019073300063610077, "outcome": "passed"}}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_schedule_jobs_resource_requirements", "lineno": 246, "outcome": "passed", "keywords": ["test_schedule_jobs_resource_requirements", "test_deadline_scheduler.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0011265940265730023, "outcome": "passed"}, "call": {"duration": 0.0016669400501996279, "outcome": "passed"}, "teardown": {"duration": 0.00018144899513572454, "outcome": "passed"}}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_preemption", "lineno": 258, "outcome": "passed", "keywords": ["test_preemption", "test_deadline_scheduler.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.001132167992182076, "outcome": "passed"}, "call": {"duration": 0.0016057329485192895, "outcome": "passed"}, "teardown": {"duration": 0.00018235191237181425, "outcome": "passed"}}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_preemption_disabled", "lineno": 285, "outcome": "passed", "keywords": ["test_preemption_disabled", "test_deadline_scheduler.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.001112746074795723, "outcome": "passed"}, "call": {"duration": 0.002429010928608477, "outcome": "passed"}, "teardown": {"duration": 0.000186602002941072, "outcome": "passed"}}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_can_meet_deadline", "lineno": 305, "outcome": "passed", "keywords": ["test_can_meet_deadline", "test_deadline_scheduler.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0010993439937010407, "outcome": "passed"}, "call": {"duration": 0.0001862960634753108, "outcome": "passed"}, "teardown": {"duration": 0.0001643310533836484, "outcome": "passed"}}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_should_preempt", "lineno": 337, "outcome": "passed", "keywords": ["test_should_preempt", "test_deadline_scheduler.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0009986989898607135, "outcome": "passed"}, "call": {"duration": 0.00014692998956888914, "outcome": "passed"}, "teardown": {"duration": 0.00015443796291947365, "outcome": "passed"}}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_schedule_with_dependencies", "lineno": 360, "outcome": "passed", "keywords": ["test_schedule_with_dependencies", "test_deadline_scheduler.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0010142360115423799, "outcome": "passed"}, "call": {"duration": 0.0015874119708314538, "outcome": "passed"}, "teardown": {"duration": 0.00017210491932928562, "outcome": "passed"}}, {"nodeid": "tests/unit/test_deadline_scheduler.py::test_rescheduling_failed_job", "lineno": 425, "outcome": "passed", "keywords": ["test_rescheduling_failed_job", "test_deadline_scheduler.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.00110819807741791, "outcome": "passed"}, "call": {"duration": 0.001726676942780614, "outcome": "passed"}, "teardown": {"duration": 0.00018187810201197863, "outcome": "passed"}}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_energy_optimizer_initialization", "lineno": 190, "outcome": "passed", "keywords": ["test_energy_optimizer_initialization", "test_energy_optimizer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0009655040921643376, "outcome": "passed"}, "call": {"duration": 0.00013573491014540195, "outcome": "passed"}, "teardown": {"duration": 0.00016071100253611803, "outcome": "passed"}}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_optimize_energy_usage", "lineno": 199, "outcome": "passed", "keywords": ["test_optimize_energy_usage", "test_energy_optimizer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0010699279373511672, "outcome": "passed"}, "call": {"duration": 0.0017551430501043797, "outcome": "passed"}, "teardown": {"duration": 0.0001783580519258976, "outcome": "passed"}}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_energy_mode_affects_scheduling", "lineno": 227, "outcome": "passed", "keywords": ["test_energy_mode_affects_scheduling", "test_energy_optimizer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0010998420184478164, "outcome": "passed"}, "call": {"duration": 0.002011024975217879, "outcome": "passed"}, "teardown": {"duration": 0.00018273002933710814, "outcome": "passed"}}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_calculate_energy_cost", "lineno": 252, "outcome": "passed", "keywords": ["test_calculate_energy_cost", "test_energy_optimizer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0011070150649175048, "outcome": "passed"}, "call": {"duration": 0.000549643998965621, "outcome": "passed"}, "teardown": {"duration": 0.0001850599655881524, "outcome": "passed"}}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_time_of_day_energy_price", "lineno": 282, "outcome": "passed", "keywords": ["test_time_of_day_energy_price", "test_energy_optimizer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0010156439384445548, "outcome": "passed"}, "call": {"duration": 0.0001324390759691596, "outcome": "passed"}, "teardown": {"duration": 0.00014959904365241528, "outcome": "passed"}}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_set_energy_mode", "lineno": 297, "outcome": "passed", "keywords": ["test_set_energy_mode", "test_energy_optimizer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0009173559956252575, "outcome": "passed"}, "call": {"duration": 0.0005702739581465721, "outcome": "passed"}, "teardown": {"duration": 0.00015867501497268677, "outcome": "passed"}}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_estimate_energy_savings", "lineno": 313, "outcome": "passed", "keywords": ["test_estimate_energy_savings", "test_energy_optimizer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0012168589746579528, "outcome": "passed"}, "call": {"duration": 0.0005920910043641925, "outcome": "passed"}, "teardown": {"duration": 0.00017500098329037428, "outcome": "passed"}}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_energy_mode_update_based_on_time", "lineno": 331, "outcome": "passed", "keywords": ["test_energy_mode_update_based_on_time", "test_energy_optimizer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0009933710098266602, "outcome": "passed"}, "call": {"duration": 0.0014525629812851548, "outcome": "passed"}, "teardown": {"duration": 0.00018199090845882893, "outcome": "passed"}}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_node_meets_requirements", "lineno": 350, "outcome": "passed", "keywords": ["test_node_meets_requirements", "test_energy_optimizer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0010915169259533286, "outcome": "passed"}, "call": {"duration": 0.00018306600395590067, "outcome": "passed"}, "teardown": {"duration": 0.00016332999803125858, "outcome": "passed"}}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_get_node_type", "lineno": 368, "outcome": "passed", "keywords": ["test_get_node_type", "test_energy_optimizer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.001026722020469606, "outcome": "passed"}, "call": {"duration": 0.000180889037437737, "outcome": "passed"}, "teardown": {"duration": 0.00015344307757914066, "outcome": "passed"}}, {"nodeid": "tests/unit/test_energy_optimizer.py::test_high_priority_jobs_override_energy_considerations", "lineno": 383, "outcome": "passed", "keywords": ["test_high_priority_jobs_override_energy_considerations", "test_energy_optimizer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0010767659405246377, "outcome": "passed"}, "call": {"duration": 0.0015196660533547401, "outcome": "passed"}, "teardown": {"duration": 0.00019042694475501776, "outcome": "passed"}}, {"nodeid": "tests/unit/test_node_specialization.py::test_specialization_manager_initialization", "lineno": 249, "outcome": "passed", "keywords": ["test_specialization_manager_initialization", "test_node_specialization.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0009357150411233306, "outcome": "passed"}, "call": {"duration": 0.00014066603034734726, "outcome": "passed"}, "teardown": {"duration": 0.00014346011448651552, "outcome": "passed"}}, {"nodeid": "tests/unit/test_node_specialization.py::test_match_job_to_node_gpu_job", "lineno": 258, "outcome": "passed", "keywords": ["test_match_job_to_node_gpu_job", "test_node_specialization.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0011040869867429137, "outcome": "passed"}, "call": {"duration": 0.001538889016956091, "outcome": "passed"}, "teardown": {"duration": 0.00017870706506073475, "outcome": "passed"}}, {"nodeid": "tests/unit/test_node_specialization.py::test_match_job_to_node_cpu_job", "lineno": 274, "outcome": "passed", "keywords": ["test_match_job_to_node_cpu_job", "test_node_specialization.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.00110951391980052, "outcome": "passed"}, "call": {"duration": 0.0014752800343558192, "outcome": "passed"}, "teardown": {"duration": 0.0001810770481824875, "outcome": "passed"}}, {"nodeid": "tests/unit/test_node_specialization.py::test_match_job_to_node_memory_job", "lineno": 290, "outcome": "passed", "keywords": ["test_match_job_to_node_memory_job", "test_node_specialization.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0011080789845436811, "outcome": "passed"}, "call": {"duration": 0.0014401369262486696, "outcome": "passed"}, "teardown": {"duration": 0.00018580304458737373, "outcome": "passed"}}, {"nodeid": "tests/unit/test_node_specialization.py::test_calculate_performance_score", "lineno": 306, "outcome": "passed", "keywords": ["test_calculate_performance_score", "test_node_specialization.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0011234940029680729, "outcome": "passed"}, "call": {"duration": 0.00015263899695128202, "outcome": "passed"}, "teardown": {"duration": 0.00017442903481423855, "outcome": "passed"}}, {"nodeid": "tests/unit/test_node_specialization.py::test_update_performance_history", "lineno": 327, "outcome": "passed", "keywords": ["test_update_performance_history", "test_node_specialization.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0011075879447162151, "outcome": "passed"}, "call": {"duration": 0.0007136410567909479, "outcome": "passed"}, "teardown": {"duration": 0.00017720600590109825, "outcome": "passed"}}, {"nodeid": "tests/unit/test_node_specialization.py::test_performance_history_influence", "lineno": 361, "outcome": "passed", "keywords": ["test_performance_history_influence", "test_node_specialization.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0011244480265304446, "outcome": "passed"}, "call": {"duration": 0.0015026169130578637, "outcome": "passed"}, "teardown": {"duration": 0.0001802269835025072, "outcome": "passed"}}, {"nodeid": "tests/unit/test_node_specialization.py::test_node_capability_matching", "lineno": 376, "outcome": "passed", "keywords": ["test_node_capability_matching", "test_node_specialization.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0011191919911652803, "outcome": "passed"}, "call": {"duration": 0.0023234010441228747, "outcome": "passed"}, "teardown": {"duration": 0.000180813018232584, "outcome": "passed"}}, {"nodeid": "tests/unit/test_node_specialization.py::test_no_suitable_node", "lineno": 395, "outcome": "passed", "keywords": ["test_no_suitable_node", "test_node_specialization.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.001214305986650288, "outcome": "passed"}, "call": {"duration": 0.001073173014447093, "outcome": "passed"}, "teardown": {"duration": 0.00017646700143814087, "outcome": "passed"}}, {"nodeid": "tests/unit/test_node_specialization.py::test_specialized_vs_general_nodes", "lineno": 409, "outcome": "passed", "keywords": ["test_specialized_vs_general_nodes", "test_node_specialization.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0011080460390076041, "outcome": "passed"}, "call": {"duration": 0.0015179619658738375, "outcome": "passed"}, "teardown": {"duration": 0.00018226495012640953, "outcome": "passed"}}, {"nodeid": "tests/unit/test_node_specialization.py::test_analyze_node_efficiency", "lineno": 444, "outcome": "passed", "keywords": ["test_analyze_node_efficiency", "test_node_specialization.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0010242890566587448, "outcome": "passed"}, "call": {"duration": 0.0001867960672825575, "outcome": "passed"}, "teardown": {"duration": 0.0001598689705133438, "outcome": "passed"}}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_progressive_renderer_initialization", "lineno": 167, "outcome": "passed", "keywords": ["test_progressive_renderer_initialization", "test_progressive_renderer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0009341679979115725, "outcome": "passed"}, "call": {"duration": 0.00013627205044031143, "outcome": "passed"}, "teardown": {"duration": 0.00014748598914593458, "outcome": "passed"}}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_schedule_progressive_output_long_job", "lineno": 175, "outcome": "passed", "keywords": ["test_schedule_progressive_output_long_job", "test_progressive_renderer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0009927019709721208, "outcome": "passed"}, "call": {"duration": 0.0015783869894221425, "outcome": "passed"}, "teardown": {"duration": 0.00019289995543658733, "outcome": "passed"}}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_schedule_progressive_output_short_job", "lineno": 192, "outcome": "passed", "keywords": ["test_schedule_progressive_output_short_job", "test_progressive_renderer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.001018204027786851, "outcome": "passed"}, "call": {"duration": 0.001430756994523108, "outcome": "passed"}, "teardown": {"duration": 0.0001749920193105936, "outcome": "passed"}}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_schedule_progressive_output_disabled_config", "lineno": 207, "outcome": "passed", "keywords": ["test_schedule_progressive_output_disabled_config", "test_progressive_renderer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0010238729882985353, "outcome": "passed"}, "call": {"duration": 0.0010730390204116702, "outcome": "passed"}, "teardown": {"duration": 0.0001725150505080819, "outcome": "passed"}}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_schedule_progressive_output_unsupported_job", "lineno": 226, "outcome": "passed", "keywords": ["test_schedule_progressive_output_unsupported_job", "test_progressive_renderer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0010141879320144653, "outcome": "passed"}, "call": {"duration": 0.0010857789311558008, "outcome": "passed"}, "teardown": {"duration": 0.00018279999494552612, "outcome": "passed"}}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_generate_progressive_output", "lineno": 237, "outcome": "passed", "keywords": ["test_generate_progressive_output", "test_progressive_renderer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.001068937941454351, "outcome": "passed"}, "call": {"duration": 0.0023433039896190166, "outcome": "passed"}, "teardown": {"duration": 0.00018047704361379147, "outcome": "passed"}}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_generate_progressive_output_unsupported_job", "lineno": 258, "outcome": "passed", "keywords": ["test_generate_progressive_output_unsupported_job", "test_progressive_renderer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0009991669794544578, "outcome": "passed"}, "call": {"duration": 0.001310146995820105, "outcome": "passed", "log": [{"name": "render_farm.progressive_renderer", "msg": "Job no-progressive-job does not support progressive output", "args": null, "levelname": "ERROR", "levelno": 40, "pathname": "/home/justinchiu_cohere_com/librarybench/projects/concurrent_task_scheduler/concurrent_task_scheduler_render_farm_manager/render_farm_manager/progressive_result/progressive_renderer.py", "filename": "progressive_renderer.py", "module": "progressive_renderer", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 142, "funcName": "generate_progressive_output", "created": 1747281844.0829952, "msecs": 82.0, "relativeCreated": 798.7439632415771, "thread": 139893473384256, "threadName": "MainThread", "processName": "MainProcess", "process": 1066106}]}, "teardown": {"duration": 0.00018352700863033533, "outcome": "passed"}}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_estimate_overhead", "lineno": 267, "outcome": "passed", "keywords": ["test_estimate_overhead", "test_progressive_renderer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.001017800997942686, "outcome": "passed"}, "call": {"duration": 0.00013954902533441782, "outcome": "passed"}, "teardown": {"duration": 0.00016376806888729334, "outcome": "passed"}}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_process_pending_outputs", "lineno": 292, "outcome": "passed", "keywords": ["test_process_pending_outputs", "test_progressive_renderer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0009805109584704041, "outcome": "passed"}, "call": {"duration": 0.0016102429945021868, "outcome": "passed"}, "teardown": {"duration": 0.00016797997523099184, "outcome": "passed"}}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_get_latest_progressive_output", "lineno": 338, "outcome": "passed", "keywords": ["test_get_latest_progressive_output", "test_progressive_renderer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0010063860099762678, "outcome": "passed"}, "call": {"duration": 0.0015645429957658052, "outcome": "passed"}, "teardown": {"duration": 0.000175348948687315, "outcome": "passed"}}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_quality_overhead_factors", "lineno": 355, "outcome": "passed", "keywords": ["test_quality_overhead_factors", "test_progressive_renderer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0009337840601801872, "outcome": "passed"}, "call": {"duration": 0.00012658094055950642, "outcome": "passed"}, "teardown": {"duration": 0.00014552101492881775, "outcome": "passed"}}, {"nodeid": "tests/unit/test_progressive_renderer.py::test_max_overhead_limit", "lineno": 362, "outcome": "passed", "keywords": ["test_max_overhead_limit", "test_progressive_renderer.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0009757699444890022, "outcome": "passed"}, "call": {"duration": 0.0001469410490244627, "outcome": "passed"}, "teardown": {"duration": 0.0001572510227560997, "outcome": "passed"}}, {"nodeid": "tests/unit/test_resource_borrowing.py::test_client_resource_borrowing", "lineno": 174, "outcome": "passed", "keywords": ["test_client_resource_borrowing", "test_resource_borrowing.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0016068639233708382, "outcome": "passed"}, "call": {"duration": 0.0023245790507644415, "outcome": "passed"}, "teardown": {"duration": 0.00017676595598459244, "outcome": "passed"}}, {"nodeid": "tests/unit/test_resource_borrowing.py::test_borrowing_limit_variations", "lineno": 308, "outcome": "passed", "keywords": ["test_borrowing_limit_variations", "test_resource_borrowing.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.002455051988363266, "outcome": "passed"}, "call": {"duration": 0.014195446972735226, "outcome": "passed"}, "teardown": {"duration": 0.00016653700731694698, "outcome": "passed"}}, {"nodeid": "tests/unit/test_resource_borrowing_fixed.py::test_client_resource_borrowing", "lineno": 175, "outcome": "passed", "keywords": ["test_client_resource_borrowing", "test_resource_borrowing_fixed.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0008381119696423411, "outcome": "passed"}, "call": {"duration": 0.0027313909959048033, "outcome": "passed"}, "teardown": {"duration": 0.00016800407320261002, "outcome": "passed"}}, {"nodeid": "tests/unit/test_resource_borrowing_fixed.py::test_borrowing_limit_variations", "lineno": 313, "outcome": "passed", "keywords": ["test_borrowing_limit_variations", "test_resource_borrowing_fixed.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0006862760055810213, "outcome": "passed"}, "call": {"duration": 0.0025432100519537926, "outcome": "passed"}, "teardown": {"duration": 0.00016604503616690636, "outcome": "passed"}}, {"nodeid": "tests/unit/test_resource_partitioner.py::test_partitioner_initialization", "lineno": 171, "outcome": "passed", "keywords": ["test_partitioner_initialization", "test_resource_partitioner.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0009318470256403089, "outcome": "passed"}, "call": {"duration": 0.00014195998664945364, "outcome": "passed"}, "teardown": {"duration": 0.00014884397387504578, "outcome": "passed"}}, {"nodeid": "tests/unit/test_resource_partitioner.py::test_allocate_resources_guaranteed_minimums", "lineno": 177, "outcome": "passed", "keywords": ["test_allocate_resources_guaranteed_minimums", "test_resource_partitioner.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0011948950123041868, "outcome": "passed"}, "call": {"duration": 0.0018596380250528455, "outcome": "passed"}, "teardown": {"duration": 0.0001797069562599063, "outcome": "passed"}}, {"nodeid": "tests/unit/test_resource_partitioner.py::test_allocate_resources_borrowing", "lineno": 197, "outcome": "passed", "keywords": ["test_allocate_resources_borrowing", "test_resource_partitioner.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0011035810457542539, "outcome": "passed"}, "call": {"duration": 0.002734657027758658, "outcome": "passed"}, "teardown": {"duration": 0.00017753895372152328, "outcome": "passed"}}, {"nodeid": "tests/unit/test_resource_partitioner.py::test_can_borrow_resources", "lineno": 218, "outcome": "passed", "keywords": ["test_can_borrow_resources", "test_resource_partitioner.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0009674719767645001, "outcome": "passed"}, "call": {"duration": 0.00013885600492358208, "outcome": "passed"}, "teardown": {"duration": 0.00016236200463026762, "outcome": "passed"}}, {"nodeid": "tests/unit/test_resource_partitioner.py::test_calculate_resource_usage", "lineno": 249, "outcome": "passed", "keywords": ["test_calculate_resource_usage", "test_resource_partitioner.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0012926090275868773, "outcome": "passed"}, "call": {"duration": 0.0001832490088418126, "outcome": "passed"}, "teardown": {"duration": 0.00017310399562120438, "outcome": "passed"}}, {"nodeid": "tests/unit/test_resource_partitioner.py::test_allocate_resources_with_offline_nodes", "lineno": 273, "outcome": "passed", "keywords": ["test_allocate_resources_with_offline_nodes", "test_resource_partitioner.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0010883969953283668, "outcome": "passed"}, "call": {"duration": 0.002019864972680807, "outcome": "passed"}, "teardown": {"duration": 0.00018026691395789385, "outcome": "passed"}}, {"nodeid": "tests/unit/test_resource_partitioner.py::test_resource_allocation_scaling", "lineno": 295, "outcome": "passed", "keywords": ["test_resource_allocation_scaling", "test_resource_partitioner.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0010956129990518093, "outcome": "passed"}, "call": {"duration": 0.002138726064004004, "outcome": "passed"}, "teardown": {"duration": 0.00018024502787739038, "outcome": "passed"}}, {"nodeid": "tests/unit/test_resource_partitioner.py::test_resource_allocation_special_hardware", "lineno": 313, "outcome": "passed", "keywords": ["test_resource_allocation_special_hardware", "test_resource_partitioner.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0011072340421378613, "outcome": "passed"}, "call": {"duration": 0.0018955880077555776, "outcome": "passed"}, "teardown": {"duration": 0.00018201407510787249, "outcome": "passed"}}, {"nodeid": "tests/unit/test_resource_partitioner.py::test_allocate_resources_with_no_clients", "lineno": 334, "outcome": "passed", "keywords": ["test_allocate_resources_with_no_clients", "test_resource_partitioner.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.001072195009328425, "outcome": "passed"}, "call": {"duration": 0.001138197025284171, "outcome": "passed"}, "teardown": {"duration": 0.00017334497533738613, "outcome": "passed"}}, {"nodeid": "tests/unit/test_resource_partitioner.py::test_allocate_resources_with_no_nodes", "lineno": 342, "outcome": "passed", "keywords": ["test_allocate_resources_with_no_nodes", "test_resource_partitioner.py", "unit", "tests", "concurrent_task_scheduler_render_farm_manager", ""], "setup": {"duration": 0.0009434829698875546, "outcome": "passed"}, "call": {"duration": 0.002666214946657419, "outcome": "passed"}, "teardown": {"duration": 0.00017479888629168272, "outcome": "passed"}}]}