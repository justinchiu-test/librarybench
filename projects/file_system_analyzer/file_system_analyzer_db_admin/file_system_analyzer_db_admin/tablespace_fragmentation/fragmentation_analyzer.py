"""Tablespace fragmentation analysis and visualization."""

import os
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple, Union, Any
from datetime import datetime, timedelta
import logging
import uuid
import json
import re
from enum import Enum
import numpy as np
from collections import defaultdict

from pydantic import BaseModel, Field

from ..utils.types import (
    DatabaseEngine, 
    FileCategory, 
    ScanStatus, 
    AnalysisResult,
    DatabaseFile,
    OptimizationRecommendation,
    OptimizationPriority
)


logger = logging.getLogger(__name__)


class FragmentationType(str, Enum):
    """Types of database fragmentation."""

    INTERNAL = "internal"
    EXTERNAL = "external"
    MIXED = "mixed"
    MINIMAL = "minimal"


class FragmentationSeverity(str, Enum):
    """Severity levels for fragmentation."""

    CRITICAL = "critical"
    HIGH = "high"
    MODERATE = "moderate"
    LOW = "low"
    NEGLIGIBLE = "negligible"


class SpaceDistributionType(str, Enum):
    """Types of free space distribution."""

    UNIFORM = "uniform"
    CLUSTERED = "clustered"
    SCATTERED = "scattered"
    DEPLETED = "depleted"


class TablespaceInfo(BaseModel):
    """Information about a tablespace."""

    name: str
    engine: DatabaseEngine
    file_paths: List[str]
    total_size_bytes: int
    used_size_bytes: int
    free_size_bytes: int
    max_size_bytes: Optional[int] = None
    autoextend: bool = False
    tables: List[str] = Field(default_factory=list)
    creation_time: Optional[datetime] = None
    last_modified: Optional[datetime] = None
    metadata: Dict[str, Any] = Field(default_factory=dict)


class FragmentationMetrics(BaseModel):
    """Metrics for tablespace fragmentation."""

    tablespace: TablespaceInfo
    fragmentation_percent: float
    fragmentation_type: FragmentationType
    severity: FragmentationSeverity
    free_space_distribution: SpaceDistributionType
    largest_contiguous_free_chunk_bytes: int
    free_chunks_count: int
    avg_free_chunk_size_bytes: float
    growth_trend_bytes_per_day: Optional[float] = None
    days_until_full: Optional[int] = None
    optimal_fill_factor: Optional[float] = None
    estimated_reorganization_benefit_percent: float


class TablespacePath(BaseModel):
    """Path configuration for DB tablespace visualization."""

    x: List[float]  # Normalized positions (0-1)
    y: List[float]  # Normalized positions (0-1)
    width: List[float]  # Normalized widths (0-1)
    height: List[float]  # Normalized heights (0-1)
    type: List[str]  # "data", "free", "fragmented"
    size_bytes: List[int]  # Actual size in bytes


class FragmentationAnalysisResult(AnalysisResult):
    """Results from tablespace fragmentation analysis."""

    total_tablespaces: int
    total_size_bytes: int
    free_space_bytes: int
    fragmented_tablespaces: List[FragmentationMetrics]
    tablespaces_by_severity: Dict[FragmentationSeverity, int]
    total_reorganization_benefit_bytes: int
    visualization_data: Dict[str, TablespacePath]
    estimated_recovery_time_hours: float


class TablespaceFragmentationAnalyzer:
    """
    Analyzes tablespace fragmentation and provides optimization recommendations.
    
    This class examines database tablespace files, detects and quantifies 
    fragmentation, visualizes free space distribution, and provides
    actionable recommendations for optimization.
    """

    def __init__(
        self,
        critical_fragmentation_threshold: float = 40.0,
        high_fragmentation_threshold: float = 25.0,
        moderate_fragmentation_threshold: float = 15.0,
        min_reorganization_benefit_percent: float = 10.0,
        visualization_resolution: int = 100,
    ):
        """
        Initialize the tablespace fragmentation analyzer.

        Args:
            critical_fragmentation_threshold: Percent threshold for critical fragmentation
            high_fragmentation_threshold: Percent threshold for high fragmentation
            moderate_fragmentation_threshold: Percent threshold for moderate fragmentation
            min_reorganization_benefit_percent: Minimum benefit percent to recommend reorganization
            visualization_resolution: Resolution for visualization (higher = more detail)
        """
        self.critical_fragmentation_threshold = critical_fragmentation_threshold
        self.high_fragmentation_threshold = high_fragmentation_threshold
        self.moderate_fragmentation_threshold = moderate_fragmentation_threshold
        self.min_reorganization_benefit_percent = min_reorganization_benefit_percent
        self.visualization_resolution = visualization_resolution

    def detect_fragmentation_severity(self, fragmentation_percent: float) -> FragmentationSeverity:
        """
        Determine fragmentation severity based on percentage.

        Args:
            fragmentation_percent: Fragmentation percentage

        Returns:
            Fragmentation severity level
        """
        if fragmentation_percent >= self.critical_fragmentation_threshold:
            return FragmentationSeverity.CRITICAL
        elif fragmentation_percent >= self.high_fragmentation_threshold:
            return FragmentationSeverity.HIGH
        elif fragmentation_percent >= self.moderate_fragmentation_threshold:
            return FragmentationSeverity.MODERATE
        elif fragmentation_percent >= 5.0:
            return FragmentationSeverity.LOW
        else:
            return FragmentationSeverity.NEGLIGIBLE

    def analyze_free_space_distribution(
        self, free_chunks: List[int], total_free_space: int
    ) -> SpaceDistributionType:
        """
        Analyze distribution pattern of free space chunks.

        Args:
            free_chunks: List of free chunk sizes in bytes
            total_free_space: Total free space in bytes

        Returns:
            Type of free space distribution
        """
        if not free_chunks:
            return SpaceDistributionType.DEPLETED
            
        # Calculate metrics
        chunk_count = len(free_chunks)
        avg_chunk_size = sum(free_chunks) / chunk_count if chunk_count > 0 else 0
        max_chunk_size = max(free_chunks) if free_chunks else 0
        
        # Calculate variance coefficient
        if avg_chunk_size > 0:
            variance = np.var(free_chunks)
            variance_coefficient = np.sqrt(variance) / avg_chunk_size
        else:
            variance_coefficient = 0
            
        # Calculate percentage of space in largest chunk
        largest_chunk_percent = (max_chunk_size / total_free_space) * 100 if total_free_space > 0 else 0
        
        # Determine distribution type
        if chunk_count <= 2 and largest_chunk_percent > 80:
            return SpaceDistributionType.UNIFORM
        elif largest_chunk_percent > 60:
            return SpaceDistributionType.CLUSTERED
        elif variance_coefficient > 1.5:
            return SpaceDistributionType.SCATTERED
        elif total_free_space < 1024 * 1024:  # Less than 1MB free
            return SpaceDistributionType.DEPLETED
        else:
            return SpaceDistributionType.SCATTERED

    def estimate_reorganization_benefit(
        self,
        fragmentation_percent: float,
        fragmentation_type: FragmentationType,
        free_space_distribution: SpaceDistributionType,
    ) -> float:
        """
        Estimate potential benefit percentage from reorganization.

        Args:
            fragmentation_percent: Fragmentation percentage
            fragmentation_type: Type of fragmentation
            free_space_distribution: Type of free space distribution

        Returns:
            Estimated benefit percentage
        """
        # Base benefit is proportional to fragmentation percentage
        base_benefit = fragmentation_percent * 0.5  # Start with 50% of fragmentation percentage
        
        # Adjust based on fragmentation type
        type_multiplier = 1.0
        if fragmentation_type == FragmentationType.INTERNAL:
            type_multiplier = 1.2  # Internal fragmentation is more fixable
        elif fragmentation_type == FragmentationType.EXTERNAL:
            type_multiplier = 0.8  # External fragmentation may require more than reorganization
        
        # Adjust based on free space distribution
        distribution_multiplier = 1.0
        if free_space_distribution == SpaceDistributionType.SCATTERED:
            distribution_multiplier = 1.3  # Scattered free space has more to gain
        elif free_space_distribution == SpaceDistributionType.CLUSTERED:
            distribution_multiplier = 0.9  # Clustered free space is less problematic
        elif free_space_distribution == SpaceDistributionType.DEPLETED:
            distribution_multiplier = 0.7  # Depleted space needs more than reorganization
        
        # Calculate final benefit percentage
        benefit_percent = base_benefit * type_multiplier * distribution_multiplier
        
        # Cap at reasonable limits
        return min(80.0, max(0.0, benefit_percent))

    def calculate_optimal_fill_factor(
        self,
        current_fragmentation: float,
        growth_rate_bytes_per_day: Optional[float],
        total_size_bytes: int,
        free_space_bytes: int,
    ) -> float:
        """
        Calculate optimal fill factor for tablespace.

        Args:
            current_fragmentation: Current fragmentation percentage
            growth_rate_bytes_per_day: Growth rate in bytes per day
            total_size_bytes: Total size in bytes
            free_space_bytes: Free space in bytes

        Returns:
            Optimal fill factor (0-100 percent)
        """
        # Start with default fill factor
        fill_factor = 80.0  # 80% is a common default
        
        # If we have growth rate data, adjust based on it
        if growth_rate_bytes_per_day is not None and growth_rate_bytes_per_day > 0:
            # Calculate days of capacity at current growth rate
            if free_space_bytes > 0:
                days_capacity = free_space_bytes / growth_rate_bytes_per_day
            else:
                days_capacity = 0
                
            # Adjust fill factor based on growth rate and capacity
            if days_capacity < 7:  # Less than a week of capacity
                fill_factor -= 10.0  # Lower fill factor to leave more room
            elif days_capacity > 90:  # More than 3 months of capacity
                fill_factor += 5.0  # Can use higher fill factor
        
        # Adjust based on fragmentation
        if current_fragmentation > self.critical_fragmentation_threshold:
            fill_factor -= 15.0  # Significantly lower fill factor for highly fragmented tablespaces
        elif current_fragmentation > self.high_fragmentation_threshold:
            fill_factor -= 10.0
        elif current_fragmentation > self.moderate_fragmentation_threshold:
            fill_factor -= 5.0
            
        # Ensure fill factor is within reasonable bounds
        return min(95.0, max(50.0, fill_factor))

    def generate_visualization_data(
        self, 
        tablespace: TablespaceInfo, 
        fragmentation_metrics: Dict[str, Any]
    ) -> TablespacePath:
        """
        Generate data for visualization of tablespace fragmentation.

        Args:
            tablespace: Tablespace information
            fragmentation_metrics: Fragmentation metrics dictionary

        Returns:
            Visualization data structure
        """
        # Extract needed metrics
        free_chunks = fragmentation_metrics.get("free_chunks", [])
        data_chunks = fragmentation_metrics.get("data_chunks", [])
        
        if not free_chunks and not data_chunks:
            # Create dummy data if no real chunks available
            return TablespacePath(
                x=[0.0, 0.5],
                y=[0.0, 0.0],
                width=[0.5, 0.5],
                height=[1.0, 1.0],
                type=["data", "free"],
                size_bytes=[tablespace.used_size_bytes, tablespace.free_size_bytes]
            )
        
        # Sort chunks by position
        all_chunks = [(pos, size, "data") for pos, size in data_chunks]
        all_chunks.extend([(pos, size, "free") for pos, size in free_chunks])
        all_chunks.sort(key=lambda x: x[0])
        
        # Calculate total tablespace size
        total_size = tablespace.total_size_bytes
        
        # Initialize visualization data
        x_positions = []
        y_positions = []
        widths = []
        heights = []
        types = []
        sizes = []
        
        # Process each chunk
        current_pos = 0
        for chunk_pos, chunk_size, chunk_type in all_chunks:
            # Skip invalid chunks
            if chunk_size <= 0 or total_size <= 0:
                continue
                
            # Calculate normalized position and width
            norm_pos = current_pos / total_size
            norm_width = chunk_size / total_size
            
            # Add to visualization data
            x_positions.append(norm_pos)
            y_positions.append(0.0)  # Use single row layout
            widths.append(norm_width)
            heights.append(1.0)  # Full height
            types.append(chunk_type)
            sizes.append(chunk_size)
            
            # Update current position
            current_pos += chunk_size
            
        return TablespacePath(
            x=x_positions,
            y=y_positions,
            width=widths,
            height=heights,
            type=types,
            size_bytes=sizes
        )

    def generate_recommendations(
        self, metrics: List[FragmentationMetrics]
    ) -> List[OptimizationRecommendation]:
        """
        Generate optimization recommendations based on fragmentation analysis.

        Args:
            metrics: List of fragmentation metrics for tablespaces

        Returns:
            List of optimization recommendations
        """
        recommendations = []
        
        # Sort metrics by severity (most severe first)
        sorted_metrics = sorted(
            metrics,
            key=lambda m: (
                {"critical": 0, "high": 1, "moderate": 2, "low": 3, "negligible": 4}[m.severity.value],
                -m.fragmentation_percent
            )
        )
        
        # Generate recommendations for each tablespace
        for metric in sorted_metrics:
            # Skip tablespaces with negligible fragmentation
            if metric.severity == FragmentationSeverity.NEGLIGIBLE:
                continue
                
            # Skip if reorganization benefit is too low
            if metric.estimated_reorganization_benefit_percent < self.min_reorganization_benefit_percent:
                continue
                
            # Generate recommendation based on severity and type
            if metric.severity in [FragmentationSeverity.CRITICAL, FragmentationSeverity.HIGH]:
                # For critical and high severity, recommend immediate reorganization
                reorganization_method = self._get_reorganization_method(metric.tablespace.engine)
                
                recommendations.append(
                    OptimizationRecommendation(
                        id=f"FRAG-REORG-{uuid.uuid4().hex[:6]}",
                        title=f"Reorganize highly fragmented tablespace {metric.tablespace.name}",
                        description=(
                            f"Perform {reorganization_method} on tablespace {metric.tablespace.name} "
                            f"which has {metric.fragmentation_percent:.1f}% {metric.fragmentation_type.value} "
                            f"fragmentation. Reorganization is estimated to recover "
                            f"{(metric.tablespace.total_size_bytes * metric.estimated_reorganization_benefit_percent / 100) / (1024*1024):.1f} MB "
                            f"of space and improve query performance."
                        ),
                        priority=OptimizationPriority.HIGH if metric.severity == FragmentationSeverity.CRITICAL else OptimizationPriority.MEDIUM,
                        estimated_space_savings_bytes=int(metric.tablespace.total_size_bytes * metric.estimated_reorganization_benefit_percent / 100),
                        estimated_performance_impact_percent=min(30.0, metric.estimated_reorganization_benefit_percent * 0.8),
                        implementation_complexity="medium",
                        affected_files=metric.tablespace.file_paths,
                    )
                )
                
                # For critical fragmentation, also recommend fill factor adjustment
                if metric.severity == FragmentationSeverity.CRITICAL and metric.optimal_fill_factor is not None:
                    recommendations.append(
                        OptimizationRecommendation(
                            id=f"FRAG-FILL-{uuid.uuid4().hex[:6]}",
                            title=f"Adjust fill factor for tablespace {metric.tablespace.name}",
                            description=(
                                f"Adjust fill factor to {metric.optimal_fill_factor:.1f}% for tablespace "
                                f"{metric.tablespace.name} to reduce future fragmentation. "
                                f"Current high fragmentation indicates the current fill factor may be too aggressive."
                            ),
                            priority=OptimizationPriority.MEDIUM,
                            estimated_space_savings_bytes=0,  # No immediate space savings
                            estimated_performance_impact_percent=5.0,  # Moderate performance impact
                            implementation_complexity="low",
                            affected_files=metric.tablespace.file_paths,
                        )
                    )
            
            elif metric.severity == FragmentationSeverity.MODERATE:
                # For moderate severity, recommend scheduled reorganization
                reorganization_method = self._get_reorganization_method(metric.tablespace.engine)
                
                recommendations.append(
                    OptimizationRecommendation(
                        id=f"FRAG-SCHED-{uuid.uuid4().hex[:6]}",
                        title=f"Schedule reorganization for tablespace {metric.tablespace.name}",
                        description=(
                            f"Schedule {reorganization_method} for tablespace {metric.tablespace.name} "
                            f"which has moderate fragmentation ({metric.fragmentation_percent:.1f}%). "
                            f"This can be performed during a maintenance window to optimize "
                            f"space usage and query performance."
                        ),
                        priority=OptimizationPriority.LOW,
                        estimated_space_savings_bytes=int(metric.tablespace.total_size_bytes * metric.estimated_reorganization_benefit_percent / 100),
                        estimated_performance_impact_percent=metric.estimated_reorganization_benefit_percent * 0.5,
                        implementation_complexity="medium",
                        affected_files=metric.tablespace.file_paths,
                    )
                )
            
            # Recommendation for growth trend if space is running low
            if metric.days_until_full is not None and metric.days_until_full < 60:
                recommendations.append(
                    OptimizationRecommendation(
                        id=f"FRAG-GROW-{uuid.uuid4().hex[:6]}",
                        title=f"Address space shortage in tablespace {metric.tablespace.name}",
                        description=(
                            f"Tablespace {metric.tablespace.name} is projected to run out of space "
                            f"in {metric.days_until_full} days at current growth rate. "
                            f"Consider adding space, purging old data, or implementing archiving "
                            f"to prevent operational issues."
                        ),
                        priority=OptimizationPriority.HIGH if metric.days_until_full < 30 else OptimizationPriority.MEDIUM,
                        estimated_space_savings_bytes=0,  # This is about adding space, not saving it
                        estimated_performance_impact_percent=0.0,
                        implementation_complexity="medium" if metric.tablespace.autoextend else "high",
                        affected_files=metric.tablespace.file_paths,
                    )
                )
        
        return recommendations

    def _get_reorganization_method(self, engine: DatabaseEngine) -> str:
        """Get the appropriate reorganization method for a database engine."""
        methods = {
            DatabaseEngine.MYSQL: "OPTIMIZE TABLE",
            DatabaseEngine.POSTGRESQL: "VACUUM FULL",
            DatabaseEngine.ORACLE: "table reorganization",
            DatabaseEngine.MSSQL: "DBCC DBREINDEX and DBCC SHRINKFILE",
            DatabaseEngine.MONGODB: "compact operation",
        }
        return methods.get(engine, "reorganization")

    def analyze_tablespace_fragmentation(
        self, 
        tablespaces: List[TablespaceInfo],
        fragmentation_data: Dict[str, Dict[str, Any]] = None,
    ) -> FragmentationAnalysisResult:
        """
        Analyze tablespace fragmentation and generate visualization data.

        Args:
            tablespaces: List of tablespace information
            fragmentation_data: Dictionary with raw fragmentation data by tablespace name

        Returns:
            Fragmentation analysis result
        """
        start_time = datetime.now()
        fragmentation_data = fragmentation_data or {}
        
        try:
            # Calculate metrics for each tablespace
            metrics_list = []
            visualization_data = {}
            
            for tablespace in tablespaces:
                # Use provided fragmentation data or generate placeholder
                ts_data = fragmentation_data.get(tablespace.name, {})
                
                # Extract fragmentation percentage
                fragmentation_percent = ts_data.get("fragmentation_percent", 0.0)
                
                # Determine fragmentation type
                frag_type_str = ts_data.get("fragmentation_type", "mixed")
                fragmentation_type = getattr(FragmentationType, frag_type_str.upper()) if hasattr(FragmentationType, frag_type_str.upper()) else FragmentationType.MIXED
                
                # Calculate free chunks metrics
                free_chunks = ts_data.get("free_chunks_sizes", [])
                free_chunks_count = len(free_chunks)
                largest_free_chunk = max(free_chunks) if free_chunks else 0
                avg_free_chunk_size = sum(free_chunks) / free_chunks_count if free_chunks_count > 0 else 0
                
                # Determine free space distribution
                free_space_distribution = self.analyze_free_space_distribution(
                    free_chunks, tablespace.free_size_bytes
                )
                
                # Determine severity
                severity = self.detect_fragmentation_severity(fragmentation_percent)
                
                # Calculate growth trend
                growth_trend = ts_data.get("growth_bytes_per_day")
                days_until_full = None
                if growth_trend and growth_trend > 0 and tablespace.free_size_bytes > 0:
                    days_until_full = int(tablespace.free_size_bytes / growth_trend)
                
                # Calculate optimal fill factor
                optimal_fill_factor = self.calculate_optimal_fill_factor(
                    fragmentation_percent, growth_trend,
                    tablespace.total_size_bytes, tablespace.free_size_bytes
                )
                
                # Estimate reorganization benefit
                reorganization_benefit = self.estimate_reorganization_benefit(
                    fragmentation_percent, fragmentation_type, free_space_distribution
                )
                
                # Create metrics object
                metrics = FragmentationMetrics(
                    tablespace=tablespace,
                    fragmentation_percent=fragmentation_percent,
                    fragmentation_type=fragmentation_type,
                    severity=severity,
                    free_space_distribution=free_space_distribution,
                    largest_contiguous_free_chunk_bytes=largest_free_chunk,
                    free_chunks_count=free_chunks_count,
                    avg_free_chunk_size_bytes=avg_free_chunk_size,
                    growth_trend_bytes_per_day=growth_trend,
                    days_until_full=days_until_full,
                    optimal_fill_factor=optimal_fill_factor,
                    estimated_reorganization_benefit_percent=reorganization_benefit,
                )
                
                metrics_list.append(metrics)
                
                # Generate visualization data
                visualization_data[tablespace.name] = self.generate_visualization_data(
                    tablespace, ts_data
                )
            
            # Calculate overall statistics
            total_size = sum(ts.total_size_bytes for ts in tablespaces)
            free_space = sum(ts.free_size_bytes for ts in tablespaces)
            
            # Count tablespaces by severity
            severity_counts = defaultdict(int)
            for metric in metrics_list:
                severity_counts[metric.severity] += 1
            
            # Calculate total reorganization benefit
            total_reorg_benefit = sum(
                int(metric.tablespace.total_size_bytes * metric.estimated_reorganization_benefit_percent / 100)
                for metric in metrics_list
            )
            
            # Estimate recovery time (rough estimate based on database size)
            # Assume 1GB per minute as a baseline recovery rate
            estimated_recovery_hours = total_size / (1024 * 1024 * 1024 * 60) 
            
            # Generate recommendations
            recommendations = self.generate_recommendations(metrics_list)
            
            # Create result
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            return FragmentationAnalysisResult(
                analysis_duration_seconds=duration,
                scan_status=ScanStatus.COMPLETED,
                total_tablespaces=len(tablespaces),
                total_size_bytes=total_size,
                free_space_bytes=free_space,
                fragmented_tablespaces=metrics_list,
                tablespaces_by_severity=dict(severity_counts),
                total_reorganization_benefit_bytes=total_reorg_benefit,
                visualization_data=visualization_data,
                estimated_recovery_time_hours=estimated_recovery_hours,
                recommendations=recommendations,
            )
            
        except Exception as e:
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            logger.error(f"Error in tablespace fragmentation analysis: {e}")
            
            return FragmentationAnalysisResult(
                analysis_duration_seconds=duration,
                scan_status=ScanStatus.FAILED,
                error_message=str(e),
                total_tablespaces=0,
                total_size_bytes=0,
                free_space_bytes=0,
                fragmented_tablespaces=[],
                tablespaces_by_severity={},
                total_reorganization_benefit_bytes=0,
                visualization_data={},
                estimated_recovery_time_hours=0,
            )