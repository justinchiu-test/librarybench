{
    "total_logprobs": -78073.81155136993,
    "total_tokens": 128365,
    "unified/ethical_finance/impact_measurement/impact.py": {
        "logprobs": -3640.4791135726796,
        "metrics": {
            "loc": 800,
            "sloc": 502,
            "lloc": 302,
            "comments": 99,
            "multi": 84,
            "blank": 132,
            "cyclomatic": 113,
            "internal_imports": [
                "class BaseAnalyzer(Generic[T, R], ABC):\n    \"\"\"\n    Abstract base class for analysis engines.\n    \n    Defines the core interface and functionality for all analyzers\n    across different persona implementations.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the analyzer.\"\"\"\n        self._analysis_cache: Dict[str, R] = {}\n    \n    @abstractmethod\n    def analyze(\n        self, subject: T, parameters: Optional[AnalysisParameters] = None\n    ) -> R:\n        \"\"\"\n        Analyze a single subject.\n        \n        Args:\n            subject: The subject to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Analysis result\n        \"\"\"\n        pass\n    \n    def analyze_batch(\n        self, subjects: List[T], parameters: Optional[AnalysisParameters] = None\n    ) -> List[R]:\n        \"\"\"\n        Analyze multiple subjects.\n        \n        Args:\n            subjects: List of subjects to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            List of analysis results\n        \"\"\"\n        # Start performance timer\n        start_time = time.time()\n        \n        # Analyze each subject\n        results = []\n        for subject in subjects:\n            result = self.analyze(subject, parameters)\n            results.append(result)\n        \n        # Performance metrics\n        elapsed_time = time.time() - start_time\n        \n        return results\n    \n    def clear_cache(self) -> None:\n        \"\"\"Clear the analysis cache.\"\"\"\n        self._analysis_cache = {}\n    \n    def _generate_cache_key(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> str:\n        \"\"\"\n        Generate a cache key for a subject and parameters.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cache key string\n        \"\"\"\n        # Start with the subject ID\n        key = f\"subject_{subject_id}\"\n        \n        # Add parameter details if provided\n        if parameters:\n            param_dict = parameters.dict(exclude_none=True)\n            for k, v in sorted(param_dict.items()):\n                if k != \"custom_settings\":\n                    key += f\"_{k}_{v}\"\n                    \n            # Handle custom settings separately (they could be complex)\n            if parameters.custom_settings:\n                for k, v in sorted(parameters.custom_settings.items()):\n                    key += f\"_{k}_{v}\"\n        \n        return key\n    \n    def _get_from_cache(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> Optional[R]:\n        \"\"\"\n        Get a cached analysis result if available.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cached result or None if not found\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        return self._analysis_cache.get(cache_key)\n    \n    def _save_to_cache(\n        self, subject_id: Union[str, UUID], result: R, parameters: Optional[AnalysisParameters] = None\n    ) -> None:\n        \"\"\"\n        Save an analysis result to the cache.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            result: The analysis result to cache\n            parameters: Optional parameters to configure the analysis\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        self._analysis_cache[cache_key] = result",
                "class AnalysisParameters(BaseModel):\n    \"\"\"\n    Parameters for an analysis operation.\n    \n    Used to configure analysis options and settings.\n    \"\"\"\n    \n    period_start: Optional[Union[date, datetime]] = None\n    period_end: Optional[Union[date, datetime]] = None\n    include_details: bool = True\n    calculation_mode: str = \"standard\"  # \"standard\", \"detailed\", \"fast\"\n    grouping: Optional[str] = None\n    custom_settings: Dict[str, Any] = Field(default_factory=dict)",
                "class AnalysisResult(BaseModel, Generic[T]):\n    \"\"\"\n    Result of an analysis operation.\n    \n    Provides information about the analysis process and outcome.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    subject_id: Optional[Union[str, UUID]] = None\n    subject_type: str\n    analysis_type: str\n    analysis_date: datetime = Field(default_factory=datetime.now)\n    processing_time_ms: Optional[float] = None\n    result_summary: Dict[str, Any] = Field(default_factory=dict)\n    detailed_results: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Timer:\n    \"\"\"Utility for measuring execution time.\"\"\"\n    \n    def __init__(self, name: Optional[str] = None):\n        \"\"\"\n        Initialize the timer.\n        \n        Args:\n            name: Optional name for the timer\n        \"\"\"\n        self.name = name\n        self.start_time: Optional[float] = None\n        self.end_time: Optional[float] = None\n    \n    def __enter__(self) -> 'Timer':\n        \"\"\"Start the timer when entering a context.\"\"\"\n        self.start()\n        return self\n    \n    def __exit__(self, *args: Any) -> None:\n        \"\"\"Stop the timer when exiting a context.\"\"\"\n        self.stop()\n    \n    def start(self) -> None:\n        \"\"\"Start the timer.\"\"\"\n        self.start_time = time.time()\n        self.end_time = None\n    \n    def stop(self) -> float:\n        \"\"\"\n        Stop the timer.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        self.end_time = time.time()\n        return self.elapsed_time\n    \n    @property\n    def elapsed_time(self) -> float:\n        \"\"\"\n        Get the elapsed time.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        end = self.end_time if self.end_time is not None else time.time()\n        return end - self.start_time\n    \n    @property\n    def elapsed_milliseconds(self) -> float:\n        \"\"\"\n        Get the elapsed time in milliseconds.\n        \n        Returns:\n            Elapsed time in milliseconds\n        \"\"\"\n        return self.elapsed_time * 1000",
                "def memoize(func: F = None, *, max_size: int = 1000, ttl_seconds: Optional[int] = None) -> F:\n    \"\"\"\n    Decorator to memoize a function's return value with optional max size and TTL.\n    \n    Can be used with or without arguments:\n    @memoize  # No arguments\n    def func():\n        ...\n        \n    @memoize(max_size=100, ttl_seconds=3600)  # With arguments\n    def func():\n        ...\n    \n    Args:\n        func: The function to memoize (when used without arguments)\n        max_size: Maximum number of items to store in cache (default: 1000)\n        ttl_seconds: Time-to-live in seconds (default: None, meaning no expiration)\n        \n    Returns:\n        Memoized function\n    \"\"\"\n    def decorator(f: F) -> F:\n        # Cache stores tuples of (result, timestamp) if TTL is specified, otherwise just result\n        cache: Dict[str, Union[Any, Tuple[Any, float]]] = {}\n        \n        @functools.wraps(f)\n        def wrapper(*args: Any, **kwargs: Any) -> Any:\n            # Create a cache key from the function arguments\n            key = _create_cache_key(f, args, kwargs)\n            \n            # Check if we need to enforce max size\n            if len(cache) >= max_size and key not in cache:\n                # Remove oldest item (simple implementation)\n                if ttl_seconds is not None:\n                    # If using TTL, find oldest by timestamp\n                    oldest_key = min(cache.items(), key=lambda x: x[1][1])[0]\n                else:\n                    # Otherwise just remove the first key\n                    oldest_key = next(iter(cache))\n                del cache[oldest_key]\n            \n            # Check if result is in cache\n            if key in cache:\n                if ttl_seconds is not None:\n                    # Check if expired when using TTL\n                    result, timestamp = cache[key]  # type: ignore\n                    if time.time() - timestamp < ttl_seconds:\n                        return result\n                    # If expired, remove from cache and recalculate\n                else:\n                    # No TTL, just return cached result\n                    return cache[key]\n            \n            # Call the function and cache the result\n            result = f(*args, **kwargs)\n            \n            if ttl_seconds is not None:\n                # Store with timestamp if using TTL\n                cache[key] = (result, time.time())\n            else:\n                # Store just the result otherwise\n                cache[key] = result\n            \n            return result\n        \n        # Add cache management functions\n        wrapper.cache = cache  # type: ignore\n        wrapper.cache_clear = cache.clear  # type: ignore\n        wrapper.cache_size = lambda: len(cache)  # type: ignore\n        \n        return cast(F, wrapper)\n    \n    # Handle both @memoize and @memoize(args) syntax\n    if func is None:\n        return decorator\n    return decorator(func)",
                "class ImpactMetric(BaseModel):\n    \"\"\"\n    Impact metric model for defining and tracking non-financial impacts.\n    \n    Used for measuring the social and environmental impact of investments.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    category: str\n    unit: str\n    description: str\n    higher_is_better: bool\n    data_source: str",
                "class ImpactData(BaseModel):\n    \"\"\"\n    Impact data for a specific investment in a specific year.\n    \n    Used for tracking the actual impact of investments over time.\n    \"\"\"\n\n    investment_id: str\n    year: int\n    metrics: Dict[str, float]\n    \n    @validator(\"year\")\n    def validate_year(cls, v):\n        \"\"\"Validate that year is reasonable.\"\"\"\n        current_year = datetime.now().year\n        if v < 1900 or v > current_year + 1:\n            raise ValueError(f\"Year {v} is outside reasonable range\")\n        return v",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Portfolio(BasePortfolio):\n    \"\"\"A collection of investment holdings.\"\"\"\n    \n    # These fields come from BasePortfolio:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # holdings: List[InvestmentHolding] = Field(default_factory=list)\n    # total_value: float\n    # cash_balance: float\n    # creation_date: Union[date, datetime]\n    # last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Portfolio(BasePortfolio):\n    \"\"\"A collection of investment holdings.\"\"\"\n    \n    # These fields come from BasePortfolio:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # holdings: List[InvestmentHolding] = Field(default_factory=list)\n    # total_value: float\n    # cash_balance: float\n    # creation_date: Union[date, datetime]\n    # last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Portfolio(BasePortfolio):\n    \"\"\"A collection of investment holdings.\"\"\"\n    \n    # These fields come from BasePortfolio:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # holdings: List[InvestmentHolding] = Field(default_factory=list)\n    # total_value: float\n    # cash_balance: float\n    # creation_date: Union[date, datetime]\n    # last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Portfolio(BasePortfolio):\n    \"\"\"A collection of investment holdings.\"\"\"\n    \n    # These fields come from BasePortfolio:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # holdings: List[InvestmentHolding] = Field(default_factory=list)\n    # total_value: float\n    # cash_balance: float\n    # creation_date: Union[date, datetime]\n    # last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Portfolio(BasePortfolio):\n    \"\"\"A collection of investment holdings.\"\"\"\n    \n    # These fields come from BasePortfolio:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # holdings: List[InvestmentHolding] = Field(default_factory=list)\n    # total_value: float\n    # cash_balance: float\n    # creation_date: Union[date, datetime]\n    # last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Portfolio(BasePortfolio):\n    \"\"\"A collection of investment holdings.\"\"\"\n    \n    # These fields come from BasePortfolio:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # holdings: List[InvestmentHolding] = Field(default_factory=list)\n    # total_value: float\n    # cash_balance: float\n    # creation_date: Union[date, datetime]\n    # last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class ImpactMetric(CommonImpactMetric):\n    \"\"\"Model for defining and tracking impact metrics.\"\"\"\n    \n    # All fields come from CommonImpactMetric\n    \n    @classmethod\n    def from_common_metric(cls, common_metric: CommonImpactMetric) -> \"ImpactMetric\":\n        \"\"\"Convert from common model to specialized model.\"\"\"\n        return cls(\n            id=common_metric.id,\n            name=common_metric.name,\n            category=common_metric.category,\n            unit=common_metric.unit,\n            description=common_metric.description,\n            higher_is_better=common_metric.higher_is_better,\n            data_source=common_metric.data_source\n        )\n    \n    def to_common_metric(self) -> CommonImpactMetric:\n        \"\"\"Convert to common model.\"\"\"\n        return CommonImpactMetric(\n            id=self.id,\n            name=self.name,\n            category=self.category,\n            unit=self.unit,\n            description=self.description,\n            higher_is_better=self.higher_is_better,\n            data_source=self.data_source\n        )\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class ImpactMetric(CommonImpactMetric):\n    \"\"\"Model for defining and tracking impact metrics.\"\"\"\n    \n    # All fields come from CommonImpactMetric\n    \n    @classmethod\n    def from_common_metric(cls, common_metric: CommonImpactMetric) -> \"ImpactMetric\":\n        \"\"\"Convert from common model to specialized model.\"\"\"\n        return cls(\n            id=common_metric.id,\n            name=common_metric.name,\n            category=common_metric.category,\n            unit=common_metric.unit,\n            description=common_metric.description,\n            higher_is_better=common_metric.higher_is_better,\n            data_source=common_metric.data_source\n        )\n    \n    def to_common_metric(self) -> CommonImpactMetric:\n        \"\"\"Convert to common model.\"\"\"\n        return CommonImpactMetric(\n            id=self.id,\n            name=self.name,\n            category=self.category,\n            unit=self.unit,\n            description=self.description,\n            higher_is_better=self.higher_is_better,\n            data_source=self.data_source\n        )\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class ImpactMetric(CommonImpactMetric):\n    \"\"\"Model for defining and tracking impact metrics.\"\"\"\n    \n    # All fields come from CommonImpactMetric\n    \n    @classmethod\n    def from_common_metric(cls, common_metric: CommonImpactMetric) -> \"ImpactMetric\":\n        \"\"\"Convert from common model to specialized model.\"\"\"\n        return cls(\n            id=common_metric.id,\n            name=common_metric.name,\n            category=common_metric.category,\n            unit=common_metric.unit,\n            description=common_metric.description,\n            higher_is_better=common_metric.higher_is_better,\n            data_source=common_metric.data_source\n        )\n    \n    def to_common_metric(self) -> CommonImpactMetric:\n        \"\"\"Convert to common model.\"\"\"\n        return CommonImpactMetric(\n            id=self.id,\n            name=self.name,\n            category=self.category,\n            unit=self.unit,\n            description=self.description,\n            higher_is_better=self.higher_is_better,\n            data_source=self.data_source\n        )\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class ImpactMetric(CommonImpactMetric):\n    \"\"\"Model for defining and tracking impact metrics.\"\"\"\n    \n    # All fields come from CommonImpactMetric\n    \n    @classmethod\n    def from_common_metric(cls, common_metric: CommonImpactMetric) -> \"ImpactMetric\":\n        \"\"\"Convert from common model to specialized model.\"\"\"\n        return cls(\n            id=common_metric.id,\n            name=common_metric.name,\n            category=common_metric.category,\n            unit=common_metric.unit,\n            description=common_metric.description,\n            higher_is_better=common_metric.higher_is_better,\n            data_source=common_metric.data_source\n        )\n    \n    def to_common_metric(self) -> CommonImpactMetric:\n        \"\"\"Convert to common model.\"\"\"\n        return CommonImpactMetric(\n            id=self.id,\n            name=self.name,\n            category=self.category,\n            unit=self.unit,\n            description=self.description,\n            higher_is_better=self.higher_is_better,\n            data_source=self.data_source\n        )\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class ImpactMetric(CommonImpactMetric):\n    \"\"\"Model for defining and tracking impact metrics.\"\"\"\n    \n    # All fields come from CommonImpactMetric\n    \n    @classmethod\n    def from_common_metric(cls, common_metric: CommonImpactMetric) -> \"ImpactMetric\":\n        \"\"\"Convert from common model to specialized model.\"\"\"\n        return cls(\n            id=common_metric.id,\n            name=common_metric.name,\n            category=common_metric.category,\n            unit=common_metric.unit,\n            description=common_metric.description,\n            higher_is_better=common_metric.higher_is_better,\n            data_source=common_metric.data_source\n        )\n    \n    def to_common_metric(self) -> CommonImpactMetric:\n        \"\"\"Convert to common model.\"\"\"\n        return CommonImpactMetric(\n            id=self.id,\n            name=self.name,\n            category=self.category,\n            unit=self.unit,\n            description=self.description,\n            higher_is_better=self.higher_is_better,\n            data_source=self.data_source\n        )\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class ImpactMetric(CommonImpactMetric):\n    \"\"\"Model for defining and tracking impact metrics.\"\"\"\n    \n    # All fields come from CommonImpactMetric\n    \n    @classmethod\n    def from_common_metric(cls, common_metric: CommonImpactMetric) -> \"ImpactMetric\":\n        \"\"\"Convert from common model to specialized model.\"\"\"\n        return cls(\n            id=common_metric.id,\n            name=common_metric.name,\n            category=common_metric.category,\n            unit=common_metric.unit,\n            description=common_metric.description,\n            higher_is_better=common_metric.higher_is_better,\n            data_source=common_metric.data_source\n        )\n    \n    def to_common_metric(self) -> CommonImpactMetric:\n        \"\"\"Convert to common model.\"\"\"\n        return CommonImpactMetric(\n            id=self.id,\n            name=self.name,\n            category=self.category,\n            unit=self.unit,\n            description=self.description,\n            higher_is_better=self.higher_is_better,\n            data_source=self.data_source\n        )\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class ImpactData(CommonImpactData):\n    \"\"\"Impact data for a specific investment in a specific year.\"\"\"\n    \n    # All fields come from CommonImpactData\n    \n    @classmethod\n    def from_common_data(cls, common_data: CommonImpactData) -> \"ImpactData\":\n        \"\"\"Convert from common model to specialized model.\"\"\"\n        return cls(\n            investment_id=common_data.investment_id,\n            year=common_data.year,\n            metrics=common_data.metrics\n        )\n    \n    def to_common_data(self) -> CommonImpactData:\n        \"\"\"Convert to common model.\"\"\"\n        return CommonImpactData(\n            investment_id=self.investment_id,\n            year=self.year,\n            metrics=self.metrics\n        )\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class ImpactData(CommonImpactData):\n    \"\"\"Impact data for a specific investment in a specific year.\"\"\"\n    \n    # All fields come from CommonImpactData\n    \n    @classmethod\n    def from_common_data(cls, common_data: CommonImpactData) -> \"ImpactData\":\n        \"\"\"Convert from common model to specialized model.\"\"\"\n        return cls(\n            investment_id=common_data.investment_id,\n            year=common_data.year,\n            metrics=common_data.metrics\n        )\n    \n    def to_common_data(self) -> CommonImpactData:\n        \"\"\"Convert to common model.\"\"\"\n        return CommonImpactData(\n            investment_id=self.investment_id,\n            year=self.year,\n            metrics=self.metrics\n        )\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class ImpactData(CommonImpactData):\n    \"\"\"Impact data for a specific investment in a specific year.\"\"\"\n    \n    # All fields come from CommonImpactData\n    \n    @classmethod\n    def from_common_data(cls, common_data: CommonImpactData) -> \"ImpactData\":\n        \"\"\"Convert from common model to specialized model.\"\"\"\n        return cls(\n            investment_id=common_data.investment_id,\n            year=common_data.year,\n            metrics=common_data.metrics\n        )\n    \n    def to_common_data(self) -> CommonImpactData:\n        \"\"\"Convert to common model.\"\"\"\n        return CommonImpactData(\n            investment_id=self.investment_id,\n            year=self.year,\n            metrics=self.metrics\n        )\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class ImpactData(CommonImpactData):\n    \"\"\"Impact data for a specific investment in a specific year.\"\"\"\n    \n    # All fields come from CommonImpactData\n    \n    @classmethod\n    def from_common_data(cls, common_data: CommonImpactData) -> \"ImpactData\":\n        \"\"\"Convert from common model to specialized model.\"\"\"\n        return cls(\n            investment_id=common_data.investment_id,\n            year=common_data.year,\n            metrics=common_data.metrics\n        )\n    \n    def to_common_data(self) -> CommonImpactData:\n        \"\"\"Convert to common model.\"\"\"\n        return CommonImpactData(\n            investment_id=self.investment_id,\n            year=self.year,\n            metrics=self.metrics\n        )\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class ImpactData(CommonImpactData):\n    \"\"\"Impact data for a specific investment in a specific year.\"\"\"\n    \n    # All fields come from CommonImpactData\n    \n    @classmethod\n    def from_common_data(cls, common_data: CommonImpactData) -> \"ImpactData\":\n        \"\"\"Convert from common model to specialized model.\"\"\"\n        return cls(\n            investment_id=common_data.investment_id,\n            year=common_data.year,\n            metrics=common_data.metrics\n        )\n    \n    def to_common_data(self) -> CommonImpactData:\n        \"\"\"Convert to common model.\"\"\"\n        return CommonImpactData(\n            investment_id=self.investment_id,\n            year=self.year,\n            metrics=self.metrics\n        )\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class ImpactData(CommonImpactData):\n    \"\"\"Impact data for a specific investment in a specific year.\"\"\"\n    \n    # All fields come from CommonImpactData\n    \n    @classmethod\n    def from_common_data(cls, common_data: CommonImpactData) -> \"ImpactData\":\n        \"\"\"Convert from common model to specialized model.\"\"\"\n        return cls(\n            investment_id=common_data.investment_id,\n            year=common_data.year,\n            metrics=common_data.metrics\n        )\n    \n    def to_common_data(self) -> CommonImpactData:\n        \"\"\"Convert to common model.\"\"\"\n        return CommonImpactData(\n            investment_id=self.investment_id,\n            year=self.year,\n            metrics=self.metrics\n        )\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True"
            ]
        }
    },
    "unified/tests/socially_responsible_investor/test_ethical_screening/__init__.py": {
        "logprobs": -176.29193783537,
        "metrics": {
            "loc": 1,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 0,
            "blank": 0,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/common/core/utils/performance.py": {
        "logprobs": -681.3784432063159,
        "metrics": {
            "loc": 271,
            "sloc": 114,
            "lloc": 132,
            "comments": 7,
            "multi": 81,
            "blank": 63,
            "cyclomatic": 36,
            "internal_imports": []
        }
    },
    "unified/personal_finance_tracker/income/__init__.py": {
        "logprobs": -241.6657962841,
        "metrics": {
            "loc": 5,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 4,
            "blank": 1,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/common/core/utils/validation.py": {
        "logprobs": -669.0492780260976,
        "metrics": {
            "loc": 316,
            "sloc": 88,
            "lloc": 92,
            "comments": 6,
            "multi": 134,
            "blank": 87,
            "cyclomatic": 36,
            "internal_imports": []
        }
    },
    "unified/common/core/reporting/report.py": {
        "logprobs": -1112.1454187869926,
        "metrics": {
            "loc": 330,
            "sloc": 151,
            "lloc": 193,
            "comments": 21,
            "multi": 80,
            "blank": 74,
            "cyclomatic": 63,
            "internal_imports": []
        }
    },
    "unified/tests/freelancer/expense/__init__.py": {
        "logprobs": -191.33415222343004,
        "metrics": {
            "loc": 1,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 0,
            "blank": 0,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/common/core/models/transaction.py": {
        "logprobs": -622.2337047891871,
        "metrics": {
            "loc": 132,
            "sloc": 78,
            "lloc": 122,
            "comments": 1,
            "multi": 13,
            "blank": 31,
            "cyclomatic": 28,
            "internal_imports": []
        }
    },
    "unified/common/core/__init__.py": {
        "logprobs": -229.8332207204829,
        "metrics": {
            "loc": 7,
            "sloc": 5,
            "lloc": 6,
            "comments": 0,
            "multi": 0,
            "blank": 1,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/common/core/categorization/investment_categorizer.py": {
        "logprobs": -1691.5891589292114,
        "metrics": {
            "loc": 373,
            "sloc": 196,
            "lloc": 172,
            "comments": 49,
            "multi": 56,
            "blank": 75,
            "cyclomatic": 65,
            "internal_imports": [
                "class BaseCategorizer(Generic[T, R], ABC):\n    \"\"\"\n    Abstract base class for categorization engines.\n    \n    Defines the core interface and functionality for all categorizers\n    across different persona implementations.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the categorizer.\"\"\"\n        self.rules: List[Rule] = []\n        self.audit_trail: List[AuditRecord] = []\n        self._categorization_cache: Dict[str, R] = {}\n        \n    def add_rule(self, rule: Rule) -> Rule:\n        \"\"\"\n        Add a new rule to the categorizer.\n        \n        Args:\n            rule: The rule to add\n            \n        Returns:\n            The added rule\n        \"\"\"\n        # Check for duplicate rule ID\n        if any(r.id == rule.id for r in self.rules):\n            raise ValueError(f\"Rule with ID {rule.id} already exists\")\n        \n        # Add the rule\n        self.rules.append(rule)\n        \n        # Sort rules by priority (highest first)\n        self.rules.sort(key=lambda r: r.priority, reverse=True)\n        \n        # Clear cache since rules have changed\n        self._categorization_cache = {}\n        \n        return rule\n    \n    def update_rule(self, rule: Rule) -> Rule:\n        \"\"\"\n        Update an existing rule.\n        \n        Args:\n            rule: The rule to update\n            \n        Returns:\n            The updated rule\n        \"\"\"\n        # Find the rule to update\n        for i, existing_rule in enumerate(self.rules):\n            if existing_rule.id == rule.id:\n                # Update the rule\n                rule.updated_at = datetime.now()\n                self.rules[i] = rule\n                \n                # Sort rules by priority (highest first)\n                self.rules.sort(key=lambda r: r.priority, reverse=True)\n                \n                # Clear cache since rules have changed\n                self._categorization_cache = {}\n                \n                return rule\n        \n        raise ValueError(f\"Rule with ID {rule.id} not found\")\n    \n    def remove_rule(self, rule_id: Union[str, UUID]) -> bool:\n        \"\"\"\n        Remove a rule.\n        \n        Args:\n            rule_id: ID of the rule to remove\n            \n        Returns:\n            True if the rule was removed, False otherwise\n        \"\"\"\n        # Find the rule to remove\n        for i, rule in enumerate(self.rules):\n            if rule.id == rule_id:\n                # Remove the rule\n                del self.rules[i]\n                \n                # Clear cache since rules have changed\n                self._categorization_cache = {}\n                \n                return True\n        \n        return False\n    \n    def get_rules(self) -> List[Rule]:\n        \"\"\"\n        Get all rules.\n        \n        Returns:\n            List of all rules\n        \"\"\"\n        return self.rules\n    \n    def get_audit_trail(\n        self, item_id: Optional[Union[str, UUID]] = None, limit: int = 100\n    ) -> List[AuditRecord]:\n        \"\"\"\n        Get the audit trail for categorization actions.\n        \n        Args:\n            item_id: Optional item ID to filter by\n            limit: Maximum number of records to return\n            \n        Returns:\n            List of audit records\n        \"\"\"\n        if item_id:\n            # Filter to specific item\n            filtered_trail = [\n                record\n                for record in self.audit_trail\n                if record.item_id == item_id\n            ]\n        else:\n            filtered_trail = self.audit_trail\n        \n        # Sort by timestamp (newest first) and limit\n        sorted_trail = sorted(filtered_trail, key=lambda r: r.timestamp, reverse=True)\n        \n        return sorted_trail[:limit]\n    \n    def clear_cache(self) -> None:\n        \"\"\"Clear the categorization cache.\"\"\"\n        self._categorization_cache = {}\n    \n    @abstractmethod\n    def categorize(self, item: T, recategorize: bool = False) -> R:\n        \"\"\"\n        Categorize a single item.\n        \n        Args:\n            item: The item to categorize\n            recategorize: Whether to recategorize even if already categorized\n            \n        Returns:\n            Categorization result\n        \"\"\"\n        pass\n    \n    def categorize_batch(self, items: List[T], recategorize: bool = False) -> List[R]:\n        \"\"\"\n        Categorize multiple items.\n        \n        Args:\n            items: List of items to categorize\n            recategorize: Whether to recategorize even if already categorized\n            \n        Returns:\n            List of categorization results\n        \"\"\"\n        # Start performance timer\n        start_time = time.time()\n        \n        # Categorize each item\n        results = []\n        for item in items:\n            result = self.categorize(item, recategorize)\n            results.append(result)\n        \n        # Performance metrics\n        elapsed_time = time.time() - start_time\n        \n        return results\n    \n    def record_audit(\n        self,\n        item_id: Union[str, UUID],\n        action: str,\n        previous_state: Dict[str, Any],\n        new_state: Dict[str, Any],\n        notes: Optional[str] = None,\n    ) -> AuditRecord:\n        \"\"\"\n        Record an action in the audit trail.\n        \n        Args:\n            item_id: ID of the item being modified\n            action: Type of action performed\n            previous_state: State before the action\n            new_state: State after the action\n            notes: Optional notes about the action\n            \n        Returns:\n            The created audit record\n        \"\"\"\n        audit_record = AuditRecord(\n            item_id=item_id,\n            action=action,\n            previous_state=previous_state,\n            new_state=new_state,\n            notes=notes,\n        )\n        \n        self.audit_trail.append(audit_record)\n        \n        return audit_record",
                "class CategorizationResult(BaseModel, Generic[T]):\n    \"\"\"\n    Result of a categorization operation.\n    \n    Provides information about the categorization process and outcome.\n    \"\"\"\n    \n    item_id: Union[str, UUID]\n    original_item: T\n    assigned_category: Optional[str] = None\n    confidence_score: float  # 0.0 to 1.0\n    matched_rule: Optional[Rule] = None\n    processing_time_ms: Optional[float] = None\n    notes: Optional[str] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Rule(BaseModel, ABC):\n    \"\"\"\n    Abstract base class for categorization rules.\n    \n    Defines the interface for all rules used in categorization\n    across different persona implementations.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    description: Optional[str] = None\n    priority: int = 0  # Higher numbers have higher priority\n    created_at: datetime = Field(default_factory=datetime.now)\n    updated_at: datetime = Field(default_factory=datetime.now)\n    is_active: bool = True\n    \n    @abstractmethod\n    def matches(self, item: Any) -> bool:\n        \"\"\"\n        Check if this rule matches the given item.\n        \n        Args:\n            item: The item to check against this rule\n            \n        Returns:\n            True if the rule matches, False otherwise\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def apply(self, item: Any) -> Any:\n        \"\"\"\n        Apply this rule to the given item.\n        \n        Args:\n            item: The item to apply this rule to\n            \n        Returns:\n            The result of applying the rule\n        \"\"\"\n        pass\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(BaseModel):\n    \"\"\"\n    Investment model representing an investment opportunity.\n    \n    Used for tracking investment options, ESG ratings, and performance.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    sector: str\n    industry: str\n    market_cap: float\n    price: float\n    esg_ratings: ESGRating\n    carbon_footprint: float\n    renewable_energy_use: float\n    diversity_score: float\n    board_independence: float\n    controversies: List[str] = Field(default_factory=list)\n    positive_practices: List[str] = Field(default_factory=list)\n    \n    @property\n    def has_major_controversies(self) -> bool:\n        \"\"\"Check if the investment has major controversies.\"\"\"\n        major_issues = [\"human_rights\", \"fraud\", \"corruption\", \"environmental_disaster\"]\n        return any(issue in self.controversies for issue in major_issues)\n    \n    @validator(\"market_cap\", \"price\", \"carbon_footprint\")\n    def validate_positive_numbers(cls, v):\n        \"\"\"Validate that financial amounts are positive numbers.\"\"\"\n        if v < 0:\n            raise ValueError(\"Value must be a positive number\")\n        return v\n    \n    @validator(\"renewable_energy_use\", \"diversity_score\", \"board_independence\")\n    def validate_percentage(cls, v):\n        \"\"\"Validate that percentages are between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Value must be between 0 and 1\")\n        return v",
                "class EthicalCriteria(BaseModel):\n    \"\"\"\n    Ethical screening criteria for investments.\n    \n    Used for evaluating investments against personalized ethical standards.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    environmental: Dict[str, Any]\n    social: Dict[str, Any]\n    governance: Dict[str, Any]\n    min_overall_score: float\n    exclusions: List[str] = Field(default_factory=list)\n    inclusions: List[str] = Field(default_factory=list)\n    \n    @root_validator(skip_on_failure=True)\n    def validate_criteria_weights(cls, values):\n        \"\"\"Validate that criteria weights are included and sum approximately to 1.\"\"\"\n        for field_name in ['environmental', 'social', 'governance']:\n            field_value = values.get(field_name, {})\n            \n            # Check that weight exists\n            if 'weight' not in field_value:\n                raise ValueError(f\"{field_name} criteria must include a weight\")\n            \n            # Ensure weight is between 0 and 1\n            if field_value['weight'] < 0 or field_value['weight'] > 1:\n                raise ValueError(f\"{field_name} weight must be between 0 and 1\")\n        \n        # Check that weights sum to approximately 1\n        weights_sum = (\n            values.get('environmental', {}).get('weight', 0) + \n            values.get('social', {}).get('weight', 0) + \n            values.get('governance', {}).get('weight', 0)\n        )\n        \n        if abs(weights_sum - 1.0) > 0.01:  # Allow for small rounding errors\n            raise ValueError(f\"Criteria weights sum to {weights_sum}, expected 1.0\")\n            \n        return values",
                "class ESGRating(BaseModel):\n    \"\"\"Environmental, Social, and Governance ratings for an investment.\"\"\"\n    \n    environmental: int\n    social: int\n    governance: int\n    overall: int\n    \n    @root_validator(skip_on_failure=True)\n    def validate_overall_score(cls, values):\n        \"\"\"Validate that the overall score is consistent with component scores.\"\"\"\n        env = values.get(\"environmental\", 0)\n        soc = values.get(\"social\", 0) \n        gov = values.get(\"governance\", 0)\n        overall = values.get(\"overall\", 0)\n        \n        # Check if overall is within a reasonable range of the average\n        component_avg = (env + soc + gov) / 3\n        if abs(overall - component_avg) > 15:  # Allow some variation in methodology\n            raise ValueError(\n                f\"Overall score {overall} is too different from component average {component_avg:.1f}\"\n            )\n        return values"
            ]
        }
    },
    "unified/tests/socially_responsible_investor/test_shareholder_advocacy/__init__.py": {
        "logprobs": -193.60925484185,
        "metrics": {
            "loc": 1,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 0,
            "blank": 0,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/common/core/utils/__init__.py": {
        "logprobs": -458.0852545309961,
        "metrics": {
            "loc": 101,
            "sloc": 92,
            "lloc": 6,
            "comments": 4,
            "multi": 0,
            "blank": 8,
            "cyclomatic": 0,
            "internal_imports": [
                "class DateRangeType(str, Enum):\n    \"\"\"Types of date ranges for financial analysis.\"\"\"\n    \n    DAILY = \"daily\"\n    WEEKLY = \"weekly\"\n    MONTHLY = \"monthly\"\n    QUARTERLY = \"quarterly\"\n    YEARLY = \"yearly\"\n    CUSTOM = \"custom\"",
                "def get_date_range(\n    range_type: DateRangeType,\n    start_date: Optional[Union[date, datetime]] = None,\n    end_date: Optional[Union[date, datetime]] = None,\n    num_periods: Optional[int] = None,\n) -> Tuple[Union[date, datetime], Union[date, datetime]]:\n    \"\"\"\n    Get a date range based on the specified type.\n    \n    Args:\n        range_type: Type of date range\n        start_date: Optional start date (defaults to today if not provided)\n        end_date: Optional end date\n        num_periods: Optional number of periods for relative ranges\n        \n    Returns:\n        Tuple of (start_date, end_date)\n    \"\"\"\n    today = datetime.now().date()\n    \n    if range_type == DateRangeType.CUSTOM:\n        # Use provided dates for custom range\n        if start_date is None:\n            start_date = today\n        if end_date is None:\n            end_date = today\n        return start_date, end_date\n    \n    # Set default for num_periods\n    if num_periods is None:\n        num_periods = 1\n    \n    # Calculate date range based on type\n    if range_type == DateRangeType.DAILY:\n        if end_date is None:\n            end_date = today\n        start_date = end_date - timedelta(days=num_periods - 1)\n    \n    elif range_type == DateRangeType.WEEKLY:\n        if end_date is None:\n            # End on the last day of the current week (Sunday)\n            days_to_end_of_week = 6 - today.weekday()\n            end_date = today + timedelta(days=days_to_end_of_week)\n        start_date = end_date - timedelta(weeks=num_periods, days=-1)\n    \n    elif range_type == DateRangeType.MONTHLY:\n        if end_date is None:\n            # End on the last day of the current month\n            end_date = get_last_day_of_month(today)\n        \n        # Start on the first day of the month, num_periods months ago\n        year = end_date.year\n        month = end_date.month - num_periods + 1\n        \n        while month <= 0:\n            year -= 1\n            month += 12\n        \n        start_date = date(year, month, 1)\n    \n    elif range_type == DateRangeType.QUARTERLY:\n        if end_date is None:\n            # End on the last day of the current quarter\n            quarter_end_month = ((today.month - 1) // 3 + 1) * 3\n            end_date = get_last_day_of_month(date(today.year, quarter_end_month, 1))\n        \n        # Start on the first day of the quarter, num_periods quarters ago\n        quarter = ((end_date.month - 1) // 3 + 1)\n        year = end_date.year\n        quarter_start = quarter - num_periods + 1\n        \n        while quarter_start <= 0:\n            year -= 1\n            quarter_start += 4\n        \n        start_month = (quarter_start - 1) * 3 + 1\n        start_date = date(year, start_month, 1)\n    \n    elif range_type == DateRangeType.YEARLY:\n        if end_date is None:\n            # End on the last day of the current year\n            end_date = date(today.year, 12, 31)\n        \n        # Start on the first day of the year, num_periods years ago\n        start_date = date(end_date.year - num_periods + 1, 1, 1)\n    \n    else:\n        # Default to daily\n        if end_date is None:\n            end_date = today\n        start_date = end_date - timedelta(days=num_periods - 1)\n    \n    return start_date, end_date",
                "def get_first_day_of_month(dt: Union[date, datetime]) -> date:\n    \"\"\"\n    Get the first day of the month for a given date.\n    \n    Args:\n        dt: The input date\n        \n    Returns:\n        Date representing the first day of the month\n    \"\"\"\n    return date(dt.year, dt.month, 1)",
                "def get_last_day_of_month(dt: Union[date, datetime]) -> date:\n    \"\"\"\n    Get the last day of the month for a given date.\n    \n    Args:\n        dt: The input date\n        \n    Returns:\n        Date representing the last day of the month\n    \"\"\"\n    # Get the number of days in the month\n    days_in_month = calendar.monthrange(dt.year, dt.month)[1]\n    return date(dt.year, dt.month, days_in_month)",
                "def get_first_day_of_quarter(dt: Union[date, datetime]) -> date:\n    \"\"\"\n    Get the first day of the quarter for a given date.\n    \n    Args:\n        dt: The input date\n        \n    Returns:\n        Date representing the first day of the quarter\n    \"\"\"\n    quarter = (dt.month - 1) // 3\n    return date(dt.year, quarter * 3 + 1, 1)",
                "def get_last_day_of_quarter(dt: Union[date, datetime]) -> date:\n    \"\"\"\n    Get the last day of the quarter for a given date.\n    \n    Args:\n        dt: The input date\n        \n    Returns:\n        Date representing the last day of the quarter\n    \"\"\"\n    quarter = (dt.month - 1) // 3\n    month = quarter * 3 + 3\n    return get_last_day_of_month(date(dt.year, month, 1))",
                "def get_first_day_of_year(dt: Union[date, datetime]) -> date:\n    \"\"\"\n    Get the first day of the year for a given date.\n    \n    Args:\n        dt: The input date\n        \n    Returns:\n        Date representing the first day of the year\n    \"\"\"\n    return date(dt.year, 1, 1)",
                "def get_last_day_of_year(dt: Union[date, datetime]) -> date:\n    \"\"\"\n    Get the last day of the year for a given date.\n    \n    Args:\n        dt: The input date\n        \n    Returns:\n        Date representing the last day of the year\n    \"\"\"\n    return date(dt.year, 12, 31)",
                "def date_range(\n    start_date: Union[date, datetime],\n    end_date: Union[date, datetime],\n    step: timedelta = timedelta(days=1),\n) -> Generator[date, None, None]:\n    \"\"\"\n    Generate a range of dates.\n    \n    Args:\n        start_date: The start date\n        end_date: The end date\n        step: The step size (default: 1 day)\n        \n    Yields:\n        Dates in the range\n    \"\"\"\n    # Convert to date if datetime\n    if isinstance(start_date, datetime):\n        start_date = start_date.date()\n    if isinstance(end_date, datetime):\n        end_date = end_date.date()\n    \n    # Generate dates\n    current_date = start_date\n    while current_date <= end_date:\n        yield current_date\n        current_date += step",
                "def month_range(\n    start_date: Union[date, datetime],\n    end_date: Union[date, datetime],\n) -> Generator[date, None, None]:\n    \"\"\"\n    Generate a range of month start dates.\n    \n    Args:\n        start_date: The start date\n        end_date: The end date\n        \n    Yields:\n        First day of each month in the range\n    \"\"\"\n    # Convert to date if datetime\n    if isinstance(start_date, datetime):\n        start_date = start_date.date()\n    if isinstance(end_date, datetime):\n        end_date = end_date.date()\n    \n    # Start from the first day of the month\n    current_month = get_first_day_of_month(start_date)\n    \n    # Generate month start dates\n    while current_month <= end_date:\n        yield current_month\n        \n        # Move to the next month\n        if current_month.month == 12:\n            current_month = date(current_month.year + 1, 1, 1)\n        else:\n            current_month = date(current_month.year, current_month.month + 1, 1)",
                "def quarter_range(\n    start_date: Union[date, datetime],\n    end_date: Union[date, datetime],\n) -> Generator[date, None, None]:\n    \"\"\"\n    Generate a range of quarter start dates.\n    \n    Args:\n        start_date: The start date\n        end_date: The end date\n        \n    Yields:\n        First day of each quarter in the range\n    \"\"\"\n    # Convert to date if datetime\n    if isinstance(start_date, datetime):\n        start_date = start_date.date()\n    if isinstance(end_date, datetime):\n        end_date = end_date.date()\n    \n    # Start from the first day of the quarter\n    current_quarter = get_first_day_of_quarter(start_date)\n    \n    # Generate quarter start dates\n    while current_quarter <= end_date:\n        yield current_quarter\n        \n        # Move to the next quarter\n        month = current_quarter.month\n        year = current_quarter.year\n        \n        month += 3\n        if month > 12:\n            month -= 12\n            year += 1\n        \n        current_quarter = date(year, month, 1)",
                "def year_range(\n    start_date: Union[date, datetime],\n    end_date: Union[date, datetime],\n) -> Generator[date, None, None]:\n    \"\"\"\n    Generate a range of year start dates.\n    \n    Args:\n        start_date: The start date\n        end_date: The end date\n        \n    Yields:\n        First day of each year in the range\n    \"\"\"\n    # Convert to date if datetime\n    if isinstance(start_date, datetime):\n        start_date = start_date.date()\n    if isinstance(end_date, datetime):\n        end_date = end_date.date()\n    \n    # Start from the first day of the year\n    current_year = get_first_day_of_year(start_date)\n    \n    # Generate year start dates\n    while current_year <= end_date:\n        yield current_year\n        current_year = date(current_year.year + 1, 1, 1)",
                "def is_same_month(date1: Union[date, datetime], date2: Union[date, datetime]) -> bool:\n    \"\"\"\n    Check if two dates are in the same month.\n    \n    Args:\n        date1: First date\n        date2: Second date\n        \n    Returns:\n        True if dates are in the same month, False otherwise\n    \"\"\"\n    return date1.year == date2.year and date1.month == date2.month",
                "def is_same_quarter(date1: Union[date, datetime], date2: Union[date, datetime]) -> bool:\n    \"\"\"\n    Check if two dates are in the same quarter.\n    \n    Args:\n        date1: First date\n        date2: Second date\n        \n    Returns:\n        True if dates are in the same quarter, False otherwise\n    \"\"\"\n    return (\n        date1.year == date2.year and\n        (date1.month - 1) // 3 == (date2.month - 1) // 3\n    )",
                "def is_same_year(date1: Union[date, datetime], date2: Union[date, datetime]) -> bool:\n    \"\"\"\n    Check if two dates are in the same year.\n    \n    Args:\n        date1: First date\n        date2: Second date\n        \n    Returns:\n        True if dates are in the same year, False otherwise\n    \"\"\"\n    return date1.year == date2.year",
                "def get_fiscal_year(\n    dt: Union[date, datetime], fiscal_start_month: int = 1\n) -> Tuple[int, date, date]:\n    \"\"\"\n    Get the fiscal year information for a given date.\n    \n    Args:\n        dt: The input date\n        fiscal_start_month: The month when the fiscal year starts (1-12)\n        \n    Returns:\n        Tuple of (fiscal_year, fiscal_year_start, fiscal_year_end)\n    \"\"\"\n    # Validate fiscal start month\n    if fiscal_start_month < 1 or fiscal_start_month > 12:\n        fiscal_start_month = 1\n    \n    # Determine the fiscal year\n    if dt.month < fiscal_start_month:\n        fiscal_year = dt.year - 1\n    else:\n        fiscal_year = dt.year\n    \n    # Calculate start and end dates\n    fiscal_year_start = date(fiscal_year, fiscal_start_month, 1)\n    \n    if fiscal_start_month == 1:\n        fiscal_year_end = date(fiscal_year, 12, 31)\n    else:\n        next_fiscal_year = fiscal_year + 1\n        next_fiscal_month = fiscal_start_month - 1\n        if next_fiscal_month == 0:\n            next_fiscal_month = 12\n            next_fiscal_year -= 1\n        \n        fiscal_year_end = get_last_day_of_month(date(next_fiscal_year, next_fiscal_month, 1))\n    \n    return fiscal_year, fiscal_year_start, fiscal_year_end",
                "class Cache:\n    \"\"\"Simple in-memory cache with expiration.\"\"\"\n    \n    def __init__(self, max_size: int = 1000, expiration_seconds: Optional[int] = None):\n        \"\"\"\n        Initialize the cache.\n        \n        Args:\n            max_size: Maximum number of items in the cache\n            expiration_seconds: Time in seconds after which items expire (None for no expiration)\n        \"\"\"\n        self._cache: Dict[str, Tuple[Any, float]] = {}\n        self._max_size = max_size\n        self._expiration_seconds = expiration_seconds\n    \n    def get(self, key: str) -> Optional[Any]:\n        \"\"\"\n        Get a value from the cache.\n        \n        Args:\n            key: The cache key\n            \n        Returns:\n            The cached value or None if not found or expired\n        \"\"\"\n        if key not in self._cache:\n            return None\n        \n        value, timestamp = self._cache[key]\n        \n        # Check if expired\n        if self._expiration_seconds is not None:\n            if time.time() - timestamp > self._expiration_seconds:\n                # Remove expired item\n                del self._cache[key]\n                return None\n        \n        return value\n    \n    def set(self, key: str, value: Any) -> None:\n        \"\"\"\n        Set a value in the cache.\n        \n        Args:\n            key: The cache key\n            value: The value to cache\n        \"\"\"\n        # Ensure we don't exceed max size\n        if len(self._cache) >= self._max_size and key not in self._cache:\n            # Remove oldest item (simplistic approach)\n            oldest_key = min(self._cache.items(), key=lambda x: x[1][1])[0]\n            del self._cache[oldest_key]\n        \n        # Store with current timestamp\n        self._cache[key] = (value, time.time())\n    \n    def delete(self, key: str) -> bool:\n        \"\"\"\n        Delete a value from the cache.\n        \n        Args:\n            key: The cache key\n            \n        Returns:\n            True if the key was found and deleted, False otherwise\n        \"\"\"\n        if key in self._cache:\n            del self._cache[key]\n            return True\n        return False\n    \n    def clear(self) -> None:\n        \"\"\"Clear all cache entries.\"\"\"\n        self._cache.clear()\n    \n    def size(self) -> int:\n        \"\"\"\n        Get the current size of the cache.\n        \n        Returns:\n            Number of items in the cache\n        \"\"\"\n        return len(self._cache)\n    \n    def clean_expired(self) -> int:\n        \"\"\"\n        Remove all expired entries from the cache.\n        \n        Returns:\n            Number of expired entries removed\n        \"\"\"\n        if self._expiration_seconds is None:\n            return 0\n        \n        # Find expired keys\n        now = time.time()\n        expired_keys = [\n            key for key, (_, timestamp) in self._cache.items()\n            if now - timestamp > self._expiration_seconds\n        ]\n        \n        # Delete expired keys\n        for key in expired_keys:\n            del self._cache[key]\n        \n        return len(expired_keys)",
                "def memoize(func: F = None, *, max_size: int = 1000, ttl_seconds: Optional[int] = None) -> F:\n    \"\"\"\n    Decorator to memoize a function's return value with optional max size and TTL.\n    \n    Can be used with or without arguments:\n    @memoize  # No arguments\n    def func():\n        ...\n        \n    @memoize(max_size=100, ttl_seconds=3600)  # With arguments\n    def func():\n        ...\n    \n    Args:\n        func: The function to memoize (when used without arguments)\n        max_size: Maximum number of items to store in cache (default: 1000)\n        ttl_seconds: Time-to-live in seconds (default: None, meaning no expiration)\n        \n    Returns:\n        Memoized function\n    \"\"\"\n    def decorator(f: F) -> F:\n        # Cache stores tuples of (result, timestamp) if TTL is specified, otherwise just result\n        cache: Dict[str, Union[Any, Tuple[Any, float]]] = {}\n        \n        @functools.wraps(f)\n        def wrapper(*args: Any, **kwargs: Any) -> Any:\n            # Create a cache key from the function arguments\n            key = _create_cache_key(f, args, kwargs)\n            \n            # Check if we need to enforce max size\n            if len(cache) >= max_size and key not in cache:\n                # Remove oldest item (simple implementation)\n                if ttl_seconds is not None:\n                    # If using TTL, find oldest by timestamp\n                    oldest_key = min(cache.items(), key=lambda x: x[1][1])[0]\n                else:\n                    # Otherwise just remove the first key\n                    oldest_key = next(iter(cache))\n                del cache[oldest_key]\n            \n            # Check if result is in cache\n            if key in cache:\n                if ttl_seconds is not None:\n                    # Check if expired when using TTL\n                    result, timestamp = cache[key]  # type: ignore\n                    if time.time() - timestamp < ttl_seconds:\n                        return result\n                    # If expired, remove from cache and recalculate\n                else:\n                    # No TTL, just return cached result\n                    return cache[key]\n            \n            # Call the function and cache the result\n            result = f(*args, **kwargs)\n            \n            if ttl_seconds is not None:\n                # Store with timestamp if using TTL\n                cache[key] = (result, time.time())\n            else:\n                # Store just the result otherwise\n                cache[key] = result\n            \n            return result\n        \n        # Add cache management functions\n        wrapper.cache = cache  # type: ignore\n        wrapper.cache_clear = cache.clear  # type: ignore\n        wrapper.cache_size = lambda: len(cache)  # type: ignore\n        \n        return cast(F, wrapper)\n    \n    # Handle both @memoize and @memoize(args) syntax\n    if func is None:\n        return decorator\n    return decorator(func)",
                "def memoize_with_expiry(expiration_seconds: int) -> Callable[[F], F]:\n    \"\"\"\n    Create a decorator to memoize a function's return value with expiration.\n    \n    Args:\n        expiration_seconds: Time in seconds after which cached items expire\n        \n    Returns:\n        Decorator function\n    \"\"\"\n    def decorator(func: F) -> F:\n        # Cache stores tuples of (result, timestamp)\n        cache: Dict[str, Tuple[Any, float]] = {}\n        \n        @functools.wraps(func)\n        def wrapper(*args: Any, **kwargs: Any) -> Any:\n            # Create a cache key from the function arguments\n            key = _create_cache_key(func, args, kwargs)\n            \n            # Check if result is in cache and not expired\n            if key in cache:\n                result, timestamp = cache[key]\n                if time.time() - timestamp < expiration_seconds:\n                    return result\n            \n            # Call the function and cache the result with timestamp\n            result = func(*args, **kwargs)\n            cache[key] = (result, time.time())\n            \n            return result\n        \n        # Add cache management functions\n        wrapper.cache = cache  # type: ignore\n        wrapper.cache_clear = cache.clear  # type: ignore\n        wrapper.cache_size = lambda: len(cache)  # type: ignore\n        \n        # Add function to clean expired entries\n        def clean_expired() -> int:\n            now = time.time()\n            expired_keys = [\n                key for key, (_, timestamp) in cache.items()\n                if now - timestamp >= expiration_seconds\n            ]\n            for key in expired_keys:\n                del cache[key]\n            return len(expired_keys)\n        \n        wrapper.clean_expired = clean_expired  # type: ignore\n        \n        return cast(F, wrapper)\n    \n    return decorator",
                "class Timer:\n    \"\"\"Utility for measuring execution time.\"\"\"\n    \n    def __init__(self, name: Optional[str] = None):\n        \"\"\"\n        Initialize the timer.\n        \n        Args:\n            name: Optional name for the timer\n        \"\"\"\n        self.name = name\n        self.start_time: Optional[float] = None\n        self.end_time: Optional[float] = None\n    \n    def __enter__(self) -> 'Timer':\n        \"\"\"Start the timer when entering a context.\"\"\"\n        self.start()\n        return self\n    \n    def __exit__(self, *args: Any) -> None:\n        \"\"\"Stop the timer when exiting a context.\"\"\"\n        self.stop()\n    \n    def start(self) -> None:\n        \"\"\"Start the timer.\"\"\"\n        self.start_time = time.time()\n        self.end_time = None\n    \n    def stop(self) -> float:\n        \"\"\"\n        Stop the timer.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        self.end_time = time.time()\n        return self.elapsed_time\n    \n    @property\n    def elapsed_time(self) -> float:\n        \"\"\"\n        Get the elapsed time.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        end = self.end_time if self.end_time is not None else time.time()\n        return end - self.start_time\n    \n    @property\n    def elapsed_milliseconds(self) -> float:\n        \"\"\"\n        Get the elapsed time in milliseconds.\n        \n        Returns:\n            Elapsed time in milliseconds\n        \"\"\"\n        return self.elapsed_time * 1000",
                "class PerformanceMonitor:\n    \"\"\"\n    Monitor for tracking performance metrics of function calls.\n    \n    Tracks execution times, counts, and statistics for functions.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the performance monitor.\"\"\"\n        self._metrics: Dict[str, List[float]] = {}\n        self._call_counts: Dict[str, int] = {}\n        self._start_times: Dict[str, float] = {}\n    \n    def start(self, name: str) -> None:\n        \"\"\"\n        Start timing a named operation.\n        \n        Args:\n            name: Name of the operation\n        \"\"\"\n        self._start_times[name] = time.time()\n    \n    def stop(self, name: str) -> float:\n        \"\"\"\n        Stop timing a named operation and record the elapsed time.\n        \n        Args:\n            name: Name of the operation\n            \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if name not in self._start_times:\n            raise ValueError(f\"No timing started for {name}\")\n        \n        elapsed_time = time.time() - self._start_times[name]\n        del self._start_times[name]\n        \n        # Record the metric\n        if name not in self._metrics:\n            self._metrics[name] = []\n        self._metrics[name].append(elapsed_time)\n        \n        # Update call count\n        self._call_counts[name] = self._call_counts.get(name, 0) + 1\n        \n        return elapsed_time\n    \n    def record(self, name: str, value: float) -> None:\n        \"\"\"\n        Record a metric value directly.\n        \n        Args:\n            name: Name of the metric\n            value: Value to record\n        \"\"\"\n        if name not in self._metrics:\n            self._metrics[name] = []\n        self._metrics[name].append(value)\n        \n        # Update call count\n        self._call_counts[name] = self._call_counts.get(name, 0) + 1\n    \n    def get_metrics(self, name: str) -> Dict[str, Any]:\n        \"\"\"\n        Get statistics for a named metric.\n        \n        Args:\n            name: Name of the metric\n            \n        Returns:\n            Dictionary with statistics\n        \"\"\"\n        if name not in self._metrics:\n            return {}\n        \n        values = self._metrics[name]\n        \n        if not values:\n            return {\"count\": 0}\n        \n        # Calculate statistics\n        return {\n            \"count\": len(values),\n            \"min\": min(values),\n            \"max\": max(values),\n            \"mean\": statistics.mean(values),\n            \"median\": statistics.median(values),\n            \"std_dev\": statistics.stdev(values) if len(values) > 1 else 0,\n            \"total\": sum(values),\n        }\n    \n    def get_all_metrics(self) -> Dict[str, Dict[str, Any]]:\n        \"\"\"\n        Get statistics for all metrics.\n        \n        Returns:\n            Dictionary mapping metric names to statistics\n        \"\"\"\n        return {name: self.get_metrics(name) for name in self._metrics}\n    \n    def reset(self, name: Optional[str] = None) -> None:\n        \"\"\"\n        Reset metrics.\n        \n        Args:\n            name: Name of the metric to reset, or None to reset all\n        \"\"\"\n        if name is None:\n            # Reset all metrics\n            self._metrics = {}\n            self._call_counts = {}\n            self._start_times = {}\n        else:\n            # Reset specific metric\n            if name in self._metrics:\n                del self._metrics[name]\n            if name in self._call_counts:\n                del self._call_counts[name]\n            if name in self._start_times:\n                del self._start_times[name]",
                "def time_it(func: F) -> F:\n    \"\"\"\n    Decorator to time function execution.\n    \n    Args:\n        func: The function to time\n        \n    Returns:\n        Wrapped function that logs timing information\n    \"\"\"\n    @functools.wraps(func)\n    def wrapper(*args: Any, **kwargs: Any) -> Any:\n        start_time = time.time()\n        \n        try:\n            result = func(*args, **kwargs)\n            return result\n        finally:\n            elapsed_time = time.time() - start_time\n            func_name = func.__qualname__\n            print(f\"{func_name} took {elapsed_time:.6f} seconds\")\n    \n    return cast(F, wrapper)",
                "def monitor_performance(\n    monitor: PerformanceMonitor, name: Optional[str] = None\n) -> Callable[[F], F]:\n    \"\"\"\n    Decorator to monitor function performance.\n    \n    Args:\n        monitor: PerformanceMonitor instance\n        name: Optional name for the metric (defaults to function name)\n        \n    Returns:\n        Decorator function\n    \"\"\"\n    def decorator(func: F) -> F:\n        metric_name = name or func.__qualname__\n        \n        @functools.wraps(func)\n        def wrapper(*args: Any, **kwargs: Any) -> Any:\n            monitor.start(metric_name)\n            \n            try:\n                result = func(*args, **kwargs)\n                return result\n            finally:\n                monitor.stop(metric_name)\n        \n        return cast(F, wrapper)\n    \n    return decorator",
                "def global_timer(name: Optional[str] = None) -> Callable[[F], F]:\n    \"\"\"\n    Decorator to time function with the global monitor.\n    \n    Args:\n        name: Optional name for the metric (defaults to function name)\n        \n    Returns:\n        Decorator function\n    \"\"\"\n    return monitor_performance(global_monitor, name)",
                "def validate_non_negative(value: Union[int, float, Decimal]) -> Union[int, float, Decimal]:\n    \"\"\"\n    Validate that a value is non-negative.\n    \n    Args:\n        value: Value to validate\n        \n    Returns:\n        The value if valid\n        \n    Raises:\n        ValueError: If the value is negative\n    \"\"\"\n    if value < 0:\n        raise ValueError(\"Value must be non-negative\")\n    return value",
                "def validate_positive(value: Union[int, float, Decimal]) -> Union[int, float, Decimal]:\n    \"\"\"\n    Validate that a value is positive.\n    \n    Args:\n        value: Value to validate\n        \n    Returns:\n        The value if valid\n        \n    Raises:\n        ValueError: If the value is not positive\n    \"\"\"\n    if value <= 0:\n        raise ValueError(\"Value must be positive\")\n    return value",
                "def validate_percentage(value: Union[int, float, Decimal]) -> Union[int, float, Decimal]:\n    \"\"\"\n    Validate that a value is a percentage (0-100).\n    \n    Args:\n        value: Value to validate\n        \n    Returns:\n        The value if valid\n        \n    Raises:\n        ValueError: If the value is not between 0 and 100\n    \"\"\"\n    if value < 0 or value > 100:\n        raise ValueError(\"Value must be between 0 and 100\")\n    return value",
                "def validate_decimal_percentage(value: Union[float, Decimal]) -> Union[float, Decimal]:\n    \"\"\"\n    Validate that a value is a decimal percentage (0-1).\n    \n    Args:\n        value: Value to validate\n        \n    Returns:\n        The value if valid\n        \n    Raises:\n        ValueError: If the value is not between 0 and 1\n    \"\"\"\n    if value < 0 or value > 1:\n        raise ValueError(\"Value must be between 0 and 1\")\n    return value",
                "def validate_date_not_future(value: Union[date, datetime]) -> Union[date, datetime]:\n    \"\"\"\n    Validate that a date is not in the future.\n    \n    Args:\n        value: Date to validate\n        \n    Returns:\n        The date if valid\n        \n    Raises:\n        ValueError: If the date is in the future\n    \"\"\"\n    # Get current date\n    current = datetime.now().date() if isinstance(value, date) else datetime.now()\n    \n    if value > current:\n        raise ValueError(\"Date cannot be in the future\")\n    return value",
                "def validate_date_range(\n    start: Union[date, datetime], end: Union[date, datetime]\n) -> Tuple[Union[date, datetime], Union[date, datetime]]:\n    \"\"\"\n    Validate that a date range is valid (start <= end).\n    \n    Args:\n        start: Start date\n        end: End date\n        \n    Returns:\n        Tuple of (start, end) if valid\n        \n    Raises:\n        ValueError: If the start date is after the end date\n    \"\"\"\n    if start > end:\n        raise ValueError(\"Start date cannot be after end date\")\n    return start, end",
                "def validate_string_not_empty(value: str) -> str:\n    \"\"\"\n    Validate that a string is not empty.\n    \n    Args:\n        value: String to validate\n        \n    Returns:\n        The string if valid\n        \n    Raises:\n        ValueError: If the string is empty\n    \"\"\"\n    if not value:\n        raise ValueError(\"String cannot be empty\")\n    return value",
                "def validate_string_length(\n    value: str, min_length: int = 0, max_length: Optional[int] = None\n) -> str:\n    \"\"\"\n    Validate that a string is within length constraints.\n    \n    Args:\n        value: String to validate\n        min_length: Minimum allowed length\n        max_length: Maximum allowed length (None for no upper limit)\n        \n    Returns:\n        The string if valid\n        \n    Raises:\n        ValueError: If the string length is outside the allowed range\n    \"\"\"\n    if len(value) < min_length:\n        raise ValueError(f\"String must be at least {min_length} characters long\")\n    \n    if max_length is not None and len(value) > max_length:\n        raise ValueError(f\"String cannot be longer than {max_length} characters\")\n    \n    return value",
                "def validate_string_pattern(value: str, pattern: Union[str, Pattern]) -> str:\n    \"\"\"\n    Validate that a string matches a pattern.\n    \n    Args:\n        value: String to validate\n        pattern: Regex pattern to match\n        \n    Returns:\n        The string if valid\n        \n    Raises:\n        ValueError: If the string doesn't match the pattern\n    \"\"\"\n    if isinstance(pattern, str):\n        pattern = re.compile(pattern)\n    \n    if not pattern.match(value):\n        raise ValueError(\"String does not match the required pattern\")\n    \n    return value",
                "def validate_email(value: str) -> str:\n    \"\"\"\n    Validate that a string is a valid email address.\n    \n    Args:\n        value: Email to validate\n        \n    Returns:\n        The email if valid\n        \n    Raises:\n        ValueError: If the email is invalid\n    \"\"\"\n    # Simple regex for email validation\n    email_pattern = r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\"\n    \n    if not re.match(email_pattern, value):\n        raise ValueError(\"Invalid email address\")\n    \n    return value",
                "def validate_in_set(value: Any, allowed_values: Set[Any]) -> Any:\n    \"\"\"\n    Validate that a value is in a set of allowed values.\n    \n    Args:\n        value: Value to validate\n        allowed_values: Set of allowed values\n        \n    Returns:\n        The value if valid\n        \n    Raises:\n        ValueError: If the value is not in the allowed set\n    \"\"\"\n    if value not in allowed_values:\n        values_str = \", \".join(str(v) for v in allowed_values)\n        raise ValueError(f\"Value must be one of: {values_str}\")\n    \n    return value",
                "def validate_list_not_empty(value: List[Any]) -> List[Any]:\n    \"\"\"\n    Validate that a list is not empty.\n    \n    Args:\n        value: List to validate\n        \n    Returns:\n        The list if valid\n        \n    Raises:\n        ValueError: If the list is empty\n    \"\"\"\n    if not value:\n        raise ValueError(\"List cannot be empty\")\n    \n    return value",
                "def validate_list_length(\n    value: List[Any], min_length: int = 0, max_length: Optional[int] = None\n) -> List[Any]:\n    \"\"\"\n    Validate that a list is within length constraints.\n    \n    Args:\n        value: List to validate\n        min_length: Minimum allowed length\n        max_length: Maximum allowed length (None for no upper limit)\n        \n    Returns:\n        The list if valid\n        \n    Raises:\n        ValueError: If the list length is outside the allowed range\n    \"\"\"\n    if len(value) < min_length:\n        raise ValueError(f\"List must have at least {min_length} items\")\n    \n    if max_length is not None and len(value) > max_length:\n        raise ValueError(f\"List cannot have more than {max_length} items\")\n    \n    return value",
                "def add_validator(\n    model_class: Type[BaseModel], field_name: str, validator_func: Callable, **kwargs: Any\n) -> Type[BaseModel]:\n    \"\"\"\n    Dynamically add a validator to a Pydantic model.\n    \n    Args:\n        model_class: The Pydantic model class\n        field_name: The field to validate\n        validator_func: The validator function\n        **kwargs: Additional validator parameters\n        \n    Returns:\n        Updated model class\n    \"\"\"\n    # Create a named validator\n    validator_name = f\"validate_{field_name}_{validator_func.__name__}\"\n    \n    # Create the validator function\n    def dynamic_validator(cls, v, values):\n        return validator_func(v)\n    \n    # Set the function name\n    dynamic_validator.__name__ = validator_name\n    \n    # Add the validator to the model\n    validator_decorator = validator(field_name, **kwargs)\n    model_class = type(\n        model_class.__name__,\n        (model_class,),\n        {validator_name: validator_decorator(dynamic_validator)},\n    )\n    \n    return cast(Type[BaseModel], model_class)"
            ]
        }
    },
    "unified/common/core/utils/cache_utils.py": {
        "logprobs": -1016.0320375069316,
        "metrics": {
            "loc": 307,
            "sloc": 131,
            "lloc": 141,
            "comments": 41,
            "multi": 75,
            "blank": 65,
            "cyclomatic": 31,
            "internal_imports": []
        }
    },
    "unified/common/core/categorization/__init__.py": {
        "logprobs": -396.0319160404868,
        "metrics": {
            "loc": 47,
            "sloc": 38,
            "lloc": 6,
            "comments": 4,
            "multi": 0,
            "blank": 8,
            "cyclomatic": 0,
            "internal_imports": [
                "class Rule(BaseModel, ABC):\n    \"\"\"\n    Abstract base class for categorization rules.\n    \n    Defines the interface for all rules used in categorization\n    across different persona implementations.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    description: Optional[str] = None\n    priority: int = 0  # Higher numbers have higher priority\n    created_at: datetime = Field(default_factory=datetime.now)\n    updated_at: datetime = Field(default_factory=datetime.now)\n    is_active: bool = True\n    \n    @abstractmethod\n    def matches(self, item: Any) -> bool:\n        \"\"\"\n        Check if this rule matches the given item.\n        \n        Args:\n            item: The item to check against this rule\n            \n        Returns:\n            True if the rule matches, False otherwise\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def apply(self, item: Any) -> Any:\n        \"\"\"\n        Apply this rule to the given item.\n        \n        Args:\n            item: The item to apply this rule to\n            \n        Returns:\n            The result of applying the rule\n        \"\"\"\n        pass\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class TextMatchRule(Rule):\n    \"\"\"\n    Rule that matches based on text patterns in a field.\n    \n    Used for simple substring or regex matching against text fields.\n    \"\"\"\n    \n    field_name: str\n    pattern: str\n    pattern_type: str = \"contains\"  # \"contains\", \"starts_with\", \"ends_with\", \"regex\", \"exact\"\n    case_sensitive: bool = False\n    \n    _compiled_regex: Optional[Pattern] = None\n    \n    def matches(self, item: Any) -> bool:\n        \"\"\"\n        Check if the item matches this rule based on text patterns.\n        \n        Args:\n            item: The item to check against this rule\n            \n        Returns:\n            True if the rule matches, False otherwise\n        \"\"\"\n        # Extract the field value\n        if not hasattr(item, self.field_name) and not isinstance(item, dict):\n            return False\n        \n        field_value = getattr(item, self.field_name) if hasattr(item, self.field_name) else item.get(self.field_name)\n        \n        # Skip if field doesn't exist or is None\n        if field_value is None:\n            return False\n        \n        # Convert to string if needed\n        if not isinstance(field_value, str):\n            field_value = str(field_value)\n        \n        # Apply case sensitivity\n        pattern = self.pattern\n        if not self.case_sensitive:\n            field_value = field_value.lower()\n            pattern = pattern.lower()\n        \n        # Match based on pattern type\n        if self.pattern_type == \"contains\":\n            return pattern in field_value\n        elif self.pattern_type == \"starts_with\":\n            return field_value.startswith(pattern)\n        elif self.pattern_type == \"ends_with\":\n            return field_value.endswith(pattern)\n        elif self.pattern_type == \"exact\":\n            return field_value == pattern\n        elif self.pattern_type == \"regex\":\n            if self._compiled_regex is None:\n                self._compiled_regex = re.compile(pattern, 0 if self.case_sensitive else re.IGNORECASE)\n            return bool(self._compiled_regex.search(field_value))\n        \n        return False\n    \n    def apply(self, item: Any) -> Dict[str, Any]:\n        \"\"\"\n        Apply this rule by returning a dictionary of fields to update.\n        \n        Args:\n            item: The item to apply this rule to\n            \n        Returns:\n            Dictionary of fields to update on the item\n        \"\"\"\n        return {}",
                "class TransactionRule(TextMatchRule):\n    \"\"\"\n    Rule for categorizing financial transactions.\n    \n    Used for both expense categorization and ethical transaction analysis.\n    \"\"\"\n    \n    category: str\n    business_use_percentage: Optional[float] = None\n    \n    def apply(self, transaction: BaseTransaction) -> Dict[str, Any]:\n        \"\"\"\n        Apply this rule to a transaction by returning fields to update.\n        \n        Args:\n            transaction: The transaction to categorize\n            \n        Returns:\n            Dictionary with category and optional business use percentage\n        \"\"\"\n        result = {\"category\": self.category}\n        \n        if self.business_use_percentage is not None:\n            result[\"business_use_percentage\"] = self.business_use_percentage\n            \n        return result",
                "class CompositeRule(Rule):\n    \"\"\"\n    Rule that combines multiple other rules with logical operators.\n    \n    Allows for complex rule conditions using AND, OR, and NOT operators.\n    \"\"\"\n    \n    operator: str = \"and\"  # \"and\", \"or\", \"not\"\n    rules: List[Rule]\n    \n    def matches(self, item: Any) -> bool:\n        \"\"\"\n        Check if the item matches this composite rule.\n        \n        Args:\n            item: The item to check against this rule\n            \n        Returns:\n            True if the rule matches, False otherwise\n        \"\"\"\n        if not self.rules:\n            return False\n        \n        if self.operator == \"and\":\n            return all(rule.matches(item) for rule in self.rules)\n        elif self.operator == \"or\":\n            return any(rule.matches(item) for rule in self.rules)\n        elif self.operator == \"not\":\n            # For NOT, we only consider the first rule\n            return not self.rules[0].matches(item)\n        \n        return False\n    \n    def apply(self, item: Any) -> Dict[str, Any]:\n        \"\"\"\n        Apply the highest priority matching rule to the item.\n        \n        Args:\n            item: The item to apply this rule to\n            \n        Returns:\n            Result of applying the highest priority matching rule\n        \"\"\"\n        matching_rules = [rule for rule in self.rules if rule.matches(item)]\n        \n        if not matching_rules:\n            return {}\n        \n        # Get the highest priority rule (highest priority value)\n        highest_priority_rule = max(matching_rules, key=lambda r: r.priority)\n        \n        return highest_priority_rule.apply(item)",
                "class ValueThresholdRule(Rule):\n    \"\"\"\n    Rule that matches based on numeric value comparisons.\n    \n    Used for matching based on thresholds like amount, score, or percentage.\n    \"\"\"\n    \n    field_name: str\n    operator: str  # \"eq\", \"ne\", \"gt\", \"lt\", \"ge\", \"le\", \"between\"\n    value: float\n    max_value: Optional[float] = None  # Used for \"between\" operator\n    \n    def matches(self, item: Any) -> bool:\n        \"\"\"\n        Check if the item matches based on numeric comparison.\n        \n        Args:\n            item: The item to check against this rule\n            \n        Returns:\n            True if the rule matches, False otherwise\n        \"\"\"\n        # Extract the field value\n        if not hasattr(item, self.field_name) and not isinstance(item, dict):\n            return False\n        \n        field_value = getattr(item, self.field_name) if hasattr(item, self.field_name) else item.get(self.field_name)\n        \n        # Skip if field doesn't exist or is None\n        if field_value is None:\n            return False\n        \n        # Ensure numeric value\n        try:\n            field_value = float(field_value)\n        except (ValueError, TypeError):\n            return False\n        \n        # Compare based on operator\n        if self.operator == \"eq\":\n            return field_value == self.value\n        elif self.operator == \"ne\":\n            return field_value != self.value\n        elif self.operator == \"gt\":\n            return field_value > self.value\n        elif self.operator == \"lt\":\n            return field_value < self.value\n        elif self.operator == \"ge\":\n            return field_value >= self.value\n        elif self.operator == \"le\":\n            return field_value <= self.value\n        elif self.operator == \"between\" and self.max_value is not None:\n            return self.value <= field_value <= self.max_value\n        \n        return False\n    \n    def apply(self, item: Any) -> Dict[str, Any]:\n        \"\"\"\n        Apply this rule by returning a dictionary of fields to update.\n        \n        Args:\n            item: The item to apply this rule to\n            \n        Returns:\n            Dictionary of fields to update on the item\n        \"\"\"\n        return {}",
                "class BaseCategorizer(Generic[T, R], ABC):\n    \"\"\"\n    Abstract base class for categorization engines.\n    \n    Defines the core interface and functionality for all categorizers\n    across different persona implementations.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the categorizer.\"\"\"\n        self.rules: List[Rule] = []\n        self.audit_trail: List[AuditRecord] = []\n        self._categorization_cache: Dict[str, R] = {}\n        \n    def add_rule(self, rule: Rule) -> Rule:\n        \"\"\"\n        Add a new rule to the categorizer.\n        \n        Args:\n            rule: The rule to add\n            \n        Returns:\n            The added rule\n        \"\"\"\n        # Check for duplicate rule ID\n        if any(r.id == rule.id for r in self.rules):\n            raise ValueError(f\"Rule with ID {rule.id} already exists\")\n        \n        # Add the rule\n        self.rules.append(rule)\n        \n        # Sort rules by priority (highest first)\n        self.rules.sort(key=lambda r: r.priority, reverse=True)\n        \n        # Clear cache since rules have changed\n        self._categorization_cache = {}\n        \n        return rule\n    \n    def update_rule(self, rule: Rule) -> Rule:\n        \"\"\"\n        Update an existing rule.\n        \n        Args:\n            rule: The rule to update\n            \n        Returns:\n            The updated rule\n        \"\"\"\n        # Find the rule to update\n        for i, existing_rule in enumerate(self.rules):\n            if existing_rule.id == rule.id:\n                # Update the rule\n                rule.updated_at = datetime.now()\n                self.rules[i] = rule\n                \n                # Sort rules by priority (highest first)\n                self.rules.sort(key=lambda r: r.priority, reverse=True)\n                \n                # Clear cache since rules have changed\n                self._categorization_cache = {}\n                \n                return rule\n        \n        raise ValueError(f\"Rule with ID {rule.id} not found\")\n    \n    def remove_rule(self, rule_id: Union[str, UUID]) -> bool:\n        \"\"\"\n        Remove a rule.\n        \n        Args:\n            rule_id: ID of the rule to remove\n            \n        Returns:\n            True if the rule was removed, False otherwise\n        \"\"\"\n        # Find the rule to remove\n        for i, rule in enumerate(self.rules):\n            if rule.id == rule_id:\n                # Remove the rule\n                del self.rules[i]\n                \n                # Clear cache since rules have changed\n                self._categorization_cache = {}\n                \n                return True\n        \n        return False\n    \n    def get_rules(self) -> List[Rule]:\n        \"\"\"\n        Get all rules.\n        \n        Returns:\n            List of all rules\n        \"\"\"\n        return self.rules\n    \n    def get_audit_trail(\n        self, item_id: Optional[Union[str, UUID]] = None, limit: int = 100\n    ) -> List[AuditRecord]:\n        \"\"\"\n        Get the audit trail for categorization actions.\n        \n        Args:\n            item_id: Optional item ID to filter by\n            limit: Maximum number of records to return\n            \n        Returns:\n            List of audit records\n        \"\"\"\n        if item_id:\n            # Filter to specific item\n            filtered_trail = [\n                record\n                for record in self.audit_trail\n                if record.item_id == item_id\n            ]\n        else:\n            filtered_trail = self.audit_trail\n        \n        # Sort by timestamp (newest first) and limit\n        sorted_trail = sorted(filtered_trail, key=lambda r: r.timestamp, reverse=True)\n        \n        return sorted_trail[:limit]\n    \n    def clear_cache(self) -> None:\n        \"\"\"Clear the categorization cache.\"\"\"\n        self._categorization_cache = {}\n    \n    @abstractmethod\n    def categorize(self, item: T, recategorize: bool = False) -> R:\n        \"\"\"\n        Categorize a single item.\n        \n        Args:\n            item: The item to categorize\n            recategorize: Whether to recategorize even if already categorized\n            \n        Returns:\n            Categorization result\n        \"\"\"\n        pass\n    \n    def categorize_batch(self, items: List[T], recategorize: bool = False) -> List[R]:\n        \"\"\"\n        Categorize multiple items.\n        \n        Args:\n            items: List of items to categorize\n            recategorize: Whether to recategorize even if already categorized\n            \n        Returns:\n            List of categorization results\n        \"\"\"\n        # Start performance timer\n        start_time = time.time()\n        \n        # Categorize each item\n        results = []\n        for item in items:\n            result = self.categorize(item, recategorize)\n            results.append(result)\n        \n        # Performance metrics\n        elapsed_time = time.time() - start_time\n        \n        return results\n    \n    def record_audit(\n        self,\n        item_id: Union[str, UUID],\n        action: str,\n        previous_state: Dict[str, Any],\n        new_state: Dict[str, Any],\n        notes: Optional[str] = None,\n    ) -> AuditRecord:\n        \"\"\"\n        Record an action in the audit trail.\n        \n        Args:\n            item_id: ID of the item being modified\n            action: Type of action performed\n            previous_state: State before the action\n            new_state: State after the action\n            notes: Optional notes about the action\n            \n        Returns:\n            The created audit record\n        \"\"\"\n        audit_record = AuditRecord(\n            item_id=item_id,\n            action=action,\n            previous_state=previous_state,\n            new_state=new_state,\n            notes=notes,\n        )\n        \n        self.audit_trail.append(audit_record)\n        \n        return audit_record",
                "class CategorizationResult(BaseModel, Generic[T]):\n    \"\"\"\n    Result of a categorization operation.\n    \n    Provides information about the categorization process and outcome.\n    \"\"\"\n    \n    item_id: Union[str, UUID]\n    original_item: T\n    assigned_category: Optional[str] = None\n    confidence_score: float  # 0.0 to 1.0\n    matched_rule: Optional[Rule] = None\n    processing_time_ms: Optional[float] = None\n    notes: Optional[str] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class AuditRecord(BaseModel):\n    \"\"\"\n    Record of a categorization action for audit purposes.\n    \n    Tracks changes for accountability and analysis.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    item_id: Union[str, UUID]\n    action: str\n    timestamp: datetime = Field(default_factory=datetime.now)\n    previous_state: Dict[str, Any] = Field(default_factory=dict)\n    new_state: Dict[str, Any] = Field(default_factory=dict)\n    user_id: Optional[str] = None\n    notes: Optional[str] = None",
                "class TransactionCategorizer(BaseCategorizer[BaseTransaction, CategorizationResult[BaseTransaction]]):\n    \"\"\"\n    Categorizer for financial transactions.\n    \n    Handles categorization of transactions based on rules and mixed-use items.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the transaction categorizer.\"\"\"\n        super().__init__()\n        self.mixed_use_items: List[MixedUseItem] = []\n    \n    def add_mixed_use_item(self, item: MixedUseItem) -> MixedUseItem:\n        \"\"\"\n        Add a new mixed-use item.\n        \n        Args:\n            item: The mixed-use item to add\n            \n        Returns:\n            The added item\n        \"\"\"\n        # Check for duplicate item ID\n        if any(i.id == item.id for i in self.mixed_use_items):\n            raise ValueError(f\"Mixed-use item with ID {item.id} already exists\")\n        \n        # Add the item\n        self.mixed_use_items.append(item)\n        \n        # Clear cache\n        self._categorization_cache = {}\n        \n        return item\n    \n    def categorize(\n        self, transaction: BaseTransaction, recategorize: bool = False\n    ) -> CategorizationResult[BaseTransaction]:\n        \"\"\"\n        Categorize a transaction using the defined rules.\n        \n        Args:\n            transaction: The transaction to categorize\n            recategorize: Whether to recategorize even if already categorized\n            \n        Returns:\n            CategorizationResult with the categorization details\n        \"\"\"\n        # Start performance timer\n        start_time = time.time()\n        \n        # Skip non-expense transactions if desired\n        if hasattr(transaction, 'transaction_type'):\n            if getattr(transaction, 'transaction_type') != TransactionType.EXPENSE:\n                result = CategorizationResult(\n                    item_id=transaction.id,\n                    original_item=transaction,\n                    confidence_score=0.0,\n                    processing_time_ms=(time.time() - start_time) * 1000,\n                    notes=\"Non-expense transaction\",\n                )\n                return result\n        \n        # Check cache unless forced to recategorize\n        cache_key = str(transaction.id)\n        if not recategorize and cache_key in self._categorization_cache:\n            return self._categorization_cache[cache_key]\n        \n        # Skip if already categorized and not forced to recategorize\n        if (\n            not recategorize \n            and hasattr(transaction, 'category') \n            and getattr(transaction, 'category') is not None\n        ):\n            # For business transactions, check business use percentage\n            business_use_percentage = None\n            if hasattr(transaction, 'business_use_percentage'):\n                business_use_percentage = getattr(transaction, 'business_use_percentage')\n                \n            result = CategorizationResult(\n                item_id=transaction.id,\n                original_item=transaction,\n                assigned_category=transaction.category,\n                business_use_percentage=business_use_percentage,\n                confidence_score=1.0,  # Already categorized, so high confidence\n                processing_time_ms=(time.time() - start_time) * 1000,\n                notes=\"Transaction was already categorized\",\n            )\n            \n            self._categorization_cache[cache_key] = result\n            return result\n        \n        # Check if this matches a known mixed-use item\n        mixed_use_match = None\n        for item in self.mixed_use_items:\n            if (\n                hasattr(transaction, 'description') \n                and item.name.lower() in getattr(transaction, 'description', '').lower()\n            ):\n                mixed_use_match = item\n                break\n        \n        # Apply categorization rules\n        matched_rule = None\n        for rule in self.rules:\n            if rule.matches(transaction):\n                matched_rule = rule\n                break\n        \n        # Determine category and business use percentage\n        category = None\n        business_percentage = None\n        is_mixed_use = False\n        confidence = 0.5\n        notes = \"No matching rules or mixed-use items\"\n        metadata = {}\n        \n        if mixed_use_match:\n            category = mixed_use_match.category\n            business_percentage = mixed_use_match.business_use_percentage\n            is_mixed_use = True\n            confidence = 0.9\n            notes = f\"Matched mixed-use item: {mixed_use_match.name}\"\n            metadata[\"mixed_use_item_id\"] = str(mixed_use_match.id)\n        elif matched_rule:\n            # Extract category and business percentage from rule\n            rule_result = matched_rule.apply(transaction)\n            category = rule_result.get(\"category\")\n            \n            if \"business_use_percentage\" in rule_result:\n                business_percentage = rule_result.get(\"business_use_percentage\")\n                is_mixed_use = business_percentage < 100 and business_percentage > 0\n                \n            confidence = 0.8\n            notes = f\"Matched rule: {matched_rule.name}\"\n            metadata[\"rule_id\"] = str(matched_rule.id)\n            \n        # Finalize processing time\n        processing_time_ms = (time.time() - start_time) * 1000\n        \n        # Create result\n        result = CategorizationResult(\n            item_id=transaction.id,\n            original_item=transaction,\n            assigned_category=category,\n            confidence_score=confidence,\n            matched_rule=matched_rule,\n            processing_time_ms=processing_time_ms,\n            notes=notes,\n            metadata={\n                \"is_mixed_use\": is_mixed_use,\n                \"business_use_percentage\": business_percentage,\n                **metadata,\n            },\n        )\n        \n        # Record audit trail\n        previous_state = {}\n        if hasattr(transaction, 'category'):\n            previous_state[\"category\"] = getattr(transaction, 'category')\n        if hasattr(transaction, 'business_use_percentage'):\n            previous_state[\"business_use_percentage\"] = getattr(transaction, 'business_use_percentage')\n        \n        new_state = {\n            \"category\": category,\n            \"business_use_percentage\": business_percentage,\n        }\n        \n        self.record_audit(\n            item_id=transaction.id,\n            action=\"categorize\",\n            previous_state=previous_state,\n            new_state=new_state,\n        )\n        \n        # Update cache\n        self._categorization_cache[cache_key] = result\n        \n        return result\n    \n    def apply_categorization(\n        self, transaction: BaseTransaction, result: CategorizationResult\n    ) -> BaseTransaction:\n        \"\"\"\n        Apply a categorization result to a transaction.\n        \n        Args:\n            transaction: The transaction to update\n            result: The categorization result to apply\n            \n        Returns:\n            The updated transaction\n        \"\"\"\n        # Record previous state for audit\n        previous_state = {}\n        if hasattr(transaction, 'category'):\n            previous_state[\"category\"] = getattr(transaction, 'category')\n        if hasattr(transaction, 'business_use_percentage'):\n            previous_state[\"business_use_percentage\"] = getattr(transaction, 'business_use_percentage')\n        \n        # Apply categorization if possible\n        if hasattr(transaction, 'category') and result.assigned_category is not None:\n            setattr(transaction, 'category', result.assigned_category)\n            \n        if (\n            hasattr(transaction, 'business_use_percentage') \n            and result.metadata.get('business_use_percentage') is not None\n        ):\n            setattr(\n                transaction, \n                'business_use_percentage', \n                result.metadata['business_use_percentage']\n            )\n        \n        # Record audit trail\n        new_state = {}\n        if hasattr(transaction, 'category'):\n            new_state[\"category\"] = getattr(transaction, 'category')\n        if hasattr(transaction, 'business_use_percentage'):\n            new_state[\"business_use_percentage\"] = getattr(transaction, 'business_use_percentage')\n        \n        self.record_audit(\n            item_id=transaction.id,\n            action=\"apply_categorization\",\n            previous_state=previous_state,\n            new_state=new_state,\n        )\n        \n        # Clear cache for this transaction\n        cache_key = str(transaction.id)\n        if cache_key in self._categorization_cache:\n            del self._categorization_cache[cache_key]\n        \n        return transaction",
                "class MixedUseItem(BaseModel):\n    \"\"\"\n    Model for tracking items that are partially business and partially personal.\n    \n    Used in expense categorization to handle items used for both business\n    and personal purposes.\n    \"\"\"\n    \n    id: Union[str, UUID]\n    name: str\n    category: str\n    business_use_percentage: float\n    description: Optional[str] = None",
                "class InvestmentCategorizer(BaseCategorizer[Investment, ScreeningResult]):\n    \"\"\"\n    Categorizer for investments based on ethical criteria.\n    \n    Handles screening of investments against ESG criteria and exclusion/inclusion lists.\n    \"\"\"\n    \n    def __init__(self, criteria: EthicalCriteria):\n        \"\"\"\n        Initialize with the given ethical criteria.\n        \n        Args:\n            criteria: The ethical criteria to use for screening\n        \"\"\"\n        super().__init__()\n        self.criteria = criteria\n    \n    def categorize(\n        self, investment: Investment, recategorize: bool = False\n    ) -> ScreeningResult:\n        \"\"\"\n        Screen an investment against the ethical criteria.\n        \n        Args:\n            investment: The investment to screen\n            recategorize: Whether to rescreen even if already screened\n            \n        Returns:\n            ScreeningResult with the screening outcome\n        \"\"\"\n        # Start timing for performance benchmarking\n        start_time = time.time()\n        \n        # Check cache unless forced to recategorize\n        cache_key = str(investment.id)\n        if not recategorize and cache_key in self._categorization_cache:\n            return self._categorization_cache[cache_key]\n        \n        # Check for exclusions (immediate disqualification)\n        exclusion_flags = self._check_exclusions(investment)\n        \n        # Check for inclusions (positive attributes)\n        inclusion_flags = self._check_inclusions(investment)\n        \n        # Evaluate environmental criteria\n        env_score, env_details = self._evaluate_environmental_criteria(investment)\n        \n        # Evaluate social criteria\n        social_score, social_details = self._evaluate_social_criteria(investment)\n        \n        # Evaluate governance criteria\n        gov_score, gov_details = self._evaluate_governance_criteria(investment)\n        \n        # Calculate weighted overall score\n        overall_score = (\n            env_score * self.criteria.environmental[\"weight\"] +\n            social_score * self.criteria.social[\"weight\"] +\n            gov_score * self.criteria.governance[\"weight\"]\n        )\n        \n        # Determine if the investment passes the screening\n        passes = (\n            len(exclusion_flags) == 0 and  # No exclusion criteria violated\n            overall_score >= self.criteria.min_overall_score\n        )\n        \n        # Assign category based on outcome\n        category = \"PASS\" if passes else \"FAIL\"\n        \n        # Compile detailed results\n        details = {\n            \"environmental\": env_details,\n            \"social\": social_details,\n            \"governance\": gov_details,\n        }\n        \n        # Calculate processing time\n        processing_time_ms = (time.time() - start_time) * 1000\n        \n        # Create result\n        result = ScreeningResult(\n            item_id=investment.id,\n            original_item=investment,\n            assigned_category=category,\n            passed=passes,\n            overall_score=overall_score,\n            environmental_score=env_score,\n            social_score=social_score,\n            governance_score=gov_score,\n            exclusion_flags=exclusion_flags,\n            inclusion_flags=inclusion_flags,\n            confidence_score=0.9,  # High confidence for objective criteria\n            processing_time_ms=processing_time_ms,\n            metadata=details,\n        )\n        \n        # Record audit trail\n        self.record_audit(\n            item_id=investment.id,\n            action=\"screen\",\n            previous_state={},  # No previous state for first screening\n            new_state={\n                \"category\": category,\n                \"passed\": passes,\n                \"overall_score\": overall_score,\n                \"exclusion_flags\": exclusion_flags,\n                \"inclusion_flags\": inclusion_flags,\n            },\n        )\n        \n        # Update cache\n        self._categorization_cache[cache_key] = result\n        \n        return result\n    \n    def _check_exclusions(self, investment: Investment) -> List[str]:\n        \"\"\"\n        Check if the investment violates any exclusion criteria.\n        \n        Args:\n            investment: The investment to check\n            \n        Returns:\n            List of exclusion flags that apply to this investment\n        \"\"\"\n        exclusion_flags = []\n        \n        # Check industry exclusions (from the top-level exclusions list)\n        for exclusion in self.criteria.exclusions:\n            # Direct match on industry\n            if investment.industry.lower() == exclusion.lower():\n                exclusion_flags.append(f\"excluded_industry:{investment.industry}\")\n            \n            # Direct match on sector\n            if investment.sector.lower() == exclusion.lower():\n                exclusion_flags.append(f\"excluded_sector:{investment.sector}\")\n                \n            # Partial match on industry name (handles cases like \"fossil_fuels\" vs \"Oil & Gas\")\n            if exclusion.lower() in [\"fossil_fuels\", \"fossil_fuel\"] and \"oil\" in investment.industry.lower():\n                exclusion_flags.append(f\"excluded_fossil_fuels_industry:{investment.industry}\")\n                \n            # Check for related terms in industry or sector\n            for term in exclusion.lower().split(\"_\"):\n                if len(term) > 3:  # Only use meaningful words, not short ones\n                    if term in investment.industry.lower() or term in investment.sector.lower():\n                        exclusion_flags.append(f\"excluded_term:{term}\")\n        \n        # Check environmental exclusions\n        if (self.criteria.environmental.get(\"exclude_fossil_fuel_production\", False) and\n                (\"fossil_fuel_production\" in [p.lower() for p in investment.positive_practices + investment.controversies] \n                 or \"oil\" in investment.industry.lower())):\n            exclusion_flags.append(\"fossil_fuel_production\")\n        \n        # Check social exclusions\n        if (self.criteria.social.get(\"exclude_human_rights_violations\", False) and\n                any(\"human_rights\" in c.lower() for c in investment.controversies)):\n            exclusion_flags.append(\"human_rights_violations\")\n            \n        if (self.criteria.social.get(\"exclude_weapons_manufacturing\", False) and\n                \"weapons_manufacturing\" in [p.lower() for p in investment.positive_practices + investment.controversies]):\n            exclusion_flags.append(\"weapons_manufacturing\")\n        \n        # Check governance exclusions\n        if (self.criteria.governance.get(\"exclude_excessive_executive_compensation\", False) and\n                any(\"compensation\" in c.lower() for c in investment.controversies)):\n            exclusion_flags.append(\"excessive_executive_compensation\")\n        \n        return exclusion_flags\n    \n    def _check_inclusions(self, investment: Investment) -> List[str]:\n        \"\"\"\n        Check if the investment matches any inclusion criteria.\n        \n        Args:\n            investment: The investment to check\n            \n        Returns:\n            List of inclusion flags that apply to this investment\n        \"\"\"\n        inclusion_flags = []\n        \n        # Check industry inclusions\n        if investment.industry.lower() in [i.lower() for i in self.criteria.inclusions]:\n            inclusion_flags.append(f\"preferred_industry:{investment.industry}\")\n        \n        # Check sector inclusions\n        if investment.sector.lower() in [i.lower() for i in self.criteria.inclusions]:\n            inclusion_flags.append(f\"preferred_sector:{investment.sector}\")\n        \n        # Check positive practices\n        for practice in investment.positive_practices:\n            if practice.lower() in [i.lower() for i in self.criteria.inclusions]:\n                inclusion_flags.append(f\"positive_practice:{practice}\")\n        \n        return inclusion_flags\n    \n    def _evaluate_environmental_criteria(self, investment: Investment) -> Tuple[float, Dict[str, Any]]:\n        \"\"\"\n        Evaluate the investment against environmental criteria.\n        \n        Args:\n            investment: The investment to evaluate\n            \n        Returns:\n            Tuple of (score, details) where score is 0-100 and details contains the reasoning\n        \"\"\"\n        env_criteria = self.criteria.environmental\n        details = {}\n        \n        # Start with the ESG environmental score\n        base_score = investment.esg_ratings.environmental\n        details[\"base_score\"] = base_score\n        \n        # Adjust for carbon footprint\n        if \"max_carbon_footprint\" in env_criteria:\n            max_carbon = env_criteria[\"max_carbon_footprint\"]\n            if investment.carbon_footprint <= max_carbon:\n                carbon_ratio = investment.carbon_footprint / max_carbon\n                carbon_score = 100 - (carbon_ratio * 100)\n                details[\"carbon_footprint_score\"] = carbon_score\n            else:\n                # Exceeds maximum carbon footprint\n                carbon_penalty = min(30, (investment.carbon_footprint / max_carbon - 1) * 20)\n                base_score -= carbon_penalty\n                details[\"carbon_footprint_penalty\"] = carbon_penalty\n        \n        # Adjust for renewable energy use\n        if \"min_renewable_energy_use\" in env_criteria:\n            min_renewable = env_criteria[\"min_renewable_energy_use\"]\n            if investment.renewable_energy_use >= min_renewable:\n                renewable_bonus = (investment.renewable_energy_use - min_renewable) * 50\n                base_score += renewable_bonus\n                details[\"renewable_energy_bonus\"] = renewable_bonus\n            else:\n                # Below minimum renewable energy use\n                renewable_penalty = min(20, (min_renewable - investment.renewable_energy_use) * 40)\n                base_score -= renewable_penalty\n                details[\"renewable_energy_penalty\"] = renewable_penalty\n        \n        # Apply minimum environmental score threshold\n        if \"min_environmental_score\" in env_criteria:\n            min_score = env_criteria[\"min_environmental_score\"]\n            if base_score < min_score:\n                details[\"below_min_threshold\"] = True\n        \n        # Cap the final score at 100\n        final_score = max(0, min(100, base_score))\n        details[\"final_score\"] = final_score\n        \n        return final_score, details\n    \n    def _evaluate_social_criteria(self, investment: Investment) -> Tuple[float, Dict[str, Any]]:\n        \"\"\"\n        Evaluate the investment against social criteria.\n        \n        Args:\n            investment: The investment to evaluate\n            \n        Returns:\n            Tuple of (score, details) where score is 0-100 and details contains the reasoning\n        \"\"\"\n        social_criteria = self.criteria.social\n        details = {}\n        \n        # Start with the ESG social score\n        base_score = investment.esg_ratings.social\n        details[\"base_score\"] = base_score\n        \n        # Adjust for diversity score\n        if \"min_diversity_score\" in social_criteria:\n            min_diversity = social_criteria[\"min_diversity_score\"]\n            if investment.diversity_score >= min_diversity:\n                diversity_bonus = (investment.diversity_score - min_diversity) * 50\n                base_score += diversity_bonus\n                details[\"diversity_bonus\"] = diversity_bonus\n            else:\n                # Below minimum diversity score\n                diversity_penalty = min(20, (min_diversity - investment.diversity_score) * 40)\n                base_score -= diversity_penalty\n                details[\"diversity_penalty\"] = diversity_penalty\n        \n        # Adjust for controversies\n        controversy_count = len(investment.controversies)\n        if controversy_count > 0:\n            # More controversies means a larger penalty\n            controversy_penalty = min(30, controversy_count * 10)\n            base_score -= controversy_penalty\n            details[\"controversy_penalty\"] = controversy_penalty\n            details[\"controversies\"] = investment.controversies\n        \n        # Apply minimum social score threshold\n        if \"min_social_score\" in social_criteria:\n            min_score = social_criteria[\"min_social_score\"]\n            if base_score < min_score:\n                details[\"below_min_threshold\"] = True\n        \n        # Cap the final score at 100\n        final_score = max(0, min(100, base_score))\n        details[\"final_score\"] = final_score\n        \n        return final_score, details\n    \n    def _evaluate_governance_criteria(self, investment: Investment) -> Tuple[float, Dict[str, Any]]:\n        \"\"\"\n        Evaluate the investment against governance criteria.\n        \n        Args:\n            investment: The investment to evaluate\n            \n        Returns:\n            Tuple of (score, details) where score is 0-100 and details contains the reasoning\n        \"\"\"\n        gov_criteria = self.criteria.governance\n        details = {}\n        \n        # Start with the ESG governance score\n        base_score = investment.esg_ratings.governance\n        details[\"base_score\"] = base_score\n        \n        # Adjust for board independence\n        if \"min_board_independence\" in gov_criteria:\n            min_independence = gov_criteria[\"min_board_independence\"]\n            if investment.board_independence >= min_independence:\n                independence_bonus = (investment.board_independence - min_independence) * 50\n                base_score += independence_bonus\n                details[\"board_independence_bonus\"] = independence_bonus\n            else:\n                # Below minimum board independence\n                independence_penalty = min(20, (min_independence - investment.board_independence) * 40)\n                base_score -= independence_penalty\n                details[\"board_independence_penalty\"] = independence_penalty\n        \n        # Apply minimum governance score threshold\n        if \"min_governance_score\" in gov_criteria:\n            min_score = gov_criteria[\"min_governance_score\"]\n            if base_score < min_score:\n                details[\"below_min_threshold\"] = True\n        \n        # Cap the final score at 100\n        final_score = max(0, min(100, base_score))\n        details[\"final_score\"] = final_score\n        \n        return final_score, details",
                "class ScreeningResult(CategorizationResult):\n    \"\"\"\n    Result of screening an investment against ethical criteria.\n    \n    Extends the base categorization result with investment-specific fields.\n    \"\"\"\n    \n    passed: bool = False\n    overall_score: float = 0.0\n    environmental_score: float = 0.0\n    social_score: float = 0.0\n    governance_score: float = 0.0\n    exclusion_flags: List[str] = Field(default_factory=list)\n    inclusion_flags: List[str] = Field(default_factory=list)"
            ]
        }
    },
    "unified/ethical_finance/portfolio_analysis/__init__.py": {
        "logprobs": -187.22582435622002,
        "metrics": {
            "loc": 1,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 0,
            "blank": 0,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/ethical_finance/values_budgeting/__init__.py": {
        "logprobs": -204.57784938808697,
        "metrics": {
            "loc": 1,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 0,
            "blank": 0,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/common/core/models/category.py": {
        "logprobs": -1003.9378612063854,
        "metrics": {
            "loc": 201,
            "sloc": 142,
            "lloc": 85,
            "comments": 9,
            "multi": 15,
            "blank": 31,
            "cyclomatic": 26,
            "internal_imports": []
        }
    },
    "unified/common/core/models/__init__.py": {
        "logprobs": -436.5467413751125,
        "metrics": {
            "loc": 82,
            "sloc": 71,
            "lloc": 7,
            "comments": 5,
            "multi": 0,
            "blank": 10,
            "cyclomatic": 0,
            "internal_imports": [
                "class TransactionType(str, Enum):\n    \"\"\"Transaction type enum for all financial transactions.\"\"\"\n\n    INCOME = \"income\"\n    EXPENSE = \"expense\"\n    TAX_PAYMENT = \"tax_payment\"\n    TRANSFER = \"transfer\"\n    INVESTMENT = \"investment\"\n    DIVIDEND = \"dividend\"\n    INTEREST = \"interest\"",
                "class AccountType(str, Enum):\n    \"\"\"Account type enum for all financial accounts.\"\"\"\n\n    CHECKING = \"checking\"\n    SAVINGS = \"savings\"\n    CREDIT_CARD = \"credit_card\"\n    INVESTMENT = \"investment\"\n    RETIREMENT = \"retirement\"\n    CASH = \"cash\"\n    OTHER = \"other\"",
                "class BaseTransaction(BaseModel):\n    \"\"\"\n    Base transaction model for all financial transactions.\n    \n    This abstract base class provides common fields for tracking\n    financial transactions across different persona implementations.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    date: Union[date, datetime]\n    amount: float\n    description: str\n    transaction_type: TransactionType\n    \n    # Optional fields\n    account_id: Optional[str] = None\n    category: Optional[str] = None\n    tags: List[str] = Field(default_factory=list)\n    notes: Optional[str] = None\n    \n    @validator(\"amount\")\n    def validate_amount(cls, v):\n        \"\"\"Validate that amount is a valid number.\"\"\"\n        if not isinstance(v, (int, float)):\n            raise ValueError(\"Amount must be a number\")\n        return v",
                "class BusinessTransaction(BaseTransaction):\n    \"\"\"\n    Transaction model for business transactions with additional fields.\n    \n    Extends the base transaction model with business-specific fields.\n    \"\"\"\n\n    business_use_percentage: Optional[float] = None\n    project_id: Optional[str] = None\n    client_id: Optional[str] = None\n    invoice_id: Optional[str] = None\n    receipt_path: Optional[str] = None\n    \n    @validator(\"business_use_percentage\")\n    def validate_business_percentage(cls, v):\n        \"\"\"Validate that business use percentage is between 0 and 100.\"\"\"\n        if v is not None and (v < 0 or v > 100):\n            raise ValueError(\"Business use percentage must be between 0 and 100\")\n        return v",
                "class InvestmentTransaction(BaseTransaction):\n    \"\"\"\n    Transaction model for investment transactions with additional fields.\n    \n    Extends the base transaction model with investment-specific fields.\n    \"\"\"\n\n    investment_id: Optional[str] = None\n    shares: Optional[float] = None\n    price_per_share: Optional[float] = None\n    exchange_id: Optional[str] = None\n    fees: Optional[float] = None\n    \n    @validator(\"shares\")\n    def validate_shares(cls, v):\n        \"\"\"Validate that shares is a positive number.\"\"\"\n        if v is not None and v < 0:\n            raise ValueError(\"Shares must be a positive number\")\n        return v\n    \n    @validator(\"price_per_share\")\n    def validate_price(cls, v):\n        \"\"\"Validate that price is a positive number.\"\"\"\n        if v is not None and v < 0:\n            raise ValueError(\"Price per share must be a positive number\")\n        return v",
                "class Account(BaseModel):\n    \"\"\"Account model for all financial accounts.\"\"\"\n\n    id: str\n    name: str\n    account_type: AccountType\n    balance: float\n    currency: str = \"USD\"\n    institution: Optional[str] = None\n    description: Optional[str] = None\n    is_active: bool = True",
                "class AccountBalance(BaseModel):\n    \"\"\"Account balance at a specific point in time.\"\"\"\n\n    account_id: str\n    account_name: str\n    account_type: AccountType\n    balance: float\n    as_of_date: datetime",
                "class CategoryType(str, Enum):\n    \"\"\"Type of category for organizing and filtering.\"\"\"\n\n    INCOME = \"income\"\n    EXPENSE = \"expense\"\n    TAX = \"tax\"\n    INVESTMENT = \"investment\"\n    MIXED = \"mixed\"\n    OTHER = \"other\"",
                "class BaseCategory(BaseModel):\n    \"\"\"\n    Base category model for all categorization systems.\n    \n    This abstract base class provides common fields for categorizing\n    financial data across different persona implementations.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    type: CategoryType\n    description: Optional[str] = None\n    parent_id: Optional[Union[str, UUID]] = None\n    is_active: bool = True\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True\n        \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert the category to a dictionary.\"\"\"\n        return self.dict()",
                "class ExpenseCategory(BaseCategory):\n    \"\"\"\n    Expense category model for business vs. personal expenses.\n    \n    Specialized category model for expense categorization with\n    business-specific attributes.\n    \"\"\"\n    \n    is_business: bool = False\n    is_tax_deductible: bool = False\n    default_business_percentage: Optional[float] = None\n    \n    @root_validator(skip_on_failure=True)\n    def validate_business_category(cls, values):\n        \"\"\"Validate that business categories have proper attributes.\"\"\"\n        is_business = values.get(\"is_business\", False)\n        is_tax_deductible = values.get(\"is_tax_deductible\", False)\n        \n        # If it's a business expense, it should be tax deductible by default\n        if is_business and not is_tax_deductible:\n            values[\"is_tax_deductible\"] = True\n            \n        # If it has a business percentage, it should be a business expense\n        if values.get(\"default_business_percentage\") is not None and not is_business:\n            values[\"is_business\"] = True\n            \n        return values\n    \n    @classmethod\n    def create_standard_categories(cls) -> List[\"ExpenseCategory\"]:\n        \"\"\"Create a standard set of expense categories.\"\"\"\n        return [\n            cls(name=\"Business Supplies\", type=CategoryType.EXPENSE, \n                is_business=True, is_tax_deductible=True),\n            cls(name=\"Software\", type=CategoryType.EXPENSE, \n                is_business=True, is_tax_deductible=True),\n            cls(name=\"Marketing\", type=CategoryType.EXPENSE, \n                is_business=True, is_tax_deductible=True),\n            cls(name=\"Office Rent\", type=CategoryType.EXPENSE, \n                is_business=True, is_tax_deductible=True),\n            cls(name=\"Utilities\", type=CategoryType.EXPENSE, \n                is_business=True, is_tax_deductible=True, \n                default_business_percentage=50.0),\n            cls(name=\"Travel\", type=CategoryType.EXPENSE, \n                is_business=True, is_tax_deductible=True),\n            cls(name=\"Meals\", type=CategoryType.EXPENSE, \n                is_business=True, is_tax_deductible=True, \n                default_business_percentage=50.0),\n            cls(name=\"Equipment\", type=CategoryType.EXPENSE, \n                is_business=True, is_tax_deductible=True),\n            cls(name=\"Professional Development\", type=CategoryType.EXPENSE, \n                is_business=True, is_tax_deductible=True),\n            cls(name=\"Professional Services\", type=CategoryType.EXPENSE, \n                is_business=True, is_tax_deductible=True),\n            cls(name=\"Health Insurance\", type=CategoryType.EXPENSE, \n                is_business=True, is_tax_deductible=True),\n            cls(name=\"Retirement\", type=CategoryType.EXPENSE, \n                is_business=False, is_tax_deductible=True),\n            cls(name=\"Phone\", type=CategoryType.EXPENSE, \n                is_business=True, is_tax_deductible=True, \n                default_business_percentage=50.0),\n            cls(name=\"Internet\", type=CategoryType.EXPENSE, \n                is_business=True, is_tax_deductible=True, \n                default_business_percentage=50.0),\n            cls(name=\"Car\", type=CategoryType.EXPENSE, \n                is_business=True, is_tax_deductible=True, \n                default_business_percentage=50.0),\n            cls(name=\"Home Office\", type=CategoryType.EXPENSE, \n                is_business=True, is_tax_deductible=True, \n                default_business_percentage=25.0),\n            cls(name=\"Personal\", type=CategoryType.EXPENSE, \n                is_business=False, is_tax_deductible=False),\n            cls(name=\"Other\", type=CategoryType.EXPENSE, \n                is_business=False, is_tax_deductible=False),\n        ]",
                "class EthicalCategory(BaseCategory):\n    \"\"\"\n    Ethical category model for values-based categorization.\n    \n    Specialized category model for ethical categorization with\n    ESG (Environmental, Social, Governance) attributes.\n    \"\"\"\n    \n    dimension: str  # e.g., \"environmental\", \"social\", \"governance\"\n    positive_impact: bool = True\n    score_weight: float = 1.0\n    exclusion_flag: bool = False\n    inclusion_flag: bool = False\n    \n    @root_validator(skip_on_failure=True)\n    def validate_ethical_category(cls, values):\n        \"\"\"Validate that ethical categories have proper attributes.\"\"\"\n        # Ensure dimension is one of the allowed values\n        dimension = values.get(\"dimension\", \"\").lower()\n        if dimension not in [\"environmental\", \"social\", \"governance\", \"other\"]:\n            raise ValueError(\"Dimension must be one of: environmental, social, governance, other\")\n        \n        # Ensure weight is between 0 and 1\n        weight = values.get(\"score_weight\", 1.0)\n        if weight < 0 or weight > 1:\n            raise ValueError(\"Score weight must be between 0 and 1\")\n            \n        # Cannot be both inclusion and exclusion\n        if values.get(\"exclusion_flag\") and values.get(\"inclusion_flag\"):\n            raise ValueError(\"Category cannot be both an inclusion and exclusion criteria\")\n            \n        return values\n    \n    @classmethod\n    def create_standard_categories(cls) -> List[\"EthicalCategory\"]:\n        \"\"\"Create a standard set of ethical categories.\"\"\"\n        return [\n            # Environmental categories\n            cls(name=\"Renewable Energy\", type=CategoryType.INVESTMENT, \n                dimension=\"environmental\", positive_impact=True, \n                inclusion_flag=True, score_weight=0.8),\n            cls(name=\"Carbon Emissions\", type=CategoryType.INVESTMENT, \n                dimension=\"environmental\", positive_impact=False, \n                score_weight=0.7),\n            cls(name=\"Fossil Fuels\", type=CategoryType.INVESTMENT, \n                dimension=\"environmental\", positive_impact=False, \n                exclusion_flag=True, score_weight=0.9),\n            cls(name=\"Water Usage\", type=CategoryType.INVESTMENT, \n                dimension=\"environmental\", positive_impact=False, \n                score_weight=0.6),\n            \n            # Social categories\n            cls(name=\"Diversity & Inclusion\", type=CategoryType.INVESTMENT, \n                dimension=\"social\", positive_impact=True, \n                inclusion_flag=True, score_weight=0.7),\n            cls(name=\"Human Rights\", type=CategoryType.INVESTMENT, \n                dimension=\"social\", positive_impact=True, \n                score_weight=0.8),\n            cls(name=\"Labor Practices\", type=CategoryType.INVESTMENT, \n                dimension=\"social\", positive_impact=True, \n                score_weight=0.6),\n            cls(name=\"Weapons Manufacturing\", type=CategoryType.INVESTMENT, \n                dimension=\"social\", positive_impact=False, \n                exclusion_flag=True, score_weight=0.9),\n            \n            # Governance categories\n            cls(name=\"Board Independence\", type=CategoryType.INVESTMENT, \n                dimension=\"governance\", positive_impact=True, \n                score_weight=0.7),\n            cls(name=\"Executive Compensation\", type=CategoryType.INVESTMENT, \n                dimension=\"governance\", positive_impact=False, \n                score_weight=0.6),\n            cls(name=\"Corporate Ethics\", type=CategoryType.INVESTMENT, \n                dimension=\"governance\", positive_impact=True, \n                score_weight=0.8),\n            cls(name=\"Transparency\", type=CategoryType.INVESTMENT, \n                dimension=\"governance\", positive_impact=True, \n                score_weight=0.7),\n        ]",
                "class ProjectStatus(str, Enum):\n    \"\"\"Status of a project throughout its lifecycle.\"\"\"\n\n    PLANNED = \"planned\"\n    ACTIVE = \"active\"\n    ON_HOLD = \"on_hold\"\n    COMPLETED = \"completed\"\n    CANCELLED = \"cancelled\"",
                "class Project(BaseModel):\n    \"\"\"\n    Project model for tracking client projects.\n    \n    Used for organizing work, time tracking, and financial analysis\n    across multiple persona implementations.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    client_id: Optional[str] = None\n    start_date: Union[date, datetime]\n    end_date: Optional[Union[date, datetime]] = None\n    status: ProjectStatus = ProjectStatus.ACTIVE\n    hourly_rate: Optional[float] = None\n    fixed_price: Optional[float] = None\n    estimated_hours: Optional[float] = None\n    description: Optional[str] = None\n    tags: List[str] = Field(default_factory=list)\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    @validator(\"end_date\")\n    def validate_end_date(cls, v, values):\n        \"\"\"Validate that end_date is after start_date if both are provided.\"\"\"\n        if v is not None and \"start_date\" in values:\n            start = values[\"start_date\"]\n            if start > v:\n                raise ValueError(\"End date must be after start date\")\n        return v\n    \n    @validator(\"hourly_rate\", \"fixed_price\", \"estimated_hours\")\n    def validate_positive_numbers(cls, v):\n        \"\"\"Validate that financial amounts are positive numbers.\"\"\"\n        if v is not None and v < 0:\n            raise ValueError(\"Value must be a positive number\")\n        return v",
                "class Client(BaseModel):\n    \"\"\"\n    Client model for tracking information about clients.\n    \n    Used for organizing projects and managing client relationships.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    contact_email: Optional[str] = None\n    contact_phone: Optional[str] = None\n    address: Optional[str] = None\n    notes: Optional[str] = None\n    active: bool = True\n    metadata: Dict[str, Any] = Field(default_factory=dict)",
                "class TimeEntry(BaseModel):\n    \"\"\"\n    Time entry model for tracking hours worked on projects.\n    \n    Used for billing, project profitability analysis, and reporting.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    project_id: str\n    start_time: datetime\n    end_time: Optional[datetime] = None\n    duration_minutes: Optional[float] = None\n    description: str\n    billable: bool = True\n    tags: List[str] = Field(default_factory=list)\n    user_id: Optional[str] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    @validator(\"duration_minutes\", always=True)\n    def calculate_duration(cls, v, values):\n        \"\"\"Calculate duration from start and end time if not provided.\"\"\"\n        if v is not None:\n            return v\n        if (\n            \"start_time\" in values\n            and \"end_time\" in values\n            and values[\"end_time\"] is not None\n        ):\n            delta = values[\"end_time\"] - values[\"start_time\"]\n            return delta.total_seconds() / 60\n        return None\n    \n    @validator(\"end_time\")\n    def validate_end_time(cls, v, values):\n        \"\"\"Validate that end_time is after start_time if both are provided.\"\"\"\n        if v is not None and \"start_time\" in values:\n            if values[\"start_time\"] > v:\n                raise ValueError(\"End time must be after start time\")\n        return v",
                "class Invoice(BaseModel):\n    \"\"\"\n    Invoice model for tracking client billing.\n    \n    Used for revenue tracking, client relationship management, and tax reporting.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    client_id: str\n    project_id: Optional[str] = None\n    issue_date: Union[date, datetime]\n    due_date: Union[date, datetime]\n    amount: float\n    status: str  # e.g., \"draft\", \"sent\", \"paid\", \"overdue\"\n    payment_date: Optional[Union[date, datetime]] = None\n    description: Optional[str] = None\n    line_items: List[Dict[str, Any]] = Field(default_factory=list)\n    \n    @validator(\"due_date\")\n    def validate_due_date(cls, v, values):\n        \"\"\"Validate that due_date is after issue_date.\"\"\"\n        if \"issue_date\" in values:\n            if v < values[\"issue_date\"]:\n                raise ValueError(\"Due date must be after issue date\")\n        return v\n    \n    @validator(\"amount\")\n    def validate_amount(cls, v):\n        \"\"\"Validate that amount is a positive number.\"\"\"\n        if v < 0:\n            raise ValueError(\"Invoice amount must be a positive number\")\n        return v",
                "class ESGRating(BaseModel):\n    \"\"\"Environmental, Social, and Governance ratings for an investment.\"\"\"\n    \n    environmental: int\n    social: int\n    governance: int\n    overall: int\n    \n    @root_validator(skip_on_failure=True)\n    def validate_overall_score(cls, values):\n        \"\"\"Validate that the overall score is consistent with component scores.\"\"\"\n        env = values.get(\"environmental\", 0)\n        soc = values.get(\"social\", 0) \n        gov = values.get(\"governance\", 0)\n        overall = values.get(\"overall\", 0)\n        \n        # Check if overall is within a reasonable range of the average\n        component_avg = (env + soc + gov) / 3\n        if abs(overall - component_avg) > 15:  # Allow some variation in methodology\n            raise ValueError(\n                f\"Overall score {overall} is too different from component average {component_avg:.1f}\"\n            )\n        return values",
                "class Investment(BaseModel):\n    \"\"\"\n    Investment model representing an investment opportunity.\n    \n    Used for tracking investment options, ESG ratings, and performance.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    sector: str\n    industry: str\n    market_cap: float\n    price: float\n    esg_ratings: ESGRating\n    carbon_footprint: float\n    renewable_energy_use: float\n    diversity_score: float\n    board_independence: float\n    controversies: List[str] = Field(default_factory=list)\n    positive_practices: List[str] = Field(default_factory=list)\n    \n    @property\n    def has_major_controversies(self) -> bool:\n        \"\"\"Check if the investment has major controversies.\"\"\"\n        major_issues = [\"human_rights\", \"fraud\", \"corruption\", \"environmental_disaster\"]\n        return any(issue in self.controversies for issue in major_issues)\n    \n    @validator(\"market_cap\", \"price\", \"carbon_footprint\")\n    def validate_positive_numbers(cls, v):\n        \"\"\"Validate that financial amounts are positive numbers.\"\"\"\n        if v < 0:\n            raise ValueError(\"Value must be a positive number\")\n        return v\n    \n    @validator(\"renewable_energy_use\", \"diversity_score\", \"board_independence\")\n    def validate_percentage(cls, v):\n        \"\"\"Validate that percentages are between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Value must be between 0 and 1\")\n        return v",
                "class InvestmentHolding(BaseModel):\n    \"\"\"\n    Investment holding model for tracking specific holdings in a portfolio.\n    \n    Used for tracking portfolio composition, performance, and value.\n    \"\"\"\n\n    investment_id: str\n    shares: float\n    purchase_price: float\n    purchase_date: Union[date, datetime]\n    current_price: float\n    current_value: float\n    \n    @root_validator(skip_on_failure=True)\n    def validate_current_value(cls, values):\n        \"\"\"Validate that current_value = shares * current_price.\"\"\"\n        shares = values.get(\"shares\", 0)\n        current_price = values.get(\"current_price\", 0)\n        current_value = values.get(\"current_value\", 0)\n        \n        expected_value = shares * current_price\n        if abs(current_value - expected_value) > 0.01:  # Allow for small rounding errors\n            raise ValueError(\n                f\"Current value {current_value} does not match shares * price {expected_value}\"\n            )\n        return values\n    \n    @property\n    def return_percentage(self) -> float:\n        \"\"\"Calculate the percentage return on this holding.\"\"\"\n        return (self.current_price / self.purchase_price - 1) * 100",
                "class Portfolio(BaseModel):\n    \"\"\"\n    Portfolio model for tracking a collection of investment holdings.\n    \n    Used for portfolio analysis, performance tracking, and reporting.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    holdings: List[InvestmentHolding] = Field(default_factory=list)\n    total_value: float\n    cash_balance: float\n    creation_date: Union[date, datetime]\n    last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    @root_validator(skip_on_failure=True)\n    def validate_total_value(cls, values):\n        \"\"\"Validate that total_value equals the sum of all holdings' values.\"\"\"\n        holdings = values.get(\"holdings\", [])\n        total_value = values.get(\"total_value\", 0)\n        \n        if not holdings:\n            # If no holdings, total value should equal cash balance\n            cash_balance = values.get(\"cash_balance\", 0)\n            if abs(total_value - cash_balance) > 0.01:  # Allow for small rounding errors\n                raise ValueError(\n                    f\"Total value {total_value} does not match cash balance {cash_balance}\"\n                )\n        else:\n            # If there are holdings, validate total value\n            holdings_sum = sum(holding.current_value for holding in holdings)\n            if abs(total_value - holdings_sum) > 0.01:  # Allow for small rounding errors\n                raise ValueError(\n                    f\"Total value {total_value} does not match holdings sum {holdings_sum}\"\n                )\n        \n        return values\n    \n    @property\n    def total_assets(self) -> float:\n        \"\"\"Calculate total assets including cash.\"\"\"\n        return self.total_value + self.cash_balance\n    \n    def get_asset_allocation(self) -> Dict[str, float]:\n        \"\"\"Calculate the allocation percentage for each asset.\"\"\"\n        if not self.holdings:\n            return {\"cash\": 100.0}\n        \n        allocation = {}\n        total_assets = self.total_assets\n        \n        # Add cash allocation\n        cash_percent = (self.cash_balance / total_assets) * 100\n        allocation[\"cash\"] = cash_percent\n        \n        # Add investment allocations\n        for holding in self.holdings:\n            holding_percent = (holding.current_value / total_assets) * 100\n            allocation[holding.investment_id] = holding_percent\n            \n        return allocation",
                "class EthicalCriteria(BaseModel):\n    \"\"\"\n    Ethical screening criteria for investments.\n    \n    Used for evaluating investments against personalized ethical standards.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    environmental: Dict[str, Any]\n    social: Dict[str, Any]\n    governance: Dict[str, Any]\n    min_overall_score: float\n    exclusions: List[str] = Field(default_factory=list)\n    inclusions: List[str] = Field(default_factory=list)\n    \n    @root_validator(skip_on_failure=True)\n    def validate_criteria_weights(cls, values):\n        \"\"\"Validate that criteria weights are included and sum approximately to 1.\"\"\"\n        for field_name in ['environmental', 'social', 'governance']:\n            field_value = values.get(field_name, {})\n            \n            # Check that weight exists\n            if 'weight' not in field_value:\n                raise ValueError(f\"{field_name} criteria must include a weight\")\n            \n            # Ensure weight is between 0 and 1\n            if field_value['weight'] < 0 or field_value['weight'] > 1:\n                raise ValueError(f\"{field_name} weight must be between 0 and 1\")\n        \n        # Check that weights sum to approximately 1\n        weights_sum = (\n            values.get('environmental', {}).get('weight', 0) + \n            values.get('social', {}).get('weight', 0) + \n            values.get('governance', {}).get('weight', 0)\n        )\n        \n        if abs(weights_sum - 1.0) > 0.01:  # Allow for small rounding errors\n            raise ValueError(f\"Criteria weights sum to {weights_sum}, expected 1.0\")\n            \n        return values",
                "class ImpactMetric(BaseModel):\n    \"\"\"\n    Impact metric model for defining and tracking non-financial impacts.\n    \n    Used for measuring the social and environmental impact of investments.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    category: str\n    unit: str\n    description: str\n    higher_is_better: bool\n    data_source: str",
                "class ImpactData(BaseModel):\n    \"\"\"\n    Impact data for a specific investment in a specific year.\n    \n    Used for tracking the actual impact of investments over time.\n    \"\"\"\n\n    investment_id: str\n    year: int\n    metrics: Dict[str, float]\n    \n    @validator(\"year\")\n    def validate_year(cls, v):\n        \"\"\"Validate that year is reasonable.\"\"\"\n        current_year = datetime.now().year\n        if v < 1900 or v > current_year + 1:\n            raise ValueError(f\"Year {v} is outside reasonable range\")\n        return v",
                "class TaxPayment(BaseModel):\n    \"\"\"\n    Tax payment model for tracking payments to tax authorities.\n    \n    Used for tax planning, compliance, and financial projections.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    date: Union[date, datetime]\n    amount: float\n    tax_year: int\n    quarter: Optional[int] = None\n    payment_method: str\n    jurisdiction: str = \"federal\"  # e.g., \"federal\", \"state\", \"local\"\n    confirmation_number: Optional[str] = None\n    notes: Optional[str] = None\n    \n    @validator(\"amount\")\n    def validate_amount(cls, v):\n        \"\"\"Validate that amount is a positive number.\"\"\"\n        if v < 0:\n            raise ValueError(\"Tax payment amount must be a positive number\")\n        return v\n    \n    @validator(\"tax_year\")\n    def validate_tax_year(cls, v):\n        \"\"\"Validate that tax year is reasonable.\"\"\"\n        current_year = datetime.now().year\n        if v < 1900 or v > current_year + 1:\n            raise ValueError(f\"Tax year {v} is outside reasonable range\")\n        return v\n    \n    @validator(\"quarter\")\n    def validate_quarter(cls, v):\n        \"\"\"Validate that quarter is 1-4.\"\"\"\n        if v is not None and (v < 1 or v > 4):\n            raise ValueError(\"Quarter must be between 1 and 4\")\n        return v",
                "class TaxRate(BaseModel):\n    \"\"\"\n    Tax rate model for a specific income bracket.\n    \n    Used for calculating tax obligations and financial planning.\n    \"\"\"\n\n    bracket_min: float\n    bracket_max: Optional[float] = None\n    rate: float  # Percentage (0-100)\n    tax_year: int\n    jurisdiction: str = \"federal\"  # e.g., \"federal\", \"state\", \"local\"\n    \n    @validator(\"rate\")\n    def validate_rate(cls, v):\n        \"\"\"Validate that rate is between 0 and 100.\"\"\"\n        if v < 0 or v > 100:\n            raise ValueError(\"Tax rate must be between 0 and 100\")\n        return v\n    \n    @validator(\"tax_year\")\n    def validate_tax_year(cls, v):\n        \"\"\"Validate that tax year is reasonable.\"\"\"\n        current_year = datetime.now().year\n        if v < 1900 or v > current_year + 1:\n            raise ValueError(f\"Tax year {v} is outside reasonable range\")\n        return v",
                "class TaxDeduction(BaseModel):\n    \"\"\"\n    Tax deduction model for tracking deductible expenses.\n    \n    Used for tax optimization and financial planning.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    amount: float\n    tax_year: int\n    category: str\n    description: Optional[str] = None\n    jurisdiction: str = \"federal\"\n    receipt_path: Optional[str] = None\n    \n    @validator(\"amount\")\n    def validate_amount(cls, v):\n        \"\"\"Validate that amount is a positive number.\"\"\"\n        if v < 0:\n            raise ValueError(\"Deduction amount must be a positive number\")\n        return v\n    \n    @validator(\"tax_year\")\n    def validate_tax_year(cls, v):\n        \"\"\"Validate that tax year is reasonable.\"\"\"\n        current_year = datetime.now().year\n        if v < 1900 or v > current_year + 1:\n            raise ValueError(f\"Tax year {v} is outside reasonable range\")\n        return v",
                "class TaxLiability(BaseModel):\n    \"\"\"\n    Tax liability model for tracking calculated tax obligations.\n    \n    Used for tax planning, compliance, and financial projections.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    tax_year: int\n    jurisdiction: str = \"federal\"\n    income: float\n    deductions: float\n    taxable_income: float\n    tax_amount: float\n    payments_made: float = 0.0\n    remaining_balance: float\n    calculation_date: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    @validator(\"income\", \"tax_amount\", \"payments_made\")\n    def validate_positive_numbers(cls, v):\n        \"\"\"Validate that financial amounts are positive numbers.\"\"\"\n        if v < 0:\n            raise ValueError(\"Value must be a positive number\")\n        return v\n    \n    @validator(\"tax_year\")\n    def validate_tax_year(cls, v):\n        \"\"\"Validate that tax year is reasonable.\"\"\"\n        current_year = datetime.now().year\n        if v < 1900 or v > current_year + 1:\n            raise ValueError(f\"Tax year {v} is outside reasonable range\")\n        return v\n    \n    @validator(\"remaining_balance\", always=True)\n    def calculate_remaining_balance(cls, v, values):\n        \"\"\"Calculate remaining balance if not provided.\"\"\"\n        if \"tax_amount\" in values and \"payments_made\" in values:\n            return values[\"tax_amount\"] - values[\"payments_made\"]\n        return v"
            ]
        }
    },
    "unified/ethical_finance/portfolio_analysis/analysis.py": {
        "logprobs": -5543.861580893313,
        "metrics": {
            "loc": 1241,
            "sloc": 800,
            "lloc": 464,
            "comments": 165,
            "multi": 99,
            "blank": 196,
            "cyclomatic": 164,
            "internal_imports": [
                "class BaseAnalyzer(Generic[T, R], ABC):\n    \"\"\"\n    Abstract base class for analysis engines.\n    \n    Defines the core interface and functionality for all analyzers\n    across different persona implementations.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the analyzer.\"\"\"\n        self._analysis_cache: Dict[str, R] = {}\n    \n    @abstractmethod\n    def analyze(\n        self, subject: T, parameters: Optional[AnalysisParameters] = None\n    ) -> R:\n        \"\"\"\n        Analyze a single subject.\n        \n        Args:\n            subject: The subject to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Analysis result\n        \"\"\"\n        pass\n    \n    def analyze_batch(\n        self, subjects: List[T], parameters: Optional[AnalysisParameters] = None\n    ) -> List[R]:\n        \"\"\"\n        Analyze multiple subjects.\n        \n        Args:\n            subjects: List of subjects to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            List of analysis results\n        \"\"\"\n        # Start performance timer\n        start_time = time.time()\n        \n        # Analyze each subject\n        results = []\n        for subject in subjects:\n            result = self.analyze(subject, parameters)\n            results.append(result)\n        \n        # Performance metrics\n        elapsed_time = time.time() - start_time\n        \n        return results\n    \n    def clear_cache(self) -> None:\n        \"\"\"Clear the analysis cache.\"\"\"\n        self._analysis_cache = {}\n    \n    def _generate_cache_key(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> str:\n        \"\"\"\n        Generate a cache key for a subject and parameters.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cache key string\n        \"\"\"\n        # Start with the subject ID\n        key = f\"subject_{subject_id}\"\n        \n        # Add parameter details if provided\n        if parameters:\n            param_dict = parameters.dict(exclude_none=True)\n            for k, v in sorted(param_dict.items()):\n                if k != \"custom_settings\":\n                    key += f\"_{k}_{v}\"\n                    \n            # Handle custom settings separately (they could be complex)\n            if parameters.custom_settings:\n                for k, v in sorted(parameters.custom_settings.items()):\n                    key += f\"_{k}_{v}\"\n        \n        return key\n    \n    def _get_from_cache(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> Optional[R]:\n        \"\"\"\n        Get a cached analysis result if available.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cached result or None if not found\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        return self._analysis_cache.get(cache_key)\n    \n    def _save_to_cache(\n        self, subject_id: Union[str, UUID], result: R, parameters: Optional[AnalysisParameters] = None\n    ) -> None:\n        \"\"\"\n        Save an analysis result to the cache.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            result: The analysis result to cache\n            parameters: Optional parameters to configure the analysis\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        self._analysis_cache[cache_key] = result",
                "class AnalysisParameters(BaseModel):\n    \"\"\"\n    Parameters for an analysis operation.\n    \n    Used to configure analysis options and settings.\n    \"\"\"\n    \n    period_start: Optional[Union[date, datetime]] = None\n    period_end: Optional[Union[date, datetime]] = None\n    include_details: bool = True\n    calculation_mode: str = \"standard\"  # \"standard\", \"detailed\", \"fast\"\n    grouping: Optional[str] = None\n    custom_settings: Dict[str, Any] = Field(default_factory=dict)",
                "class AnalysisResult(BaseModel, Generic[T]):\n    \"\"\"\n    Result of an analysis operation.\n    \n    Provides information about the analysis process and outcome.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    subject_id: Optional[Union[str, UUID]] = None\n    subject_type: str\n    analysis_type: str\n    analysis_date: datetime = Field(default_factory=datetime.now)\n    processing_time_ms: Optional[float] = None\n    result_summary: Dict[str, Any] = Field(default_factory=dict)\n    detailed_results: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class PortfolioAnalyzer(BaseAnalyzer[Portfolio, PortfolioAnalysisResult]):\n    \"\"\"\n    Analyzer for investment portfolios.\n    \n    Used for portfolio composition, performance, and ESG analysis.\n    \"\"\"\n    \n    def __init__(self, investments: Dict[str, Investment]):\n        \"\"\"\n        Initialize with a database of available investments.\n        \n        Args:\n            investments: Dictionary mapping investment IDs to Investment objects\n        \"\"\"\n        super().__init__()\n        self.investments = investments\n    \n    def analyze(\n        self, portfolio: Portfolio, parameters: Optional[PortfolioAnalysisParameters] = None\n    ) -> PortfolioAnalysisResult:\n        \"\"\"\n        Analyze a portfolio.\n        \n        Args:\n            portfolio: The portfolio to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Portfolio analysis result\n        \"\"\"\n        # Start timing for performance benchmarking\n        start_time = time.time()\n        \n        # Set default parameters if not provided\n        if parameters is None:\n            parameters = PortfolioAnalysisParameters()\n        \n        # Check cache unless details have changed\n        cached_result = self._get_from_cache(portfolio.id, parameters)\n        if cached_result and cached_result.analysis_date > portfolio.last_updated:\n            return cached_result\n        \n        # Build the portfolio breakdown\n        breakdown = self._calculate_portfolio_breakdown(portfolio)\n        \n        # Calculate performance metrics if requested\n        performance = None\n        if parameters.include_performance_metrics:\n            performance = self._calculate_performance_metrics(\n                portfolio, parameters.risk_free_rate, parameters.benchmark_id\n            )\n        \n        # Calculate ESG metrics if requested\n        esg_metrics = None\n        if parameters.include_esg_analysis:\n            esg_metrics = self._calculate_esg_metrics(portfolio)\n        \n        # Calculate diversification score\n        diversification_score = self._calculate_diversification_score(breakdown)\n        \n        # Identify risk exposures\n        risk_exposure = self._identify_risk_exposures(portfolio, breakdown)\n        \n        # Generate recommendations\n        recommendations = self._generate_recommendations(\n            portfolio, breakdown, diversification_score, risk_exposure\n        )\n        \n        # Calculate processing time\n        processing_time_ms = (time.time() - start_time) * 1000\n        \n        # Create the result\n        result = PortfolioAnalysisResult(\n            id=UUID(),\n            subject_id=portfolio.id,\n            subject_type=\"portfolio\",\n            analysis_type=\"comprehensive\",\n            analysis_date=datetime.now(),\n            processing_time_ms=processing_time_ms,\n            result_summary={\n                \"total_value\": portfolio.total_value,\n                \"num_holdings\": len(portfolio.holdings),\n                \"diversification_score\": diversification_score,\n                \"top_sector\": self._get_top_category(breakdown.by_sector),\n                \"top_industry\": self._get_top_category(breakdown.by_industry),\n            },\n            detailed_results={\n                \"holdings\": [\n                    {\n                        \"investment_id\": h.investment_id,\n                        \"weight\": (h.current_value / portfolio.total_value) if portfolio.total_value > 0 else 0,\n                    }\n                    for h in portfolio.holdings\n                ],\n            },\n            breakdown=breakdown,\n            performance=performance,\n            esg_metrics=esg_metrics,\n            diversification_score=diversification_score,\n            risk_exposure=risk_exposure,\n            recommendations=recommendations,\n        )\n        \n        # Save to cache\n        self._save_to_cache(portfolio.id, result, parameters)\n        \n        return result\n    \n    def _calculate_portfolio_breakdown(self, portfolio: Portfolio) -> PortfolioBreakdown:\n        \"\"\"\n        Calculate the breakdown of a portfolio by different dimensions.\n        \n        Args:\n            portfolio: The portfolio to analyze\n            \n        Returns:\n            PortfolioBreakdown with composition details\n        \"\"\"\n        # Initialize counters\n        by_sector = {}\n        by_industry = {}\n        by_market_cap = {}\n        by_esg_rating = {}\n        by_region = {}\n        \n        # Calculate the weight of each holding\n        total_value = portfolio.total_value\n        if total_value <= 0:\n            # Return empty breakdown for empty portfolio\n            return PortfolioBreakdown()\n        \n        # Analyze each holding\n        for holding in portfolio.holdings:\n            weight = holding.current_value / total_value\n            investment = self.investments.get(holding.investment_id)\n            \n            if investment:\n                # Sector breakdown\n                sector = investment.sector\n                by_sector[sector] = by_sector.get(sector, 0) + weight\n                \n                # Industry breakdown\n                industry = investment.industry\n                by_industry[industry] = by_industry.get(industry, 0) + weight\n                \n                # Market cap breakdown\n                market_cap_category = self._categorize_market_cap(investment.market_cap)\n                by_market_cap[market_cap_category] = by_market_cap.get(market_cap_category, 0) + weight\n                \n                # ESG rating breakdown\n                esg_category = self._categorize_esg_rating(investment.esg_ratings.overall)\n                by_esg_rating[esg_category] = by_esg_rating.get(esg_category, 0) + weight\n                \n                # Region breakdown (placeholder - would need region data)\n                region = \"unknown\"\n                by_region[region] = by_region.get(region, 0) + weight\n        \n        # Calculate concentration metrics\n        concentration_metrics = {\n            \"herfindahl_index\": self._calculate_herfindahl_index(by_sector),\n            \"top_5_holdings_weight\": self._calculate_top_n_weight(portfolio.holdings, total_value, 5),\n            \"sector_count\": len(by_sector),\n            \"industry_count\": len(by_industry),\n        }\n        \n        return PortfolioBreakdown(\n            by_sector=by_sector,\n            by_industry=by_industry,\n            by_market_cap=by_market_cap,\n            by_esg_rating=by_esg_rating,\n            by_region=by_region,\n            concentration_metrics=concentration_metrics,\n        )\n    \n    def _calculate_performance_metrics(\n        self, portfolio: Portfolio, risk_free_rate: float, benchmark_id: Optional[str]\n    ) -> PortfolioPerformance:\n        \"\"\"\n        Calculate performance metrics for a portfolio.\n        \n        Args:\n            portfolio: The portfolio to analyze\n            risk_free_rate: The risk-free rate for Sharpe ratio calculation\n            benchmark_id: Optional benchmark portfolio ID for comparison\n            \n        Returns:\n            PortfolioPerformance with performance metrics\n        \"\"\"\n        # This would require historical price data, which we don't have.\n        # In a real implementation, we would retrieve historical data and calculate returns.\n        # For now, we'll use placeholder values.\n        \n        # Get total return from current data\n        total_return = 0.0\n        total_investment = 0.0\n        \n        for holding in portfolio.holdings:\n            total_investment += holding.shares * holding.purchase_price\n            total_return += holding.shares * (holding.current_price - holding.purchase_price)\n        \n        return_pct = (total_return / total_investment) if total_investment > 0 else 0.0\n        \n        # Placeholder values for other metrics\n        annualized_return = return_pct  # Simplified\n        volatility = 0.15  # Placeholder\n        sharpe_ratio = (annualized_return - risk_free_rate) / volatility if volatility > 0 else 0\n        max_drawdown = 0.1  # Placeholder\n        \n        return PortfolioPerformance(\n            total_return=return_pct,\n            annualized_return=annualized_return,\n            volatility=volatility,\n            sharpe_ratio=sharpe_ratio,\n            max_drawdown=max_drawdown,\n        )\n    \n    def _calculate_esg_metrics(self, portfolio: Portfolio) -> PortfolioESGMetrics:\n        \"\"\"\n        Calculate ESG metrics for a portfolio.\n        \n        Args:\n            portfolio: The portfolio to analyze\n            \n        Returns:\n            PortfolioESGMetrics with ESG characteristics\n        \"\"\"\n        # Initialize counters for weighted average calculation\n        weighted_env_score = 0.0\n        weighted_social_score = 0.0\n        weighted_gov_score = 0.0\n        weighted_overall_score = 0.0\n        weighted_carbon_footprint = 0.0\n        weighted_renewable_energy = 0.0\n        weighted_diversity = 0.0\n        weighted_controversy = 0.0\n        \n        # Calculate the weight of each holding\n        total_value = portfolio.total_value\n        if total_value <= 0:\n            # Return default metrics for empty portfolio\n            return PortfolioESGMetrics(\n                overall_esg_score=0.0,\n                environmental_score=0.0,\n                social_score=0.0,\n                governance_score=0.0,\n                carbon_footprint=0.0,\n                renewable_energy_exposure=0.0,\n                diversity_score=0.0,\n                controversy_exposure=0.0,\n            )\n        \n        # Calculate weighted ESG metrics\n        for holding in portfolio.holdings:\n            weight = holding.current_value / total_value\n            investment = self.investments.get(holding.investment_id)\n            \n            if investment:\n                weighted_env_score += investment.esg_ratings.environmental * weight\n                weighted_social_score += investment.esg_ratings.social * weight\n                weighted_gov_score += investment.esg_ratings.governance * weight\n                weighted_overall_score += investment.esg_ratings.overall * weight\n                weighted_carbon_footprint += investment.carbon_footprint * weight\n                weighted_renewable_energy += investment.renewable_energy_use * weight\n                weighted_diversity += investment.diversity_score * weight\n                weighted_controversy += len(investment.controversies) * weight\n        \n        return PortfolioESGMetrics(\n            overall_esg_score=weighted_overall_score,\n            environmental_score=weighted_env_score,\n            social_score=weighted_social_score,\n            governance_score=weighted_gov_score,\n            carbon_footprint=weighted_carbon_footprint,\n            renewable_energy_exposure=weighted_renewable_energy,\n            diversity_score=weighted_diversity,\n            controversy_exposure=weighted_controversy,\n            impact_metrics={\n                \"carbon_reduction\": weighted_renewable_energy * 100,\n                \"social_impact\": weighted_social_score,\n            },\n        )\n    \n    def _calculate_diversification_score(self, breakdown: PortfolioBreakdown) -> float:\n        \"\"\"\n        Calculate a diversification score for a portfolio.\n        \n        Args:\n            breakdown: The portfolio breakdown\n            \n        Returns:\n            Diversification score between 0 and 1\n        \"\"\"\n        # Calculate based on Herfindahl index (1 - concentration)\n        herfindahl = breakdown.concentration_metrics.get(\"herfindahl_index\", 1.0)\n        sector_score = 1.0 - herfindahl\n        \n        # Adjust based on number of sectors and industries\n        sector_count = breakdown.concentration_metrics.get(\"sector_count\", 0)\n        industry_count = breakdown.concentration_metrics.get(\"industry_count\", 0)\n        \n        sector_factor = min(1.0, sector_count / 10)\n        industry_factor = min(1.0, industry_count / 20)\n        \n        # Final score is a weighted average\n        return 0.5 * sector_score + 0.3 * sector_factor + 0.2 * industry_factor\n    \n    def _identify_risk_exposures(\n        self, portfolio: Portfolio, breakdown: PortfolioBreakdown\n    ) -> Dict[str, float]:\n        \"\"\"\n        Identify key risk exposures in a portfolio.\n        \n        Args:\n            portfolio: The portfolio to analyze\n            breakdown: The portfolio breakdown\n            \n        Returns:\n            Dictionary mapping risk types to exposure levels\n        \"\"\"\n        risk_exposure = {}\n        \n        # Concentration risk\n        top_5_weight = breakdown.concentration_metrics.get(\"top_5_holdings_weight\", 0.0)\n        risk_exposure[\"concentration_risk\"] = top_5_weight\n        \n        # Sector concentration risk\n        top_sector = self._get_top_category(breakdown.by_sector)\n        top_sector_weight = breakdown.by_sector.get(top_sector, 0.0) if top_sector else 0.0\n        risk_exposure[\"sector_concentration_risk\"] = top_sector_weight\n        \n        # ESG risk\n        if \"Lowest\" in breakdown.by_esg_rating:\n            risk_exposure[\"esg_risk\"] = breakdown.by_esg_rating[\"Lowest\"]\n        else:\n            risk_exposure[\"esg_risk\"] = 0.0\n        \n        # Market cap risk\n        if \"Small\" in breakdown.by_market_cap:\n            risk_exposure[\"small_cap_risk\"] = breakdown.by_market_cap[\"Small\"]\n        else:\n            risk_exposure[\"small_cap_risk\"] = 0.0\n        \n        return risk_exposure\n    \n    def _generate_recommendations(\n        self,\n        portfolio: Portfolio,\n        breakdown: PortfolioBreakdown,\n        diversification_score: float,\n        risk_exposure: Dict[str, float],\n    ) -> List[str]:\n        \"\"\"\n        Generate portfolio improvement recommendations.\n        \n        Args:\n            portfolio: The portfolio to analyze\n            breakdown: The portfolio breakdown\n            diversification_score: The calculated diversification score\n            risk_exposure: The identified risk exposures\n            \n        Returns:\n            List of recommendation strings\n        \"\"\"\n        recommendations = []\n        \n        # Diversification recommendations\n        if diversification_score < 0.4:\n            recommendations.append(\n                \"Low diversification detected. Consider adding investments from more sectors.\"\n            )\n        elif diversification_score < 0.7:\n            recommendations.append(\n                \"Moderate diversification. Consider reducing exposure to your top sector.\"\n            )\n        \n        # Concentration risk\n        if risk_exposure.get(\"concentration_risk\", 0.0) > 0.6:\n            recommendations.append(\n                \"High concentration in top holdings. Consider rebalancing for better risk management.\"\n            )\n        \n        # Sector concentration\n        if risk_exposure.get(\"sector_concentration_risk\", 0.0) > 0.4:\n            top_sector = self._get_top_category(breakdown.by_sector)\n            recommendations.append(\n                f\"High exposure to {top_sector} sector. Consider diversifying into other sectors.\"\n            )\n        \n        # ESG recommendations\n        if risk_exposure.get(\"esg_risk\", 0.0) > 0.2:\n            recommendations.append(\n                \"Significant exposure to low-rated ESG investments. Consider alternatives with better ESG profiles.\"\n            )\n        \n        return recommendations\n    \n    def _categorize_market_cap(self, market_cap: float) -> str:\n        \"\"\"\n        Categorize an investment by market cap.\n        \n        Args:\n            market_cap: The market capitalization value\n            \n        Returns:\n            Market cap category string\n        \"\"\"\n        if market_cap >= 10_000_000_000:\n            return \"Large\"\n        elif market_cap >= 2_000_000_000:\n            return \"Mid\"\n        else:\n            return \"Small\"\n    \n    def _categorize_esg_rating(self, rating: int) -> str:\n        \"\"\"\n        Categorize an investment by ESG rating.\n        \n        Args:\n            rating: The ESG rating value\n            \n        Returns:\n            ESG rating category string\n        \"\"\"\n        if rating >= 80:\n            return \"Highest\"\n        elif rating >= 60:\n            return \"High\"\n        elif rating >= 40:\n            return \"Medium\"\n        elif rating >= 20:\n            return \"Low\"\n        else:\n            return \"Lowest\"\n    \n    def _calculate_herfindahl_index(self, weights: Dict[str, float]) -> float:\n        \"\"\"\n        Calculate the Herfindahl index (measure of concentration).\n        \n        Args:\n            weights: Dictionary mapping categories to weights\n            \n        Returns:\n            Herfindahl index value between 0 and 1\n        \"\"\"\n        return sum(weight ** 2 for weight in weights.values())\n    \n    def _calculate_top_n_weight(\n        self, holdings: List[InvestmentHolding], total_value: float, n: int\n    ) -> float:\n        \"\"\"\n        Calculate the weight of the top N holdings.\n        \n        Args:\n            holdings: List of investment holdings\n            total_value: Total portfolio value\n            n: Number of top holdings to consider\n            \n        Returns:\n            Total weight of top N holdings\n        \"\"\"\n        if not holdings or total_value <= 0:\n            return 0.0\n        \n        # Sort holdings by value (descending)\n        sorted_holdings = sorted(\n            holdings, key=lambda h: h.current_value, reverse=True\n        )\n        \n        # Get the top N holdings\n        top_n = sorted_holdings[:min(n, len(sorted_holdings))]\n        \n        # Calculate their total weight\n        top_n_value = sum(h.current_value for h in top_n)\n        \n        return top_n_value / total_value\n    \n    def _get_top_category(self, categories: Dict[str, float]) -> Optional[str]:\n        \"\"\"\n        Get the top category by weight.\n        \n        Args:\n            categories: Dictionary mapping categories to weights\n            \n        Returns:\n            The top category or None if empty\n        \"\"\"\n        if not categories:\n            return None\n        \n        return max(categories.items(), key=lambda x: x[1])[0]",
                "class PortfolioAnalysisParameters(AnalysisParameters):\n    \"\"\"\n    Parameters for portfolio analysis.\n    \n    Used to configure portfolio analysis options and settings.\n    \"\"\"\n    \n    include_sector_breakdown: bool = True\n    include_esg_analysis: bool = True\n    include_performance_metrics: bool = True\n    compare_to_benchmark: bool = False\n    benchmark_id: Optional[str] = None\n    risk_free_rate: float = 0.02",
                "class PortfolioAnalysisResult(AnalysisResult):\n    \"\"\"\n    Result of a portfolio analysis operation.\n    \n    Provides detailed information about portfolio composition and performance.\n    \"\"\"\n    \n    breakdown: PortfolioBreakdown\n    performance: Optional[PortfolioPerformance] = None\n    esg_metrics: Optional[PortfolioESGMetrics] = None\n    diversification_score: float\n    risk_exposure: Dict[str, float] = Field(default_factory=dict)\n    recommendations: List[str] = Field(default_factory=list)",
                "class PortfolioBreakdown(BaseModel):\n    \"\"\"\n    Breakdown of a portfolio by different dimensions.\n    \n    Used for analyzing portfolio composition and diversity.\n    \"\"\"\n    \n    by_sector: Dict[str, float] = Field(default_factory=dict)\n    by_industry: Dict[str, float] = Field(default_factory=dict)\n    by_market_cap: Dict[str, float] = Field(default_factory=dict)\n    by_esg_rating: Dict[str, float] = Field(default_factory=dict)\n    by_region: Dict[str, float] = Field(default_factory=dict)\n    concentration_metrics: Dict[str, float] = Field(default_factory=dict)",
                "class PortfolioPerformance(BaseModel):\n    \"\"\"\n    Performance metrics for a portfolio.\n    \n    Used for analyzing historical and risk-adjusted returns.\n    \"\"\"\n    \n    total_return: float\n    annualized_return: float\n    volatility: float\n    sharpe_ratio: float\n    max_drawdown: float\n    alpha: Optional[float] = None\n    beta: Optional[float] = None\n    correlation_to_benchmark: Optional[float] = None",
                "class PortfolioESGMetrics(BaseModel):\n    \"\"\"\n    ESG metrics for a portfolio.\n    \n    Used for analyzing environmental, social, and governance characteristics.\n    \"\"\"\n    \n    overall_esg_score: float\n    environmental_score: float\n    social_score: float\n    governance_score: float\n    carbon_footprint: float\n    renewable_energy_exposure: float\n    diversity_score: float\n    controversy_exposure: float\n    impact_metrics: Dict[str, float] = Field(default_factory=dict)",
                "class Timer:\n    \"\"\"Utility for measuring execution time.\"\"\"\n    \n    def __init__(self, name: Optional[str] = None):\n        \"\"\"\n        Initialize the timer.\n        \n        Args:\n            name: Optional name for the timer\n        \"\"\"\n        self.name = name\n        self.start_time: Optional[float] = None\n        self.end_time: Optional[float] = None\n    \n    def __enter__(self) -> 'Timer':\n        \"\"\"Start the timer when entering a context.\"\"\"\n        self.start()\n        return self\n    \n    def __exit__(self, *args: Any) -> None:\n        \"\"\"Stop the timer when exiting a context.\"\"\"\n        self.stop()\n    \n    def start(self) -> None:\n        \"\"\"Start the timer.\"\"\"\n        self.start_time = time.time()\n        self.end_time = None\n    \n    def stop(self) -> float:\n        \"\"\"\n        Stop the timer.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        self.end_time = time.time()\n        return self.elapsed_time\n    \n    @property\n    def elapsed_time(self) -> float:\n        \"\"\"\n        Get the elapsed time.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        end = self.end_time if self.end_time is not None else time.time()\n        return end - self.start_time\n    \n    @property\n    def elapsed_milliseconds(self) -> float:\n        \"\"\"\n        Get the elapsed time in milliseconds.\n        \n        Returns:\n            Elapsed time in milliseconds\n        \"\"\"\n        return self.elapsed_time * 1000",
                "def memoize(func: F = None, *, max_size: int = 1000, ttl_seconds: Optional[int] = None) -> F:\n    \"\"\"\n    Decorator to memoize a function's return value with optional max size and TTL.\n    \n    Can be used with or without arguments:\n    @memoize  # No arguments\n    def func():\n        ...\n        \n    @memoize(max_size=100, ttl_seconds=3600)  # With arguments\n    def func():\n        ...\n    \n    Args:\n        func: The function to memoize (when used without arguments)\n        max_size: Maximum number of items to store in cache (default: 1000)\n        ttl_seconds: Time-to-live in seconds (default: None, meaning no expiration)\n        \n    Returns:\n        Memoized function\n    \"\"\"\n    def decorator(f: F) -> F:\n        # Cache stores tuples of (result, timestamp) if TTL is specified, otherwise just result\n        cache: Dict[str, Union[Any, Tuple[Any, float]]] = {}\n        \n        @functools.wraps(f)\n        def wrapper(*args: Any, **kwargs: Any) -> Any:\n            # Create a cache key from the function arguments\n            key = _create_cache_key(f, args, kwargs)\n            \n            # Check if we need to enforce max size\n            if len(cache) >= max_size and key not in cache:\n                # Remove oldest item (simple implementation)\n                if ttl_seconds is not None:\n                    # If using TTL, find oldest by timestamp\n                    oldest_key = min(cache.items(), key=lambda x: x[1][1])[0]\n                else:\n                    # Otherwise just remove the first key\n                    oldest_key = next(iter(cache))\n                del cache[oldest_key]\n            \n            # Check if result is in cache\n            if key in cache:\n                if ttl_seconds is not None:\n                    # Check if expired when using TTL\n                    result, timestamp = cache[key]  # type: ignore\n                    if time.time() - timestamp < ttl_seconds:\n                        return result\n                    # If expired, remove from cache and recalculate\n                else:\n                    # No TTL, just return cached result\n                    return cache[key]\n            \n            # Call the function and cache the result\n            result = f(*args, **kwargs)\n            \n            if ttl_seconds is not None:\n                # Store with timestamp if using TTL\n                cache[key] = (result, time.time())\n            else:\n                # Store just the result otherwise\n                cache[key] = result\n            \n            return result\n        \n        # Add cache management functions\n        wrapper.cache = cache  # type: ignore\n        wrapper.cache_clear = cache.clear  # type: ignore\n        wrapper.cache_size = lambda: len(cache)  # type: ignore\n        \n        return cast(F, wrapper)\n    \n    # Handle both @memoize and @memoize(args) syntax\n    if func is None:\n        return decorator\n    return decorator(func)",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Portfolio(BasePortfolio):\n    \"\"\"A collection of investment holdings.\"\"\"\n    \n    # These fields come from BasePortfolio:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # holdings: List[InvestmentHolding] = Field(default_factory=list)\n    # total_value: float\n    # cash_balance: float\n    # creation_date: Union[date, datetime]\n    # last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Portfolio(BasePortfolio):\n    \"\"\"A collection of investment holdings.\"\"\"\n    \n    # These fields come from BasePortfolio:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # holdings: List[InvestmentHolding] = Field(default_factory=list)\n    # total_value: float\n    # cash_balance: float\n    # creation_date: Union[date, datetime]\n    # last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Portfolio(BasePortfolio):\n    \"\"\"A collection of investment holdings.\"\"\"\n    \n    # These fields come from BasePortfolio:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # holdings: List[InvestmentHolding] = Field(default_factory=list)\n    # total_value: float\n    # cash_balance: float\n    # creation_date: Union[date, datetime]\n    # last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Portfolio(BasePortfolio):\n    \"\"\"A collection of investment holdings.\"\"\"\n    \n    # These fields come from BasePortfolio:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # holdings: List[InvestmentHolding] = Field(default_factory=list)\n    # total_value: float\n    # cash_balance: float\n    # creation_date: Union[date, datetime]\n    # last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Portfolio(BasePortfolio):\n    \"\"\"A collection of investment holdings.\"\"\"\n    \n    # These fields come from BasePortfolio:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # holdings: List[InvestmentHolding] = Field(default_factory=list)\n    # total_value: float\n    # cash_balance: float\n    # creation_date: Union[date, datetime]\n    # last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Portfolio(BasePortfolio):\n    \"\"\"A collection of investment holdings.\"\"\"\n    \n    # These fields come from BasePortfolio:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # holdings: List[InvestmentHolding] = Field(default_factory=list)\n    # total_value: float\n    # cash_balance: float\n    # creation_date: Union[date, datetime]\n    # last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class InvestmentHolding(BaseInvestmentHolding):\n    \"\"\"A specific holding of an investment in a portfolio.\"\"\"\n    \n    # These fields come from BaseInvestmentHolding:\n    # investment_id: str\n    # shares: float\n    # purchase_price: float\n    # purchase_date: Union[date, datetime]\n    # current_price: float\n    # current_value: float\n    \n    # No additional fields needed\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class InvestmentHolding(BaseInvestmentHolding):\n    \"\"\"A specific holding of an investment in a portfolio.\"\"\"\n    \n    # These fields come from BaseInvestmentHolding:\n    # investment_id: str\n    # shares: float\n    # purchase_price: float\n    # purchase_date: Union[date, datetime]\n    # current_price: float\n    # current_value: float\n    \n    # No additional fields needed\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class InvestmentHolding(BaseInvestmentHolding):\n    \"\"\"A specific holding of an investment in a portfolio.\"\"\"\n    \n    # These fields come from BaseInvestmentHolding:\n    # investment_id: str\n    # shares: float\n    # purchase_price: float\n    # purchase_date: Union[date, datetime]\n    # current_price: float\n    # current_value: float\n    \n    # No additional fields needed\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class InvestmentHolding(BaseInvestmentHolding):\n    \"\"\"A specific holding of an investment in a portfolio.\"\"\"\n    \n    # These fields come from BaseInvestmentHolding:\n    # investment_id: str\n    # shares: float\n    # purchase_price: float\n    # purchase_date: Union[date, datetime]\n    # current_price: float\n    # current_value: float\n    \n    # No additional fields needed\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class InvestmentHolding(BaseInvestmentHolding):\n    \"\"\"A specific holding of an investment in a portfolio.\"\"\"\n    \n    # These fields come from BaseInvestmentHolding:\n    # investment_id: str\n    # shares: float\n    # purchase_price: float\n    # purchase_date: Union[date, datetime]\n    # current_price: float\n    # current_value: float\n    \n    # No additional fields needed\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class InvestmentHolding(BaseInvestmentHolding):\n    \"\"\"A specific holding of an investment in a portfolio.\"\"\"\n    \n    # These fields come from BaseInvestmentHolding:\n    # investment_id: str\n    # shares: float\n    # purchase_price: float\n    # purchase_date: Union[date, datetime]\n    # current_price: float\n    # current_value: float\n    \n    # No additional fields needed\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class EthicalScreener(BaseAnalyzer[Investment, ScreeningResult]):\n    \"\"\"Evaluates investments against customizable ethical criteria.\"\"\"\n    \n    def __init__(self, criteria: EthicalCriteria):\n        \"\"\"Initialize with the given ethical criteria.\n        \n        Args:\n            criteria: The ethical criteria to use for screening\n        \"\"\"\n        super().__init__()\n        self.criteria = criteria\n    \n    def analyze(\n        self, subject: Investment, parameters: Optional[AnalysisParameters] = None\n    ) -> ScreeningResult:\n        \"\"\"\n        Analyze a single investment.\n        \n        Args:\n            subject: The investment to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Analysis result\n        \"\"\"\n        # Use the screen_investment method that implements the screening logic\n        return self.screen_investment(subject)\n    \n    def analyze_batch(\n        self, subjects: List[Investment], parameters: Optional[AnalysisParameters] = None\n    ) -> List[ScreeningResult]:\n        \"\"\"\n        Analyze multiple investments.\n        \n        Args:\n            subjects: List of investments to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            List of analysis results\n        \"\"\"\n        # Use the common method with timer\n        with Timer(\"analyze_batch\") as timer:\n            results = super().analyze_batch(subjects, parameters)\n            \n            # Add custom processing if needed\n            return results\n        \n    @staticmethod\n    def generate_criteria_from_survey(survey_responses: Dict[str, Any]) -> EthicalCriteria:\n        \"\"\"Generate ethical criteria from user survey responses.\n        \n        Args:\n            survey_responses: Dictionary containing survey responses with keys:\n                - top_concerns: List of user's top ethical concerns\n                - industries_to_avoid: List of industries to exclude\n                - industries_to_support: List of industries to prioritize\n                - relative_importance: Dict with weights for environmental, social, governance\n                - environmental_priorities: List of environmental priorities\n                - social_priorities: List of social priorities  \n                - governance_priorities: List of governance priorities\n                \n        Returns:\n            EthicalCriteria object based on survey responses\n        \"\"\"\n        # Calculate weights based on relative importance\n        total_importance = sum(survey_responses[\"relative_importance\"].values())\n        env_weight = survey_responses[\"relative_importance\"][\"environmental\"] / total_importance\n        social_weight = survey_responses[\"relative_importance\"][\"social\"] / total_importance\n        gov_weight = survey_responses[\"relative_importance\"][\"governance\"] / total_importance\n        \n        # Create environmental criteria\n        environmental = {\n            \"weight\": env_weight,\n            \"min_environmental_score\": 60\n        }\n        \n        if \"carbon_reduction\" in survey_responses[\"environmental_priorities\"]:\n            environmental[\"max_carbon_footprint\"] = 50000000\n            \n        if \"renewable_energy\" in survey_responses[\"environmental_priorities\"]:\n            environmental[\"min_renewable_energy_use\"] = 0.5\n            \n        if \"fossil_fuels\" in survey_responses[\"industries_to_avoid\"]:\n            environmental[\"exclude_fossil_fuel_production\"] = True\n            \n        # Create social criteria\n        social = {\n            \"weight\": social_weight,\n            \"min_social_score\": 60\n        }\n        \n        if \"diversity\" in survey_responses[\"social_priorities\"]:\n            social[\"min_diversity_score\"] = 0.65\n            \n        if \"human_rights\" in survey_responses[\"top_concerns\"]:\n            social[\"exclude_human_rights_violations\"] = True\n            \n        if \"weapons\" in survey_responses[\"industries_to_avoid\"]:\n            social[\"exclude_weapons_manufacturing\"] = True\n            \n        # Create governance criteria\n        governance = {\n            \"weight\": gov_weight,\n            \"min_governance_score\": 60\n        }\n        \n        if \"board_diversity\" in survey_responses[\"governance_priorities\"]:\n            governance[\"min_board_independence\"] = 0.65\n            \n        if \"executive_compensation\" in survey_responses[\"governance_priorities\"]:\n            governance[\"exclude_excessive_executive_compensation\"] = True\n            \n        # Create the criteria\n        return EthicalCriteria(\n            criteria_id=\"user-personalized\",\n            name=\"User Personalized Criteria\",\n            environmental=environmental,\n            social=social,\n            governance=governance,\n            min_overall_score=65,\n            exclusions=survey_responses[\"industries_to_avoid\"],\n            inclusions=survey_responses[\"industries_to_support\"]\n        )\n    \n    def screen_investment(self, investment: Investment) -> ScreeningResult:\n        \"\"\"Screen a single investment against the ethical criteria.\n        \n        Args:\n            investment: The investment to screen\n            \n        Returns:\n            A ScreeningResult with the screening outcome\n        \"\"\"\n        # Use the Timer utility from common library for performance measurement\n        with Timer(\"screen_investment\") as timer:\n            try:\n                # Check for exclusions (immediate disqualification)\n                exclusion_flags = self._check_exclusions(investment)\n                \n                # Check for inclusions (positive attributes)\n                inclusion_flags = self._check_inclusions(investment)\n                \n                # Evaluate environmental criteria\n                env_score, env_details = self._evaluate_environmental_criteria(investment)\n                \n                # Evaluate social criteria\n                social_score, social_details = self._evaluate_social_criteria(investment)\n                \n                # Evaluate governance criteria\n                gov_score, gov_details = self._evaluate_governance_criteria(investment)\n                \n                # Calculate weighted overall score\n                overall_score = (\n                    env_score * self.criteria.environmental[\"weight\"] +\n                    social_score * self.criteria.social[\"weight\"] +\n                    gov_score * self.criteria.governance[\"weight\"]\n                )\n                \n                # Determine if the investment passes the screening\n                passes = (\n                    len(exclusion_flags) == 0 and  # No exclusion criteria violated\n                    overall_score >= self.criteria.min_overall_score\n                )\n                \n                # Compile detailed results\n                details = {\n                    \"environmental\": env_details,\n                    \"social\": social_details,\n                    \"governance\": gov_details,\n                    \"processing_time_ms\": timer.elapsed_milliseconds  # Use the correct attribute\n                }\n                \n                # Handle the case where id might be UUID or str\n                investment_id = str(investment.id)\n                \n                # Use the factory method to create a ScreeningResult from the analysis\n                result = ScreeningResult.from_screening(\n                    investment_id=investment_id,\n                    passed=passes,\n                    overall_score=overall_score,\n                    environmental_score=env_score,\n                    social_score=social_score,\n                    governance_score=gov_score,\n                    exclusion_flags=exclusion_flags,\n                    inclusion_flags=inclusion_flags,\n                    details=details,\n                    processing_time_ms=timer.elapsed_milliseconds\n                )\n                \n                # Add to cache for future reuse\n                self._save_to_cache(investment_id, result)\n                \n                return result\n            except Exception as e:\n                # Log the error details using common patterns\n                print(f\"Error in screen_investment: {type(e).__name__}: {str(e)}\")\n                if isinstance(investment.esg_ratings, dict):\n                    print(f\"ESG Ratings (dict): {investment.esg_ratings}\")\n                else:\n                    print(f\"ESG Ratings (type): {type(investment.esg_ratings)}\")\n                print(f\"Investment ID: {investment.id}, type: {type(investment.id)}\")\n                raise\n    \n    def screen_investments(self, investments: List[Investment]) -> Dict[str, ScreeningResult]:\n        \"\"\"Screen multiple investments against the ethical criteria.\n        \n        Args:\n            investments: List of investments to screen\n            \n        Returns:\n            Dict mapping investment IDs to their screening results\n        \"\"\"\n        # Use the analyze_batch method inherited from BaseAnalyzer\n        results_list = self.analyze_batch(investments)\n        \n        # Convert to a dict keyed by investment ID\n        results_dict = {str(result.subject_id): result for result in results_list}\n        \n        return results_dict\n    \n    def _check_exclusions(self, investment: Investment) -> List[str]:\n        \"\"\"Check if the investment violates any exclusion criteria.\n        \n        Args:\n            investment: The investment to check\n            \n        Returns:\n            List of exclusion flags that apply to this investment\n        \"\"\"\n        exclusion_flags = []\n        \n        # Check industry exclusions (from the top-level exclusions list)\n        for exclusion in self.criteria.exclusions:\n            # Direct match on industry\n            if investment.industry.lower() == exclusion.lower():\n                exclusion_flags.append(f\"excluded_industry:{investment.industry}\")\n            \n            # Direct match on sector\n            if investment.sector.lower() == exclusion.lower():\n                exclusion_flags.append(f\"excluded_sector:{investment.sector}\")\n                \n            # Partial match on industry name (handles cases like \"fossil_fuels\" vs \"Oil & Gas\")\n            if exclusion.lower() in [\"fossil_fuels\", \"fossil_fuel\"] and \"oil\" in investment.industry.lower():\n                exclusion_flags.append(f\"excluded_fossil_fuels_industry:{investment.industry}\")\n                \n            # Check for related terms in industry or sector\n            for term in exclusion.lower().split(\"_\"):\n                if len(term) > 3:  # Only use meaningful words, not short ones\n                    if term in investment.industry.lower() or term in investment.sector.lower():\n                        exclusion_flags.append(f\"excluded_term:{term}\")\n        \n        # Check environmental exclusions\n        if (self.criteria.environmental.get(\"exclude_fossil_fuel_production\", False) and\n                (\"fossil_fuel_production\" in [p.lower() for p in investment.positive_practices + investment.controversies] \n                 or \"oil\" in investment.industry.lower())):\n            exclusion_flags.append(\"fossil_fuel_production\")\n        \n        # Check social exclusions\n        if (self.criteria.social.get(\"exclude_human_rights_violations\", False) and\n                any(\"human_rights\" in c.lower() for c in investment.controversies)):\n            exclusion_flags.append(\"human_rights_violations\")\n            \n        if (self.criteria.social.get(\"exclude_weapons_manufacturing\", False) and\n                \"weapons_manufacturing\" in [p.lower() for p in investment.positive_practices + investment.controversies]):\n            exclusion_flags.append(\"weapons_manufacturing\")\n        \n        # Check governance exclusions\n        if (self.criteria.governance.get(\"exclude_excessive_executive_compensation\", False) and\n                any(\"compensation\" in c.lower() for c in investment.controversies)):\n            exclusion_flags.append(\"excessive_executive_compensation\")\n        \n        return exclusion_flags\n    \n    def _check_inclusions(self, investment: Investment) -> List[str]:\n        \"\"\"Check if the investment matches any inclusion criteria.\n        \n        Args:\n            investment: The investment to check\n            \n        Returns:\n            List of inclusion flags that apply to this investment\n        \"\"\"\n        inclusion_flags = []\n        \n        # Check industry inclusions\n        if investment.industry.lower() in [i.lower() for i in self.criteria.inclusions]:\n            inclusion_flags.append(f\"preferred_industry:{investment.industry}\")\n        \n        # Check sector inclusions\n        if investment.sector.lower() in [i.lower() for i in self.criteria.inclusions]:\n            inclusion_flags.append(f\"preferred_sector:{investment.sector}\")\n        \n        # Check positive practices\n        for practice in investment.positive_practices:\n            if practice.lower() in [i.lower() for i in self.criteria.inclusions]:\n                inclusion_flags.append(f\"positive_practice:{practice}\")\n        \n        return inclusion_flags\n    \n    def _evaluate_environmental_criteria(self, investment: Investment) -> Tuple[float, Dict[str, Any]]:\n        \"\"\"Evaluate the investment against environmental criteria.\n        \n        Args:\n            investment: The investment to evaluate\n            \n        Returns:\n            Tuple of (score, details) where score is 0-100 and details contains the reasoning\n        \"\"\"\n        env_criteria = self.criteria.environmental\n        details = {}\n        \n        # Start with the ESG environmental score\n        # Handle both dict and ESGRating object cases\n        if isinstance(investment.esg_ratings, dict):\n            base_score = investment.esg_ratings[\"environmental\"]\n        else:\n            base_score = investment.esg_ratings.environmental\n        \n        details[\"base_score\"] = base_score\n        \n        # Adjust for carbon footprint\n        if \"max_carbon_footprint\" in env_criteria:\n            max_carbon = env_criteria[\"max_carbon_footprint\"]\n            if investment.carbon_footprint <= max_carbon:\n                carbon_ratio = investment.carbon_footprint / max_carbon\n                carbon_score = 100 - (carbon_ratio * 100)\n                details[\"carbon_footprint_score\"] = carbon_score\n            else:\n                # Exceeds maximum carbon footprint\n                carbon_penalty = min(30, (investment.carbon_footprint / max_carbon - 1) * 20)\n                base_score -= carbon_penalty\n                details[\"carbon_footprint_penalty\"] = carbon_penalty\n        \n        # Adjust for renewable energy use\n        if \"min_renewable_energy_use\" in env_criteria:\n            min_renewable = env_criteria[\"min_renewable_energy_use\"]\n            if investment.renewable_energy_use >= min_renewable:\n                renewable_bonus = (investment.renewable_energy_use - min_renewable) * 50\n                base_score += renewable_bonus\n                details[\"renewable_energy_bonus\"] = renewable_bonus\n            else:\n                # Below minimum renewable energy use\n                renewable_penalty = min(20, (min_renewable - investment.renewable_energy_use) * 40)\n                base_score -= renewable_penalty\n                details[\"renewable_energy_penalty\"] = renewable_penalty\n        \n        # Apply minimum environmental score threshold\n        if \"min_environmental_score\" in env_criteria:\n            min_score = env_criteria[\"min_environmental_score\"]\n            if base_score < min_score:\n                details[\"below_min_threshold\"] = True\n        \n        # Cap the final score at 100\n        final_score = max(0, min(100, base_score))\n        details[\"final_score\"] = final_score\n        \n        return final_score, details\n    \n    def _evaluate_social_criteria(self, investment: Investment) -> Tuple[float, Dict[str, Any]]:\n        \"\"\"Evaluate the investment against social criteria.\n        \n        Args:\n            investment: The investment to evaluate\n            \n        Returns:\n            Tuple of (score, details) where score is 0-100 and details contains the reasoning\n        \"\"\"\n        social_criteria = self.criteria.social\n        details = {}\n        \n        # Start with the ESG social score\n        # Handle both dict and ESGRating object cases\n        if isinstance(investment.esg_ratings, dict):\n            base_score = investment.esg_ratings[\"social\"]\n        else:\n            base_score = investment.esg_ratings.social\n            \n        details[\"base_score\"] = base_score\n        \n        # Adjust for diversity score\n        if \"min_diversity_score\" in social_criteria:\n            min_diversity = social_criteria[\"min_diversity_score\"]\n            if investment.diversity_score >= min_diversity:\n                diversity_bonus = (investment.diversity_score - min_diversity) * 50\n                base_score += diversity_bonus\n                details[\"diversity_bonus\"] = diversity_bonus\n            else:\n                # Below minimum diversity score\n                diversity_penalty = min(20, (min_diversity - investment.diversity_score) * 40)\n                base_score -= diversity_penalty\n                details[\"diversity_penalty\"] = diversity_penalty\n        \n        # Adjust for controversies\n        controversy_count = len(investment.controversies)\n        if controversy_count > 0:\n            # More controversies means a larger penalty\n            controversy_penalty = min(30, controversy_count * 10)\n            base_score -= controversy_penalty\n            details[\"controversy_penalty\"] = controversy_penalty\n            details[\"controversies\"] = investment.controversies\n        \n        # Apply minimum social score threshold\n        if \"min_social_score\" in social_criteria:\n            min_score = social_criteria[\"min_social_score\"]\n            if base_score < min_score:\n                details[\"below_min_threshold\"] = True\n        \n        # Cap the final score at 100\n        final_score = max(0, min(100, base_score))\n        details[\"final_score\"] = final_score\n        \n        return final_score, details\n    \n    def _evaluate_governance_criteria(self, investment: Investment) -> Tuple[float, Dict[str, Any]]:\n        \"\"\"Evaluate the investment against governance criteria.\n        \n        Args:\n            investment: The investment to evaluate\n            \n        Returns:\n            Tuple of (score, details) where score is 0-100 and details contains the reasoning\n        \"\"\"\n        gov_criteria = self.criteria.governance\n        details = {}\n        \n        # Start with the ESG governance score\n        # Handle both dict and ESGRating object cases\n        if isinstance(investment.esg_ratings, dict):\n            base_score = investment.esg_ratings[\"governance\"]\n        else:\n            base_score = investment.esg_ratings.governance\n            \n        details[\"base_score\"] = base_score\n        \n        # Adjust for board independence\n        if \"min_board_independence\" in gov_criteria:\n            min_independence = gov_criteria[\"min_board_independence\"]\n            if investment.board_independence >= min_independence:\n                independence_bonus = (investment.board_independence - min_independence) * 50\n                base_score += independence_bonus\n                details[\"board_independence_bonus\"] = independence_bonus\n            else:\n                # Below minimum board independence\n                independence_penalty = min(20, (min_independence - investment.board_independence) * 40)\n                base_score -= independence_penalty\n                details[\"board_independence_penalty\"] = independence_penalty\n        \n        # Apply minimum governance score threshold\n        if \"min_governance_score\" in gov_criteria:\n            min_score = gov_criteria[\"min_governance_score\"]\n            if base_score < min_score:\n                details[\"below_min_threshold\"] = True\n        \n        # Cap the final score at 100\n        final_score = max(0, min(100, base_score))\n        details[\"final_score\"] = final_score\n        \n        return final_score, details",
                "class ScreeningResult(AnalysisResult):\n    \"\"\"Result of screening an investment against ethical criteria.\"\"\"\n    \n    passed: bool\n    overall_score: float\n    environmental_score: float\n    social_score: float\n    governance_score: float\n    exclusion_flags: List[str] = Field(default_factory=list)\n    inclusion_flags: List[str] = Field(default_factory=list)\n    \n    @classmethod\n    def from_screening(cls, investment_id: str, passed: bool, overall_score: float,\n                      environmental_score: float, social_score: float, governance_score: float,\n                      exclusion_flags: List[str], inclusion_flags: List[str], \n                      details: Dict[str, Any], processing_time_ms: float) -> \"ScreeningResult\":\n        \"\"\"Create a ScreeningResult from screening data.\"\"\"\n        return cls(\n            id=uuid4(),\n            subject_id=investment_id,\n            subject_type=\"investment\",\n            analysis_type=\"ethical_screening\",\n            analysis_date=datetime.now(),\n            processing_time_ms=processing_time_ms,\n            result_summary={\n                \"passed\": passed,\n                \"overall_score\": overall_score,\n                \"environmental_score\": environmental_score,\n                \"social_score\": social_score,\n                \"governance_score\": governance_score,\n            },\n            detailed_results=details,\n            passed=passed,\n            overall_score=overall_score,\n            environmental_score=environmental_score,\n            social_score=social_score,\n            governance_score=governance_score,\n            exclusion_flags=exclusion_flags,\n            inclusion_flags=inclusion_flags\n        )\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True"
            ]
        }
    },
    "unified/tests/freelancer/tax/_test_tax_manager_full.py": {
        "logprobs": -1951.9394837885898,
        "metrics": {
            "loc": 498,
            "sloc": 328,
            "lloc": 193,
            "comments": 66,
            "multi": 0,
            "blank": 91,
            "cyclomatic": 106,
            "internal_imports": [
                "class Transaction(BusinessTransaction):\n    \"\"\"\n    Transaction model for the Personal Finance Tracker.\n    \n    Extends the BusinessTransaction from the common library with\n    freelancer-specific fields and behaviors.\n    \"\"\"\n\n    # Override category field to use our specific ExpenseCategory enum\n    category: Optional[ExpenseCategory] = None\n    \n    # Make sure the account_id is required\n    account_id: str\n\n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        # This is necessary to allow field overrides\n        extra = \"allow\"",
                "class TaxPayment(CommonTaxPayment):\n    \"\"\"\n    Tax payment model for Personal Finance Tracker.\n    \n    Extends the TaxPayment model from the common library.\n    \"\"\"\n    quarter: int",
                "class TaxDeduction(CommonTaxDeduction):\n    \"\"\"\n    Tax deduction model for Personal Finance Tracker.\n    \n    Extends the TaxDeduction model from the common library.\n    \"\"\"\n    pass",
                "class FilingStatus(str, Enum):\n    \"\"\"Tax filing status.\"\"\"\n\n    SINGLE = \"single\"\n    MARRIED_JOINT = \"married_filing_jointly\"\n    MARRIED_SEPARATE = \"married_filing_separately\"\n    HEAD_OF_HOUSEHOLD = \"head_of_household\"",
                "class TaxJurisdiction(str, Enum):\n    \"\"\"Tax jurisdiction types.\"\"\"\n\n    FEDERAL = \"federal\"\n    STATE = \"state\"\n    LOCAL = \"local\"",
                "class TaxBracket(BaseModel):\n    \"\"\"Tax bracket for a specific jurisdiction and filing status.\"\"\"\n\n    jurisdiction: TaxJurisdiction\n    filing_status: FilingStatus\n    tax_year: int\n    income_thresholds: List[float]  # Lower bounds of each bracket\n    rates: List[float]  # Rates for each bracket (as percentage: 10 = 10%)\n\n    @validator(\"rates\")\n    def validate_rates(cls, v, values):\n        \"\"\"Validate that rates are between 0 and 100 and match income thresholds.\"\"\"\n        if any(r < 0 or r > 100 for r in v):\n            raise ValueError(\"Rates must be between 0 and 100\")\n\n        if \"income_thresholds\" in values and len(v) != len(values[\"income_thresholds\"]):\n            raise ValueError(\"Number of rates must match number of income thresholds\")\n\n        return v",
                "class TaxManager:\n    \"\"\"\n    Tax management engine for freelancers.\n\n    This class handles tax calculations, estimated payment scheduling,\n    and tax optimization for freelancers.\n    \"\"\"\n\n    def __init__(self, filing_status: FilingStatus = FilingStatus.SINGLE):\n        \"\"\"\n        Initialize the tax manager.\n\n        Args:\n            filing_status: Tax filing status\n        \"\"\"\n        self.filing_status = filing_status\n        self._tax_brackets = {}  # Cache for tax brackets\n        self._se_tax_rate = 15.3  # Self-employment tax rate (percentage)\n        self._se_tax_income_limit = 147000  # For 2022 (Social Security wage base)\n        self._standard_deduction = {\n            2022: {\n                FilingStatus.SINGLE: 12950,\n                FilingStatus.MARRIED_JOINT: 25900,\n                FilingStatus.MARRIED_SEPARATE: 12950,\n                FilingStatus.HEAD_OF_HOUSEHOLD: 19400,\n            }\n        }\n\n    def set_tax_brackets(self, brackets: List[TaxBracket]) -> None:\n        \"\"\"\n        Set tax brackets for calculations.\n\n        Args:\n            brackets: List of tax brackets\n        \"\"\"\n        # Index brackets by jurisdiction, year, and filing status\n        for bracket in brackets:\n            key = (bracket.jurisdiction, bracket.tax_year, bracket.filing_status)\n            self._tax_brackets[key] = bracket\n\n    def get_tax_brackets(\n        self,\n        jurisdiction: TaxJurisdiction,\n        tax_year: int,\n        filing_status: Optional[FilingStatus] = None,\n    ) -> Optional[TaxBracket]:\n        \"\"\"\n        Get tax brackets for a specific jurisdiction and year.\n\n        Args:\n            jurisdiction: Tax jurisdiction\n            tax_year: Tax year\n            filing_status: Filing status (defaults to instance filing status)\n\n        Returns:\n            Tax bracket if found, None otherwise\n        \"\"\"\n        status = filing_status or self.filing_status\n        key = (jurisdiction, tax_year, status)\n        return self._tax_brackets.get(key)\n\n    def load_default_brackets(self) -> None:\n        \"\"\"Load default tax brackets for common jurisdictions.\"\"\"\n        # 2022 federal tax brackets (simplified example)\n        federal_single = TaxBracket(\n            jurisdiction=TaxJurisdiction.FEDERAL,\n            filing_status=FilingStatus.SINGLE,\n            tax_year=2022,\n            income_thresholds=[0, 10275, 41775, 89075, 170050, 215950, 539900],\n            rates=[10, 12, 22, 24, 32, 35, 37],\n        )\n\n        federal_married_joint = TaxBracket(\n            jurisdiction=TaxJurisdiction.FEDERAL,\n            filing_status=FilingStatus.MARRIED_JOINT,\n            tax_year=2022,\n            income_thresholds=[0, 20550, 83550, 178150, 340100, 431900, 647850],\n            rates=[10, 12, 22, 24, 32, 35, 37],\n        )\n\n        self.set_tax_brackets([federal_single, federal_married_joint])\n\n    def calculate_tax_quarters(self, tax_year: int) -> List[QuarterInfo]:\n        \"\"\"\n        Calculate tax quarter information for a specific year.\n\n        Args:\n            tax_year: Tax year\n\n        Returns:\n            List of tax quarter information\n        \"\"\"\n        quarters = []\n\n        # First quarter: January 1 - March 31, due April 15\n        q1_start = datetime(tax_year, 1, 1)\n        q1_end = datetime(tax_year, 3, 31)\n        q1_due = datetime(tax_year, 4, 15)\n\n        # Second quarter: April 1 - May 31, due June 15\n        q2_start = datetime(tax_year, 4, 1)\n        q2_end = datetime(tax_year, 5, 31)\n        q2_due = datetime(tax_year, 6, 15)\n\n        # Third quarter: June 1 - August 31, due September 15\n        q3_start = datetime(tax_year, 6, 1)\n        q3_end = datetime(tax_year, 8, 31)\n        q3_due = datetime(tax_year, 9, 15)\n\n        # Fourth quarter: September 1 - December 31, due January 15 of next year\n        q4_start = datetime(tax_year, 9, 1)\n        q4_end = datetime(tax_year, 12, 31)\n        q4_due = datetime(tax_year + 1, 1, 15)\n\n        quarters = [\n            QuarterInfo(\n                year=tax_year,\n                quarter=1,\n                start_date=q1_start,\n                end_date=q1_end,\n                due_date=q1_due,\n                description=f\"Q1 {tax_year} (Jan-Mar)\",\n            ),\n            QuarterInfo(\n                year=tax_year,\n                quarter=2,\n                start_date=q2_start,\n                end_date=q2_end,\n                due_date=q2_due,\n                description=f\"Q2 {tax_year} (Apr-May)\",\n            ),\n            QuarterInfo(\n                year=tax_year,\n                quarter=3,\n                start_date=q3_start,\n                end_date=q3_end,\n                due_date=q3_due,\n                description=f\"Q3 {tax_year} (Jun-Aug)\",\n            ),\n            QuarterInfo(\n                year=tax_year,\n                quarter=4,\n                start_date=q4_start,\n                end_date=q4_end,\n                due_date=q4_due,\n                description=f\"Q4 {tax_year} (Sep-Dec)\",\n            ),\n        ]\n\n        return quarters\n\n    def get_current_quarter(self) -> QuarterInfo:\n        \"\"\"\n        Get the current tax quarter information.\n\n        Returns:\n            Information about the current tax quarter\n        \"\"\"\n        today = datetime.now()\n        year = today.year\n\n        quarters = self.calculate_tax_quarters(year)\n\n        # Find the current quarter\n        for quarter in quarters:\n            if quarter.start_date <= today <= quarter.end_date:\n                return quarter\n\n        # If not found (shouldn't happen), return the last quarter of the year\n        return quarters[-1]\n\n    def calculate_taxable_income(\n        self,\n        transactions: List[Transaction],\n        tax_year: int,\n        deductions: List[TaxDeduction] = None,\n    ) -> Tuple[float, float, float]:\n        \"\"\"\n        Calculate taxable income for a tax year.\n\n        Args:\n            transactions: List of all transactions\n            tax_year: Tax year to calculate for\n            deductions: List of tax deductions\n\n        Returns:\n            Tuple of (total income, total deductions, taxable income)\n        \"\"\"\n        # Filter transactions to the tax year\n        year_start = datetime(tax_year, 1, 1)\n        year_end = datetime(tax_year, 12, 31, 23, 59, 59)\n\n        year_transactions = [\n            t for t in transactions if year_start <= t.date <= year_end\n        ]\n\n        # Calculate total income\n        income_transactions = [\n            t for t in year_transactions if t.transaction_type == TransactionType.INCOME\n        ]\n        total_income = sum(t.amount for t in income_transactions)\n\n        # Calculate business expenses\n        expense_transactions = [\n            t\n            for t in year_transactions\n            if (\n                t.transaction_type == TransactionType.EXPENSE\n                and t.category is not None\n                and t.category.name != \"PERSONAL\"\n                and t.business_use_percentage is not None\n            )\n        ]\n\n        total_expenses = sum(\n            t.amount * (t.business_use_percentage / 100) for t in expense_transactions\n        )\n\n        # Add additional deductions\n        additional_deductions = 0.0\n        if deductions:\n            additional_deductions = sum(d.amount for d in deductions)\n\n        # Get standard deduction\n        std_deduction = self._standard_deduction.get(tax_year, {}).get(\n            self.filing_status,\n            12950,  # Default to 2022 single\n        )\n\n        # Calculate total deductions (greater of itemized or standard)\n        total_deductions = max(total_expenses + additional_deductions, std_deduction)\n\n        # Calculate taxable income\n        taxable_income = max(0, total_income - total_deductions)\n\n        return total_income, total_deductions, taxable_income\n\n    def calculate_federal_tax(\n        self,\n        taxable_income: float,\n        tax_year: int,\n        filing_status: Optional[FilingStatus] = None,\n    ) -> float:\n        \"\"\"\n        Calculate federal income tax.\n\n        Args:\n            taxable_income: Taxable income amount\n            tax_year: Tax year\n            filing_status: Filing status (defaults to instance filing status)\n\n        Returns:\n            Federal tax amount\n        \"\"\"\n        # Get tax brackets\n        status = filing_status or self.filing_status\n        brackets = self.get_tax_brackets(TaxJurisdiction.FEDERAL, tax_year, status)\n\n        if not brackets:\n            raise ValueError(f\"No federal tax brackets for {tax_year} and {status}\")\n\n        # Calculate tax\n        tax = 0.0\n        prev_threshold = 0.0\n\n        for i, threshold in enumerate(brackets.income_thresholds):\n            rate = brackets.rates[i] / 100  # Convert percentage to decimal\n\n            if taxable_income <= threshold:\n                tax += (taxable_income - prev_threshold) * rate\n                break\n            else:\n                tax += (threshold - prev_threshold) * rate\n\n            prev_threshold = threshold\n\n            # If this is the last bracket, calculate tax on remaining income\n            if i == len(brackets.income_thresholds) - 1:\n                tax += (taxable_income - threshold) * rate\n\n        return tax\n\n    def calculate_self_employment_tax(self, net_business_income: float) -> float:\n        \"\"\"\n        Calculate self-employment tax.\n\n        Args:\n            net_business_income: Net business income\n\n        Returns:\n            Self-employment tax amount\n        \"\"\"\n        # SE tax is calculated on 92.35% of net business income\n        taxable_income = net_business_income * 0.9235\n\n        # Social Security portion (12.4%) is subject to wage base limit\n        social_security_portion = min(taxable_income, self._se_tax_income_limit) * 0.124\n\n        # Medicare portion (2.9%) applies to all income\n        medicare_portion = taxable_income * 0.029\n\n        # Additional Medicare Tax (0.9%) on income above threshold\n        # (simplified - would normally depend on filing status)\n        additional_medicare = max(0, taxable_income - 200000) * 0.009\n\n        return social_security_portion + medicare_portion + additional_medicare\n\n    def calculate_tax_liability(\n        self,\n        income: Optional[float] = None,\n        transactions: Optional[List[Transaction]] = None,\n        tax_year: int = datetime.now().year,\n        deductions: List[TaxDeduction] = None,\n        include_state: bool = True,\n        jurisdiction: TaxJurisdiction = TaxJurisdiction.FEDERAL,\n    ) -> TaxLiability:\n        \"\"\"\n        Calculate total tax liability.\n\n        Args:\n            transactions: List of all transactions\n            tax_year: Tax year to calculate for\n            deductions: List of tax deductions\n            include_state: Whether to include state tax calculations\n\n        Returns:\n            TaxLiability object with detailed tax information\n        \"\"\"\n        # Performance measurement\n        start_time = time.time()\n\n        # Calculate taxable income\n        if income is not None:\n            # Direct income provided\n            total_income = income\n            # Use standard deduction as default\n            std_deduction = self._standard_deduction.get(tax_year, {}).get(\n                self.filing_status,\n                12950,  # Default to 2022 single\n            )\n            total_deductions = std_deduction\n            taxable_income = max(0, total_income - total_deductions)\n        elif transactions is not None:\n            # Calculate from transactions\n            total_income, total_deductions, taxable_income = self.calculate_taxable_income(\n                transactions, tax_year, deductions\n            )\n        else:\n            raise ValueError(\"Either income or transactions must be provided\")\n\n        # Calculate federal income tax\n        federal_tax = self.calculate_federal_tax(taxable_income, tax_year)\n\n        # Calculate self-employment tax\n        # For this example, assume all income is business income\n        self_employment_tax = self.calculate_self_employment_tax(\n            total_income - total_deductions\n        )\n\n        # Calculate state tax (simplified example)\n        state_tax = 0.0\n        if include_state:\n            # Simplified: assume 5% flat state tax\n            state_tax = taxable_income * 0.05\n\n        # Calculate total tax\n        total_tax = federal_tax + self_employment_tax + state_tax\n\n        # Calculate effective and marginal rates\n        effective_rate = 0.0\n        if total_income > 0:\n            effective_rate = (total_tax / total_income) * 100\n\n        # Get federal brackets to determine marginal rate\n        brackets = self.get_tax_brackets(\n            TaxJurisdiction.FEDERAL, tax_year, self.filing_status\n        )\n        marginal_rate = 0.0\n\n        if brackets:\n            for i, threshold in enumerate(brackets.income_thresholds):\n                if i < len(brackets.income_thresholds) - 1:\n                    if taxable_income < brackets.income_thresholds[i + 1]:\n                        marginal_rate = brackets.rates[i]\n                        break\n                else:\n                    marginal_rate = brackets.rates[i]\n\n        # Create detailed breakdown\n        breakdown = {\n            \"federal_income_tax\": federal_tax,\n            \"self_employment_tax\": self_employment_tax,\n            \"state_tax\": state_tax,\n            \"total_tax\": total_tax,\n        }\n\n        # Create tax liability object\n        liability = TaxLiability(\n            jurisdiction=TaxJurisdiction.FEDERAL,  # Primary jurisdiction\n            tax_year=tax_year,\n            income=total_income,\n            deductions=total_deductions,\n            taxable_income=taxable_income,\n            tax_amount=total_tax,\n            effective_rate=effective_rate,\n            marginal_rate=marginal_rate,\n            filing_status=self.filing_status,\n            breakdown=breakdown,\n        )\n\n        # Verify performance requirement\n        elapsed_time = time.time() - start_time\n        if elapsed_time > 1.0:\n            print(\n                f\"Warning: Tax liability calculation took {elapsed_time:.2f} seconds, which exceeds the 1 second requirement\"\n            )\n\n        return liability\n\n    def calculate_quarterly_tax_payment(\n        self,\n        quarterly_taxable_income: float,\n        ytd_taxable_income: float,\n        tax_year: int,\n        quarter: int,\n        prior_payments: float = 0.0,\n    ) -> EstimatedPayment:\n        \"\"\"\n        Calculate estimated quarterly tax payment.\n\n        Args:\n            quarterly_taxable_income: Taxable income for the quarter\n            ytd_taxable_income: Year-to-date taxable income\n            tax_year: Tax year\n            quarter: Quarter number (1-4)\n            prior_payments: Sum of prior payments made this year\n\n        Returns:\n            EstimatedPayment object with payment details\n        \"\"\"\n        # Get quarter information\n        quarters = self.calculate_tax_quarters(tax_year)\n        quarter_info = next((q for q in quarters if q.quarter == quarter), None)\n        \n        if not quarter_info:\n            raise ValueError(f\"Invalid quarter: {quarter}\")\n            \n        # Calculate federal tax on YTD income\n        ytd_federal_tax = self.calculate_federal_tax(ytd_taxable_income, tax_year)\n        \n        # Calculate self-employment tax on YTD income (simplified)\n        ytd_se_tax = ytd_taxable_income * 0.15  # Approximate SE tax rate\n        \n        # Total YTD liability\n        ytd_liability = ytd_federal_tax + ytd_se_tax\n        \n        # Calculate payment based on quarter\n        if quarter == 1:\n            # First quarter - pay 25% of projected annual tax\n            payment_amount = ytd_liability * 0.25\n        else:\n            # For later quarters, adjust for prior payments\n            remaining_liability = ytd_liability - prior_payments\n            remaining_quarters = 5 - quarter  # Quarters remaining including current\n            \n            if remaining_quarters <= 0:\n                # Last quarter or past end of year\n                payment_amount = remaining_liability\n            else:\n                payment_amount = remaining_liability / remaining_quarters\n                \n        # Calculate safe harbor amount (simplified)\n        safe_harbor = ytd_liability * 0.225  # 90% of annual tax / 4\n        \n        # Create estimated payment object with federal tax component for test compatibility\n        payment = EstimatedPayment(\n            tax_year=tax_year,\n            quarter=quarter,\n            jurisdiction=TaxJurisdiction.FEDERAL,\n            due_date=quarter_info.due_date,\n            payment_amount=max(0, payment_amount),\n            minimum_required=max(0, min(payment_amount, safe_harbor)),\n            safe_harbor_amount=safe_harbor,\n            year_to_date_liability=ytd_liability,\n            previous_payments=prior_payments,\n            federal_tax=ytd_federal_tax * (quarter/4),\n            self_employment_tax=ytd_se_tax * (quarter/4),\n            notes=f\"Estimated Q{quarter} tax payment for {tax_year}\",\n        )\n        \n        return payment\n    \n    def calculate_estimated_payment(\n        self,\n        transactions: List[Transaction],\n        payments: List[TaxPayment],\n        tax_year: int,\n        quarter: int,\n        deductions: List[TaxDeduction] = None,\n    ) -> EstimatedPayment:\n        \"\"\"\n        Calculate estimated quarterly tax payment.\n\n        Args:\n            transactions: List of all transactions\n            payments: Previous tax payments\n            tax_year: Tax year\n            quarter: Quarter number (1-4)\n            deductions: List of tax deductions\n\n        Returns:\n            EstimatedPayment object with payment details\n        \"\"\"\n        # Get quarter information\n        quarters = self.calculate_tax_quarters(tax_year)\n        quarter_info = next((q for q in quarters if q.quarter == quarter), None)\n\n        if not quarter_info:\n            raise ValueError(f\"Invalid quarter: {quarter}\")\n\n        # Calculate year-to-date liability\n        ytd_transactions = [\n            t\n            for t in transactions\n            if t.date.year == tax_year and t.date <= quarter_info.end_date\n        ]\n\n        liability = self.calculate_tax_liability(ytd_transactions, tax_year, deductions)\n\n        # Get previous payments for this year\n        previous_payments_total = sum(\n            p.amount for p in payments if p.tax_year == tax_year and p.quarter < quarter\n        )\n\n        # Calculate required payment\n        # Basic rule: Pay 25% of annual liability each quarter\n        annual_projection = liability.tax_amount * (4 / quarter)  # Simple extrapolation\n\n        # Simplistic approach for safe harbor (for illustration)\n        # Safe harbor is typically 100% of previous year tax or 90% of current year\n        safe_harbor = (\n            annual_projection * 0.9 / 4\n        )  # 90% of projected annual tax divided by 4\n\n        # Required payment is remaining liability divided by remaining quarters\n        remaining_liability = liability.tax_amount - previous_payments_total\n        remaining_quarters = 5 - quarter  # Quarters remaining including current\n\n        if remaining_quarters <= 0:\n            # Last quarter or past end of year\n            suggested_amount = remaining_liability\n        else:\n            suggested_amount = remaining_liability / remaining_quarters\n\n        # Create estimated payment object\n        payment = EstimatedPayment(\n            tax_year=tax_year,\n            quarter=quarter,\n            jurisdiction=TaxJurisdiction.FEDERAL,\n            due_date=quarter_info.due_date,\n            suggested_amount=max(0, suggested_amount),\n            minimum_required=max(0, min(suggested_amount, safe_harbor)),\n            safe_harbor_amount=safe_harbor,\n            year_to_date_liability=liability.tax_amount,\n            previous_payments=previous_payments_total,\n            notes=f\"Estimated Q{quarter} tax payment for {tax_year}\",\n        )\n\n        return payment\n\n    def record_tax_payment(self, payment: TaxPayment) -> TaxPayment:\n        \"\"\"\n        Record a tax payment.\n\n        Args:\n            payment: Tax payment to record\n\n        Returns:\n            The recorded payment\n        \"\"\"\n        # In a real implementation, this would store the payment in a database\n        # For this example, we just return the payment\n        return payment\n\n    def get_tax_summary(\n        self,\n        transactions: List[Transaction],\n        payments: List[TaxPayment],\n        tax_year: int,\n        deductions: List[TaxDeduction] = None,\n    ) -> TaxYearSummary:\n        \"\"\"\n        Generate a summary of tax obligations for a year.\n\n        Args:\n            transactions: List of all transactions\n            payments: List of tax payments\n            tax_year: Tax year\n            deductions: List of tax deductions\n\n        Returns:\n            TaxYearSummary object with detailed tax information\n        \"\"\"\n        # Calculate liability\n        liability = self.calculate_tax_liability(transactions, tax_year, deductions)\n\n        # Filter to business transactions for the year\n        year_start = datetime(tax_year, 1, 1)\n        year_end = datetime(tax_year, 12, 31, 23, 59, 59)\n\n        year_transactions = [\n            t for t in transactions if year_start <= t.date <= year_end\n        ]\n\n        # Calculate income and expenses\n        income_transactions = [\n            t for t in year_transactions if t.transaction_type == TransactionType.INCOME\n        ]\n        total_income = sum(t.amount for t in income_transactions)\n\n        expense_transactions = [\n            t\n            for t in year_transactions\n            if (\n                t.transaction_type == TransactionType.EXPENSE\n                and t.category is not None\n                and t.category.name != \"PERSONAL\"\n                and t.business_use_percentage is not None\n            )\n        ]\n        total_expenses = sum(\n            t.amount * (t.business_use_percentage / 100) for t in expense_transactions\n        )\n\n        # Get total payments\n        year_payments = [p for p in payments if p.tax_year == tax_year]\n        total_paid = sum(p.amount for p in year_payments)\n\n        # Create summary\n        summary = TaxYearSummary(\n            tax_year=tax_year,\n            total_income=total_income,\n            total_expenses=total_expenses,\n            total_deductions=liability.deductions,\n            taxable_income=liability.taxable_income,\n            total_tax=liability.tax_amount,\n            effective_tax_rate=liability.effective_rate,\n            federal_tax=liability.breakdown[\"federal_income_tax\"],\n            state_tax=liability.breakdown.get(\"state_tax\", 0.0),\n            self_employment_tax=liability.breakdown[\"self_employment_tax\"],\n            total_paid=total_paid,\n            balance_due=max(0, liability.tax_amount - total_paid),\n            deductions=deductions or [],\n            payments=year_payments,\n        )\n\n        return summary\n\n    def compare_tax_years(\n        self,\n        transactions: List[Transaction],\n        payments: List[TaxPayment],\n        tax_year1: int,\n        tax_year2: int,\n        deductions1: List[TaxDeduction] = None,\n        deductions2: List[TaxDeduction] = None,\n    ) -> Dict[str, float]:\n        \"\"\"\n        Compare tax obligations between two years.\n\n        Args:\n            transactions: List of all transactions\n            payments: List of all payments\n            tax_year1: First tax year\n            tax_year2: Second tax year\n            deductions1: Deductions for first year\n            deductions2: Deductions for second year\n\n        Returns:\n            Dictionary with comparison metrics\n        \"\"\"\n        # Get summaries for both years\n        summary1 = self.get_tax_summary(transactions, payments, tax_year1, deductions1)\n        summary2 = self.get_tax_summary(transactions, payments, tax_year2, deductions2)\n\n        # Calculate differences\n        income_change = summary2.total_income - summary1.total_income\n        income_change_pct = (\n            (income_change / summary1.total_income * 100)\n            if summary1.total_income > 0\n            else 0\n        )\n\n        expense_change = summary2.total_expenses - summary1.total_expenses\n        expense_change_pct = (\n            (expense_change / summary1.total_expenses * 100)\n            if summary1.total_expenses > 0\n            else 0\n        )\n\n        tax_change = summary2.total_tax - summary1.total_tax\n        tax_change_pct = (\n            (tax_change / summary1.total_tax * 100) if summary1.total_tax > 0 else 0\n        )\n\n        effective_rate_change = (\n            summary2.effective_tax_rate - summary1.effective_tax_rate\n        )\n\n        # Create comparison result\n        comparison = {\n            \"income_change\": income_change,\n            \"income_change_pct\": income_change_pct,\n            \"expense_change\": expense_change,\n            \"expense_change_pct\": expense_change_pct,\n            \"tax_change\": tax_change,\n            \"tax_change_pct\": tax_change_pct,\n            \"effective_rate_change\": effective_rate_change,\n            \"year1\": summary1.tax_year,\n            \"year2\": summary2.tax_year,\n            \"year1_tax\": summary1.total_tax,\n            \"year2_tax\": summary2.total_tax,\n        }\n\n        return comparison\n\n    def optimize_deductions(\n        self,\n        transactions: List[Transaction],\n        potential_deductions: List[TaxDeduction],\n        tax_year: int,\n        target_liability: Optional[float] = None,\n    ) -> List[TaxDeduction]:\n        \"\"\"\n        Optimize tax deductions to minimize tax liability.\n\n        Args:\n            transactions: List of all transactions\n            potential_deductions: List of potential deductions to consider\n            tax_year: Tax year\n            target_liability: Optional target tax liability\n\n        Returns:\n            List of optimized deductions\n        \"\"\"\n        # Start with base liability without extra deductions\n        base_liability = self.calculate_tax_liability(transactions, tax_year)\n\n        # If no target, simply use all deductions\n        if target_liability is None:\n            return potential_deductions\n\n        # Sort deductions by amount (largest first)\n        sorted_deductions = sorted(\n            potential_deductions, key=lambda d: d.amount, reverse=True\n        )\n\n        # Start with no deductions\n        selected_deductions = []\n        current_liability = base_liability.tax_amount\n\n        # Add deductions until target is reached\n        for deduction in sorted_deductions:\n            # Calculate liability with this deduction\n            test_deductions = selected_deductions + [deduction]\n            test_liability = self.calculate_tax_liability(\n                transactions, tax_year, test_deductions\n            )\n\n            # If this reduces liability closer to target, add it\n            if abs(test_liability.tax_amount - target_liability) < abs(\n                current_liability - target_liability\n            ):\n                selected_deductions.append(deduction)\n                current_liability = test_liability.tax_amount\n\n            # If we've reached or gone below target, stop\n            if current_liability <= target_liability:\n                break\n\n        return selected_deductions"
            ]
        }
    },
    "unified/tests/socially_responsible_investor/test_values_budgeting/__init__.py": {
        "logprobs": -196.681849484544,
        "metrics": {
            "loc": 1,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 0,
            "blank": 0,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/tests/freelancer/__init__.py": {
        "logprobs": -188.087841629733,
        "metrics": {
            "loc": 1,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 0,
            "blank": 0,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/common/core/categorization/transaction_categorizer.py": {
        "logprobs": -1271.6311803907483,
        "metrics": {
            "loc": 262,
            "sloc": 161,
            "lloc": 118,
            "comments": 21,
            "multi": 32,
            "blank": 47,
            "cyclomatic": 44,
            "internal_imports": [
                "class BaseCategorizer(Generic[T, R], ABC):\n    \"\"\"\n    Abstract base class for categorization engines.\n    \n    Defines the core interface and functionality for all categorizers\n    across different persona implementations.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the categorizer.\"\"\"\n        self.rules: List[Rule] = []\n        self.audit_trail: List[AuditRecord] = []\n        self._categorization_cache: Dict[str, R] = {}\n        \n    def add_rule(self, rule: Rule) -> Rule:\n        \"\"\"\n        Add a new rule to the categorizer.\n        \n        Args:\n            rule: The rule to add\n            \n        Returns:\n            The added rule\n        \"\"\"\n        # Check for duplicate rule ID\n        if any(r.id == rule.id for r in self.rules):\n            raise ValueError(f\"Rule with ID {rule.id} already exists\")\n        \n        # Add the rule\n        self.rules.append(rule)\n        \n        # Sort rules by priority (highest first)\n        self.rules.sort(key=lambda r: r.priority, reverse=True)\n        \n        # Clear cache since rules have changed\n        self._categorization_cache = {}\n        \n        return rule\n    \n    def update_rule(self, rule: Rule) -> Rule:\n        \"\"\"\n        Update an existing rule.\n        \n        Args:\n            rule: The rule to update\n            \n        Returns:\n            The updated rule\n        \"\"\"\n        # Find the rule to update\n        for i, existing_rule in enumerate(self.rules):\n            if existing_rule.id == rule.id:\n                # Update the rule\n                rule.updated_at = datetime.now()\n                self.rules[i] = rule\n                \n                # Sort rules by priority (highest first)\n                self.rules.sort(key=lambda r: r.priority, reverse=True)\n                \n                # Clear cache since rules have changed\n                self._categorization_cache = {}\n                \n                return rule\n        \n        raise ValueError(f\"Rule with ID {rule.id} not found\")\n    \n    def remove_rule(self, rule_id: Union[str, UUID]) -> bool:\n        \"\"\"\n        Remove a rule.\n        \n        Args:\n            rule_id: ID of the rule to remove\n            \n        Returns:\n            True if the rule was removed, False otherwise\n        \"\"\"\n        # Find the rule to remove\n        for i, rule in enumerate(self.rules):\n            if rule.id == rule_id:\n                # Remove the rule\n                del self.rules[i]\n                \n                # Clear cache since rules have changed\n                self._categorization_cache = {}\n                \n                return True\n        \n        return False\n    \n    def get_rules(self) -> List[Rule]:\n        \"\"\"\n        Get all rules.\n        \n        Returns:\n            List of all rules\n        \"\"\"\n        return self.rules\n    \n    def get_audit_trail(\n        self, item_id: Optional[Union[str, UUID]] = None, limit: int = 100\n    ) -> List[AuditRecord]:\n        \"\"\"\n        Get the audit trail for categorization actions.\n        \n        Args:\n            item_id: Optional item ID to filter by\n            limit: Maximum number of records to return\n            \n        Returns:\n            List of audit records\n        \"\"\"\n        if item_id:\n            # Filter to specific item\n            filtered_trail = [\n                record\n                for record in self.audit_trail\n                if record.item_id == item_id\n            ]\n        else:\n            filtered_trail = self.audit_trail\n        \n        # Sort by timestamp (newest first) and limit\n        sorted_trail = sorted(filtered_trail, key=lambda r: r.timestamp, reverse=True)\n        \n        return sorted_trail[:limit]\n    \n    def clear_cache(self) -> None:\n        \"\"\"Clear the categorization cache.\"\"\"\n        self._categorization_cache = {}\n    \n    @abstractmethod\n    def categorize(self, item: T, recategorize: bool = False) -> R:\n        \"\"\"\n        Categorize a single item.\n        \n        Args:\n            item: The item to categorize\n            recategorize: Whether to recategorize even if already categorized\n            \n        Returns:\n            Categorization result\n        \"\"\"\n        pass\n    \n    def categorize_batch(self, items: List[T], recategorize: bool = False) -> List[R]:\n        \"\"\"\n        Categorize multiple items.\n        \n        Args:\n            items: List of items to categorize\n            recategorize: Whether to recategorize even if already categorized\n            \n        Returns:\n            List of categorization results\n        \"\"\"\n        # Start performance timer\n        start_time = time.time()\n        \n        # Categorize each item\n        results = []\n        for item in items:\n            result = self.categorize(item, recategorize)\n            results.append(result)\n        \n        # Performance metrics\n        elapsed_time = time.time() - start_time\n        \n        return results\n    \n    def record_audit(\n        self,\n        item_id: Union[str, UUID],\n        action: str,\n        previous_state: Dict[str, Any],\n        new_state: Dict[str, Any],\n        notes: Optional[str] = None,\n    ) -> AuditRecord:\n        \"\"\"\n        Record an action in the audit trail.\n        \n        Args:\n            item_id: ID of the item being modified\n            action: Type of action performed\n            previous_state: State before the action\n            new_state: State after the action\n            notes: Optional notes about the action\n            \n        Returns:\n            The created audit record\n        \"\"\"\n        audit_record = AuditRecord(\n            item_id=item_id,\n            action=action,\n            previous_state=previous_state,\n            new_state=new_state,\n            notes=notes,\n        )\n        \n        self.audit_trail.append(audit_record)\n        \n        return audit_record",
                "class CategorizationResult(BaseModel, Generic[T]):\n    \"\"\"\n    Result of a categorization operation.\n    \n    Provides information about the categorization process and outcome.\n    \"\"\"\n    \n    item_id: Union[str, UUID]\n    original_item: T\n    assigned_category: Optional[str] = None\n    confidence_score: float  # 0.0 to 1.0\n    matched_rule: Optional[Rule] = None\n    processing_time_ms: Optional[float] = None\n    notes: Optional[str] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Rule(BaseModel, ABC):\n    \"\"\"\n    Abstract base class for categorization rules.\n    \n    Defines the interface for all rules used in categorization\n    across different persona implementations.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    description: Optional[str] = None\n    priority: int = 0  # Higher numbers have higher priority\n    created_at: datetime = Field(default_factory=datetime.now)\n    updated_at: datetime = Field(default_factory=datetime.now)\n    is_active: bool = True\n    \n    @abstractmethod\n    def matches(self, item: Any) -> bool:\n        \"\"\"\n        Check if this rule matches the given item.\n        \n        Args:\n            item: The item to check against this rule\n            \n        Returns:\n            True if the rule matches, False otherwise\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def apply(self, item: Any) -> Any:\n        \"\"\"\n        Apply this rule to the given item.\n        \n        Args:\n            item: The item to apply this rule to\n            \n        Returns:\n            The result of applying the rule\n        \"\"\"\n        pass\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class TransactionRule(TextMatchRule):\n    \"\"\"\n    Rule for categorizing financial transactions.\n    \n    Used for both expense categorization and ethical transaction analysis.\n    \"\"\"\n    \n    category: str\n    business_use_percentage: Optional[float] = None\n    \n    def apply(self, transaction: BaseTransaction) -> Dict[str, Any]:\n        \"\"\"\n        Apply this rule to a transaction by returning fields to update.\n        \n        Args:\n            transaction: The transaction to categorize\n            \n        Returns:\n            Dictionary with category and optional business use percentage\n        \"\"\"\n        result = {\"category\": self.category}\n        \n        if self.business_use_percentage is not None:\n            result[\"business_use_percentage\"] = self.business_use_percentage\n            \n        return result",
                "class BaseTransaction(BaseModel):\n    \"\"\"\n    Base transaction model for all financial transactions.\n    \n    This abstract base class provides common fields for tracking\n    financial transactions across different persona implementations.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    date: Union[date, datetime]\n    amount: float\n    description: str\n    transaction_type: TransactionType\n    \n    # Optional fields\n    account_id: Optional[str] = None\n    category: Optional[str] = None\n    tags: List[str] = Field(default_factory=list)\n    notes: Optional[str] = None\n    \n    @validator(\"amount\")\n    def validate_amount(cls, v):\n        \"\"\"Validate that amount is a valid number.\"\"\"\n        if not isinstance(v, (int, float)):\n            raise ValueError(\"Amount must be a number\")\n        return v",
                "class TransactionType(str, Enum):\n    \"\"\"Transaction type enum for all financial transactions.\"\"\"\n\n    INCOME = \"income\"\n    EXPENSE = \"expense\"\n    TAX_PAYMENT = \"tax_payment\"\n    TRANSFER = \"transfer\"\n    INVESTMENT = \"investment\"\n    DIVIDEND = \"dividend\"\n    INTEREST = \"interest\""
            ]
        }
    },
    "unified/personal_finance_tracker/project/__init__.py": {
        "logprobs": -253.16112137134996,
        "metrics": {
            "loc": 5,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 4,
            "blank": 1,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/common/core/analysis/portfolio.py": {
        "logprobs": -2067.822292391748,
        "metrics": {
            "loc": 583,
            "sloc": 303,
            "lloc": 265,
            "comments": 49,
            "multi": 122,
            "blank": 112,
            "cyclomatic": 57,
            "internal_imports": [
                "class BaseAnalyzer(Generic[T, R], ABC):\n    \"\"\"\n    Abstract base class for analysis engines.\n    \n    Defines the core interface and functionality for all analyzers\n    across different persona implementations.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the analyzer.\"\"\"\n        self._analysis_cache: Dict[str, R] = {}\n    \n    @abstractmethod\n    def analyze(\n        self, subject: T, parameters: Optional[AnalysisParameters] = None\n    ) -> R:\n        \"\"\"\n        Analyze a single subject.\n        \n        Args:\n            subject: The subject to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Analysis result\n        \"\"\"\n        pass\n    \n    def analyze_batch(\n        self, subjects: List[T], parameters: Optional[AnalysisParameters] = None\n    ) -> List[R]:\n        \"\"\"\n        Analyze multiple subjects.\n        \n        Args:\n            subjects: List of subjects to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            List of analysis results\n        \"\"\"\n        # Start performance timer\n        start_time = time.time()\n        \n        # Analyze each subject\n        results = []\n        for subject in subjects:\n            result = self.analyze(subject, parameters)\n            results.append(result)\n        \n        # Performance metrics\n        elapsed_time = time.time() - start_time\n        \n        return results\n    \n    def clear_cache(self) -> None:\n        \"\"\"Clear the analysis cache.\"\"\"\n        self._analysis_cache = {}\n    \n    def _generate_cache_key(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> str:\n        \"\"\"\n        Generate a cache key for a subject and parameters.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cache key string\n        \"\"\"\n        # Start with the subject ID\n        key = f\"subject_{subject_id}\"\n        \n        # Add parameter details if provided\n        if parameters:\n            param_dict = parameters.dict(exclude_none=True)\n            for k, v in sorted(param_dict.items()):\n                if k != \"custom_settings\":\n                    key += f\"_{k}_{v}\"\n                    \n            # Handle custom settings separately (they could be complex)\n            if parameters.custom_settings:\n                for k, v in sorted(parameters.custom_settings.items()):\n                    key += f\"_{k}_{v}\"\n        \n        return key\n    \n    def _get_from_cache(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> Optional[R]:\n        \"\"\"\n        Get a cached analysis result if available.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cached result or None if not found\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        return self._analysis_cache.get(cache_key)\n    \n    def _save_to_cache(\n        self, subject_id: Union[str, UUID], result: R, parameters: Optional[AnalysisParameters] = None\n    ) -> None:\n        \"\"\"\n        Save an analysis result to the cache.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            result: The analysis result to cache\n            parameters: Optional parameters to configure the analysis\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        self._analysis_cache[cache_key] = result",
                "class AnalysisResult(BaseModel, Generic[T]):\n    \"\"\"\n    Result of an analysis operation.\n    \n    Provides information about the analysis process and outcome.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    subject_id: Optional[Union[str, UUID]] = None\n    subject_type: str\n    analysis_type: str\n    analysis_date: datetime = Field(default_factory=datetime.now)\n    processing_time_ms: Optional[float] = None\n    result_summary: Dict[str, Any] = Field(default_factory=dict)\n    detailed_results: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class AnalysisParameters(BaseModel):\n    \"\"\"\n    Parameters for an analysis operation.\n    \n    Used to configure analysis options and settings.\n    \"\"\"\n    \n    period_start: Optional[Union[date, datetime]] = None\n    period_end: Optional[Union[date, datetime]] = None\n    include_details: bool = True\n    calculation_mode: str = \"standard\"  # \"standard\", \"detailed\", \"fast\"\n    grouping: Optional[str] = None\n    custom_settings: Dict[str, Any] = Field(default_factory=dict)",
                "class Portfolio(BaseModel):\n    \"\"\"\n    Portfolio model for tracking a collection of investment holdings.\n    \n    Used for portfolio analysis, performance tracking, and reporting.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    holdings: List[InvestmentHolding] = Field(default_factory=list)\n    total_value: float\n    cash_balance: float\n    creation_date: Union[date, datetime]\n    last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    @root_validator(skip_on_failure=True)\n    def validate_total_value(cls, values):\n        \"\"\"Validate that total_value equals the sum of all holdings' values.\"\"\"\n        holdings = values.get(\"holdings\", [])\n        total_value = values.get(\"total_value\", 0)\n        \n        if not holdings:\n            # If no holdings, total value should equal cash balance\n            cash_balance = values.get(\"cash_balance\", 0)\n            if abs(total_value - cash_balance) > 0.01:  # Allow for small rounding errors\n                raise ValueError(\n                    f\"Total value {total_value} does not match cash balance {cash_balance}\"\n                )\n        else:\n            # If there are holdings, validate total value\n            holdings_sum = sum(holding.current_value for holding in holdings)\n            if abs(total_value - holdings_sum) > 0.01:  # Allow for small rounding errors\n                raise ValueError(\n                    f\"Total value {total_value} does not match holdings sum {holdings_sum}\"\n                )\n        \n        return values\n    \n    @property\n    def total_assets(self) -> float:\n        \"\"\"Calculate total assets including cash.\"\"\"\n        return self.total_value + self.cash_balance\n    \n    def get_asset_allocation(self) -> Dict[str, float]:\n        \"\"\"Calculate the allocation percentage for each asset.\"\"\"\n        if not self.holdings:\n            return {\"cash\": 100.0}\n        \n        allocation = {}\n        total_assets = self.total_assets\n        \n        # Add cash allocation\n        cash_percent = (self.cash_balance / total_assets) * 100\n        allocation[\"cash\"] = cash_percent\n        \n        # Add investment allocations\n        for holding in self.holdings:\n            holding_percent = (holding.current_value / total_assets) * 100\n            allocation[holding.investment_id] = holding_percent\n            \n        return allocation",
                "class InvestmentHolding(BaseModel):\n    \"\"\"\n    Investment holding model for tracking specific holdings in a portfolio.\n    \n    Used for tracking portfolio composition, performance, and value.\n    \"\"\"\n\n    investment_id: str\n    shares: float\n    purchase_price: float\n    purchase_date: Union[date, datetime]\n    current_price: float\n    current_value: float\n    \n    @root_validator(skip_on_failure=True)\n    def validate_current_value(cls, values):\n        \"\"\"Validate that current_value = shares * current_price.\"\"\"\n        shares = values.get(\"shares\", 0)\n        current_price = values.get(\"current_price\", 0)\n        current_value = values.get(\"current_value\", 0)\n        \n        expected_value = shares * current_price\n        if abs(current_value - expected_value) > 0.01:  # Allow for small rounding errors\n            raise ValueError(\n                f\"Current value {current_value} does not match shares * price {expected_value}\"\n            )\n        return values\n    \n    @property\n    def return_percentage(self) -> float:\n        \"\"\"Calculate the percentage return on this holding.\"\"\"\n        return (self.current_price / self.purchase_price - 1) * 100",
                "class Investment(BaseModel):\n    \"\"\"\n    Investment model representing an investment opportunity.\n    \n    Used for tracking investment options, ESG ratings, and performance.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    sector: str\n    industry: str\n    market_cap: float\n    price: float\n    esg_ratings: ESGRating\n    carbon_footprint: float\n    renewable_energy_use: float\n    diversity_score: float\n    board_independence: float\n    controversies: List[str] = Field(default_factory=list)\n    positive_practices: List[str] = Field(default_factory=list)\n    \n    @property\n    def has_major_controversies(self) -> bool:\n        \"\"\"Check if the investment has major controversies.\"\"\"\n        major_issues = [\"human_rights\", \"fraud\", \"corruption\", \"environmental_disaster\"]\n        return any(issue in self.controversies for issue in major_issues)\n    \n    @validator(\"market_cap\", \"price\", \"carbon_footprint\")\n    def validate_positive_numbers(cls, v):\n        \"\"\"Validate that financial amounts are positive numbers.\"\"\"\n        if v < 0:\n            raise ValueError(\"Value must be a positive number\")\n        return v\n    \n    @validator(\"renewable_energy_use\", \"diversity_score\", \"board_independence\")\n    def validate_percentage(cls, v):\n        \"\"\"Validate that percentages are between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Value must be between 0 and 1\")\n        return v"
            ]
        }
    },
    "unified/tests/freelancer/projection/_test_financial_projector_simple.py": {
        "logprobs": -709.9074704493456,
        "metrics": {
            "loc": 107,
            "sloc": 78,
            "lloc": 38,
            "comments": 6,
            "multi": 0,
            "blank": 18,
            "cyclomatic": 20,
            "internal_imports": [
                "class ExpenseCategory(str, Enum):\n    \"\"\"Expense category enum.\"\"\"\n\n    BUSINESS_SUPPLIES = \"business_supplies\"\n    SOFTWARE = \"software\"\n    MARKETING = \"marketing\"\n    OFFICE_RENT = \"office_rent\"\n    UTILITIES = \"utilities\"\n    TRAVEL = \"travel\"\n    MEALS = \"meals\"\n    EQUIPMENT = \"equipment\"\n    PROFESSIONAL_DEVELOPMENT = \"professional_development\"\n    PROFESSIONAL_SERVICES = \"professional_services\"\n    HEALTH_INSURANCE = \"health_insurance\"\n    RETIREMENT = \"retirement\"\n    PHONE = \"phone\"\n    INTERNET = \"internet\"\n    CAR = \"car\"\n    HOME_OFFICE = \"home_office\"\n    PERSONAL = \"personal\"\n    OTHER = \"other\"",
                "class SpendingLevel(str, Enum):\n    \"\"\"Spending level for cash runway projections.\"\"\"\n\n    MINIMAL = \"minimal\"  # Essential expenses only\n    REDUCED = \"reduced\"  # Reduced discretionary spending\n    NORMAL = \"normal\"  # Normal spending patterns\n    INCREASED = \"increased\"",
                "class SpendingLevel(str, Enum):\n    \"\"\"Spending level for cash runway projections.\"\"\"\n\n    MINIMAL = \"minimal\"  # Essential expenses only\n    REDUCED = \"reduced\"  # Reduced discretionary spending\n    NORMAL = \"normal\"  # Normal spending patterns\n    INCREASED = \"increased\"",
                "class SpendingLevel(str, Enum):\n    \"\"\"Spending level for cash runway projections.\"\"\"\n\n    MINIMAL = \"minimal\"  # Essential expenses only\n    REDUCED = \"reduced\"  # Reduced discretionary spending\n    NORMAL = \"normal\"  # Normal spending patterns\n    INCREASED = \"increased\"",
                "class SpendingLevel(str, Enum):\n    \"\"\"Spending level for cash runway projections.\"\"\"\n\n    MINIMAL = \"minimal\"  # Essential expenses only\n    REDUCED = \"reduced\"  # Reduced discretionary spending\n    NORMAL = \"normal\"  # Normal spending patterns\n    INCREASED = \"increased\"",
                "class RevenueSource(BaseModel):\n    \"\"\"Revenue source for cash flow projections.\"\"\"\n\n    name: str\n    amount: float\n    probability: float = 100.0  # Percentage probability of receiving this income\n    expected_date: Optional[datetime] = None\n    recurring: bool = False\n    recurrence_frequency: Optional[str] = None  # e.g., \"monthly\", \"quarterly\"\n    notes: Optional[str] = None\n\n    @validator(\"probability\")\n    def validate_probability(cls, v):\n        \"\"\"Validate probability is between 0 and 100.\"\"\"\n        if v < 0 or v > 100:\n            raise ValueError(\"Probability must be between 0 and 100\")\n        return v",
                "class RevenueSource(BaseModel):\n    \"\"\"Revenue source for cash flow projections.\"\"\"\n\n    name: str\n    amount: float\n    probability: float = 100.0  # Percentage probability of receiving this income\n    expected_date: Optional[datetime] = None\n    recurring: bool = False\n    recurrence_frequency: Optional[str] = None  # e.g., \"monthly\", \"quarterly\"\n    notes: Optional[str] = None\n\n    @validator(\"probability\")\n    def validate_probability(cls, v):\n        \"\"\"Validate probability is between 0 and 100.\"\"\"\n        if v < 0 or v > 100:\n            raise ValueError(\"Probability must be between 0 and 100\")\n        return v",
                "class RevenueSource(BaseModel):\n    \"\"\"Revenue source for cash flow projections.\"\"\"\n\n    name: str\n    amount: float\n    probability: float = 100.0  # Percentage probability of receiving this income\n    expected_date: Optional[datetime] = None\n    recurring: bool = False\n    recurrence_frequency: Optional[str] = None  # e.g., \"monthly\", \"quarterly\"\n    notes: Optional[str] = None\n\n    @validator(\"probability\")\n    def validate_probability(cls, v):\n        \"\"\"Validate probability is between 0 and 100.\"\"\"\n        if v < 0 or v > 100:\n            raise ValueError(\"Probability must be between 0 and 100\")\n        return v",
                "class RevenueSource(BaseModel):\n    \"\"\"Revenue source for cash flow projections.\"\"\"\n\n    name: str\n    amount: float\n    probability: float = 100.0  # Percentage probability of receiving this income\n    expected_date: Optional[datetime] = None\n    recurring: bool = False\n    recurrence_frequency: Optional[str] = None  # e.g., \"monthly\", \"quarterly\"\n    notes: Optional[str] = None\n\n    @validator(\"probability\")\n    def validate_probability(cls, v):\n        \"\"\"Validate probability is between 0 and 100.\"\"\"\n        if v < 0 or v > 100:\n            raise ValueError(\"Probability must be between 0 and 100\")\n        return v",
                "class ExpenseItem(BaseModel):\n    \"\"\"Expense item for cash flow projections.\"\"\"\n\n    name: str\n    amount: float\n    category: str\n    due_date: Optional[datetime] = None\n    recurring: bool = False\n    recurrence_frequency: Optional[str] = None  # e.g., \"monthly\", \"quarterly\"\n    essential: bool = False  # Whether this is an essential expense\n    notes: Optional[str] = None",
                "class ExpenseItem(BaseModel):\n    \"\"\"Expense item for cash flow projections.\"\"\"\n\n    name: str\n    amount: float\n    category: str\n    due_date: Optional[datetime] = None\n    recurring: bool = False\n    recurrence_frequency: Optional[str] = None  # e.g., \"monthly\", \"quarterly\"\n    essential: bool = False  # Whether this is an essential expense\n    notes: Optional[str] = None",
                "class ExpenseItem(BaseModel):\n    \"\"\"Expense item for cash flow projections.\"\"\"\n\n    name: str\n    amount: float\n    category: str\n    due_date: Optional[datetime] = None\n    recurring: bool = False\n    recurrence_frequency: Optional[str] = None  # e.g., \"monthly\", \"quarterly\"\n    essential: bool = False  # Whether this is an essential expense\n    notes: Optional[str] = None",
                "class ExpenseItem(BaseModel):\n    \"\"\"Expense item for cash flow projections.\"\"\"\n\n    name: str\n    amount: float\n    category: str\n    due_date: Optional[datetime] = None\n    recurring: bool = False\n    recurrence_frequency: Optional[str] = None  # e.g., \"monthly\", \"quarterly\"\n    essential: bool = False  # Whether this is an essential expense\n    notes: Optional[str] = None",
                "class ScenarioParameter(BaseModel):\n    \"\"\"Parameter for what-if scenario analysis.\"\"\"\n\n    name: str\n    description: Optional[str] = None\n    current_value: float\n    min_value: float\n    max_value: float\n    step_size: float = 1.0\n    unit: Optional[str] = None",
                "class ScenarioParameter(BaseModel):\n    \"\"\"Parameter for what-if scenario analysis.\"\"\"\n\n    name: str\n    description: Optional[str] = None\n    current_value: float\n    min_value: float\n    max_value: float\n    step_size: float = 1.0\n    unit: Optional[str] = None",
                "class ScenarioParameter(BaseModel):\n    \"\"\"Parameter for what-if scenario analysis.\"\"\"\n\n    name: str\n    description: Optional[str] = None\n    current_value: float\n    min_value: float\n    max_value: float\n    step_size: float = 1.0\n    unit: Optional[str] = None",
                "class ScenarioParameter(BaseModel):\n    \"\"\"Parameter for what-if scenario analysis.\"\"\"\n\n    name: str\n    description: Optional[str] = None\n    current_value: float\n    min_value: float\n    max_value: float\n    step_size: float = 1.0\n    unit: Optional[str] = None",
                "class FinancialProjector:\n    \"\"\"\n    Financial projection model for freelancers.\n\n    This class provides cash flow forecasting, runway calculations,\n    what-if analysis, and emergency fund assessment.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the financial projector.\"\"\"\n        self._projection_cache = {}\n        self._common_projector = CommonFinancialProjector()\n        self.timer = Timer()\n\n    def project_cash_flow(\n        self,\n        starting_balance: float,\n        current_date: datetime,\n        months_ahead: int,\n        revenue_sources: List[RevenueSource],\n        expense_items: List[ExpenseItem],\n        scenario: ProjectionScenario = ProjectionScenario.BASELINE,\n        historical_transactions: Optional[List[Transaction]] = None,\n        confidence_interval: float = 0.8,\n    ) -> CashFlowProjection:\n        \"\"\"\n        Project cash flow for a specific timeframe.\n\n        Args:\n            starting_balance: Current cash balance\n            current_date: Start date for projection\n            months_ahead: Number of months to project\n            revenue_sources: Expected revenue sources\n            expense_items: Expected expenses\n            scenario: Projection scenario\n            historical_transactions: Optional historical transactions for trend analysis\n            confidence_interval: Confidence interval for projections\n\n        Returns:\n            CashFlowProjection object with detailed cash flow projection\n        \"\"\"\n        # Start performance timer\n        self.timer.start()\n\n        # Calculate dates\n        start_date = datetime(current_date.year, current_date.month, 1)\n        end_month = current_date.month + months_ahead\n        end_year = current_date.year + (end_month - 1) // 12\n        end_month = ((end_month - 1) % 12) + 1\n        end_date = datetime(\n            end_year, end_month, calendar.monthrange(end_year, end_month)[1]\n        )\n\n        # Create historical time series data if provided\n        historical_data = None\n        if historical_transactions:\n            # Extract dates and net cash flow values from transactions\n            dates = []\n            values = []\n            \n            for tx in sorted(historical_transactions, key=lambda t: t.date):\n                dates.append(tx.date)\n                # Income adds to cash flow, expenses subtract\n                value = tx.amount if tx.transaction_type == TransactionType.INCOME else -tx.amount\n                values.append(value)\n            \n            historical_data = TimeSeriesData(dates=dates, values=values)\n        else:\n            # Create minimal historical data with just the starting balance\n            historical_data = TimeSeriesData(\n                dates=[current_date],\n                values=[starting_balance]\n            )\n\n        # Create projection parameters\n        params = ProjectionParameters(\n            projection_length=months_ahead,\n            scenario=scenario,\n            income_growth_rate=0.0,  # Will be handled in revenue sources\n            expense_growth_rate=0.0,  # Will be handled in expense items\n        )\n\n        # Prepare income and expenses for the common projector\n        # This is needed to convert our revenue sources and expense items format\n        # to the common library's expected format\n        monthly_income = {}\n        monthly_expenses = {}\n        \n        # Process revenue sources\n        for revenue in revenue_sources:\n            if revenue.recurring:\n                self._add_recurring_item_to_dict(\n                    monthly_dict=monthly_income,\n                    item=revenue,\n                    start_date=start_date,\n                    end_date=end_date,\n                    multiplier=self._get_scenario_income_multiplier(scenario)\n                )\n            elif revenue.expected_date:\n                month_key = revenue.expected_date.strftime(\"%Y-%m\")\n                adjusted_amount = revenue.amount * (revenue.probability / 100) * self._get_scenario_income_multiplier(scenario)\n                monthly_income[month_key] = monthly_income.get(month_key, 0) + adjusted_amount\n\n        # Process expenses\n        for expense in expense_items:\n            if expense.recurring:\n                self._add_recurring_item_to_dict(\n                    monthly_dict=monthly_expenses,\n                    item=expense,\n                    start_date=start_date,\n                    end_date=end_date,\n                    multiplier=self._get_scenario_expense_multiplier(scenario)\n                )\n            elif expense.due_date:\n                month_key = expense.due_date.strftime(\"%Y-%m\")\n                adjusted_amount = expense.amount * self._get_scenario_expense_multiplier(scenario)\n                monthly_expenses[month_key] = monthly_expenses.get(month_key, 0) + adjusted_amount\n\n        # Convert to time series format\n        month_strings = []\n        current_month = start_date\n        while current_month <= end_date:\n            month_strings.append(current_month.strftime(\"%Y-%m\"))\n            # Move to next month\n            month = current_month.month + 1\n            year = current_month.year + (month - 1) // 12\n            month = ((month - 1) % 12) + 1\n            current_month = datetime(year, month, 1)\n\n        # Generate all dates for the projection period\n        projection_dates = []\n        projection_income = []\n        projection_expenses = []\n        \n        for month in month_strings:\n            year, month_num = map(int, month.split('-'))\n            projection_date = datetime(year, int(month_num), 1)\n            projection_dates.append(projection_date)\n            projection_income.append(monthly_income.get(month, 0))\n            projection_expenses.append(monthly_expenses.get(month, 0))\n\n        # Use the common financial projector to create projections\n        # We create our own custom projection from the results\n        projection_result = self._create_custom_projection(\n            starting_balance=starting_balance,\n            projection_dates=projection_dates,\n            projection_income=projection_income,\n            projection_expenses=projection_expenses,\n            scenario=scenario\n        )\n\n        # Calculate totals\n        total_income = sum(monthly_income.get(month, 0) for month in month_strings)\n        total_expenses = sum(monthly_expenses.get(month, 0) for month in month_strings)\n        net_cash_flow = total_income - total_expenses\n        ending_balance = starting_balance + net_cash_flow\n\n        # Create monthly breakdown structure for compatibility\n        monthly_breakdown = {}\n        for i, month in enumerate(month_strings):\n            monthly_breakdown[month] = {\n                \"income\": projection_income[i],\n                \"expenses\": projection_expenses[i],\n                \"balance\": 0  # Will be calculated below\n            }\n\n        # Calculate running balance for each month\n        running_balance = starting_balance\n        for month in month_strings:\n            income = monthly_breakdown[month][\"income\"]\n            expenses = monthly_breakdown[month][\"expenses\"]\n            net = income - expenses\n            running_balance += net\n            monthly_breakdown[month][\"balance\"] = running_balance\n\n        # Create projection for return\n        projection = CashFlowProjection(\n            start_date=start_date,\n            end_date=end_date,\n            scenario=scenario,\n            starting_balance=starting_balance,\n            ending_balance=ending_balance,\n            total_income=total_income,\n            total_expenses=total_expenses,\n            net_cash_flow=net_cash_flow,\n            monthly_breakdown=monthly_breakdown,\n            confidence_interval=confidence_interval,\n        )\n\n        # Stop timer\n        elapsed_time = self.timer.stop()\n\n        return projection\n\n    def _create_custom_projection(\n        self,\n        starting_balance: float,\n        projection_dates: List[datetime],\n        projection_income: List[float],\n        projection_expenses: List[float],\n        scenario: ProjectionScenario\n    ) -> Projection:\n        \"\"\"\n        Create a custom projection using the common library.\n        \n        Args:\n            starting_balance: Current cash balance\n            projection_dates: List of dates for projection\n            projection_income: List of income values\n            projection_expenses: List of expense values\n            scenario: Projection scenario\n            \n        Returns:\n            Projection object\n        \"\"\"\n        # Create cash flows\n        cash_flows = []\n        cumulative_balance = starting_balance\n        lowest_balance = starting_balance\n        highest_balance = starting_balance\n        \n        for i, date in enumerate(projection_dates):\n            income = projection_income[i]\n            expenses = projection_expenses[i]\n            net = income - expenses\n            cumulative_balance += net\n            \n            # Track min/max balances\n            lowest_balance = min(lowest_balance, cumulative_balance)\n            highest_balance = max(highest_balance, cumulative_balance)\n            \n            # Create cash flow\n            cash_flow = CashFlow(\n                date=date,\n                income=income,\n                expenses=expenses,\n                net=net,\n                cumulative=cumulative_balance\n            )\n            cash_flows.append(cash_flow)\n        \n        # Calculate runway months\n        runway_months = None\n        avg_expenses = sum(projection_expenses) / len(projection_expenses) if projection_expenses else 0\n        \n        if avg_expenses > 0:\n            for i, cf in enumerate(cash_flows):\n                if cf.cumulative <= 0:\n                    runway_months = i\n                    break\n            \n            if runway_months is None and lowest_balance > 0:\n                if cash_flows[-1].net < 0:\n                    runway_months = len(projection_dates) + (cash_flows[-1].cumulative / -cash_flows[-1].net)\n                else:\n                    runway_months = float('inf')  # Sustainable cash flow\n        \n        # Determine emergency fund status\n        emergency_fund_months = 6  # Default value\n        emergency_fund_status = \"insufficient\"\n        if lowest_balance >= avg_expenses * emergency_fund_months:\n            emergency_fund_status = \"adequate\"\n        elif lowest_balance >= avg_expenses * (emergency_fund_months / 2):\n            emergency_fund_status = \"partial\"\n            \n        # Create the projection\n        return Projection(\n            scenario=scenario,\n            start_date=projection_dates[0],\n            end_date=projection_dates[-1],\n            starting_balance=starting_balance,\n            cash_flows=cash_flows,\n            final_balance=cash_flows[-1].cumulative if cash_flows else starting_balance,\n            lowest_balance=lowest_balance,\n            highest_balance=highest_balance,\n            runway_months=runway_months,\n            emergency_fund_status=emergency_fund_status,\n            tax_liability={},  # Not used in this implementation\n            confidence_level=0.8,\n            metadata={\n                \"avg_monthly_income\": sum(projection_income) / len(projection_income) if projection_income else 0,\n                \"avg_monthly_expenses\": avg_expenses,\n            }\n        )\n\n    def _add_recurring_item_to_dict(\n        self,\n        monthly_dict: Dict[str, float],\n        item: Union[RevenueSource, ExpenseItem],\n        start_date: datetime,\n        end_date: datetime,\n        multiplier: float = 1.0,\n    ) -> None:\n        \"\"\"Add a recurring item to monthly dictionary.\"\"\"\n        # Handle different recurrence frequencies\n        months_interval = 1  # Default to monthly\n        frequency_multiplier = 1.0\n\n        if item.recurrence_frequency == \"quarterly\":\n            months_interval = 3\n        elif item.recurrence_frequency == \"biannual\":\n            months_interval = 6\n        elif item.recurrence_frequency == \"annual\":\n            months_interval = 12\n        elif item.recurrence_frequency == \"biweekly\":\n            # Approximate biweekly as 2.17 payments per month\n            frequency_multiplier = 2.17\n        elif item.recurrence_frequency == \"weekly\":\n            # Approximate weekly as 4.33 payments per month\n            frequency_multiplier = 4.33\n\n        # Determine start month (use expected_date if available)\n        current_month = None\n        if hasattr(item, \"expected_date\") and item.expected_date:\n            current_month = item.expected_date\n        else:\n            current_month = start_date\n\n        # Add to each applicable month\n        while current_month <= end_date:\n            month_key = current_month.strftime(\"%Y-%m\")\n\n            # Apply probability adjustment for revenue\n            if hasattr(item, \"probability\"):\n                adjusted_amount = item.amount * (item.probability / 100) * multiplier * frequency_multiplier\n            else:\n                adjusted_amount = item.amount * multiplier * frequency_multiplier\n\n            monthly_dict[month_key] = monthly_dict.get(month_key, 0) + adjusted_amount\n\n            # Move to next applicable month\n            month = current_month.month + months_interval\n            year = current_month.year + (month - 1) // 12\n            month = ((month - 1) % 12) + 1\n            current_month = datetime(year, month, 1)\n\n    def _get_scenario_income_multiplier(self, scenario: ProjectionScenario) -> float:\n        \"\"\"Get income multiplier based on scenario.\"\"\"\n        if scenario == ProjectionScenario.STRESS_TEST:\n            return 0.7  # 70% of expected income\n        elif scenario == ProjectionScenario.CONSERVATIVE:\n            return 0.85  # 85% of expected income\n        elif scenario == ProjectionScenario.BASELINE:\n            return 1.0  # 100% of expected income\n        elif scenario == ProjectionScenario.OPTIMISTIC:\n            return 1.15  # 115% of expected income\n        return 1.0\n\n    def _get_scenario_expense_multiplier(self, scenario: ProjectionScenario) -> float:\n        \"\"\"Get expense multiplier based on scenario.\"\"\"\n        if scenario == ProjectionScenario.STRESS_TEST:\n            return 1.15  # 115% of expected expenses\n        elif scenario == ProjectionScenario.CONSERVATIVE:\n            return 1.05  # 105% of expected expenses\n        elif scenario == ProjectionScenario.BASELINE:\n            return 1.0  # 100% of expected expenses\n        elif scenario == ProjectionScenario.OPTIMISTIC:\n            return 0.95  # 95% of expected expenses\n        return 1.0\n\n    def calculate_runway(\n        self,\n        current_balance: float,\n        spending_level: SpendingLevel,\n        monthly_expenses: Optional[float] = None,\n        historical_transactions: Optional[List[Transaction]] = None,\n        expected_revenue: Optional[Dict[str, float]] = None,\n        confidence_level: float = 0.8,\n    ) -> RunwayProjection:\n        \"\"\"\n        Calculate how long current funds will last at different spending levels.\n\n        Args:\n            current_balance: Current cash balance\n            spending_level: Level of spending to project\n            monthly_expenses: Optional override for monthly expense rate\n            historical_transactions: Optional historical transactions for expense analysis\n            expected_revenue: Optional expected future revenue by month\n            confidence_level: Confidence level for projection\n\n        Returns:\n            RunwayProjection with detailed runway information\n        \"\"\"\n        # Performance measurement\n        self.timer.start()\n\n        # Determine monthly expense rate\n        monthly_expense_rate = 0.0\n\n        if monthly_expenses is not None:\n            # Use provided expense rate\n            monthly_expense_rate = monthly_expenses\n        elif historical_transactions:\n            # Calculate from historical data (last 3 months)\n            now = datetime.now()\n            three_months_ago = datetime(now.year, now.month, 1) - timedelta(days=90)\n\n            # Filter to expenses in the last 3 months\n            recent_expenses = [\n                t\n                for t in historical_transactions\n                if (\n                    t.transaction_type == TransactionType.EXPENSE\n                    and t.date >= three_months_ago\n                )\n            ]\n\n            # Group by month and calculate average\n            expenses_by_month = {}\n            for expense in recent_expenses:\n                month_key = expense.date.strftime(\"%Y-%m\")\n                if month_key not in expenses_by_month:\n                    expenses_by_month[month_key] = 0\n                expenses_by_month[month_key] += expense.amount\n\n            if expenses_by_month:\n                monthly_expense_rate = sum(expenses_by_month.values()) / len(\n                    expenses_by_month\n                )\n            else:\n                raise ValueError(\"No historical expense data available\")\n        else:\n            raise ValueError(\n                \"Either monthly_expenses or historical_transactions must be provided\"\n            )\n\n        # Apply spending level adjustment\n        adjusted_expense_rate = self._adjust_for_spending_level(\n            monthly_expense_rate, spending_level\n        )\n\n        # Calculate runway without expected revenue\n        bare_runway_months = (\n            current_balance / adjusted_expense_rate\n            if adjusted_expense_rate > 0\n            else float(\"inf\")\n        )\n\n        # Include expected revenue if provided\n        if expected_revenue:\n            # Get expected revenue by month\n            sorted_months = sorted(expected_revenue.keys())\n\n            # Calculate runway with revenue\n            balance = current_balance\n            months = 0\n            depletion_date = None\n\n            while balance > 0 and months < 60:  # Cap at 5 years\n                # Current month index\n                current_month_idx = months % len(sorted_months)\n                current_month = sorted_months[current_month_idx]\n\n                # Subtract expenses and add revenue\n                balance -= adjusted_expense_rate\n                if current_month in expected_revenue:\n                    balance += expected_revenue[current_month]\n\n                months += 1\n\n                # Calculate depletion date\n                if balance <= 0:\n                    now = datetime.now()\n                    depletion_date = datetime(\n                        now.year + (now.month + months - 1) // 12,\n                        ((now.month + months - 1) % 12) + 1,\n                        1,\n                    )\n                    break\n\n            # If we reached the cap without depleting, set to infinity\n            runway_months = months if months < 60 else float(\"inf\")\n        else:\n            # Without expected revenue, use simple calculation\n            runway_months = bare_runway_months\n\n            # Calculate depletion date\n            if runway_months < float(\"inf\"):\n                now = datetime.now()\n                months_to_add = math.floor(runway_months)\n                depletion_date = datetime(\n                    now.year + (now.month + months_to_add - 1) // 12,\n                    ((now.month + months_to_add - 1) % 12) + 1,\n                    1,\n                )\n            else:\n                depletion_date = None\n\n        # Create result\n        result = RunwayProjection(\n            calculation_date=datetime.now(),\n            starting_balance=current_balance,\n            spending_level=spending_level,\n            monthly_expense_rate=adjusted_expense_rate,\n            expected_income=expected_revenue or {},\n            runway_months=runway_months,\n            depletion_date=depletion_date,\n            confidence_level=confidence_level,\n        )\n\n        # Verify performance\n        elapsed_time = self.timer.stop()\n\n        return result\n\n    def _adjust_for_spending_level(\n        self, base_expense_rate: float, spending_level: SpendingLevel\n    ) -> float:\n        \"\"\"Adjust expense rate based on spending level.\"\"\"\n        if spending_level == SpendingLevel.MINIMAL:\n            return base_expense_rate * 0.6  # 60% of normal expenses\n        elif spending_level == SpendingLevel.REDUCED:\n            return base_expense_rate * 0.8  # 80% of normal expenses\n        elif spending_level == SpendingLevel.NORMAL:\n            return base_expense_rate  # 100% of normal expenses\n        elif spending_level == SpendingLevel.INCREASED:\n            return base_expense_rate * 1.2  # 120% of normal expenses\n        return base_expense_rate\n\n    def create_what_if_scenario(\n        self,\n        name: str,\n        base_scenario: ProjectionScenario,\n        parameters: List[ScenarioParameter],\n        description: Optional[str] = None,\n    ) -> WhatIfScenario:\n        \"\"\"\n        Create a what-if scenario for financial planning.\n\n        Args:\n            name: Name for the scenario\n            base_scenario: Base projection scenario\n            parameters: Parameters for the scenario\n            description: Optional description\n\n        Returns:\n            WhatIfScenario object\n        \"\"\"\n        # Create the scenario\n        scenario = WhatIfScenario(\n            name=name,\n            description=description,\n            base_scenario=base_scenario,\n            parameters=parameters,\n            creation_date=datetime.now(),\n        )\n\n        return scenario\n\n    def evaluate_what_if_scenario(\n        self,\n        scenario: WhatIfScenario,\n        starting_balance: float,\n        revenue_sources: List[RevenueSource],\n        expense_items: List[ExpenseItem],\n        months_ahead: int = 12,\n    ) -> Tuple[WhatIfScenario, CashFlowProjection]:\n        \"\"\"\n        Evaluate a what-if scenario and calculate its impact.\n\n        Args:\n            scenario: What-if scenario to evaluate\n            starting_balance: Current cash balance\n            revenue_sources: Expected revenue sources\n            expense_items: Expected expenses\n            months_ahead: Number of months to project\n\n        Returns:\n            Tuple of (updated scenario with results, cash flow projection)\n        \"\"\"\n        # Apply parameter adjustments to revenue and expenses\n        adjusted_revenue = list(revenue_sources)\n        adjusted_expenses = list(expense_items)\n\n        # Track adjustments made for each parameter\n        adjustments = {}\n\n        for param in scenario.parameters:\n            # Store original value\n            adjustments[param.name] = param.current_value\n\n            # Apply parameter adjustments based on name patterns\n            if \"hourly_rate\" in param.name.lower():\n                # Adjust revenue based on hourly rate change\n                for i, revenue in enumerate(adjusted_revenue):\n                    if \"hourly\" in revenue.name.lower():\n                        # Create a new object with updated amount\n                        new_revenue = RevenueSource(\n                            name=revenue.name,\n                            amount=param.current_value,\n                            probability=revenue.probability,\n                            expected_date=revenue.expected_date,\n                            recurring=revenue.recurring,\n                            recurrence_frequency=revenue.recurrence_frequency,\n                            notes=revenue.notes,\n                        )\n                        adjusted_revenue[i] = new_revenue\n\n            elif \"monthly_income\" in param.name.lower():\n                # Adjust monthly income\n                for i, revenue in enumerate(adjusted_revenue):\n                    if revenue.recurring and revenue.recurrence_frequency == \"monthly\":\n                        # Create a new object with updated amount\n                        new_revenue = RevenueSource(\n                            name=revenue.name,\n                            amount=param.current_value,\n                            probability=revenue.probability,\n                            expected_date=revenue.expected_date,\n                            recurring=revenue.recurring,\n                            recurrence_frequency=revenue.recurrence_frequency,\n                            notes=revenue.notes,\n                        )\n                        adjusted_revenue[i] = new_revenue\n\n            elif \"expense_reduction\" in param.name.lower():\n                # Apply expense reduction percentage\n                reduction_factor = 1.0 - (param.current_value / 100)\n                for i, expense in enumerate(adjusted_expenses):\n                    # Create a new object with updated amount\n                    new_expense = ExpenseItem(\n                        name=expense.name,\n                        amount=expense.amount * reduction_factor,\n                        category=expense.category,\n                        due_date=expense.due_date,\n                        recurring=expense.recurring,\n                        recurrence_frequency=expense.recurrence_frequency,\n                        essential=expense.essential,\n                        notes=expense.notes,\n                    )\n                    adjusted_expenses[i] = new_expense\n\n            # Add more parameter handling as needed\n\n        # Run projection with adjusted values\n        projection = self.project_cash_flow(\n            starting_balance=starting_balance,\n            current_date=datetime.now(),\n            months_ahead=months_ahead,\n            revenue_sources=adjusted_revenue,\n            expense_items=adjusted_expenses,\n            scenario=scenario.base_scenario,\n        )\n\n        # Calculate result metrics\n        result_metrics = {\n            \"ending_balance\": projection.ending_balance,\n            \"net_cash_flow\": projection.net_cash_flow,\n            \"total_income\": projection.total_income,\n            \"total_expenses\": projection.total_expenses,\n        }\n\n        # Update scenario with results\n        # Create a new scenario with updated result metrics\n        updated_scenario = WhatIfScenario(\n            id=scenario.id,\n            name=scenario.name,\n            description=scenario.description,\n            base_scenario=scenario.base_scenario,\n            parameters=scenario.parameters,\n            result_metrics=result_metrics,\n            creation_date=scenario.creation_date,\n            notes=scenario.notes,\n        )\n\n        return updated_scenario, projection\n\n    def assess_emergency_fund(\n        self,\n        current_fund_balance: float,\n        monthly_expenses: Optional[float] = None,\n        historical_transactions: Optional[List[Transaction]] = None,\n        recommended_months: float = 6.0,\n    ) -> EmergencyFundAssessment:\n        \"\"\"\n        Assess the adequacy of an emergency fund.\n\n        Args:\n            current_fund_balance: Current emergency fund balance\n            monthly_expenses: Optional override for monthly expenses\n            historical_transactions: Optional historical transactions for expense analysis\n            recommended_months: Recommended number of months coverage\n\n        Returns:\n            EmergencyFundAssessment with detailed assessment\n        \"\"\"\n        # Determine monthly essential expenses\n        monthly_essential = 0.0\n\n        if monthly_expenses is not None:\n            # Use provided expense amount\n            monthly_essential = monthly_expenses\n        elif historical_transactions:\n            # Calculate from historical data (last 3 months)\n            now = datetime.now()\n            three_months_ago = datetime(now.year, now.month, 1) - timedelta(days=90)\n\n            # Filter to essential expenses in the last 3 months\n            essential_expenses = [\n                t\n                for t in historical_transactions\n                if (\n                    t.transaction_type == TransactionType.EXPENSE\n                    and t.date >= three_months_ago\n                    and t.category\n                    in [\n                        ExpenseCategory.UTILITIES,\n                        ExpenseCategory.HEALTH_INSURANCE,\n                        ExpenseCategory.OFFICE_RENT,\n                        ExpenseCategory.INTERNET,\n                        ExpenseCategory.PHONE,\n                    ]\n                )\n            ]\n\n            # Group by month and calculate average\n            expenses_by_month = {}\n            for expense in essential_expenses:\n                month_key = expense.date.strftime(\"%Y-%m\")\n                if month_key not in expenses_by_month:\n                    expenses_by_month[month_key] = 0\n                expenses_by_month[month_key] += expense.amount\n\n            if expenses_by_month:\n                monthly_essential = sum(expenses_by_month.values()) / len(\n                    expenses_by_month\n                )\n            else:\n                raise ValueError(\"No historical essential expense data available\")\n        else:\n            raise ValueError(\n                \"Either monthly_expenses or historical_transactions must be provided\"\n            )\n\n        # Calculate recommended fund size\n        recommended_fund_size = monthly_essential * recommended_months\n\n        # Calculate current coverage\n        current_coverage_months = (\n            current_fund_balance / monthly_essential if monthly_essential > 0 else 0\n        )\n\n        # Determine adequacy level\n        if current_coverage_months < 1:\n            adequacy_level = \"inadequate\"\n            funding_plan = (\n                \"Immediate action needed: Build to 1 month coverage as soon as possible\"\n            )\n        elif current_coverage_months < 3:\n            adequacy_level = \"minimal\"\n            funding_plan = \"Continue building: Aim for 3 months coverage\"\n        elif current_coverage_months < recommended_months:\n            adequacy_level = \"adequate\"\n            funding_plan = f\"Good progress: Continue building toward {recommended_months} months coverage\"\n        else:\n            adequacy_level = \"excellent\"\n            funding_plan = (\n                \"Well funded: Maintain current level or consider other financial goals\"\n            )\n\n        # Create assessment\n        assessment = EmergencyFundAssessment(\n            assessment_date=datetime.now(),\n            current_fund_balance=current_fund_balance,\n            monthly_essential_expenses=monthly_essential,\n            recommended_months_coverage=recommended_months,\n            recommended_fund_size=recommended_fund_size,\n            current_coverage_months=current_coverage_months,\n            adequacy_level=adequacy_level,\n            funding_plan=funding_plan,\n        )\n\n        return assessment",
                "class FinancialProjector(BaseAnalyzer[TimeSeriesData, ProjectionResult]):\n    \"\"\"\n    Analyzer for financial projections.\n    \n    Used for forecasting future financial states and scenario analysis.\n    \"\"\"\n    \n    def analyze(\n        self, historical_data: TimeSeriesData, parameters: Optional[ProjectionParameters] = None\n    ) -> ProjectionResult:\n        \"\"\"\n        Project future financial states based on historical data.\n        \n        Args:\n            historical_data: Historical financial data\n            parameters: Optional parameters to configure the projection\n            \n        Returns:\n            ProjectionResult with different scenario projections\n        \"\"\"\n        # Start timing for performance benchmarking\n        start_time = time.time()\n        \n        # Set default parameters if not provided\n        if parameters is None:\n            parameters = ProjectionParameters()\n        \n        # Check cache\n        cached_result = self._get_from_cache(UUID(), parameters)\n        if cached_result:\n            return cached_result\n        \n        # Calculate starting balance (last cumulative value)\n        starting_balance = (\n            historical_data.values[-1] if historical_data.values else 0.0\n        )\n        \n        # Generate projections for baseline scenario\n        baseline = self._generate_projection(\n            historical_data,\n            ProjectionScenario.BASELINE,\n            parameters,\n            income_factor=1.0,\n            expense_factor=1.0,\n            investment_factor=1.0,\n        )\n        \n        # Generate projections for optimistic scenario\n        optimistic = self._generate_projection(\n            historical_data,\n            ProjectionScenario.OPTIMISTIC,\n            parameters,\n            income_factor=1.1,\n            expense_factor=0.9,\n            investment_factor=1.2,\n        )\n        \n        # Generate projections for conservative scenario\n        conservative = self._generate_projection(\n            historical_data,\n            ProjectionScenario.CONSERVATIVE,\n            parameters,\n            income_factor=0.9,\n            expense_factor=1.1,\n            investment_factor=0.8,\n        )\n        \n        # Generate projections for stress test scenario\n        stress_test = self._generate_projection(\n            historical_data,\n            ProjectionScenario.STRESS_TEST,\n            parameters,\n            income_factor=0.7,\n            expense_factor=1.2,\n            investment_factor=0.5,\n        )\n        \n        # Generate recommended actions\n        recommended_actions = self._generate_recommendations(\n            baseline, conservative, stress_test, parameters\n        )\n        \n        # Calculate processing time\n        processing_time_ms = (time.time() - start_time) * 1000\n        \n        # Create the result\n        result = ProjectionResult(\n            id=UUID(),\n            subject_id=UUID(),\n            subject_type=\"financial_data\",\n            analysis_type=\"projection\",\n            analysis_date=datetime.now(),\n            processing_time_ms=processing_time_ms,\n            result_summary={\n                \"starting_balance\": starting_balance,\n                \"baseline_final_balance\": baseline.final_balance,\n                \"runway_months\": baseline.runway_months,\n                \"emergency_fund_status\": baseline.emergency_fund_status,\n            },\n            detailed_results={\n                \"projection_length\": parameters.projection_length,\n                \"scenarios\": [s.value for s in ProjectionScenario],\n                \"historical_data_points\": len(historical_data.values),\n            },\n            baseline=baseline,\n            optimistic=optimistic,\n            conservative=conservative,\n            stress_test=stress_test,\n            recommended_actions=recommended_actions,\n        )\n        \n        # Save to cache\n        self._save_to_cache(UUID(), result, parameters)\n        \n        return result\n    \n    def _generate_projection(\n        self,\n        historical_data: TimeSeriesData,\n        scenario: ProjectionScenario,\n        parameters: ProjectionParameters,\n        income_factor: float = 1.0,\n        expense_factor: float = 1.0,\n        investment_factor: float = 1.0,\n    ) -> Projection:\n        \"\"\"\n        Generate a financial projection for a specific scenario.\n        \n        Args:\n            historical_data: Historical financial data\n            scenario: The projection scenario\n            parameters: Projection parameters\n            income_factor: Adjustment factor for income\n            expense_factor: Adjustment factor for expenses\n            investment_factor: Adjustment factor for investment returns\n            \n        Returns:\n            Projection for the specified scenario\n        \"\"\"\n        # Calculate starting balance (last cumulative value)\n        starting_balance = (\n            historical_data.values[-1] if historical_data.values else 0.0\n        )\n        \n        # Determine start and end dates\n        if historical_data.dates:\n            start_date = historical_data.dates[-1]\n            # Add 1 month to avoid overlap with historical data\n            if isinstance(start_date, datetime):\n                start_date = start_date.replace(\n                    day=1, hour=0, minute=0, second=0, microsecond=0\n                )\n                start_date = (start_date.replace(day=28) + timedelta(days=4)).replace(day=1)\n            else:\n                # For date objects\n                year = start_date.year + ((start_date.month) // 12)\n                month = (start_date.month % 12) + 1\n                start_date = date(year, month, 1)\n        else:\n            start_date = datetime.now().replace(\n                day=1, hour=0, minute=0, second=0, microsecond=0\n            )\n        \n        # Generate projection dates (monthly)\n        projection_dates = []\n        current_date = start_date\n        for _ in range(parameters.projection_length):\n            projection_dates.append(current_date)\n            if isinstance(current_date, datetime):\n                current_date = (current_date.replace(day=28) + timedelta(days=4)).replace(day=1)\n            else:\n                # For date objects\n                year = current_date.year + ((current_date.month) // 12)\n                month = (current_date.month % 12) + 1\n                current_date = date(year, month, 1)\n        \n        end_date = projection_dates[-1]\n        \n        # Adjust rates based on scenario\n        income_growth = parameters.income_growth_rate * income_factor\n        expense_growth = parameters.expense_growth_rate * expense_factor\n        investment_return = parameters.investment_return_rate * investment_factor\n        \n        # Calculate historical averages\n        avg_income, avg_expenses = self._calculate_historical_averages(historical_data)\n        \n        # Generate cash flows\n        cash_flows = []\n        cumulative_balance = starting_balance\n        lowest_balance = starting_balance\n        highest_balance = starting_balance\n        \n        for i, projection_date in enumerate(projection_dates):\n            # Calculate projected income with growth\n            income = avg_income * (1 + income_growth) ** (i / 12) if parameters.include_income else 0\n            \n            # Calculate projected expenses with growth\n            expenses = avg_expenses * (1 + expense_growth) ** (i / 12) if parameters.include_expenses else 0\n            \n            # Calculate investment returns (monthly)\n            investment_income = (\n                cumulative_balance * (investment_return / 12)\n                if parameters.include_investments and cumulative_balance > 0\n                else 0\n            )\n            \n            # Add investment income to total income\n            income += investment_income\n            \n            # Calculate net and update cumulative\n            net = income - expenses\n            cumulative_balance += net\n            \n            # Track lowest and highest balances\n            lowest_balance = min(lowest_balance, cumulative_balance)\n            highest_balance = max(highest_balance, cumulative_balance)\n            \n            # Create cash flow record\n            cash_flow = CashFlow(\n                date=projection_date,\n                income=income,\n                expenses=expenses,\n                net=net,\n                cumulative=cumulative_balance,\n            )\n            \n            cash_flows.append(cash_flow)\n        \n        # Calculate runway months (how long until funds are depleted)\n        runway_months = None\n        if avg_expenses > 0:\n            for i, cf in enumerate(cash_flows):\n                if cf.cumulative <= 0:\n                    runway_months = i\n                    break\n            \n            if runway_months is None and lowest_balance > 0:\n                # If we didn't go negative, estimate based on final balance and burn rate\n                if cash_flows[-1].net < 0:\n                    runway_months = parameters.projection_length + (cash_flows[-1].cumulative / -cash_flows[-1].net)\n                else:\n                    runway_months = float('inf')  # Sustainable cash flow\n        \n        # Determine emergency fund status\n        emergency_fund_status = \"insufficient\"\n        if lowest_balance >= avg_expenses * parameters.emergency_fund_months:\n            emergency_fund_status = \"adequate\"\n        elif lowest_balance >= avg_expenses * (parameters.emergency_fund_months / 2):\n            emergency_fund_status = \"partial\"\n        \n        # Calculate projected tax liability\n        tax_liability = self._calculate_tax_liability(cash_flows, parameters.tax_rate)\n        \n        # Create the projection\n        return Projection(\n            scenario=scenario,\n            start_date=start_date,\n            end_date=end_date,\n            starting_balance=starting_balance,\n            cash_flows=cash_flows,\n            final_balance=cash_flows[-1].cumulative if cash_flows else starting_balance,\n            lowest_balance=lowest_balance,\n            highest_balance=highest_balance,\n            runway_months=runway_months,\n            emergency_fund_status=emergency_fund_status,\n            tax_liability=tax_liability,\n            confidence_level=self._calculate_confidence_level(scenario),\n            metadata={\n                \"income_growth_rate\": income_growth,\n                \"expense_growth_rate\": expense_growth,\n                \"investment_return_rate\": investment_return,\n                \"avg_monthly_income\": avg_income,\n                \"avg_monthly_expenses\": avg_expenses,\n            },\n        )\n    \n    def _calculate_historical_averages(\n        self, historical_data: TimeSeriesData\n    ) -> Tuple[float, float]:\n        \"\"\"\n        Calculate average monthly income and expenses from historical data.\n        \n        Args:\n            historical_data: Historical financial data\n            \n        Returns:\n            Tuple of (avg_income, avg_expenses)\n        \"\"\"\n        # In a real implementation, the historical data would likely contain\n        # separate income and expense data. Here we'll simulate it.\n        \n        # If we don't have historical data, use reasonable defaults\n        if not historical_data.values:\n            return 5000.0, 4000.0  # Default monthly income and expenses\n        \n        # Normally we would split the historical cash flows into income and expenses\n        # For now, we'll use a heuristic based on the net cash flow\n        \n        # Assuming the TimeSeriesData values are net cash flows\n        avg_net = np.mean(historical_data.values[-6:]) if len(historical_data.values) >= 6 else np.mean(historical_data.values)\n        \n        # Assuming expenses are about 80% of income on average\n        avg_income = max(avg_net * 1.8, 0)\n        avg_expenses = max(avg_income - avg_net, 0)\n        \n        return avg_income, avg_expenses\n    \n    def _calculate_tax_liability(\n        self, cash_flows: List[CashFlow], tax_rate: float\n    ) -> Dict[str, float]:\n        \"\"\"\n        Calculate projected tax liability.\n        \n        Args:\n            cash_flows: List of projected cash flows\n            tax_rate: The effective tax rate\n            \n        Returns:\n            Dictionary with tax liability information\n        \"\"\"\n        # Group by year\n        yearly_income = {}\n        \n        for cf in cash_flows:\n            year = cf.date.year\n            if year not in yearly_income:\n                yearly_income[year] = 0\n            \n            yearly_income[year] += cf.income\n        \n        # Calculate tax for each year\n        yearly_tax = {year: income * tax_rate for year, income in yearly_income.items()}\n        \n        # Calculate total and average\n        total_tax = sum(yearly_tax.values())\n        avg_monthly_tax = total_tax / len(cash_flows) if cash_flows else 0\n        \n        return {\n            \"yearly\": yearly_tax,\n            \"total\": total_tax,\n            \"avg_monthly\": avg_monthly_tax,\n            \"effective_rate\": tax_rate,\n        }\n    \n    def _calculate_confidence_level(self, scenario: ProjectionScenario) -> float:\n        \"\"\"\n        Calculate confidence level for a scenario.\n        \n        Args:\n            scenario: The projection scenario\n            \n        Returns:\n            Confidence level between 0 and 1\n        \"\"\"\n        # Assign confidence levels based on the scenario\n        if scenario == ProjectionScenario.BASELINE:\n            return 0.8\n        elif scenario == ProjectionScenario.OPTIMISTIC:\n            return 0.2\n        elif scenario == ProjectionScenario.CONSERVATIVE:\n            return 0.6\n        elif scenario == ProjectionScenario.STRESS_TEST:\n            return 0.1\n        \n        return 0.5  # Default\n    \n    def _generate_recommendations(\n        self,\n        baseline: Projection,\n        conservative: Projection,\n        stress_test: Projection,\n        parameters: ProjectionParameters,\n    ) -> List[str]:\n        \"\"\"\n        Generate financial recommendations based on projections.\n        \n        Args:\n            baseline: Baseline scenario projection\n            conservative: Conservative scenario projection\n            stress_test: Stress test scenario projection\n            parameters: Projection parameters\n            \n        Returns:\n            List of recommendation strings\n        \"\"\"\n        recommendations = []\n        \n        # Emergency fund recommendations\n        if baseline.emergency_fund_status == \"insufficient\":\n            recommendations.append(\n                f\"Build an emergency fund of {parameters.emergency_fund_months} months of expenses \"\n                f\"(approximately ${parameters.emergency_fund_months * baseline.metadata['avg_monthly_expenses']:,.2f}).\"\n            )\n        elif baseline.emergency_fund_status == \"partial\":\n            months_needed = parameters.emergency_fund_months\n            current_months = baseline.lowest_balance / baseline.metadata[\"avg_monthly_expenses\"]\n            recommendations.append(\n                f\"Increase your emergency fund from {current_months:.1f} months to {months_needed} months \"\n                f\"(add approximately ${(months_needed - current_months) * baseline.metadata['avg_monthly_expenses']:,.2f}).\"\n            )\n        \n        # Cash flow recommendations\n        if baseline.cash_flows and baseline.cash_flows[-1].net < 0:\n            recommendations.append(\n                \"Your expenses exceed your income. Consider reducing expenses or increasing income \"\n                f\"to close the monthly gap of ${-baseline.cash_flows[-1].net:,.2f}.\"\n            )\n        \n        # Runway concerns\n        if baseline.runway_months is not None and baseline.runway_months < parameters.projection_length:\n            recommendations.append(\n                f\"Based on current projections, your funds will be depleted in approximately {baseline.runway_months:.1f} months. \"\n                \"Take immediate action to increase income or reduce expenses.\"\n            )\n        elif conservative.runway_months is not None and conservative.runway_months < parameters.projection_length:\n            recommendations.append(\n                f\"In a conservative scenario, your funds could be depleted in approximately {conservative.runway_months:.1f} months. \"\n                \"Consider building additional reserves or reducing discretionary expenses.\"\n            )\n        \n        # Investment recommendations\n        if parameters.include_investments and baseline.metadata[\"avg_monthly_expenses\"] > 0:\n            # Calculate months of expenses covered by investments\n            investment_coverage = baseline.final_balance / baseline.metadata[\"avg_monthly_expenses\"]\n            if investment_coverage > 24:\n                recommendations.append(\n                    f\"Your projected balance exceeds 24 months of expenses. Consider investing a portion for long-term growth.\"\n                )\n        \n        # Tax planning\n        if baseline.tax_liability[\"total\"] > 0:\n            recommendations.append(\n                f\"Set aside approximately ${baseline.tax_liability['avg_monthly']:,.2f} monthly for taxes, \"\n                f\"with an estimated annual liability of ${baseline.tax_liability['yearly'].get(datetime.now().year, 0):,.2f}.\"\n            )\n        \n        # Stress test preparedness\n        if stress_test.lowest_balance < 0:\n            recommendations.append(\n                \"Your financial position is vulnerable to economic stress. Consider building additional reserves \"\n                f\"of at least ${-stress_test.lowest_balance:,.2f} to withstand worst-case scenarios.\"\n            )\n        \n        return recommendations"
            ]
        }
    },
    "unified/personal_finance_tracker/tax/__init__.py": {
        "logprobs": -249.09740424265797,
        "metrics": {
            "loc": 5,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 4,
            "blank": 1,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/personal_finance_tracker/projection/__init__.py": {
        "logprobs": -250.401945474615,
        "metrics": {
            "loc": 5,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 4,
            "blank": 1,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/personal_finance_tracker/income/models.py": {
        "logprobs": -675.5566927495796,
        "metrics": {
            "loc": 97,
            "sloc": 67,
            "lloc": 103,
            "comments": 12,
            "multi": 0,
            "blank": 20,
            "cyclomatic": 19,
            "internal_imports": [
                "class TimeSeriesGranularity(str, Enum):\n    \"\"\"Granularity for time series data.\"\"\"\n    \n    DAILY = \"daily\"\n    WEEKLY = \"weekly\"\n    MONTHLY = \"monthly\"\n    QUARTERLY = \"quarterly\"\n    YEARLY = \"yearly\"",
                "class Transaction(BusinessTransaction):\n    \"\"\"\n    Transaction model for the Personal Finance Tracker.\n    \n    Extends the BusinessTransaction from the common library with\n    freelancer-specific fields and behaviors.\n    \"\"\"\n\n    # Override category field to use our specific ExpenseCategory enum\n    category: Optional[ExpenseCategory] = None\n    \n    # Make sure the account_id is required\n    account_id: str\n\n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        # This is necessary to allow field overrides\n        extra = \"allow\""
            ]
        }
    },
    "unified/personal_finance_tracker/tax/tax_manager.py": {
        "logprobs": -2925.0177195257797,
        "metrics": {
            "loc": 810,
            "sloc": 467,
            "lloc": 229,
            "comments": 90,
            "multi": 132,
            "blank": 132,
            "cyclomatic": 90,
            "internal_imports": [
                "class Transaction(BusinessTransaction):\n    \"\"\"\n    Transaction model for the Personal Finance Tracker.\n    \n    Extends the BusinessTransaction from the common library with\n    freelancer-specific fields and behaviors.\n    \"\"\"\n\n    # Override category field to use our specific ExpenseCategory enum\n    category: Optional[ExpenseCategory] = None\n    \n    # Make sure the account_id is required\n    account_id: str\n\n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        # This is necessary to allow field overrides\n        extra = \"allow\"",
                "class TaxPayment(CommonTaxPayment):\n    \"\"\"\n    Tax payment model for Personal Finance Tracker.\n    \n    Extends the TaxPayment model from the common library.\n    \"\"\"\n    quarter: int",
                "class TaxRate(CommonTaxRate):\n    \"\"\"\n    Tax rate model for Personal Finance Tracker.\n    \n    Extends the TaxRate model from the common library.\n    \"\"\"\n    pass",
                "class TaxDeduction(CommonTaxDeduction):\n    \"\"\"\n    Tax deduction model for Personal Finance Tracker.\n    \n    Extends the TaxDeduction model from the common library.\n    \"\"\"\n    pass",
                "class FilingStatus(str, Enum):\n    \"\"\"Tax filing status.\"\"\"\n\n    SINGLE = \"single\"\n    MARRIED_JOINT = \"married_filing_jointly\"\n    MARRIED_SEPARATE = \"married_filing_separately\"\n    HEAD_OF_HOUSEHOLD = \"head_of_household\"",
                "class TaxJurisdiction(str, Enum):\n    \"\"\"Tax jurisdiction types.\"\"\"\n\n    FEDERAL = \"federal\"\n    STATE = \"state\"\n    LOCAL = \"local\"",
                "class QuarterInfo(BaseModel):\n    \"\"\"Information about a tax quarter.\"\"\"\n\n    year: int\n    quarter: int\n    start_date: datetime\n    end_date: datetime\n    due_date: datetime\n    description: str",
                "class TaxBracket(BaseModel):\n    \"\"\"Tax bracket for a specific jurisdiction and filing status.\"\"\"\n\n    jurisdiction: TaxJurisdiction\n    filing_status: FilingStatus\n    tax_year: int\n    income_thresholds: List[float]  # Lower bounds of each bracket\n    rates: List[float]  # Rates for each bracket (as percentage: 10 = 10%)\n\n    @validator(\"rates\")\n    def validate_rates(cls, v, values):\n        \"\"\"Validate that rates are between 0 and 100 and match income thresholds.\"\"\"\n        if any(r < 0 or r > 100 for r in v):\n            raise ValueError(\"Rates must be between 0 and 100\")\n\n        if \"income_thresholds\" in values and len(v) != len(values[\"income_thresholds\"]):\n            raise ValueError(\"Number of rates must match number of income thresholds\")\n\n        return v",
                "class TaxLiability(BaseModel):\n    \"\"\"Calculated tax liability for a jurisdiction and period.\"\"\"\n\n    jurisdiction: TaxJurisdiction\n    tax_year: int\n    income: float\n    deductions: float\n    taxable_income: float\n    tax_amount: float\n    effective_rate: float  # As percentage\n    marginal_rate: float  # As percentage\n    filing_status: FilingStatus\n    calculation_date: datetime = Field(default_factory=datetime.now)\n    breakdown: Dict[str, float] = Field(default_factory=dict)  # Detailed breakdown\n\n    @validator(\"effective_rate\", \"marginal_rate\")\n    def validate_rates(cls, v):\n        \"\"\"Validate that rates are between 0 and 100.\"\"\"\n        if v < 0 or v > 100:\n            raise ValueError(\"Rates must be between 0 and 100\")\n        return v\n        \n    @classmethod\n    def from_common_liability(cls, common_liability: CommonTaxLiability, filing_status: FilingStatus, \n                            effective_rate: float, marginal_rate: float,\n                            breakdown: Dict[str, float]) -> \"TaxLiability\":\n        \"\"\"\n        Convert a common TaxLiability to our specialized version.\n        \n        Args:\n            common_liability: The common liability to convert\n            filing_status: Filing status for this liability\n            effective_rate: Effective tax rate\n            marginal_rate: Marginal tax rate\n            breakdown: Detailed breakdown of tax components\n            \n        Returns:\n            Our specialized TaxLiability\n        \"\"\"\n        return cls(\n            jurisdiction=TaxJurisdiction(common_liability.jurisdiction),\n            tax_year=common_liability.tax_year,\n            income=common_liability.income,\n            deductions=common_liability.deductions,\n            taxable_income=common_liability.taxable_income,\n            tax_amount=common_liability.tax_amount,\n            effective_rate=effective_rate,\n            marginal_rate=marginal_rate,\n            filing_status=filing_status,\n            calculation_date=common_liability.calculation_date,\n            breakdown=breakdown\n        )",
                "class EstimatedPayment(BaseModel):\n    \"\"\"Estimated tax payment calculation.\"\"\"\n\n    tax_year: int\n    quarter: int\n    jurisdiction: TaxJurisdiction\n    due_date: datetime\n    payment_amount: float  # Use this field instead of suggested_amount\n    suggested_amount: Optional[float] = None  # Keep for backwards compatibility\n    minimum_required: float\n    safe_harbor_amount: Optional[float] = None\n    year_to_date_liability: float\n    previous_payments: float\n    federal_tax: Optional[float] = None  # Added for test compatibility\n    self_employment_tax: Optional[float] = None  # Added for test compatibility\n    state_tax: Optional[float] = None  # Added for test compatibility\n    calculation_date: datetime = Field(default_factory=datetime.now)\n    notes: Optional[str] = None",
                "class TaxYearSummary(BaseModel):\n    \"\"\"Summary of tax obligations for a tax year.\"\"\"\n\n    tax_year: int\n    total_income: float\n    total_expenses: float\n    total_deductions: float\n    taxable_income: float\n    total_tax: float\n    effective_tax_rate: float\n    federal_tax: float\n    state_tax: float\n    self_employment_tax: float\n    total_paid: float\n    balance_due: float\n    calculation_date: datetime = Field(default_factory=datetime.now)\n    deductions: List[TaxDeduction] = Field(default_factory=list)\n    payments: List[TaxPayment] = Field(default_factory=list)\n\n    @validator(\"effective_tax_rate\")\n    def validate_rate(cls, v):\n        \"\"\"Validate that rate is between 0 and 100.\"\"\"\n        if v < 0 or v > 100:\n            raise ValueError(\"Rate must be between 0 and 100\")\n        return v"
            ]
        }
    },
    "unified/common/core/analysis/analyzer.py": {
        "logprobs": -803.8568737158228,
        "metrics": {
            "loc": 171,
            "sloc": 69,
            "lloc": 86,
            "comments": 9,
            "multi": 52,
            "blank": 38,
            "cyclomatic": 18,
            "internal_imports": []
        }
    },
    "unified/personal_finance_tracker/models/common.py": {
        "logprobs": -865.783149414778,
        "metrics": {
            "loc": 158,
            "sloc": 68,
            "lloc": 82,
            "comments": 12,
            "multi": 33,
            "blank": 42,
            "cyclomatic": 10,
            "internal_imports": [
                "class TransactionType(str, Enum):\n    \"\"\"Transaction type enum for all financial transactions.\"\"\"\n\n    INCOME = \"income\"\n    EXPENSE = \"expense\"\n    TAX_PAYMENT = \"tax_payment\"\n    TRANSFER = \"transfer\"\n    INVESTMENT = \"investment\"\n    DIVIDEND = \"dividend\"\n    INTEREST = \"interest\"",
                "class AccountType(str, Enum):\n    \"\"\"Account type enum for all financial accounts.\"\"\"\n\n    CHECKING = \"checking\"\n    SAVINGS = \"savings\"\n    CREDIT_CARD = \"credit_card\"\n    INVESTMENT = \"investment\"\n    RETIREMENT = \"retirement\"\n    CASH = \"cash\"\n    OTHER = \"other\"",
                "class BusinessTransaction(BaseTransaction):\n    \"\"\"\n    Transaction model for business transactions with additional fields.\n    \n    Extends the base transaction model with business-specific fields.\n    \"\"\"\n\n    business_use_percentage: Optional[float] = None\n    project_id: Optional[str] = None\n    client_id: Optional[str] = None\n    invoice_id: Optional[str] = None\n    receipt_path: Optional[str] = None\n    \n    @validator(\"business_use_percentage\")\n    def validate_business_percentage(cls, v):\n        \"\"\"Validate that business use percentage is between 0 and 100.\"\"\"\n        if v is not None and (v < 0 or v > 100):\n            raise ValueError(\"Business use percentage must be between 0 and 100\")\n        return v",
                "class TaxPayment(BaseModel):\n    \"\"\"\n    Tax payment model for tracking payments to tax authorities.\n    \n    Used for tax planning, compliance, and financial projections.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    date: Union[date, datetime]\n    amount: float\n    tax_year: int\n    quarter: Optional[int] = None\n    payment_method: str\n    jurisdiction: str = \"federal\"  # e.g., \"federal\", \"state\", \"local\"\n    confirmation_number: Optional[str] = None\n    notes: Optional[str] = None\n    \n    @validator(\"amount\")\n    def validate_amount(cls, v):\n        \"\"\"Validate that amount is a positive number.\"\"\"\n        if v < 0:\n            raise ValueError(\"Tax payment amount must be a positive number\")\n        return v\n    \n    @validator(\"tax_year\")\n    def validate_tax_year(cls, v):\n        \"\"\"Validate that tax year is reasonable.\"\"\"\n        current_year = datetime.now().year\n        if v < 1900 or v > current_year + 1:\n            raise ValueError(f\"Tax year {v} is outside reasonable range\")\n        return v\n    \n    @validator(\"quarter\")\n    def validate_quarter(cls, v):\n        \"\"\"Validate that quarter is 1-4.\"\"\"\n        if v is not None and (v < 1 or v > 4):\n            raise ValueError(\"Quarter must be between 1 and 4\")\n        return v",
                "class TaxRate(BaseModel):\n    \"\"\"\n    Tax rate model for a specific income bracket.\n    \n    Used for calculating tax obligations and financial planning.\n    \"\"\"\n\n    bracket_min: float\n    bracket_max: Optional[float] = None\n    rate: float  # Percentage (0-100)\n    tax_year: int\n    jurisdiction: str = \"federal\"  # e.g., \"federal\", \"state\", \"local\"\n    \n    @validator(\"rate\")\n    def validate_rate(cls, v):\n        \"\"\"Validate that rate is between 0 and 100.\"\"\"\n        if v < 0 or v > 100:\n            raise ValueError(\"Tax rate must be between 0 and 100\")\n        return v\n    \n    @validator(\"tax_year\")\n    def validate_tax_year(cls, v):\n        \"\"\"Validate that tax year is reasonable.\"\"\"\n        current_year = datetime.now().year\n        if v < 1900 or v > current_year + 1:\n            raise ValueError(f\"Tax year {v} is outside reasonable range\")\n        return v",
                "class TaxDeduction(BaseModel):\n    \"\"\"\n    Tax deduction model for tracking deductible expenses.\n    \n    Used for tax optimization and financial planning.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    amount: float\n    tax_year: int\n    category: str\n    description: Optional[str] = None\n    jurisdiction: str = \"federal\"\n    receipt_path: Optional[str] = None\n    \n    @validator(\"amount\")\n    def validate_amount(cls, v):\n        \"\"\"Validate that amount is a positive number.\"\"\"\n        if v < 0:\n            raise ValueError(\"Deduction amount must be a positive number\")\n        return v\n    \n    @validator(\"tax_year\")\n    def validate_tax_year(cls, v):\n        \"\"\"Validate that tax year is reasonable.\"\"\"\n        current_year = datetime.now().year\n        if v < 1900 or v > current_year + 1:\n            raise ValueError(f\"Tax year {v} is outside reasonable range\")\n        return v",
                "class TaxLiability(BaseModel):\n    \"\"\"\n    Tax liability model for tracking calculated tax obligations.\n    \n    Used for tax planning, compliance, and financial projections.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    tax_year: int\n    jurisdiction: str = \"federal\"\n    income: float\n    deductions: float\n    taxable_income: float\n    tax_amount: float\n    payments_made: float = 0.0\n    remaining_balance: float\n    calculation_date: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    @validator(\"income\", \"tax_amount\", \"payments_made\")\n    def validate_positive_numbers(cls, v):\n        \"\"\"Validate that financial amounts are positive numbers.\"\"\"\n        if v < 0:\n            raise ValueError(\"Value must be a positive number\")\n        return v\n    \n    @validator(\"tax_year\")\n    def validate_tax_year(cls, v):\n        \"\"\"Validate that tax year is reasonable.\"\"\"\n        current_year = datetime.now().year\n        if v < 1900 or v > current_year + 1:\n            raise ValueError(f\"Tax year {v} is outside reasonable range\")\n        return v\n    \n    @validator(\"remaining_balance\", always=True)\n    def calculate_remaining_balance(cls, v, values):\n        \"\"\"Calculate remaining balance if not provided.\"\"\"\n        if \"tax_amount\" in values and \"payments_made\" in values:\n            return values[\"tax_amount\"] - values[\"payments_made\"]\n        return v",
                "class Client(BaseModel):\n    \"\"\"\n    Client model for tracking information about clients.\n    \n    Used for organizing projects and managing client relationships.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    contact_email: Optional[str] = None\n    contact_phone: Optional[str] = None\n    address: Optional[str] = None\n    notes: Optional[str] = None\n    active: bool = True\n    metadata: Dict[str, Any] = Field(default_factory=dict)",
                "class Project(BaseModel):\n    \"\"\"\n    Project model for tracking client projects.\n    \n    Used for organizing work, time tracking, and financial analysis\n    across multiple persona implementations.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    client_id: Optional[str] = None\n    start_date: Union[date, datetime]\n    end_date: Optional[Union[date, datetime]] = None\n    status: ProjectStatus = ProjectStatus.ACTIVE\n    hourly_rate: Optional[float] = None\n    fixed_price: Optional[float] = None\n    estimated_hours: Optional[float] = None\n    description: Optional[str] = None\n    tags: List[str] = Field(default_factory=list)\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    @validator(\"end_date\")\n    def validate_end_date(cls, v, values):\n        \"\"\"Validate that end_date is after start_date if both are provided.\"\"\"\n        if v is not None and \"start_date\" in values:\n            start = values[\"start_date\"]\n            if start > v:\n                raise ValueError(\"End date must be after start date\")\n        return v\n    \n    @validator(\"hourly_rate\", \"fixed_price\", \"estimated_hours\")\n    def validate_positive_numbers(cls, v):\n        \"\"\"Validate that financial amounts are positive numbers.\"\"\"\n        if v is not None and v < 0:\n            raise ValueError(\"Value must be a positive number\")\n        return v",
                "class TimeEntry(BaseModel):\n    \"\"\"\n    Time entry model for tracking hours worked on projects.\n    \n    Used for billing, project profitability analysis, and reporting.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    project_id: str\n    start_time: datetime\n    end_time: Optional[datetime] = None\n    duration_minutes: Optional[float] = None\n    description: str\n    billable: bool = True\n    tags: List[str] = Field(default_factory=list)\n    user_id: Optional[str] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    @validator(\"duration_minutes\", always=True)\n    def calculate_duration(cls, v, values):\n        \"\"\"Calculate duration from start and end time if not provided.\"\"\"\n        if v is not None:\n            return v\n        if (\n            \"start_time\" in values\n            and \"end_time\" in values\n            and values[\"end_time\"] is not None\n        ):\n            delta = values[\"end_time\"] - values[\"start_time\"]\n            return delta.total_seconds() / 60\n        return None\n    \n    @validator(\"end_time\")\n    def validate_end_time(cls, v, values):\n        \"\"\"Validate that end_time is after start_time if both are provided.\"\"\"\n        if v is not None and \"start_time\" in values:\n            if values[\"start_time\"] > v:\n                raise ValueError(\"End time must be after start time\")\n        return v",
                "class Invoice(BaseModel):\n    \"\"\"\n    Invoice model for tracking client billing.\n    \n    Used for revenue tracking, client relationship management, and tax reporting.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    client_id: str\n    project_id: Optional[str] = None\n    issue_date: Union[date, datetime]\n    due_date: Union[date, datetime]\n    amount: float\n    status: str  # e.g., \"draft\", \"sent\", \"paid\", \"overdue\"\n    payment_date: Optional[Union[date, datetime]] = None\n    description: Optional[str] = None\n    line_items: List[Dict[str, Any]] = Field(default_factory=list)\n    \n    @validator(\"due_date\")\n    def validate_due_date(cls, v, values):\n        \"\"\"Validate that due_date is after issue_date.\"\"\"\n        if \"issue_date\" in values:\n            if v < values[\"issue_date\"]:\n                raise ValueError(\"Due date must be after issue date\")\n        return v\n    \n    @validator(\"amount\")\n    def validate_amount(cls, v):\n        \"\"\"Validate that amount is a positive number.\"\"\"\n        if v < 0:\n            raise ValueError(\"Invoice amount must be a positive number\")\n        return v",
                "class ProjectStatus(str, Enum):\n    \"\"\"Status of a project throughout its lifecycle.\"\"\"\n\n    PLANNED = \"planned\"\n    ACTIVE = \"active\"\n    ON_HOLD = \"on_hold\"\n    COMPLETED = \"completed\"\n    CANCELLED = \"cancelled\""
            ]
        }
    },
    "unified/tests/freelancer/project/__init__.py": {
        "logprobs": -192.93023395762,
        "metrics": {
            "loc": 1,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 0,
            "blank": 0,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/ethical_finance/shareholder_advocacy/__init__.py": {
        "logprobs": -197.83749044584496,
        "metrics": {
            "loc": 1,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 0,
            "blank": 0,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/common/core/analysis/financial_projector.py": {
        "logprobs": -2487.8634821334144,
        "metrics": {
            "loc": 543,
            "sloc": 324,
            "lloc": 237,
            "comments": 55,
            "multi": 72,
            "blank": 93,
            "cyclomatic": 70,
            "internal_imports": [
                "class BaseAnalyzer(Generic[T, R], ABC):\n    \"\"\"\n    Abstract base class for analysis engines.\n    \n    Defines the core interface and functionality for all analyzers\n    across different persona implementations.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the analyzer.\"\"\"\n        self._analysis_cache: Dict[str, R] = {}\n    \n    @abstractmethod\n    def analyze(\n        self, subject: T, parameters: Optional[AnalysisParameters] = None\n    ) -> R:\n        \"\"\"\n        Analyze a single subject.\n        \n        Args:\n            subject: The subject to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Analysis result\n        \"\"\"\n        pass\n    \n    def analyze_batch(\n        self, subjects: List[T], parameters: Optional[AnalysisParameters] = None\n    ) -> List[R]:\n        \"\"\"\n        Analyze multiple subjects.\n        \n        Args:\n            subjects: List of subjects to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            List of analysis results\n        \"\"\"\n        # Start performance timer\n        start_time = time.time()\n        \n        # Analyze each subject\n        results = []\n        for subject in subjects:\n            result = self.analyze(subject, parameters)\n            results.append(result)\n        \n        # Performance metrics\n        elapsed_time = time.time() - start_time\n        \n        return results\n    \n    def clear_cache(self) -> None:\n        \"\"\"Clear the analysis cache.\"\"\"\n        self._analysis_cache = {}\n    \n    def _generate_cache_key(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> str:\n        \"\"\"\n        Generate a cache key for a subject and parameters.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cache key string\n        \"\"\"\n        # Start with the subject ID\n        key = f\"subject_{subject_id}\"\n        \n        # Add parameter details if provided\n        if parameters:\n            param_dict = parameters.dict(exclude_none=True)\n            for k, v in sorted(param_dict.items()):\n                if k != \"custom_settings\":\n                    key += f\"_{k}_{v}\"\n                    \n            # Handle custom settings separately (they could be complex)\n            if parameters.custom_settings:\n                for k, v in sorted(parameters.custom_settings.items()):\n                    key += f\"_{k}_{v}\"\n        \n        return key\n    \n    def _get_from_cache(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> Optional[R]:\n        \"\"\"\n        Get a cached analysis result if available.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cached result or None if not found\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        return self._analysis_cache.get(cache_key)\n    \n    def _save_to_cache(\n        self, subject_id: Union[str, UUID], result: R, parameters: Optional[AnalysisParameters] = None\n    ) -> None:\n        \"\"\"\n        Save an analysis result to the cache.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            result: The analysis result to cache\n            parameters: Optional parameters to configure the analysis\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        self._analysis_cache[cache_key] = result",
                "class AnalysisResult(BaseModel, Generic[T]):\n    \"\"\"\n    Result of an analysis operation.\n    \n    Provides information about the analysis process and outcome.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    subject_id: Optional[Union[str, UUID]] = None\n    subject_type: str\n    analysis_type: str\n    analysis_date: datetime = Field(default_factory=datetime.now)\n    processing_time_ms: Optional[float] = None\n    result_summary: Dict[str, Any] = Field(default_factory=dict)\n    detailed_results: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class AnalysisParameters(BaseModel):\n    \"\"\"\n    Parameters for an analysis operation.\n    \n    Used to configure analysis options and settings.\n    \"\"\"\n    \n    period_start: Optional[Union[date, datetime]] = None\n    period_end: Optional[Union[date, datetime]] = None\n    include_details: bool = True\n    calculation_mode: str = \"standard\"  # \"standard\", \"detailed\", \"fast\"\n    grouping: Optional[str] = None\n    custom_settings: Dict[str, Any] = Field(default_factory=dict)",
                "class TimeSeriesData(BaseModel):\n    \"\"\"\n    Model for time series data.\n    \n    Used for storing and manipulating time series data for analysis.\n    \"\"\"\n    \n    dates: List[Union[date, datetime]]\n    values: List[float]\n    labels: Optional[List[str]] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class TimeSeriesAnalyzer:\n    \"\"\"\n    Utility class for analyzing time series data.\n    \n    Provides methods for smoothing, trend detection, and forecasting.\n    \"\"\"\n    \n    @staticmethod\n    def moving_average(\n        data: TimeSeriesData, window_size: int = 3\n    ) -> TimeSeriesData:\n        \"\"\"\n        Calculate the moving average of time series data.\n        \n        Args:\n            data: The time series data\n            window_size: The window size for the moving average\n            \n        Returns:\n            New time series data with smoothed values\n        \"\"\"\n        if not data.values:\n            return TimeSeriesData(dates=[], values=[])\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Calculate the cumulative sum of values\n        cumsum = np.cumsum(values)\n        \n        # Calculate the moving average using the window\n        smoothed = np.zeros_like(values)\n        \n        # Handle the start of the array (where we don't have a full window)\n        for i in range(min(window_size, len(values))):\n            smoothed[i] = cumsum[i] / (i + 1)\n        \n        # Handle the rest of the array\n        for i in range(window_size, len(values)):\n            smoothed[i] = (cumsum[i] - cumsum[i - window_size]) / window_size\n        \n        # Create new time series data with smoothed values\n        return TimeSeriesData(\n            dates=data.dates,\n            values=smoothed.tolist(),\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"smoothing_method\": \"moving_average\",\n                \"window_size\": window_size,\n            },\n        )\n    \n    @staticmethod\n    def exponential_smoothing(\n        data: TimeSeriesData, alpha: float = 0.3\n    ) -> TimeSeriesData:\n        \"\"\"\n        Apply exponential smoothing to time series data.\n        \n        Args:\n            data: The time series data\n            alpha: The smoothing factor (0 < alpha < 1)\n            \n        Returns:\n            New time series data with smoothed values\n        \"\"\"\n        if not data.values:\n            return TimeSeriesData(dates=[], values=[])\n        \n        # Ensure alpha is between 0 and 1\n        alpha = max(0.01, min(0.99, alpha))\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Initialize the smoothed array with the first value\n        smoothed = np.zeros_like(values)\n        smoothed[0] = values[0]\n        \n        # Apply exponential smoothing\n        for i in range(1, len(values)):\n            smoothed[i] = alpha * values[i] + (1 - alpha) * smoothed[i - 1]\n        \n        # Create new time series data with smoothed values\n        return TimeSeriesData(\n            dates=data.dates,\n            values=smoothed.tolist(),\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"smoothing_method\": \"exponential\",\n                \"alpha\": alpha,\n            },\n        )\n    \n    @staticmethod\n    def seasonal_adjustment(\n        data: TimeSeriesData, period: int = 12\n    ) -> TimeSeriesData:\n        \"\"\"\n        Apply seasonal adjustment to time series data.\n        \n        Args:\n            data: The time series data\n            period: The seasonal period (e.g., 12 for monthly data with yearly seasonality)\n            \n        Returns:\n            New time series data with seasonally adjusted values\n        \"\"\"\n        if not data.values or len(data.values) < period * 2:\n            # Not enough data for seasonal adjustment\n            return data\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Calculate the seasonal indices\n        seasonal_indices = np.zeros(period)\n        seasonal_data = []\n        \n        # Organize data by season\n        for i in range(period):\n            seasonal_data.append(values[i::period])\n        \n        # Calculate average for each season\n        for i in range(period):\n            if len(seasonal_data[i]) > 0:\n                seasonal_indices[i] = np.mean(seasonal_data[i])\n        \n        # Normalize the seasonal indices\n        if np.sum(seasonal_indices) > 0:\n            seasonal_indices = seasonal_indices * period / np.sum(seasonal_indices)\n        \n        # Apply the seasonal adjustment\n        adjusted = np.zeros_like(values)\n        for i in range(len(values)):\n            season_idx = i % period\n            if seasonal_indices[season_idx] > 0:\n                adjusted[i] = values[i] / seasonal_indices[season_idx]\n            else:\n                adjusted[i] = values[i]\n        \n        # Create new time series data with adjusted values\n        return TimeSeriesData(\n            dates=data.dates,\n            values=adjusted.tolist(),\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"smoothing_method\": \"seasonal\",\n                \"period\": period,\n                \"seasonal_indices\": seasonal_indices.tolist(),\n            },\n        )\n    \n    @staticmethod\n    def detect_trend(data: TimeSeriesData) -> Dict[str, Any]:\n        \"\"\"\n        Detect trends in time series data.\n        \n        Args:\n            data: The time series data\n            \n        Returns:\n            Dictionary with trend information\n        \"\"\"\n        if not data.values or len(data.values) < 2:\n            return {\n                \"has_trend\": False,\n                \"trend_direction\": \"none\",\n                \"trend_strength\": 0.0,\n            }\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Simple linear regression\n        x = np.arange(len(values))\n        A = np.vstack([x, np.ones(len(x))]).T\n        \n        # Solve for the best fit line\n        try:\n            slope, intercept = np.linalg.lstsq(A, values, rcond=None)[0]\n        except:\n            # Fallback if linear algebra fails\n            slope = 0.0\n            intercept = np.mean(values) if len(values) > 0 else 0.0\n        \n        # Calculate trend strength (R-squared)\n        y_hat = slope * x + intercept\n        ss_total = np.sum((values - np.mean(values)) ** 2)\n        ss_residual = np.sum((values - y_hat) ** 2)\n        r_squared = 1 - (ss_residual / ss_total) if ss_total > 0 else 0.0\n        \n        # Determine trend direction\n        trend_direction = \"up\" if slope > 0 else \"down\" if slope < 0 else \"none\"\n        \n        return {\n            \"has_trend\": abs(slope) > 0.01,\n            \"trend_direction\": trend_direction,\n            \"trend_strength\": r_squared,\n            \"slope\": slope,\n            \"intercept\": intercept,\n        }\n    \n    @staticmethod\n    def extrapolate(\n        data: TimeSeriesData, periods: int = 3, method: str = \"linear\"\n    ) -> TimeSeriesData:\n        \"\"\"\n        Extrapolate time series data into the future.\n        \n        Args:\n            data: The time series data\n            periods: The number of periods to extrapolate\n            method: The extrapolation method (\"linear\", \"mean\", \"last\")\n            \n        Returns:\n            New time series data with extrapolated values\n        \"\"\"\n        if not data.values or periods <= 0:\n            return data\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        dates = data.dates.copy()\n        \n        # Determine the date increment\n        if len(dates) >= 2:\n            if isinstance(dates[0], datetime):\n                # For datetime objects\n                date_diff = dates[1] - dates[0]\n            else:\n                # For date objects\n                date_diff = timedelta(days=(dates[1] - dates[0]).days)\n        else:\n            # Default to daily if we can't determine\n            date_diff = timedelta(days=1)\n        \n        # Extrapolate dates\n        last_date = dates[-1]\n        extrapolated_dates = []\n        \n        for i in range(1, periods + 1):\n            if isinstance(last_date, datetime):\n                next_date = last_date + date_diff * i\n            else:\n                # Convert to datetime for easier arithmetic, then back to date\n                next_date = (datetime.combine(last_date, datetime.min.time()) + date_diff * i).date()\n            \n            extrapolated_dates.append(next_date)\n        \n        # Extrapolate values based on the method\n        extrapolated_values = []\n        \n        if method == \"linear\" and len(values) >= 2:\n            # Simple linear extrapolation\n            trend_info = TimeSeriesAnalyzer.detect_trend(data)\n            slope = trend_info[\"slope\"]\n            intercept = trend_info[\"intercept\"]\n            \n            for i in range(1, periods + 1):\n                next_value = slope * (len(values) + i - 1) + intercept\n                extrapolated_values.append(next_value)\n        \n        elif method == \"mean\" and len(values) > 0:\n            # Use the mean of the last few values\n            window = min(len(values), 3)\n            mean_value = np.mean(values[-window:])\n            \n            for _ in range(periods):\n                extrapolated_values.append(mean_value)\n        \n        else:\n            # Default to using the last value\n            last_value = values[-1] if len(values) > 0 else 0.0\n            \n            for _ in range(periods):\n                extrapolated_values.append(last_value)\n        \n        # Create new time series data with original and extrapolated values\n        return TimeSeriesData(\n            dates=dates + extrapolated_dates,\n            values=values.tolist() + extrapolated_values,\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"extrapolation_method\": method,\n                \"extrapolation_periods\": periods,\n                \"original_length\": len(values),\n            },\n        )\n    \n    @staticmethod\n    def normalize(data: TimeSeriesData) -> TimeSeriesData:\n        \"\"\"\n        Normalize time series data to a 0-1 range.\n        \n        Args:\n            data: The time series data\n            \n        Returns:\n            New time series data with normalized values\n        \"\"\"\n        if not data.values:\n            return TimeSeriesData(dates=[], values=[])\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Calculate min and max\n        min_value = np.min(values)\n        max_value = np.max(values)\n        \n        # Normalize the values\n        if max_value > min_value:\n            normalized = (values - min_value) / (max_value - min_value)\n        else:\n            # If all values are the same, normalize to 0.5\n            normalized = np.full_like(values, 0.5)\n        \n        # Create new time series data with normalized values\n        return TimeSeriesData(\n            dates=data.dates,\n            values=normalized.tolist(),\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"normalization\": True,\n                \"original_min\": float(min_value),\n                \"original_max\": float(max_value),\n            },\n        )\n    \n    @staticmethod\n    def aggregate_by_period(\n        dates: List[Union[date, datetime]],\n        values: List[float],\n        granularity: TimeSeriesGranularity,\n        aggregation_fn: Callable[[List[float]], float] = lambda x: sum(x),\n    ) -> Tuple[List[Union[date, datetime]], List[float]]:\n        \"\"\"\n        Aggregate time series data by a specified granularity.\n        \n        Args:\n            dates: List of dates\n            values: List of values\n            granularity: The desired granularity\n            aggregation_fn: Function to aggregate values within a period\n            \n        Returns:\n            Tuple of (aggregated_dates, aggregated_values)\n        \"\"\"\n        if not dates or not values:\n            return [], []\n        \n        # Combine dates and values for sorting and grouping\n        data = list(zip(dates, values))\n        data.sort(key=lambda x: x[0])  # Sort by date\n        \n        # Group by the specified granularity\n        grouped_data = {}\n        \n        for dt, value in data:\n            # Convert to datetime if it's a date\n            if isinstance(dt, date) and not isinstance(dt, datetime):\n                dt = datetime.combine(dt, datetime.min.time())\n            \n            # Group based on granularity\n            if granularity == TimeSeriesGranularity.DAILY:\n                key = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n            elif granularity == TimeSeriesGranularity.WEEKLY:\n                # Get start of the week (Monday)\n                start_of_week = dt - timedelta(days=dt.weekday())\n                key = start_of_week.replace(hour=0, minute=0, second=0, microsecond=0)\n            elif granularity == TimeSeriesGranularity.MONTHLY:\n                key = dt.replace(day=1, hour=0, minute=0, second=0, microsecond=0)\n            elif granularity == TimeSeriesGranularity.QUARTERLY:\n                quarter = (dt.month - 1) // 3\n                key = dt.replace(month=quarter * 3 + 1, day=1, hour=0, minute=0, second=0, microsecond=0)\n            elif granularity == TimeSeriesGranularity.YEARLY:\n                key = dt.replace(month=1, day=1, hour=0, minute=0, second=0, microsecond=0)\n            else:\n                # Default to daily\n                key = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n            \n            # Add to the group\n            if key in grouped_data:\n                grouped_data[key].append(value)\n            else:\n                grouped_data[key] = [value]\n        \n        # Aggregate values within each group\n        aggregated_data = [\n            (key, aggregation_fn(values)) for key, values in grouped_data.items()\n        ]\n        \n        # Sort by date and separate dates and values\n        aggregated_data.sort(key=lambda x: x[0])\n        \n        # Convert datetime back to date if the input was dates\n        if all(isinstance(dt, date) and not isinstance(dt, datetime) for dt in dates):\n            aggregated_dates = [dt.date() for dt, _ in aggregated_data]\n        else:\n            aggregated_dates = [dt for dt, _ in aggregated_data]\n            \n        aggregated_values = [value for _, value in aggregated_data]\n        \n        return aggregated_dates, aggregated_values"
            ]
        }
    },
    "unified/common/core/reporting/financial_reports.py": {
        "logprobs": -2370.086164285529,
        "metrics": {
            "loc": 770,
            "sloc": 528,
            "lloc": 209,
            "comments": 51,
            "multi": 95,
            "blank": 98,
            "cyclomatic": 107,
            "internal_imports": [
                "class ReportGenerator(ABC):\n    \"\"\"\n    Abstract base class for report generators.\n    \n    Defines the core interface for all report generators\n    across different persona implementations.\n    \"\"\"\n    \n    @abstractmethod\n    def generate(self, data: Any, parameters: ReportParameters) -> Report:\n        \"\"\"\n        Generate a report from the provided data.\n        \n        Args:\n            data: The data to include in the report\n            parameters: Parameters to configure the report\n            \n        Returns:\n            Generated report\n        \"\"\"\n        pass\n    \n    def _format_currency(self, value: float) -> str:\n        \"\"\"\n        Format a value as currency.\n        \n        Args:\n            value: The value to format\n            \n        Returns:\n            Formatted currency string\n        \"\"\"\n        return f\"${value:,.2f}\"\n    \n    def _format_percentage(self, value: float) -> str:\n        \"\"\"\n        Format a value as percentage.\n        \n        Args:\n            value: The value to format\n            \n        Returns:\n            Formatted percentage string\n        \"\"\"\n        return f\"{value * 100:.2f}%\"\n    \n    def _format_date(self, value: Union[date, datetime]) -> str:\n        \"\"\"\n        Format a date value.\n        \n        Args:\n            value: The date to format\n            \n        Returns:\n            Formatted date string\n        \"\"\"\n        if isinstance(value, datetime):\n            return value.strftime(\"%Y-%m-%d %H:%M:%S\")\n        return value.strftime(\"%Y-%m-%d\")\n    \n    def export_as_markdown(self, report: Report) -> str:\n        \"\"\"\n        Export a report as markdown text.\n        \n        Args:\n            report: The report to export\n            \n        Returns:\n            Markdown text representation of the report\n        \"\"\"\n        lines = []\n        \n        # Add title and description\n        lines.append(f\"# {report.title}\")\n        lines.append(\"\")\n        \n        if report.description:\n            lines.append(report.description)\n            lines.append(\"\")\n        \n        # Add period information\n        period_str = f\"Period: {report.period.value.capitalize()}\"\n        if report.start_date and report.end_date:\n            period_str += f\" ({self._format_date(report.start_date)} to {self._format_date(report.end_date)})\"\n        lines.append(period_str)\n        lines.append(f\"Generated: {self._format_date(report.generated_at)}\")\n        lines.append(\"\")\n        \n        # Add sections\n        for section in report.sections:\n            self._append_section_markdown(lines, section, 2)\n        \n        # Add metadata if requested\n        if report.metadata and report.format == ReportFormat.DETAILED:\n            lines.append(\"## Metadata\")\n            lines.append(\"\")\n            for key, value in report.metadata.items():\n                lines.append(f\"- **{key}**: {value}\")\n            lines.append(\"\")\n        \n        return \"\\n\".join(lines)\n    \n    def _append_section_markdown(self, lines: List[str], section: ReportSection, level: int) -> None:\n        \"\"\"\n        Append a section to the markdown lines.\n        \n        Args:\n            lines: The list of markdown lines\n            section: The section to append\n            level: The heading level\n        \"\"\"\n        # Add section title\n        heading = \"#\" * level\n        lines.append(f\"{heading} {section.title}\")\n        lines.append(\"\")\n        \n        # Add section summary\n        if section.summary:\n            lines.append(section.summary)\n            lines.append(\"\")\n        \n        # Add section data as a table if available\n        if section.data:\n            # For simple key-value data\n            if all(not isinstance(v, (dict, list)) for v in section.data.values()):\n                lines.append(\"| Metric | Value |\")\n                lines.append(\"| ------ | ----- |\")\n                for key, value in section.data.items():\n                    formatted_key = key.replace(\"_\", \" \").title()\n                    formatted_value = value\n                    \n                    # Format value based on type\n                    if isinstance(value, float):\n                        if \"percentage\" in key.lower() or \"rate\" in key.lower():\n                            formatted_value = self._format_percentage(value)\n                        elif \"amount\" in key.lower() or \"balance\" in key.lower() or \"value\" in key.lower():\n                            formatted_value = self._format_currency(value)\n                    \n                    lines.append(f\"| {formatted_key} | {formatted_value} |\")\n                lines.append(\"\")\n        \n        # Add charts if available (as descriptions)\n        for chart in section.charts:\n            chart_type = chart.get(\"type\", \"unknown\")\n            chart_title = chart.get(\"title\", \"Chart\")\n            lines.append(f\"*{chart_title} ({chart_type} chart)*\")\n            lines.append(\"\")\n        \n        # Add subsections recursively\n        for subsection in section.subsections:\n            self._append_section_markdown(lines, subsection, level + 1)\n    \n    def export_as_csv(self, report: Report) -> str:\n        \"\"\"\n        Export a report as CSV text.\n        \n        Args:\n            report: The report to export\n            \n        Returns:\n            CSV text representation of the report\n        \"\"\"\n        lines = []\n        \n        # Add header\n        lines.append(f\"# {report.title}\")\n        lines.append(f\"# Period: {report.period.value.capitalize()}\")\n        if report.start_date and report.end_date:\n            lines.append(f\"# From: {self._format_date(report.start_date)} To: {self._format_date(report.end_date)}\")\n        lines.append(f\"# Generated: {self._format_date(report.generated_at)}\")\n        lines.append(\"\")\n        \n        # Add sections\n        for section in report.sections:\n            self._append_section_csv(lines, section)\n        \n        return \"\\n\".join(lines)\n    \n    def _append_section_csv(self, lines: List[str], section: ReportSection) -> None:\n        \"\"\"\n        Append a section to the CSV lines.\n        \n        Args:\n            lines: The list of CSV lines\n            section: The section to append\n        \"\"\"\n        # Add section header\n        lines.append(f\"# {section.title}\")\n        \n        # Add section data\n        if section.data:\n            # For simple key-value data\n            if all(not isinstance(v, (dict, list)) for v in section.data.values()):\n                lines.append(\"Metric,Value\")\n                for key, value in section.data.items():\n                    formatted_key = key.replace(\"_\", \" \").title()\n                    formatted_value = value\n                    \n                    # Format value based on type\n                    if isinstance(value, float):\n                        if \"percentage\" in key.lower() or \"rate\" in key.lower():\n                            formatted_value = f\"{value * 100:.2f}%\"\n                        elif \"amount\" in key.lower() or \"balance\" in key.lower() or \"value\" in key.lower():\n                            formatted_value = f\"{value:.2f}\"\n                    \n                    # Escape commas and quotes in CSV\n                    if isinstance(formatted_value, str) and (\",\" in formatted_value or '\"' in formatted_value):\n                        escaped_value = formatted_value.replace('\"', '\"\"')\n                        formatted_value = f'\"{escaped_value}\"'\n                    \n                    lines.append(f\"{formatted_key},{formatted_value}\")\n        \n        lines.append(\"\")\n        \n        # Add subsections recursively\n        for subsection in section.subsections:\n            self._append_section_csv(lines, subsection)\n    \n    def export_as_json(self, report: Report) -> Dict[str, Any]:\n        \"\"\"\n        Export a report as a JSON-serializable dictionary.\n        \n        Args:\n            report: The report to export\n            \n        Returns:\n            JSON-serializable dictionary representation of the report\n        \"\"\"\n        # Convert to dictionary with datetime formatting\n        report_dict = report.dict()\n        \n        # Format dates for JSON serialization\n        if \"generated_at\" in report_dict:\n            report_dict[\"generated_at\"] = self._format_date(report.generated_at)\n        \n        if \"start_date\" in report_dict and report_dict[\"start_date\"]:\n            report_dict[\"start_date\"] = self._format_date(report.start_date)\n        \n        if \"end_date\" in report_dict and report_dict[\"end_date\"]:\n            report_dict[\"end_date\"] = self._format_date(report.end_date)\n        \n        return report_dict",
                "class ReportParameters(BaseModel):\n    \"\"\"\n    Parameters for report generation.\n    \n    Used to configure report options and settings.\n    \"\"\"\n    \n    period: ReportPeriod = ReportPeriod.MONTHLY\n    start_date: Optional[Union[date, datetime]] = None\n    end_date: Optional[Union[date, datetime]] = None\n    format: ReportFormat = ReportFormat.DETAILED\n    include_metadata: bool = False\n    group_by: Optional[str] = None\n    filters: Dict[str, Any] = Field(default_factory=dict)\n    sort_by: Optional[str] = None\n    sort_direction: str = \"desc\"\n    limit: Optional[int] = None",
                "class ReportFormat(str, Enum):\n    \"\"\"Format options for reports.\"\"\"\n    \n    SUMMARY = \"summary\"\n    DETAILED = \"detailed\"\n    CSV = \"csv\"\n    JSON = \"json\"\n    MARKDOWN = \"markdown\"",
                "class ReportPeriod(str, Enum):\n    \"\"\"Time period options for reports.\"\"\"\n    \n    DAILY = \"daily\"\n    WEEKLY = \"weekly\"\n    MONTHLY = \"monthly\"\n    QUARTERLY = \"quarterly\"\n    YEARLY = \"yearly\"\n    CUSTOM = \"custom\"",
                "class ReportSection(BaseModel):\n    \"\"\"\n    Section of a report.\n    \n    Used to organize report data into logical sections.\n    \"\"\"\n    \n    title: str\n    summary: Optional[str] = None\n    data: Dict[str, Any] = Field(default_factory=dict)\n    charts: List[Dict[str, Any]] = Field(default_factory=list)\n    subsections: List[\"ReportSection\"] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Report(BaseModel):\n    \"\"\"\n    Report model for organizing and presenting analysis results.\n    \n    Used for generating structured reports from analysis data.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    title: str\n    description: Optional[str] = None\n    generated_at: datetime = Field(default_factory=datetime.now)\n    period: ReportPeriod\n    start_date: Optional[Union[date, datetime]] = None\n    end_date: Optional[Union[date, datetime]] = None\n    format: ReportFormat\n    sections: List[ReportSection] = Field(default_factory=list)\n    metadata: Dict[str, Any] = Field(default_factory=dict)",
                "class TimeSeriesData(BaseModel):\n    \"\"\"\n    Model for time series data.\n    \n    Used for storing and manipulating time series data for analysis.\n    \"\"\"\n    \n    dates: List[Union[date, datetime]]\n    values: List[float]\n    labels: Optional[List[str]] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class PortfolioAnalysisResult(AnalysisResult):\n    \"\"\"\n    Result of a portfolio analysis operation.\n    \n    Provides detailed information about portfolio composition and performance.\n    \"\"\"\n    \n    breakdown: PortfolioBreakdown\n    performance: Optional[PortfolioPerformance] = None\n    esg_metrics: Optional[PortfolioESGMetrics] = None\n    diversification_score: float\n    risk_exposure: Dict[str, float] = Field(default_factory=dict)\n    recommendations: List[str] = Field(default_factory=list)",
                "class PortfolioPerformance(BaseModel):\n    \"\"\"\n    Performance metrics for a portfolio.\n    \n    Used for analyzing historical and risk-adjusted returns.\n    \"\"\"\n    \n    total_return: float\n    annualized_return: float\n    volatility: float\n    sharpe_ratio: float\n    max_drawdown: float\n    alpha: Optional[float] = None\n    beta: Optional[float] = None\n    correlation_to_benchmark: Optional[float] = None",
                "class PortfolioESGMetrics(BaseModel):\n    \"\"\"\n    ESG metrics for a portfolio.\n    \n    Used for analyzing environmental, social, and governance characteristics.\n    \"\"\"\n    \n    overall_esg_score: float\n    environmental_score: float\n    social_score: float\n    governance_score: float\n    carbon_footprint: float\n    renewable_energy_exposure: float\n    diversity_score: float\n    controversy_exposure: float\n    impact_metrics: Dict[str, float] = Field(default_factory=dict)",
                "class ProjectionResult(AnalysisResult):\n    \"\"\"\n    Result of a financial projection analysis.\n    \n    Provides projected financial states across different scenarios.\n    \"\"\"\n    \n    baseline: Projection\n    optimistic: Optional[Projection] = None\n    conservative: Optional[Projection] = None\n    stress_test: Optional[Projection] = None\n    recommended_actions: List[str] = Field(default_factory=list)",
                "class Projection(BaseModel):\n    \"\"\"\n    Financial projection model.\n    \n    Used for forecasting future financial states based on different scenarios.\n    \"\"\"\n    \n    scenario: ProjectionScenario\n    start_date: Union[date, datetime]\n    end_date: Union[date, datetime]\n    starting_balance: float\n    cash_flows: List[CashFlow] = Field(default_factory=list)\n    final_balance: float\n    lowest_balance: float\n    highest_balance: float\n    runway_months: Optional[float] = None\n    emergency_fund_status: str = \"insufficient\"\n    tax_liability: Dict[str, float] = Field(default_factory=dict)\n    confidence_level: float = 0.8\n    metadata: Dict[str, Any] = Field(default_factory=dict)"
            ]
        }
    },
    "unified/personal_finance_tracker/__init__.py": {
        "logprobs": -253.5306998395016,
        "metrics": {
            "loc": 7,
            "sloc": 1,
            "lloc": 2,
            "comments": 0,
            "multi": 4,
            "blank": 2,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/ethical_finance/ethical_screening/__init__.py": {
        "logprobs": -184.54253339285737,
        "metrics": {
            "loc": 1,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 0,
            "blank": 0,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/ethical_finance/shareholder_advocacy/advocacy.py": {
        "logprobs": -2874.3416837144146,
        "metrics": {
            "loc": 692,
            "sloc": 447,
            "lloc": 335,
            "comments": 75,
            "multi": 60,
            "blank": 114,
            "cyclomatic": 151,
            "internal_imports": [
                "class BaseAnalyzer(Generic[T, R], ABC):\n    \"\"\"\n    Abstract base class for analysis engines.\n    \n    Defines the core interface and functionality for all analyzers\n    across different persona implementations.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the analyzer.\"\"\"\n        self._analysis_cache: Dict[str, R] = {}\n    \n    @abstractmethod\n    def analyze(\n        self, subject: T, parameters: Optional[AnalysisParameters] = None\n    ) -> R:\n        \"\"\"\n        Analyze a single subject.\n        \n        Args:\n            subject: The subject to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Analysis result\n        \"\"\"\n        pass\n    \n    def analyze_batch(\n        self, subjects: List[T], parameters: Optional[AnalysisParameters] = None\n    ) -> List[R]:\n        \"\"\"\n        Analyze multiple subjects.\n        \n        Args:\n            subjects: List of subjects to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            List of analysis results\n        \"\"\"\n        # Start performance timer\n        start_time = time.time()\n        \n        # Analyze each subject\n        results = []\n        for subject in subjects:\n            result = self.analyze(subject, parameters)\n            results.append(result)\n        \n        # Performance metrics\n        elapsed_time = time.time() - start_time\n        \n        return results\n    \n    def clear_cache(self) -> None:\n        \"\"\"Clear the analysis cache.\"\"\"\n        self._analysis_cache = {}\n    \n    def _generate_cache_key(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> str:\n        \"\"\"\n        Generate a cache key for a subject and parameters.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cache key string\n        \"\"\"\n        # Start with the subject ID\n        key = f\"subject_{subject_id}\"\n        \n        # Add parameter details if provided\n        if parameters:\n            param_dict = parameters.dict(exclude_none=True)\n            for k, v in sorted(param_dict.items()):\n                if k != \"custom_settings\":\n                    key += f\"_{k}_{v}\"\n                    \n            # Handle custom settings separately (they could be complex)\n            if parameters.custom_settings:\n                for k, v in sorted(parameters.custom_settings.items()):\n                    key += f\"_{k}_{v}\"\n        \n        return key\n    \n    def _get_from_cache(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> Optional[R]:\n        \"\"\"\n        Get a cached analysis result if available.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cached result or None if not found\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        return self._analysis_cache.get(cache_key)\n    \n    def _save_to_cache(\n        self, subject_id: Union[str, UUID], result: R, parameters: Optional[AnalysisParameters] = None\n    ) -> None:\n        \"\"\"\n        Save an analysis result to the cache.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            result: The analysis result to cache\n            parameters: Optional parameters to configure the analysis\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        self._analysis_cache[cache_key] = result",
                "class AnalysisParameters(BaseModel):\n    \"\"\"\n    Parameters for an analysis operation.\n    \n    Used to configure analysis options and settings.\n    \"\"\"\n    \n    period_start: Optional[Union[date, datetime]] = None\n    period_end: Optional[Union[date, datetime]] = None\n    include_details: bool = True\n    calculation_mode: str = \"standard\"  # \"standard\", \"detailed\", \"fast\"\n    grouping: Optional[str] = None\n    custom_settings: Dict[str, Any] = Field(default_factory=dict)",
                "class AnalysisResult(BaseModel, Generic[T]):\n    \"\"\"\n    Result of an analysis operation.\n    \n    Provides information about the analysis process and outcome.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    subject_id: Optional[Union[str, UUID]] = None\n    subject_type: str\n    analysis_type: str\n    analysis_date: datetime = Field(default_factory=datetime.now)\n    processing_time_ms: Optional[float] = None\n    result_summary: Dict[str, Any] = Field(default_factory=dict)\n    detailed_results: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Timer:\n    \"\"\"Utility for measuring execution time.\"\"\"\n    \n    def __init__(self, name: Optional[str] = None):\n        \"\"\"\n        Initialize the timer.\n        \n        Args:\n            name: Optional name for the timer\n        \"\"\"\n        self.name = name\n        self.start_time: Optional[float] = None\n        self.end_time: Optional[float] = None\n    \n    def __enter__(self) -> 'Timer':\n        \"\"\"Start the timer when entering a context.\"\"\"\n        self.start()\n        return self\n    \n    def __exit__(self, *args: Any) -> None:\n        \"\"\"Stop the timer when exiting a context.\"\"\"\n        self.stop()\n    \n    def start(self) -> None:\n        \"\"\"Start the timer.\"\"\"\n        self.start_time = time.time()\n        self.end_time = None\n    \n    def stop(self) -> float:\n        \"\"\"\n        Stop the timer.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        self.end_time = time.time()\n        return self.elapsed_time\n    \n    @property\n    def elapsed_time(self) -> float:\n        \"\"\"\n        Get the elapsed time.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        end = self.end_time if self.end_time is not None else time.time()\n        return end - self.start_time\n    \n    @property\n    def elapsed_milliseconds(self) -> float:\n        \"\"\"\n        Get the elapsed time in milliseconds.\n        \n        Returns:\n            Elapsed time in milliseconds\n        \"\"\"\n        return self.elapsed_time * 1000",
                "def memoize(func: F = None, *, max_size: int = 1000, ttl_seconds: Optional[int] = None) -> F:\n    \"\"\"\n    Decorator to memoize a function's return value with optional max size and TTL.\n    \n    Can be used with or without arguments:\n    @memoize  # No arguments\n    def func():\n        ...\n        \n    @memoize(max_size=100, ttl_seconds=3600)  # With arguments\n    def func():\n        ...\n    \n    Args:\n        func: The function to memoize (when used without arguments)\n        max_size: Maximum number of items to store in cache (default: 1000)\n        ttl_seconds: Time-to-live in seconds (default: None, meaning no expiration)\n        \n    Returns:\n        Memoized function\n    \"\"\"\n    def decorator(f: F) -> F:\n        # Cache stores tuples of (result, timestamp) if TTL is specified, otherwise just result\n        cache: Dict[str, Union[Any, Tuple[Any, float]]] = {}\n        \n        @functools.wraps(f)\n        def wrapper(*args: Any, **kwargs: Any) -> Any:\n            # Create a cache key from the function arguments\n            key = _create_cache_key(f, args, kwargs)\n            \n            # Check if we need to enforce max size\n            if len(cache) >= max_size and key not in cache:\n                # Remove oldest item (simple implementation)\n                if ttl_seconds is not None:\n                    # If using TTL, find oldest by timestamp\n                    oldest_key = min(cache.items(), key=lambda x: x[1][1])[0]\n                else:\n                    # Otherwise just remove the first key\n                    oldest_key = next(iter(cache))\n                del cache[oldest_key]\n            \n            # Check if result is in cache\n            if key in cache:\n                if ttl_seconds is not None:\n                    # Check if expired when using TTL\n                    result, timestamp = cache[key]  # type: ignore\n                    if time.time() - timestamp < ttl_seconds:\n                        return result\n                    # If expired, remove from cache and recalculate\n                else:\n                    # No TTL, just return cached result\n                    return cache[key]\n            \n            # Call the function and cache the result\n            result = f(*args, **kwargs)\n            \n            if ttl_seconds is not None:\n                # Store with timestamp if using TTL\n                cache[key] = (result, time.time())\n            else:\n                # Store just the result otherwise\n                cache[key] = result\n            \n            return result\n        \n        # Add cache management functions\n        wrapper.cache = cache  # type: ignore\n        wrapper.cache_clear = cache.clear  # type: ignore\n        wrapper.cache_size = lambda: len(cache)  # type: ignore\n        \n        return cast(F, wrapper)\n    \n    # Handle both @memoize and @memoize(args) syntax\n    if func is None:\n        return decorator\n    return decorator(func)",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Portfolio(BasePortfolio):\n    \"\"\"A collection of investment holdings.\"\"\"\n    \n    # These fields come from BasePortfolio:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # holdings: List[InvestmentHolding] = Field(default_factory=list)\n    # total_value: float\n    # cash_balance: float\n    # creation_date: Union[date, datetime]\n    # last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Portfolio(BasePortfolio):\n    \"\"\"A collection of investment holdings.\"\"\"\n    \n    # These fields come from BasePortfolio:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # holdings: List[InvestmentHolding] = Field(default_factory=list)\n    # total_value: float\n    # cash_balance: float\n    # creation_date: Union[date, datetime]\n    # last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Portfolio(BasePortfolio):\n    \"\"\"A collection of investment holdings.\"\"\"\n    \n    # These fields come from BasePortfolio:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # holdings: List[InvestmentHolding] = Field(default_factory=list)\n    # total_value: float\n    # cash_balance: float\n    # creation_date: Union[date, datetime]\n    # last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Portfolio(BasePortfolio):\n    \"\"\"A collection of investment holdings.\"\"\"\n    \n    # These fields come from BasePortfolio:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # holdings: List[InvestmentHolding] = Field(default_factory=list)\n    # total_value: float\n    # cash_balance: float\n    # creation_date: Union[date, datetime]\n    # last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Portfolio(BasePortfolio):\n    \"\"\"A collection of investment holdings.\"\"\"\n    \n    # These fields come from BasePortfolio:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # holdings: List[InvestmentHolding] = Field(default_factory=list)\n    # total_value: float\n    # cash_balance: float\n    # creation_date: Union[date, datetime]\n    # last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Portfolio(BasePortfolio):\n    \"\"\"A collection of investment holdings.\"\"\"\n    \n    # These fields come from BasePortfolio:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # holdings: List[InvestmentHolding] = Field(default_factory=list)\n    # total_value: float\n    # cash_balance: float\n    # creation_date: Union[date, datetime]\n    # last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class ShareholderResolution(BaseModel):\n    \"\"\"Model representing a shareholder resolution with voting results.\"\"\"\n    \n    company_id: str\n    resolution_id: str\n    year: int\n    title: str\n    category: str\n    subcategory: str\n    proposed_by: str\n    status: str\n    votes_for: Optional[float] = None\n    votes_against: Optional[float] = None\n    abstentions: Optional[float] = None\n    company_recommendation: Optional[str] = None\n    outcome: Optional[str] = None\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class ShareholderResolution(BaseModel):\n    \"\"\"Model representing a shareholder resolution with voting results.\"\"\"\n    \n    company_id: str\n    resolution_id: str\n    year: int\n    title: str\n    category: str\n    subcategory: str\n    proposed_by: str\n    status: str\n    votes_for: Optional[float] = None\n    votes_against: Optional[float] = None\n    abstentions: Optional[float] = None\n    company_recommendation: Optional[str] = None\n    outcome: Optional[str] = None\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class ShareholderResolution(BaseModel):\n    \"\"\"Model representing a shareholder resolution with voting results.\"\"\"\n    \n    company_id: str\n    resolution_id: str\n    year: int\n    title: str\n    category: str\n    subcategory: str\n    proposed_by: str\n    status: str\n    votes_for: Optional[float] = None\n    votes_against: Optional[float] = None\n    abstentions: Optional[float] = None\n    company_recommendation: Optional[str] = None\n    outcome: Optional[str] = None\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class ShareholderResolution(BaseModel):\n    \"\"\"Model representing a shareholder resolution with voting results.\"\"\"\n    \n    company_id: str\n    resolution_id: str\n    year: int\n    title: str\n    category: str\n    subcategory: str\n    proposed_by: str\n    status: str\n    votes_for: Optional[float] = None\n    votes_against: Optional[float] = None\n    abstentions: Optional[float] = None\n    company_recommendation: Optional[str] = None\n    outcome: Optional[str] = None\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class ShareholderResolution(BaseModel):\n    \"\"\"Model representing a shareholder resolution with voting results.\"\"\"\n    \n    company_id: str\n    resolution_id: str\n    year: int\n    title: str\n    category: str\n    subcategory: str\n    proposed_by: str\n    status: str\n    votes_for: Optional[float] = None\n    votes_against: Optional[float] = None\n    abstentions: Optional[float] = None\n    company_recommendation: Optional[str] = None\n    outcome: Optional[str] = None\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class ShareholderResolution(BaseModel):\n    \"\"\"Model representing a shareholder resolution with voting results.\"\"\"\n    \n    company_id: str\n    resolution_id: str\n    year: int\n    title: str\n    category: str\n    subcategory: str\n    proposed_by: str\n    status: str\n    votes_for: Optional[float] = None\n    votes_against: Optional[float] = None\n    abstentions: Optional[float] = None\n    company_recommendation: Optional[str] = None\n    outcome: Optional[str] = None\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True"
            ]
        }
    },
    "unified/common/core/categorization/categorizer.py": {
        "logprobs": -895.142343130055,
        "metrics": {
            "loc": 258,
            "sloc": 102,
            "lloc": 121,
            "comments": 19,
            "multi": 74,
            "blank": 60,
            "cyclomatic": 25,
            "internal_imports": [
                "class Rule(BaseModel, ABC):\n    \"\"\"\n    Abstract base class for categorization rules.\n    \n    Defines the interface for all rules used in categorization\n    across different persona implementations.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    description: Optional[str] = None\n    priority: int = 0  # Higher numbers have higher priority\n    created_at: datetime = Field(default_factory=datetime.now)\n    updated_at: datetime = Field(default_factory=datetime.now)\n    is_active: bool = True\n    \n    @abstractmethod\n    def matches(self, item: Any) -> bool:\n        \"\"\"\n        Check if this rule matches the given item.\n        \n        Args:\n            item: The item to check against this rule\n            \n        Returns:\n            True if the rule matches, False otherwise\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def apply(self, item: Any) -> Any:\n        \"\"\"\n        Apply this rule to the given item.\n        \n        Args:\n            item: The item to apply this rule to\n            \n        Returns:\n            The result of applying the rule\n        \"\"\"\n        pass\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True"
            ]
        }
    },
    "unified/common/core/categorization/rule.py": {
        "logprobs": -986.0485368869753,
        "metrics": {
            "loc": 283,
            "sloc": 116,
            "lloc": 154,
            "comments": 18,
            "multi": 84,
            "blank": 70,
            "cyclomatic": 75,
            "internal_imports": [
                "class BaseTransaction(BaseModel):\n    \"\"\"\n    Base transaction model for all financial transactions.\n    \n    This abstract base class provides common fields for tracking\n    financial transactions across different persona implementations.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    date: Union[date, datetime]\n    amount: float\n    description: str\n    transaction_type: TransactionType\n    \n    # Optional fields\n    account_id: Optional[str] = None\n    category: Optional[str] = None\n    tags: List[str] = Field(default_factory=list)\n    notes: Optional[str] = None\n    \n    @validator(\"amount\")\n    def validate_amount(cls, v):\n        \"\"\"Validate that amount is a valid number.\"\"\"\n        if not isinstance(v, (int, float)):\n            raise ValueError(\"Amount must be a number\")\n        return v"
            ]
        }
    },
    "unified/ethical_finance/impact_measurement/__init__.py": {
        "logprobs": -208.97782373905804,
        "metrics": {
            "loc": 1,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 0,
            "blank": 0,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/common/core/reporting/__init__.py": {
        "logprobs": -340.6700688696497,
        "metrics": {
            "loc": 31,
            "sloc": 26,
            "lloc": 4,
            "comments": 2,
            "multi": 0,
            "blank": 4,
            "cyclomatic": 0,
            "internal_imports": [
                "class ReportFormat(str, Enum):\n    \"\"\"Format options for reports.\"\"\"\n    \n    SUMMARY = \"summary\"\n    DETAILED = \"detailed\"\n    CSV = \"csv\"\n    JSON = \"json\"\n    MARKDOWN = \"markdown\"",
                "class ReportPeriod(str, Enum):\n    \"\"\"Time period options for reports.\"\"\"\n    \n    DAILY = \"daily\"\n    WEEKLY = \"weekly\"\n    MONTHLY = \"monthly\"\n    QUARTERLY = \"quarterly\"\n    YEARLY = \"yearly\"\n    CUSTOM = \"custom\"",
                "class ReportParameters(BaseModel):\n    \"\"\"\n    Parameters for report generation.\n    \n    Used to configure report options and settings.\n    \"\"\"\n    \n    period: ReportPeriod = ReportPeriod.MONTHLY\n    start_date: Optional[Union[date, datetime]] = None\n    end_date: Optional[Union[date, datetime]] = None\n    format: ReportFormat = ReportFormat.DETAILED\n    include_metadata: bool = False\n    group_by: Optional[str] = None\n    filters: Dict[str, Any] = Field(default_factory=dict)\n    sort_by: Optional[str] = None\n    sort_direction: str = \"desc\"\n    limit: Optional[int] = None",
                "class ReportSection(BaseModel):\n    \"\"\"\n    Section of a report.\n    \n    Used to organize report data into logical sections.\n    \"\"\"\n    \n    title: str\n    summary: Optional[str] = None\n    data: Dict[str, Any] = Field(default_factory=dict)\n    charts: List[Dict[str, Any]] = Field(default_factory=list)\n    subsections: List[\"ReportSection\"] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Report(BaseModel):\n    \"\"\"\n    Report model for organizing and presenting analysis results.\n    \n    Used for generating structured reports from analysis data.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    title: str\n    description: Optional[str] = None\n    generated_at: datetime = Field(default_factory=datetime.now)\n    period: ReportPeriod\n    start_date: Optional[Union[date, datetime]] = None\n    end_date: Optional[Union[date, datetime]] = None\n    format: ReportFormat\n    sections: List[ReportSection] = Field(default_factory=list)\n    metadata: Dict[str, Any] = Field(default_factory=dict)",
                "class ReportGenerator(ABC):\n    \"\"\"\n    Abstract base class for report generators.\n    \n    Defines the core interface for all report generators\n    across different persona implementations.\n    \"\"\"\n    \n    @abstractmethod\n    def generate(self, data: Any, parameters: ReportParameters) -> Report:\n        \"\"\"\n        Generate a report from the provided data.\n        \n        Args:\n            data: The data to include in the report\n            parameters: Parameters to configure the report\n            \n        Returns:\n            Generated report\n        \"\"\"\n        pass\n    \n    def _format_currency(self, value: float) -> str:\n        \"\"\"\n        Format a value as currency.\n        \n        Args:\n            value: The value to format\n            \n        Returns:\n            Formatted currency string\n        \"\"\"\n        return f\"${value:,.2f}\"\n    \n    def _format_percentage(self, value: float) -> str:\n        \"\"\"\n        Format a value as percentage.\n        \n        Args:\n            value: The value to format\n            \n        Returns:\n            Formatted percentage string\n        \"\"\"\n        return f\"{value * 100:.2f}%\"\n    \n    def _format_date(self, value: Union[date, datetime]) -> str:\n        \"\"\"\n        Format a date value.\n        \n        Args:\n            value: The date to format\n            \n        Returns:\n            Formatted date string\n        \"\"\"\n        if isinstance(value, datetime):\n            return value.strftime(\"%Y-%m-%d %H:%M:%S\")\n        return value.strftime(\"%Y-%m-%d\")\n    \n    def export_as_markdown(self, report: Report) -> str:\n        \"\"\"\n        Export a report as markdown text.\n        \n        Args:\n            report: The report to export\n            \n        Returns:\n            Markdown text representation of the report\n        \"\"\"\n        lines = []\n        \n        # Add title and description\n        lines.append(f\"# {report.title}\")\n        lines.append(\"\")\n        \n        if report.description:\n            lines.append(report.description)\n            lines.append(\"\")\n        \n        # Add period information\n        period_str = f\"Period: {report.period.value.capitalize()}\"\n        if report.start_date and report.end_date:\n            period_str += f\" ({self._format_date(report.start_date)} to {self._format_date(report.end_date)})\"\n        lines.append(period_str)\n        lines.append(f\"Generated: {self._format_date(report.generated_at)}\")\n        lines.append(\"\")\n        \n        # Add sections\n        for section in report.sections:\n            self._append_section_markdown(lines, section, 2)\n        \n        # Add metadata if requested\n        if report.metadata and report.format == ReportFormat.DETAILED:\n            lines.append(\"## Metadata\")\n            lines.append(\"\")\n            for key, value in report.metadata.items():\n                lines.append(f\"- **{key}**: {value}\")\n            lines.append(\"\")\n        \n        return \"\\n\".join(lines)\n    \n    def _append_section_markdown(self, lines: List[str], section: ReportSection, level: int) -> None:\n        \"\"\"\n        Append a section to the markdown lines.\n        \n        Args:\n            lines: The list of markdown lines\n            section: The section to append\n            level: The heading level\n        \"\"\"\n        # Add section title\n        heading = \"#\" * level\n        lines.append(f\"{heading} {section.title}\")\n        lines.append(\"\")\n        \n        # Add section summary\n        if section.summary:\n            lines.append(section.summary)\n            lines.append(\"\")\n        \n        # Add section data as a table if available\n        if section.data:\n            # For simple key-value data\n            if all(not isinstance(v, (dict, list)) for v in section.data.values()):\n                lines.append(\"| Metric | Value |\")\n                lines.append(\"| ------ | ----- |\")\n                for key, value in section.data.items():\n                    formatted_key = key.replace(\"_\", \" \").title()\n                    formatted_value = value\n                    \n                    # Format value based on type\n                    if isinstance(value, float):\n                        if \"percentage\" in key.lower() or \"rate\" in key.lower():\n                            formatted_value = self._format_percentage(value)\n                        elif \"amount\" in key.lower() or \"balance\" in key.lower() or \"value\" in key.lower():\n                            formatted_value = self._format_currency(value)\n                    \n                    lines.append(f\"| {formatted_key} | {formatted_value} |\")\n                lines.append(\"\")\n        \n        # Add charts if available (as descriptions)\n        for chart in section.charts:\n            chart_type = chart.get(\"type\", \"unknown\")\n            chart_title = chart.get(\"title\", \"Chart\")\n            lines.append(f\"*{chart_title} ({chart_type} chart)*\")\n            lines.append(\"\")\n        \n        # Add subsections recursively\n        for subsection in section.subsections:\n            self._append_section_markdown(lines, subsection, level + 1)\n    \n    def export_as_csv(self, report: Report) -> str:\n        \"\"\"\n        Export a report as CSV text.\n        \n        Args:\n            report: The report to export\n            \n        Returns:\n            CSV text representation of the report\n        \"\"\"\n        lines = []\n        \n        # Add header\n        lines.append(f\"# {report.title}\")\n        lines.append(f\"# Period: {report.period.value.capitalize()}\")\n        if report.start_date and report.end_date:\n            lines.append(f\"# From: {self._format_date(report.start_date)} To: {self._format_date(report.end_date)}\")\n        lines.append(f\"# Generated: {self._format_date(report.generated_at)}\")\n        lines.append(\"\")\n        \n        # Add sections\n        for section in report.sections:\n            self._append_section_csv(lines, section)\n        \n        return \"\\n\".join(lines)\n    \n    def _append_section_csv(self, lines: List[str], section: ReportSection) -> None:\n        \"\"\"\n        Append a section to the CSV lines.\n        \n        Args:\n            lines: The list of CSV lines\n            section: The section to append\n        \"\"\"\n        # Add section header\n        lines.append(f\"# {section.title}\")\n        \n        # Add section data\n        if section.data:\n            # For simple key-value data\n            if all(not isinstance(v, (dict, list)) for v in section.data.values()):\n                lines.append(\"Metric,Value\")\n                for key, value in section.data.items():\n                    formatted_key = key.replace(\"_\", \" \").title()\n                    formatted_value = value\n                    \n                    # Format value based on type\n                    if isinstance(value, float):\n                        if \"percentage\" in key.lower() or \"rate\" in key.lower():\n                            formatted_value = f\"{value * 100:.2f}%\"\n                        elif \"amount\" in key.lower() or \"balance\" in key.lower() or \"value\" in key.lower():\n                            formatted_value = f\"{value:.2f}\"\n                    \n                    # Escape commas and quotes in CSV\n                    if isinstance(formatted_value, str) and (\",\" in formatted_value or '\"' in formatted_value):\n                        escaped_value = formatted_value.replace('\"', '\"\"')\n                        formatted_value = f'\"{escaped_value}\"'\n                    \n                    lines.append(f\"{formatted_key},{formatted_value}\")\n        \n        lines.append(\"\")\n        \n        # Add subsections recursively\n        for subsection in section.subsections:\n            self._append_section_csv(lines, subsection)\n    \n    def export_as_json(self, report: Report) -> Dict[str, Any]:\n        \"\"\"\n        Export a report as a JSON-serializable dictionary.\n        \n        Args:\n            report: The report to export\n            \n        Returns:\n            JSON-serializable dictionary representation of the report\n        \"\"\"\n        # Convert to dictionary with datetime formatting\n        report_dict = report.dict()\n        \n        # Format dates for JSON serialization\n        if \"generated_at\" in report_dict:\n            report_dict[\"generated_at\"] = self._format_date(report.generated_at)\n        \n        if \"start_date\" in report_dict and report_dict[\"start_date\"]:\n            report_dict[\"start_date\"] = self._format_date(report.start_date)\n        \n        if \"end_date\" in report_dict and report_dict[\"end_date\"]:\n            report_dict[\"end_date\"] = self._format_date(report.end_date)\n        \n        return report_dict",
                "class TransactionSummaryGenerator(ReportGenerator):\n    \"\"\"\n    Report generator for transaction summaries.\n    \n    Used for generating reports about financial transactions.\n    \"\"\"\n    \n    def generate(\n        self, data: Dict[str, Any], parameters: ReportParameters\n    ) -> Report:\n        \"\"\"\n        Generate a transaction summary report.\n        \n        Args:\n            data: Transaction data to include in the report\n            parameters: Parameters to configure the report\n            \n        Returns:\n            Transaction summary report\n        \"\"\"\n        # Extract transactions and metadata\n        transactions = data.get(\"transactions\", [])\n        categories = data.get(\"categories\", {})\n        date_range = (\n            parameters.start_date or date.today(),\n            parameters.end_date or date.today(),\n        )\n        \n        # Create the report\n        report = Report(\n            title=\"Transaction Summary Report\",\n            description=f\"Summary of transactions for the selected period\",\n            period=parameters.period,\n            start_date=date_range[0],\n            end_date=date_range[1],\n            format=parameters.format,\n            metadata={\n                \"transaction_count\": len(transactions),\n                \"filters_applied\": parameters.filters,\n            },\n        )\n        \n        # Generate overview section\n        overview_section = self._generate_overview_section(transactions)\n        report.sections.append(overview_section)\n        \n        # Generate category breakdown section\n        if categories:\n            category_section = self._generate_category_section(transactions, categories)\n            report.sections.append(category_section)\n        \n        # Generate time analysis section\n        time_section = self._generate_time_section(transactions, parameters.period)\n        report.sections.append(time_section)\n        \n        return report\n    \n    def _generate_overview_section(self, transactions: List[Dict[str, Any]]) -> ReportSection:\n        \"\"\"\n        Generate the overview section of the report.\n        \n        Args:\n            transactions: List of transactions\n            \n        Returns:\n            Overview report section\n        \"\"\"\n        # Calculate key metrics\n        total_income = sum(\n            t[\"amount\"] for t in transactions if t.get(\"transaction_type\") == \"income\"\n        )\n        total_expenses = sum(\n            t[\"amount\"] for t in transactions if t.get(\"transaction_type\") == \"expense\"\n        )\n        net_cash_flow = total_income - total_expenses\n        largest_transaction = max(transactions, key=lambda t: t[\"amount\"], default={})\n        \n        # Create the section\n        return ReportSection(\n            title=\"Financial Overview\",\n            summary=\"Summary of key financial metrics for the period\",\n            data={\n                \"total_income\": total_income,\n                \"total_expenses\": total_expenses,\n                \"net_cash_flow\": net_cash_flow,\n                \"transaction_count\": len(transactions),\n                \"average_transaction\": sum(t[\"amount\"] for t in transactions) / len(transactions) if transactions else 0,\n                \"largest_transaction_amount\": largest_transaction.get(\"amount\", 0),\n                \"largest_transaction_description\": largest_transaction.get(\"description\", \"N/A\"),\n            },\n            charts=[\n                {\n                    \"type\": \"pie\",\n                    \"title\": \"Income vs Expenses\",\n                    \"data\": {\n                        \"Income\": total_income,\n                        \"Expenses\": total_expenses,\n                    },\n                },\n            ],\n        )\n    \n    def _generate_category_section(\n        self, transactions: List[Dict[str, Any]], categories: Dict[str, Any]\n    ) -> ReportSection:\n        \"\"\"\n        Generate the category breakdown section of the report.\n        \n        Args:\n            transactions: List of transactions\n            categories: Category information\n            \n        Returns:\n            Category breakdown report section\n        \"\"\"\n        # Calculate spending by category\n        spending_by_category = {}\n        for transaction in transactions:\n            if transaction.get(\"transaction_type\") == \"expense\":\n                category = transaction.get(\"category\", \"Uncategorized\")\n                if category not in spending_by_category:\n                    spending_by_category[category] = 0\n                spending_by_category[category] += transaction[\"amount\"]\n        \n        # Sort categories by amount (descending)\n        sorted_categories = sorted(\n            spending_by_category.items(), key=lambda x: x[1], reverse=True\n        )\n        \n        # Create subsections for top categories\n        category_subsections = []\n        for category, amount in sorted_categories[:5]:  # Top 5 categories\n            category_data = categories.get(category, {})\n            \n            # Get transactions for this category\n            category_transactions = [\n                t for t in transactions\n                if t.get(\"category\") == category and t.get(\"transaction_type\") == \"expense\"\n            ]\n            \n            # Calculate metrics\n            transaction_count = len(category_transactions)\n            average_amount = amount / transaction_count if transaction_count > 0 else 0\n            \n            category_subsections.append(\n                ReportSection(\n                    title=f\"{category}\",\n                    data={\n                        \"total_amount\": amount,\n                        \"transaction_count\": transaction_count,\n                        \"average_transaction\": average_amount,\n                        \"percentage_of_expenses\": amount / sum(spending_by_category.values()) if spending_by_category else 0,\n                        \"is_business\": category_data.get(\"is_business\", False),\n                    },\n                )\n            )\n        \n        # Create the main category section\n        return ReportSection(\n            title=\"Expense Categories\",\n            summary=\"Breakdown of expenses by category\",\n            data={\n                \"top_category\": sorted_categories[0][0] if sorted_categories else \"None\",\n                \"top_category_amount\": sorted_categories[0][1] if sorted_categories else 0,\n                \"category_count\": len(spending_by_category),\n            },\n            charts=[\n                {\n                    \"type\": \"bar\",\n                    \"title\": \"Expenses by Category\",\n                    \"data\": dict(sorted_categories),\n                },\n            ],\n            subsections=category_subsections,\n        )\n    \n    def _generate_time_section(\n        self, transactions: List[Dict[str, Any]], period: ReportPeriod\n    ) -> ReportSection:\n        \"\"\"\n        Generate the time analysis section of the report.\n        \n        Args:\n            transactions: List of transactions\n            period: The report period\n            \n        Returns:\n            Time analysis report section\n        \"\"\"\n        # Group transactions by time period\n        time_groups = {}\n        for transaction in transactions:\n            # Extract the date\n            transaction_date = transaction.get(\"date\")\n            if not transaction_date:\n                continue\n                \n            if isinstance(transaction_date, str):\n                # Parse date string if needed\n                try:\n                    transaction_date = datetime.fromisoformat(transaction_date)\n                except:\n                    continue\n            \n            # Determine the time period key\n            if period == ReportPeriod.DAILY:\n                key = transaction_date.strftime(\"%Y-%m-%d\")\n            elif period == ReportPeriod.WEEKLY:\n                # Use ISO week number\n                key = f\"{transaction_date.year}-W{transaction_date.isocalendar()[1]}\"\n            elif period == ReportPeriod.MONTHLY:\n                key = transaction_date.strftime(\"%Y-%m\")\n            elif period == ReportPeriod.QUARTERLY:\n                quarter = (transaction_date.month - 1) // 3 + 1\n                key = f\"{transaction_date.year}-Q{quarter}\"\n            elif period == ReportPeriod.YEARLY:\n                key = str(transaction_date.year)\n            else:\n                # Default to daily\n                key = transaction_date.strftime(\"%Y-%m-%d\")\n            \n            # Add to the group\n            if key not in time_groups:\n                time_groups[key] = {\n                    \"income\": 0,\n                    \"expenses\": 0,\n                    \"count\": 0,\n                }\n            \n            # Update group metrics\n            group = time_groups[key]\n            group[\"count\"] += 1\n            \n            if transaction.get(\"transaction_type\") == \"income\":\n                group[\"income\"] += transaction[\"amount\"]\n            elif transaction.get(\"transaction_type\") == \"expense\":\n                group[\"expenses\"] += transaction[\"amount\"]\n        \n        # Calculate net cash flow for each period\n        for key, group in time_groups.items():\n            group[\"net_cash_flow\"] = group[\"income\"] - group[\"expenses\"]\n        \n        # Sort groups by time period\n        sorted_groups = sorted(time_groups.items())\n        \n        # Create chart data\n        income_data = [(key, group[\"income\"]) for key, group in sorted_groups]\n        expense_data = [(key, group[\"expenses\"]) for key, group in sorted_groups]\n        net_data = [(key, group[\"net_cash_flow\"]) for key, group in sorted_groups]\n        \n        # Create the section\n        return ReportSection(\n            title=\"Time Analysis\",\n            summary=f\"Financial trends over {period.value} periods\",\n            data={\n                \"period_count\": len(time_groups),\n                \"highest_income_period\": max(sorted_groups, key=lambda x: x[1][\"income\"])[0] if sorted_groups else \"None\",\n                \"highest_expense_period\": max(sorted_groups, key=lambda x: x[1][\"expenses\"])[0] if sorted_groups else \"None\",\n                \"average_period_income\": sum(group[\"income\"] for _, group in sorted_groups) / len(sorted_groups) if sorted_groups else 0,\n                \"average_period_expenses\": sum(group[\"expenses\"] for _, group in sorted_groups) / len(sorted_groups) if sorted_groups else 0,\n            },\n            charts=[\n                {\n                    \"type\": \"line\",\n                    \"title\": \"Income and Expenses Over Time\",\n                    \"data\": {\n                        \"Income\": dict(income_data),\n                        \"Expenses\": dict(expense_data),\n                        \"Net\": dict(net_data),\n                    },\n                },\n            ],\n        )",
                "class PortfolioReportGenerator(ReportGenerator):\n    \"\"\"\n    Report generator for investment portfolios.\n    \n    Used for generating reports about portfolio composition and performance.\n    \"\"\"\n    \n    def generate(\n        self, data: PortfolioAnalysisResult, parameters: ReportParameters\n    ) -> Report:\n        \"\"\"\n        Generate a portfolio analysis report.\n        \n        Args:\n            data: Portfolio analysis data to include in the report\n            parameters: Parameters to configure the report\n            \n        Returns:\n            Portfolio analysis report\n        \"\"\"\n        # Create the report\n        report = Report(\n            title=\"Portfolio Analysis Report\",\n            description=\"Analysis of investment portfolio composition, performance, and characteristics\",\n            period=parameters.period,\n            start_date=parameters.start_date,\n            end_date=parameters.end_date,\n            format=parameters.format,\n            metadata={\n                \"portfolio_id\": data.subject_id,\n                \"analysis_date\": data.analysis_date,\n            },\n        )\n        \n        # Generate composition section\n        composition_section = self._generate_composition_section(data)\n        report.sections.append(composition_section)\n        \n        # Generate performance section if available\n        if data.performance:\n            performance_section = self._generate_performance_section(data.performance)\n            report.sections.append(performance_section)\n        \n        # Generate ESG metrics section if available\n        if data.esg_metrics:\n            esg_section = self._generate_esg_section(data.esg_metrics)\n            report.sections.append(esg_section)\n        \n        # Generate recommendations section\n        if data.recommendations:\n            recommendation_section = ReportSection(\n                title=\"Recommendations\",\n                summary=\"Suggested actions based on portfolio analysis\",\n                data={\n                    \"recommendation_count\": len(data.recommendations),\n                },\n            )\n            \n            for i, recommendation in enumerate(data.recommendations, 1):\n                recommendation_section.data[f\"recommendation_{i}\"] = recommendation\n            \n            report.sections.append(recommendation_section)\n        \n        return report\n    \n    def _generate_composition_section(\n        self, data: PortfolioAnalysisResult\n    ) -> ReportSection:\n        \"\"\"\n        Generate the portfolio composition section of the report.\n        \n        Args:\n            data: Portfolio analysis result\n            \n        Returns:\n            Portfolio composition report section\n        \"\"\"\n        # Extract breakdown data\n        breakdown = data.breakdown\n        \n        # Create sector subsection\n        sector_subsection = ReportSection(\n            title=\"Sector Allocation\",\n            data=breakdown.by_sector,\n            charts=[\n                {\n                    \"type\": \"pie\",\n                    \"title\": \"Allocation by Sector\",\n                    \"data\": breakdown.by_sector,\n                },\n            ],\n        )\n        \n        # Create industry subsection\n        industry_subsection = ReportSection(\n            title=\"Industry Allocation\",\n            data=dict(\n                sorted(breakdown.by_industry.items(), key=lambda x: x[1], reverse=True)[:10]\n            ),  # Top 10 industries\n            charts=[\n                {\n                    \"type\": \"bar\",\n                    \"title\": \"Top 10 Industries\",\n                    \"data\": dict(\n                        sorted(breakdown.by_industry.items(), key=lambda x: x[1], reverse=True)[:10]\n                    ),\n                },\n            ],\n        )\n        \n        # Create market cap subsection\n        market_cap_subsection = ReportSection(\n            title=\"Market Cap Distribution\",\n            data=breakdown.by_market_cap,\n            charts=[\n                {\n                    \"type\": \"pie\",\n                    \"title\": \"Allocation by Market Cap\",\n                    \"data\": breakdown.by_market_cap,\n                },\n            ],\n        )\n        \n        # Create the main section\n        return ReportSection(\n            title=\"Portfolio Composition\",\n            summary=\"Analysis of portfolio allocations and diversification\",\n            data={\n                \"diversification_score\": data.diversification_score,\n                \"top_sector\": max(breakdown.by_sector.items(), key=lambda x: x[1])[0] if breakdown.by_sector else \"None\",\n                \"top_sector_allocation\": max(breakdown.by_sector.items(), key=lambda x: x[1])[1] if breakdown.by_sector else 0,\n                \"sector_count\": len(breakdown.by_sector),\n                \"industry_count\": len(breakdown.by_industry),\n                \"concentration_index\": breakdown.concentration_metrics.get(\"herfindahl_index\", 0),\n            },\n            subsections=[\n                sector_subsection,\n                industry_subsection,\n                market_cap_subsection,\n            ],\n        )\n    \n    def _generate_performance_section(\n        self, performance: PortfolioPerformance\n    ) -> ReportSection:\n        \"\"\"\n        Generate the portfolio performance section of the report.\n        \n        Args:\n            performance: Portfolio performance data\n            \n        Returns:\n            Portfolio performance report section\n        \"\"\"\n        return ReportSection(\n            title=\"Performance Metrics\",\n            summary=\"Analysis of portfolio returns and risk-adjusted performance\",\n            data={\n                \"total_return\": performance.total_return,\n                \"annualized_return\": performance.annualized_return,\n                \"volatility\": performance.volatility,\n                \"sharpe_ratio\": performance.sharpe_ratio,\n                \"max_drawdown\": performance.max_drawdown,\n                \"alpha\": performance.alpha,\n                \"beta\": performance.beta,\n            },\n            charts=[\n                {\n                    \"type\": \"bar\",\n                    \"title\": \"Performance Metrics\",\n                    \"data\": {\n                        \"Total Return\": performance.total_return * 100,\n                        \"Volatility\": performance.volatility * 100,\n                        \"Max Drawdown\": performance.max_drawdown * 100,\n                    },\n                },\n            ],\n        )\n    \n    def _generate_esg_section(\n        self, esg_metrics: PortfolioESGMetrics\n    ) -> ReportSection:\n        \"\"\"\n        Generate the ESG metrics section of the report.\n        \n        Args:\n            esg_metrics: Portfolio ESG metrics data\n            \n        Returns:\n            ESG metrics report section\n        \"\"\"\n        # Create subsections for E, S, G components\n        environmental_subsection = ReportSection(\n            title=\"Environmental Metrics\",\n            data={\n                \"score\": esg_metrics.environmental_score,\n                \"carbon_footprint\": esg_metrics.carbon_footprint,\n                \"renewable_energy_exposure\": esg_metrics.renewable_energy_exposure,\n            },\n        )\n        \n        social_subsection = ReportSection(\n            title=\"Social Metrics\",\n            data={\n                \"score\": esg_metrics.social_score,\n                \"diversity_score\": esg_metrics.diversity_score,\n            },\n        )\n        \n        governance_subsection = ReportSection(\n            title=\"Governance Metrics\",\n            data={\n                \"score\": esg_metrics.governance_score,\n            },\n        )\n        \n        # Create the main section\n        return ReportSection(\n            title=\"ESG Profile\",\n            summary=\"Environmental, Social, and Governance characteristics of the portfolio\",\n            data={\n                \"overall_esg_score\": esg_metrics.overall_esg_score,\n                \"controversy_exposure\": esg_metrics.controversy_exposure,\n            },\n            charts=[\n                {\n                    \"type\": \"radar\",\n                    \"title\": \"ESG Component Scores\",\n                    \"data\": {\n                        \"Environmental\": esg_metrics.environmental_score,\n                        \"Social\": esg_metrics.social_score,\n                        \"Governance\": esg_metrics.governance_score,\n                    },\n                },\n            ],\n            subsections=[\n                environmental_subsection,\n                social_subsection,\n                governance_subsection,\n            ],\n        )",
                "class ProjectionReportGenerator(ReportGenerator):\n    \"\"\"\n    Report generator for financial projections.\n    \n    Used for generating reports about projected financial states.\n    \"\"\"\n    \n    def generate(\n        self, data: ProjectionResult, parameters: ReportParameters\n    ) -> Report:\n        \"\"\"\n        Generate a financial projection report.\n        \n        Args:\n            data: Projection data to include in the report\n            parameters: Parameters to configure the report\n            \n        Returns:\n            Financial projection report\n        \"\"\"\n        # Create the report\n        report = Report(\n            title=\"Financial Projection Report\",\n            description=\"Projected financial states across different scenarios\",\n            period=parameters.period,\n            start_date=data.baseline.start_date,\n            end_date=data.baseline.end_date,\n            format=parameters.format,\n            metadata={\n                \"analysis_date\": data.analysis_date,\n                \"projection_length\": len(data.baseline.cash_flows),\n            },\n        )\n        \n        # Generate summary section\n        summary_section = self._generate_summary_section(data)\n        report.sections.append(summary_section)\n        \n        # Generate scenario sections\n        baseline_section = self._generate_scenario_section(\n            data.baseline, \"Baseline Scenario\"\n        )\n        report.sections.append(baseline_section)\n        \n        if data.optimistic:\n            optimistic_section = self._generate_scenario_section(\n                data.optimistic, \"Optimistic Scenario\"\n            )\n            report.sections.append(optimistic_section)\n        \n        if data.conservative:\n            conservative_section = self._generate_scenario_section(\n                data.conservative, \"Conservative Scenario\"\n            )\n            report.sections.append(conservative_section)\n        \n        if data.stress_test:\n            stress_section = self._generate_scenario_section(\n                data.stress_test, \"Stress Test Scenario\"\n            )\n            report.sections.append(stress_section)\n        \n        # Generate recommendations section\n        if data.recommended_actions:\n            recommendation_section = ReportSection(\n                title=\"Recommended Actions\",\n                summary=\"Suggested financial actions based on projections\",\n                data={\n                    \"recommendation_count\": len(data.recommended_actions),\n                },\n            )\n            \n            for i, recommendation in enumerate(data.recommended_actions, 1):\n                recommendation_section.data[f\"recommendation_{i}\"] = recommendation\n            \n            report.sections.append(recommendation_section)\n        \n        return report\n    \n    def _generate_summary_section(self, data: ProjectionResult) -> ReportSection:\n        \"\"\"\n        Generate the summary section of the report.\n        \n        Args:\n            data: Projection result data\n            \n        Returns:\n            Summary report section\n        \"\"\"\n        # Compare scenarios\n        scenarios = {\n            \"Baseline\": data.baseline,\n            \"Optimistic\": data.optimistic,\n            \"Conservative\": data.conservative,\n            \"Stress Test\": data.stress_test,\n        }\n        \n        # Filter out None scenarios\n        scenarios = {k: v for k, v in scenarios.items() if v is not None}\n        \n        # Calculate scenario comparison data\n        comparison_data = {}\n        for name, scenario in scenarios.items():\n            comparison_data[f\"{name}_final_balance\"] = scenario.final_balance\n            comparison_data[f\"{name}_lowest_balance\"] = scenario.lowest_balance\n            \n            if scenario.runway_months is not None:\n                comparison_data[f\"{name}_runway\"] = (\n                    f\"{scenario.runway_months:.1f} months\"\n                    if scenario.runway_months < float('inf')\n                    else \"Sustainable\"\n                )\n            else:\n                comparison_data[f\"{name}_runway\"] = \"N/A\"\n        \n        # Create chart data for final balances\n        final_balances = {\n            name: scenario.final_balance\n            for name, scenario in scenarios.items()\n        }\n        \n        return ReportSection(\n            title=\"Projection Summary\",\n            summary=\"Comparison of different financial scenarios\",\n            data={\n                \"starting_balance\": data.baseline.starting_balance,\n                \"projection_period\": f\"{len(data.baseline.cash_flows)} months\",\n                \"baseline_final_balance\": data.baseline.final_balance,\n                \"baseline_runway\": (\n                    f\"{data.baseline.runway_months:.1f} months\"\n                    if data.baseline.runway_months and data.baseline.runway_months < float('inf')\n                    else \"Sustainable\"\n                ),\n                \"emergency_fund_status\": data.baseline.emergency_fund_status,\n                **comparison_data,\n            },\n            charts=[\n                {\n                    \"type\": \"bar\",\n                    \"title\": \"Final Balance by Scenario\",\n                    \"data\": final_balances,\n                },\n            ],\n        )\n    \n    def _generate_scenario_section(\n        self, projection: Projection, title: str\n    ) -> ReportSection:\n        \"\"\"\n        Generate a section for a specific projection scenario.\n        \n        Args:\n            projection: Projection data for the scenario\n            title: Section title\n            \n        Returns:\n            Scenario report section\n        \"\"\"\n        # Create cash flow subsection\n        cash_flow_data = {}\n        for i, cf in enumerate(projection.cash_flows[:12]):  # Limit to first 12 periods\n            month_name = cf.date.strftime(\"%b %Y\")\n            cash_flow_data[f\"{month_name}_income\"] = cf.income\n            cash_flow_data[f\"{month_name}_expenses\"] = cf.expenses\n            cash_flow_data[f\"{month_name}_net\"] = cf.net\n            cash_flow_data[f\"{month_name}_balance\"] = cf.cumulative\n        \n        cash_flow_section = ReportSection(\n            title=\"Cash Flow Projection\",\n            data=cash_flow_data,\n            charts=[\n                {\n                    \"type\": \"line\",\n                    \"title\": \"Projected Cash Flow\",\n                    \"data\": {\n                        \"Income\": {cf.date.strftime(\"%b %Y\"): cf.income for cf in projection.cash_flows[:12]},\n                        \"Expenses\": {cf.date.strftime(\"%b %Y\"): cf.expenses for cf in projection.cash_flows[:12]},\n                        \"Net\": {cf.date.strftime(\"%b %Y\"): cf.net for cf in projection.cash_flows[:12]},\n                    },\n                },\n                {\n                    \"type\": \"line\",\n                    \"title\": \"Projected Balance\",\n                    \"data\": {\n                        \"Balance\": {cf.date.strftime(\"%b %Y\"): cf.cumulative for cf in projection.cash_flows[:12]},\n                    },\n                },\n            ],\n        )\n        \n        # Create tax subsection if available\n        tax_section = None\n        if projection.tax_liability:\n            tax_data = {}\n            for year, amount in projection.tax_liability.get(\"yearly\", {}).items():\n                tax_data[f\"year_{year}\"] = amount\n            \n            tax_section = ReportSection(\n                title=\"Tax Projection\",\n                data={\n                    \"total_tax_liability\": projection.tax_liability.get(\"total\", 0),\n                    \"average_monthly_tax\": projection.tax_liability.get(\"avg_monthly\", 0),\n                    \"effective_tax_rate\": projection.tax_liability.get(\"effective_rate\", 0),\n                    **tax_data,\n                },\n            )\n        \n        # Create the main section\n        subsections = [cash_flow_section]\n        if tax_section:\n            subsections.append(tax_section)\n        \n        return ReportSection(\n            title=title,\n            summary=f\"Financial projection under {projection.scenario.value} conditions\",\n            data={\n                \"starting_balance\": projection.starting_balance,\n                \"final_balance\": projection.final_balance,\n                \"lowest_balance\": projection.lowest_balance,\n                \"highest_balance\": projection.highest_balance,\n                \"runway_months\": (\n                    f\"{projection.runway_months:.1f}\"\n                    if projection.runway_months and projection.runway_months < float('inf')\n                    else \"Sustainable\"\n                ),\n                \"emergency_fund_status\": projection.emergency_fund_status,\n                \"confidence_level\": projection.confidence_level,\n            },\n            subsections=subsections,\n        )"
            ]
        }
    },
    "unified/tests/socially_responsible_investor/test_portfolio_analysis/__init__.py": {
        "logprobs": -175.684480669426,
        "metrics": {
            "loc": 1,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 0,
            "blank": 0,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/personal_finance_tracker/project/models.py": {
        "logprobs": -368.90705203271494,
        "metrics": {
            "loc": 20,
            "sloc": 17,
            "lloc": 4,
            "comments": 1,
            "multi": 0,
            "blank": 1,
            "cyclomatic": 0,
            "internal_imports": [
                "class ProjectMetricType(str, Enum):\n    \"\"\"Types of project profitability metrics.\"\"\"\n\n    HOURLY_RATE = \"hourly_rate\"\n    TOTAL_PROFIT = \"total_profit\"\n    PROFIT_MARGIN = \"profit_margin\"\n    ROI = \"roi\"",
                "class ProfitabilityMetric(BaseModel):\n    \"\"\"Profitability metric for a project.\"\"\"\n\n    project_id: str\n    metric_type: ProjectMetricType\n    value: float\n    calculation_date: datetime = Field(default_factory=datetime.now)\n    description: Optional[str] = None",
                "class ProjectProfitability(BaseModel):\n    \"\"\"Project profitability analysis result.\"\"\"\n\n    project_id: str\n    project_name: str\n    client_id: str\n    start_date: datetime\n    end_date: Optional[datetime] = None\n    total_hours: float\n    total_revenue: float\n    total_expenses: float\n    total_profit: float\n    effective_hourly_rate: float\n    profit_margin: float  # Percentage\n    roi: float  # Return on investment\n    is_completed: bool\n    calculation_date: datetime = Field(default_factory=datetime.now)\n    metrics: List[ProfitabilityMetric] = Field(default_factory=list)\n\n    @validator(\"effective_hourly_rate\", \"profit_margin\", \"roi\", pre=True, always=True)\n    def validate_rates(cls, v, values):\n        \"\"\"Ensure rates are calculated correctly.\"\"\"\n        if v is not None:\n            return v\n\n        # If we have all required values, calculate the field\n        if (\n            \"total_hours\" in values\n            and \"total_revenue\" in values\n            and \"total_expenses\" in values\n        ):\n            hours = values[\"total_hours\"]\n            revenue = values[\"total_revenue\"]\n            expenses = values[\"total_expenses\"]\n\n            if values[\"current_field_name\"] == \"effective_hourly_rate\":\n                return revenue / max(hours, 0.01)  # Avoid division by zero\n\n            if values[\"current_field_name\"] == \"profit_margin\":\n                return 100 * (revenue - expenses) / max(revenue, 0.01)\n\n            if values[\"current_field_name\"] == \"roi\":\n                return (revenue - expenses) / max(expenses, 0.01)\n\n        return 0.0",
                "class ClientProfitability(BaseModel):\n    \"\"\"Client profitability analysis result.\"\"\"\n\n    client_id: str\n    client_name: str\n    number_of_projects: int\n    total_hours: float\n    total_revenue: float\n    total_expenses: float\n    total_profit: float\n    average_hourly_rate: float\n    average_profit_margin: float\n    average_invoice_payment_days: Optional[float] = None\n    projects: List[ProjectProfitability] = Field(default_factory=list)\n    calculation_date: datetime = Field(default_factory=datetime.now)",
                "class TrendPoint(BaseModel):\n    \"\"\"Point in a trend analysis.\"\"\"\n\n    date: datetime\n    value: float",
                "class TrendAnalysis(BaseModel):\n    \"\"\"Trend analysis for project profitability over time.\"\"\"\n\n    metric_type: ProjectMetricType\n    project_id: Optional[str] = None\n    client_id: Optional[str] = None\n    period: str  # \"weekly\", \"monthly\", \"quarterly\", \"yearly\"\n    start_date: datetime\n    end_date: datetime\n    data_points: List[TrendPoint] = Field(default_factory=list)\n    calculation_date: datetime = Field(default_factory=datetime.now)\n    description: Optional[str] = None",
                "class Project(BaseModel):\n    \"\"\"\n    Project model for tracking client projects.\n    \n    Used for organizing work, time tracking, and financial analysis\n    across multiple persona implementations.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    client_id: Optional[str] = None\n    start_date: Union[date, datetime]\n    end_date: Optional[Union[date, datetime]] = None\n    status: ProjectStatus = ProjectStatus.ACTIVE\n    hourly_rate: Optional[float] = None\n    fixed_price: Optional[float] = None\n    estimated_hours: Optional[float] = None\n    description: Optional[str] = None\n    tags: List[str] = Field(default_factory=list)\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    @validator(\"end_date\")\n    def validate_end_date(cls, v, values):\n        \"\"\"Validate that end_date is after start_date if both are provided.\"\"\"\n        if v is not None and \"start_date\" in values:\n            start = values[\"start_date\"]\n            if start > v:\n                raise ValueError(\"End date must be after start date\")\n        return v\n    \n    @validator(\"hourly_rate\", \"fixed_price\", \"estimated_hours\")\n    def validate_positive_numbers(cls, v):\n        \"\"\"Validate that financial amounts are positive numbers.\"\"\"\n        if v is not None and v < 0:\n            raise ValueError(\"Value must be a positive number\")\n        return v",
                "class Client(BaseModel):\n    \"\"\"\n    Client model for tracking information about clients.\n    \n    Used for organizing projects and managing client relationships.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    contact_email: Optional[str] = None\n    contact_phone: Optional[str] = None\n    address: Optional[str] = None\n    notes: Optional[str] = None\n    active: bool = True\n    metadata: Dict[str, Any] = Field(default_factory=dict)",
                "class TimeEntry(BaseModel):\n    \"\"\"\n    Time entry model for tracking hours worked on projects.\n    \n    Used for billing, project profitability analysis, and reporting.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    project_id: str\n    start_time: datetime\n    end_time: Optional[datetime] = None\n    duration_minutes: Optional[float] = None\n    description: str\n    billable: bool = True\n    tags: List[str] = Field(default_factory=list)\n    user_id: Optional[str] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    @validator(\"duration_minutes\", always=True)\n    def calculate_duration(cls, v, values):\n        \"\"\"Calculate duration from start and end time if not provided.\"\"\"\n        if v is not None:\n            return v\n        if (\n            \"start_time\" in values\n            and \"end_time\" in values\n            and values[\"end_time\"] is not None\n        ):\n            delta = values[\"end_time\"] - values[\"start_time\"]\n            return delta.total_seconds() / 60\n        return None\n    \n    @validator(\"end_time\")\n    def validate_end_time(cls, v, values):\n        \"\"\"Validate that end_time is after start_time if both are provided.\"\"\"\n        if v is not None and \"start_time\" in values:\n            if values[\"start_time\"] > v:\n                raise ValueError(\"End time must be after start time\")\n        return v",
                "class Invoice(BaseModel):\n    \"\"\"\n    Invoice model for tracking client billing.\n    \n    Used for revenue tracking, client relationship management, and tax reporting.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    client_id: str\n    project_id: Optional[str] = None\n    issue_date: Union[date, datetime]\n    due_date: Union[date, datetime]\n    amount: float\n    status: str  # e.g., \"draft\", \"sent\", \"paid\", \"overdue\"\n    payment_date: Optional[Union[date, datetime]] = None\n    description: Optional[str] = None\n    line_items: List[Dict[str, Any]] = Field(default_factory=list)\n    \n    @validator(\"due_date\")\n    def validate_due_date(cls, v, values):\n        \"\"\"Validate that due_date is after issue_date.\"\"\"\n        if \"issue_date\" in values:\n            if v < values[\"issue_date\"]:\n                raise ValueError(\"Due date must be after issue date\")\n        return v\n    \n    @validator(\"amount\")\n    def validate_amount(cls, v):\n        \"\"\"Validate that amount is a positive number.\"\"\"\n        if v < 0:\n            raise ValueError(\"Invoice amount must be a positive number\")\n        return v",
                "class ProjectStatus(str, Enum):\n    \"\"\"Status of a project throughout its lifecycle.\"\"\"\n\n    PLANNED = \"planned\"\n    ACTIVE = \"active\"\n    ON_HOLD = \"on_hold\"\n    COMPLETED = \"completed\"\n    CANCELLED = \"cancelled\"",
                "class BusinessTransaction(BaseTransaction):\n    \"\"\"\n    Transaction model for business transactions with additional fields.\n    \n    Extends the base transaction model with business-specific fields.\n    \"\"\"\n\n    business_use_percentage: Optional[float] = None\n    project_id: Optional[str] = None\n    client_id: Optional[str] = None\n    invoice_id: Optional[str] = None\n    receipt_path: Optional[str] = None\n    \n    @validator(\"business_use_percentage\")\n    def validate_business_percentage(cls, v):\n        \"\"\"Validate that business use percentage is between 0 and 100.\"\"\"\n        if v is not None and (v < 0 or v > 100):\n            raise ValueError(\"Business use percentage must be between 0 and 100\")\n        return v",
                "class TransactionType(str, Enum):\n    \"\"\"Transaction type enum for all financial transactions.\"\"\"\n\n    INCOME = \"income\"\n    EXPENSE = \"expense\"\n    TAX_PAYMENT = \"tax_payment\"\n    TRANSFER = \"transfer\"\n    INVESTMENT = \"investment\"\n    DIVIDEND = \"dividend\"\n    INTEREST = \"interest\""
            ]
        }
    },
    "unified/common/core/analysis/project_analyzer.py": {
        "logprobs": -2092.0400212305985,
        "metrics": {
            "loc": 589,
            "sloc": 361,
            "lloc": 173,
            "comments": 48,
            "multi": 96,
            "blank": 83,
            "cyclomatic": 108,
            "internal_imports": [
                "class BaseAnalyzer(Generic[T, R], ABC):\n    \"\"\"\n    Abstract base class for analysis engines.\n    \n    Defines the core interface and functionality for all analyzers\n    across different persona implementations.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the analyzer.\"\"\"\n        self._analysis_cache: Dict[str, R] = {}\n    \n    @abstractmethod\n    def analyze(\n        self, subject: T, parameters: Optional[AnalysisParameters] = None\n    ) -> R:\n        \"\"\"\n        Analyze a single subject.\n        \n        Args:\n            subject: The subject to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Analysis result\n        \"\"\"\n        pass\n    \n    def analyze_batch(\n        self, subjects: List[T], parameters: Optional[AnalysisParameters] = None\n    ) -> List[R]:\n        \"\"\"\n        Analyze multiple subjects.\n        \n        Args:\n            subjects: List of subjects to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            List of analysis results\n        \"\"\"\n        # Start performance timer\n        start_time = time.time()\n        \n        # Analyze each subject\n        results = []\n        for subject in subjects:\n            result = self.analyze(subject, parameters)\n            results.append(result)\n        \n        # Performance metrics\n        elapsed_time = time.time() - start_time\n        \n        return results\n    \n    def clear_cache(self) -> None:\n        \"\"\"Clear the analysis cache.\"\"\"\n        self._analysis_cache = {}\n    \n    def _generate_cache_key(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> str:\n        \"\"\"\n        Generate a cache key for a subject and parameters.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cache key string\n        \"\"\"\n        # Start with the subject ID\n        key = f\"subject_{subject_id}\"\n        \n        # Add parameter details if provided\n        if parameters:\n            param_dict = parameters.dict(exclude_none=True)\n            for k, v in sorted(param_dict.items()):\n                if k != \"custom_settings\":\n                    key += f\"_{k}_{v}\"\n                    \n            # Handle custom settings separately (they could be complex)\n            if parameters.custom_settings:\n                for k, v in sorted(parameters.custom_settings.items()):\n                    key += f\"_{k}_{v}\"\n        \n        return key\n    \n    def _get_from_cache(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> Optional[R]:\n        \"\"\"\n        Get a cached analysis result if available.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cached result or None if not found\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        return self._analysis_cache.get(cache_key)\n    \n    def _save_to_cache(\n        self, subject_id: Union[str, UUID], result: R, parameters: Optional[AnalysisParameters] = None\n    ) -> None:\n        \"\"\"\n        Save an analysis result to the cache.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            result: The analysis result to cache\n            parameters: Optional parameters to configure the analysis\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        self._analysis_cache[cache_key] = result",
                "class Project(BaseModel):\n    \"\"\"\n    Project model for tracking client projects.\n    \n    Used for organizing work, time tracking, and financial analysis\n    across multiple persona implementations.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    client_id: Optional[str] = None\n    start_date: Union[date, datetime]\n    end_date: Optional[Union[date, datetime]] = None\n    status: ProjectStatus = ProjectStatus.ACTIVE\n    hourly_rate: Optional[float] = None\n    fixed_price: Optional[float] = None\n    estimated_hours: Optional[float] = None\n    description: Optional[str] = None\n    tags: List[str] = Field(default_factory=list)\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    @validator(\"end_date\")\n    def validate_end_date(cls, v, values):\n        \"\"\"Validate that end_date is after start_date if both are provided.\"\"\"\n        if v is not None and \"start_date\" in values:\n            start = values[\"start_date\"]\n            if start > v:\n                raise ValueError(\"End date must be after start date\")\n        return v\n    \n    @validator(\"hourly_rate\", \"fixed_price\", \"estimated_hours\")\n    def validate_positive_numbers(cls, v):\n        \"\"\"Validate that financial amounts are positive numbers.\"\"\"\n        if v is not None and v < 0:\n            raise ValueError(\"Value must be a positive number\")\n        return v",
                "class Client(BaseModel):\n    \"\"\"\n    Client model for tracking information about clients.\n    \n    Used for organizing projects and managing client relationships.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    contact_email: Optional[str] = None\n    contact_phone: Optional[str] = None\n    address: Optional[str] = None\n    notes: Optional[str] = None\n    active: bool = True\n    metadata: Dict[str, Any] = Field(default_factory=dict)",
                "class TimeEntry(BaseModel):\n    \"\"\"\n    Time entry model for tracking hours worked on projects.\n    \n    Used for billing, project profitability analysis, and reporting.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    project_id: str\n    start_time: datetime\n    end_time: Optional[datetime] = None\n    duration_minutes: Optional[float] = None\n    description: str\n    billable: bool = True\n    tags: List[str] = Field(default_factory=list)\n    user_id: Optional[str] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    @validator(\"duration_minutes\", always=True)\n    def calculate_duration(cls, v, values):\n        \"\"\"Calculate duration from start and end time if not provided.\"\"\"\n        if v is not None:\n            return v\n        if (\n            \"start_time\" in values\n            and \"end_time\" in values\n            and values[\"end_time\"] is not None\n        ):\n            delta = values[\"end_time\"] - values[\"start_time\"]\n            return delta.total_seconds() / 60\n        return None\n    \n    @validator(\"end_time\")\n    def validate_end_time(cls, v, values):\n        \"\"\"Validate that end_time is after start_time if both are provided.\"\"\"\n        if v is not None and \"start_time\" in values:\n            if values[\"start_time\"] > v:\n                raise ValueError(\"End time must be after start time\")\n        return v",
                "class Invoice(BaseModel):\n    \"\"\"\n    Invoice model for tracking client billing.\n    \n    Used for revenue tracking, client relationship management, and tax reporting.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    client_id: str\n    project_id: Optional[str] = None\n    issue_date: Union[date, datetime]\n    due_date: Union[date, datetime]\n    amount: float\n    status: str  # e.g., \"draft\", \"sent\", \"paid\", \"overdue\"\n    payment_date: Optional[Union[date, datetime]] = None\n    description: Optional[str] = None\n    line_items: List[Dict[str, Any]] = Field(default_factory=list)\n    \n    @validator(\"due_date\")\n    def validate_due_date(cls, v, values):\n        \"\"\"Validate that due_date is after issue_date.\"\"\"\n        if \"issue_date\" in values:\n            if v < values[\"issue_date\"]:\n                raise ValueError(\"Due date must be after issue date\")\n        return v\n    \n    @validator(\"amount\")\n    def validate_amount(cls, v):\n        \"\"\"Validate that amount is a positive number.\"\"\"\n        if v < 0:\n            raise ValueError(\"Invoice amount must be a positive number\")\n        return v",
                "class BaseTransaction(BaseModel):\n    \"\"\"\n    Base transaction model for all financial transactions.\n    \n    This abstract base class provides common fields for tracking\n    financial transactions across different persona implementations.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    date: Union[date, datetime]\n    amount: float\n    description: str\n    transaction_type: TransactionType\n    \n    # Optional fields\n    account_id: Optional[str] = None\n    category: Optional[str] = None\n    tags: List[str] = Field(default_factory=list)\n    notes: Optional[str] = None\n    \n    @validator(\"amount\")\n    def validate_amount(cls, v):\n        \"\"\"Validate that amount is a valid number.\"\"\"\n        if not isinstance(v, (int, float)):\n            raise ValueError(\"Amount must be a number\")\n        return v",
                "class ProjectMetricType(str, Enum):\n    \"\"\"Types of project profitability metrics.\"\"\"\n\n    HOURLY_RATE = \"hourly_rate\"\n    TOTAL_PROFIT = \"total_profit\"\n    PROFIT_MARGIN = \"profit_margin\"\n    ROI = \"roi\"",
                "class ProfitabilityMetric(BaseModel):\n    \"\"\"Profitability metric for a project.\"\"\"\n\n    project_id: str\n    metric_type: ProjectMetricType\n    value: float\n    calculation_date: datetime = Field(default_factory=datetime.now)\n    description: Optional[str] = None",
                "class ProjectProfitability(BaseModel):\n    \"\"\"Project profitability analysis result.\"\"\"\n\n    project_id: str\n    project_name: str\n    client_id: str\n    start_date: datetime\n    end_date: Optional[datetime] = None\n    total_hours: float\n    total_revenue: float\n    total_expenses: float\n    total_profit: float\n    effective_hourly_rate: float\n    profit_margin: float  # Percentage\n    roi: float  # Return on investment\n    is_completed: bool\n    calculation_date: datetime = Field(default_factory=datetime.now)\n    metrics: List[ProfitabilityMetric] = Field(default_factory=list)\n\n    @validator(\"effective_hourly_rate\", \"profit_margin\", \"roi\", pre=True, always=True)\n    def validate_rates(cls, v, values):\n        \"\"\"Ensure rates are calculated correctly.\"\"\"\n        if v is not None:\n            return v\n\n        # If we have all required values, calculate the field\n        if (\n            \"total_hours\" in values\n            and \"total_revenue\" in values\n            and \"total_expenses\" in values\n        ):\n            hours = values[\"total_hours\"]\n            revenue = values[\"total_revenue\"]\n            expenses = values[\"total_expenses\"]\n\n            if values[\"current_field_name\"] == \"effective_hourly_rate\":\n                return revenue / max(hours, 0.01)  # Avoid division by zero\n\n            if values[\"current_field_name\"] == \"profit_margin\":\n                return 100 * (revenue - expenses) / max(revenue, 0.01)\n\n            if values[\"current_field_name\"] == \"roi\":\n                return (revenue - expenses) / max(expenses, 0.01)\n\n        return 0.0",
                "class ClientProfitability(BaseModel):\n    \"\"\"Client profitability analysis result.\"\"\"\n\n    client_id: str\n    client_name: str\n    number_of_projects: int\n    total_hours: float\n    total_revenue: float\n    total_expenses: float\n    total_profit: float\n    average_hourly_rate: float\n    average_profit_margin: float\n    average_invoice_payment_days: Optional[float] = None\n    projects: List[ProjectProfitability] = Field(default_factory=list)\n    calculation_date: datetime = Field(default_factory=datetime.now)",
                "class TrendPoint(BaseModel):\n    \"\"\"Point in a trend analysis.\"\"\"\n\n    date: datetime\n    value: float",
                "class TrendAnalysis(BaseModel):\n    \"\"\"Trend analysis for project profitability over time.\"\"\"\n\n    metric_type: ProjectMetricType\n    project_id: Optional[str] = None\n    client_id: Optional[str] = None\n    period: str  # \"weekly\", \"monthly\", \"quarterly\", \"yearly\"\n    start_date: datetime\n    end_date: datetime\n    data_points: List[TrendPoint] = Field(default_factory=list)\n    calculation_date: datetime = Field(default_factory=datetime.now)\n    description: Optional[str] = None",
                "class Timer:\n    \"\"\"Utility for measuring execution time.\"\"\"\n    \n    def __init__(self, name: Optional[str] = None):\n        \"\"\"\n        Initialize the timer.\n        \n        Args:\n            name: Optional name for the timer\n        \"\"\"\n        self.name = name\n        self.start_time: Optional[float] = None\n        self.end_time: Optional[float] = None\n    \n    def __enter__(self) -> 'Timer':\n        \"\"\"Start the timer when entering a context.\"\"\"\n        self.start()\n        return self\n    \n    def __exit__(self, *args: Any) -> None:\n        \"\"\"Stop the timer when exiting a context.\"\"\"\n        self.stop()\n    \n    def start(self) -> None:\n        \"\"\"Start the timer.\"\"\"\n        self.start_time = time.time()\n        self.end_time = None\n    \n    def stop(self) -> float:\n        \"\"\"\n        Stop the timer.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        self.end_time = time.time()\n        return self.elapsed_time\n    \n    @property\n    def elapsed_time(self) -> float:\n        \"\"\"\n        Get the elapsed time.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        end = self.end_time if self.end_time is not None else time.time()\n        return end - self.start_time\n    \n    @property\n    def elapsed_milliseconds(self) -> float:\n        \"\"\"\n        Get the elapsed time in milliseconds.\n        \n        Returns:\n            Elapsed time in milliseconds\n        \"\"\"\n        return self.elapsed_time * 1000",
                "class Cache:\n    \"\"\"Simple in-memory cache with expiration.\"\"\"\n    \n    def __init__(self, max_size: int = 1000, expiration_seconds: Optional[int] = None):\n        \"\"\"\n        Initialize the cache.\n        \n        Args:\n            max_size: Maximum number of items in the cache\n            expiration_seconds: Time in seconds after which items expire (None for no expiration)\n        \"\"\"\n        self._cache: Dict[str, Tuple[Any, float]] = {}\n        self._max_size = max_size\n        self._expiration_seconds = expiration_seconds\n    \n    def get(self, key: str) -> Optional[Any]:\n        \"\"\"\n        Get a value from the cache.\n        \n        Args:\n            key: The cache key\n            \n        Returns:\n            The cached value or None if not found or expired\n        \"\"\"\n        if key not in self._cache:\n            return None\n        \n        value, timestamp = self._cache[key]\n        \n        # Check if expired\n        if self._expiration_seconds is not None:\n            if time.time() - timestamp > self._expiration_seconds:\n                # Remove expired item\n                del self._cache[key]\n                return None\n        \n        return value\n    \n    def set(self, key: str, value: Any) -> None:\n        \"\"\"\n        Set a value in the cache.\n        \n        Args:\n            key: The cache key\n            value: The value to cache\n        \"\"\"\n        # Ensure we don't exceed max size\n        if len(self._cache) >= self._max_size and key not in self._cache:\n            # Remove oldest item (simplistic approach)\n            oldest_key = min(self._cache.items(), key=lambda x: x[1][1])[0]\n            del self._cache[oldest_key]\n        \n        # Store with current timestamp\n        self._cache[key] = (value, time.time())\n    \n    def delete(self, key: str) -> bool:\n        \"\"\"\n        Delete a value from the cache.\n        \n        Args:\n            key: The cache key\n            \n        Returns:\n            True if the key was found and deleted, False otherwise\n        \"\"\"\n        if key in self._cache:\n            del self._cache[key]\n            return True\n        return False\n    \n    def clear(self) -> None:\n        \"\"\"Clear all cache entries.\"\"\"\n        self._cache.clear()\n    \n    def size(self) -> int:\n        \"\"\"\n        Get the current size of the cache.\n        \n        Returns:\n            Number of items in the cache\n        \"\"\"\n        return len(self._cache)\n    \n    def clean_expired(self) -> int:\n        \"\"\"\n        Remove all expired entries from the cache.\n        \n        Returns:\n            Number of expired entries removed\n        \"\"\"\n        if self._expiration_seconds is None:\n            return 0\n        \n        # Find expired keys\n        now = time.time()\n        expired_keys = [\n            key for key, (_, timestamp) in self._cache.items()\n            if now - timestamp > self._expiration_seconds\n        ]\n        \n        # Delete expired keys\n        for key in expired_keys:\n            del self._cache[key]\n        \n        return len(expired_keys)",
                "class TimeSeriesData(BaseModel):\n    \"\"\"\n    Model for time series data.\n    \n    Used for storing and manipulating time series data for analysis.\n    \"\"\"\n    \n    dates: List[Union[date, datetime]]\n    values: List[float]\n    labels: Optional[List[str]] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class TimeSeriesAnalyzer:\n    \"\"\"\n    Utility class for analyzing time series data.\n    \n    Provides methods for smoothing, trend detection, and forecasting.\n    \"\"\"\n    \n    @staticmethod\n    def moving_average(\n        data: TimeSeriesData, window_size: int = 3\n    ) -> TimeSeriesData:\n        \"\"\"\n        Calculate the moving average of time series data.\n        \n        Args:\n            data: The time series data\n            window_size: The window size for the moving average\n            \n        Returns:\n            New time series data with smoothed values\n        \"\"\"\n        if not data.values:\n            return TimeSeriesData(dates=[], values=[])\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Calculate the cumulative sum of values\n        cumsum = np.cumsum(values)\n        \n        # Calculate the moving average using the window\n        smoothed = np.zeros_like(values)\n        \n        # Handle the start of the array (where we don't have a full window)\n        for i in range(min(window_size, len(values))):\n            smoothed[i] = cumsum[i] / (i + 1)\n        \n        # Handle the rest of the array\n        for i in range(window_size, len(values)):\n            smoothed[i] = (cumsum[i] - cumsum[i - window_size]) / window_size\n        \n        # Create new time series data with smoothed values\n        return TimeSeriesData(\n            dates=data.dates,\n            values=smoothed.tolist(),\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"smoothing_method\": \"moving_average\",\n                \"window_size\": window_size,\n            },\n        )\n    \n    @staticmethod\n    def exponential_smoothing(\n        data: TimeSeriesData, alpha: float = 0.3\n    ) -> TimeSeriesData:\n        \"\"\"\n        Apply exponential smoothing to time series data.\n        \n        Args:\n            data: The time series data\n            alpha: The smoothing factor (0 < alpha < 1)\n            \n        Returns:\n            New time series data with smoothed values\n        \"\"\"\n        if not data.values:\n            return TimeSeriesData(dates=[], values=[])\n        \n        # Ensure alpha is between 0 and 1\n        alpha = max(0.01, min(0.99, alpha))\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Initialize the smoothed array with the first value\n        smoothed = np.zeros_like(values)\n        smoothed[0] = values[0]\n        \n        # Apply exponential smoothing\n        for i in range(1, len(values)):\n            smoothed[i] = alpha * values[i] + (1 - alpha) * smoothed[i - 1]\n        \n        # Create new time series data with smoothed values\n        return TimeSeriesData(\n            dates=data.dates,\n            values=smoothed.tolist(),\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"smoothing_method\": \"exponential\",\n                \"alpha\": alpha,\n            },\n        )\n    \n    @staticmethod\n    def seasonal_adjustment(\n        data: TimeSeriesData, period: int = 12\n    ) -> TimeSeriesData:\n        \"\"\"\n        Apply seasonal adjustment to time series data.\n        \n        Args:\n            data: The time series data\n            period: The seasonal period (e.g., 12 for monthly data with yearly seasonality)\n            \n        Returns:\n            New time series data with seasonally adjusted values\n        \"\"\"\n        if not data.values or len(data.values) < period * 2:\n            # Not enough data for seasonal adjustment\n            return data\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Calculate the seasonal indices\n        seasonal_indices = np.zeros(period)\n        seasonal_data = []\n        \n        # Organize data by season\n        for i in range(period):\n            seasonal_data.append(values[i::period])\n        \n        # Calculate average for each season\n        for i in range(period):\n            if len(seasonal_data[i]) > 0:\n                seasonal_indices[i] = np.mean(seasonal_data[i])\n        \n        # Normalize the seasonal indices\n        if np.sum(seasonal_indices) > 0:\n            seasonal_indices = seasonal_indices * period / np.sum(seasonal_indices)\n        \n        # Apply the seasonal adjustment\n        adjusted = np.zeros_like(values)\n        for i in range(len(values)):\n            season_idx = i % period\n            if seasonal_indices[season_idx] > 0:\n                adjusted[i] = values[i] / seasonal_indices[season_idx]\n            else:\n                adjusted[i] = values[i]\n        \n        # Create new time series data with adjusted values\n        return TimeSeriesData(\n            dates=data.dates,\n            values=adjusted.tolist(),\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"smoothing_method\": \"seasonal\",\n                \"period\": period,\n                \"seasonal_indices\": seasonal_indices.tolist(),\n            },\n        )\n    \n    @staticmethod\n    def detect_trend(data: TimeSeriesData) -> Dict[str, Any]:\n        \"\"\"\n        Detect trends in time series data.\n        \n        Args:\n            data: The time series data\n            \n        Returns:\n            Dictionary with trend information\n        \"\"\"\n        if not data.values or len(data.values) < 2:\n            return {\n                \"has_trend\": False,\n                \"trend_direction\": \"none\",\n                \"trend_strength\": 0.0,\n            }\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Simple linear regression\n        x = np.arange(len(values))\n        A = np.vstack([x, np.ones(len(x))]).T\n        \n        # Solve for the best fit line\n        try:\n            slope, intercept = np.linalg.lstsq(A, values, rcond=None)[0]\n        except:\n            # Fallback if linear algebra fails\n            slope = 0.0\n            intercept = np.mean(values) if len(values) > 0 else 0.0\n        \n        # Calculate trend strength (R-squared)\n        y_hat = slope * x + intercept\n        ss_total = np.sum((values - np.mean(values)) ** 2)\n        ss_residual = np.sum((values - y_hat) ** 2)\n        r_squared = 1 - (ss_residual / ss_total) if ss_total > 0 else 0.0\n        \n        # Determine trend direction\n        trend_direction = \"up\" if slope > 0 else \"down\" if slope < 0 else \"none\"\n        \n        return {\n            \"has_trend\": abs(slope) > 0.01,\n            \"trend_direction\": trend_direction,\n            \"trend_strength\": r_squared,\n            \"slope\": slope,\n            \"intercept\": intercept,\n        }\n    \n    @staticmethod\n    def extrapolate(\n        data: TimeSeriesData, periods: int = 3, method: str = \"linear\"\n    ) -> TimeSeriesData:\n        \"\"\"\n        Extrapolate time series data into the future.\n        \n        Args:\n            data: The time series data\n            periods: The number of periods to extrapolate\n            method: The extrapolation method (\"linear\", \"mean\", \"last\")\n            \n        Returns:\n            New time series data with extrapolated values\n        \"\"\"\n        if not data.values or periods <= 0:\n            return data\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        dates = data.dates.copy()\n        \n        # Determine the date increment\n        if len(dates) >= 2:\n            if isinstance(dates[0], datetime):\n                # For datetime objects\n                date_diff = dates[1] - dates[0]\n            else:\n                # For date objects\n                date_diff = timedelta(days=(dates[1] - dates[0]).days)\n        else:\n            # Default to daily if we can't determine\n            date_diff = timedelta(days=1)\n        \n        # Extrapolate dates\n        last_date = dates[-1]\n        extrapolated_dates = []\n        \n        for i in range(1, periods + 1):\n            if isinstance(last_date, datetime):\n                next_date = last_date + date_diff * i\n            else:\n                # Convert to datetime for easier arithmetic, then back to date\n                next_date = (datetime.combine(last_date, datetime.min.time()) + date_diff * i).date()\n            \n            extrapolated_dates.append(next_date)\n        \n        # Extrapolate values based on the method\n        extrapolated_values = []\n        \n        if method == \"linear\" and len(values) >= 2:\n            # Simple linear extrapolation\n            trend_info = TimeSeriesAnalyzer.detect_trend(data)\n            slope = trend_info[\"slope\"]\n            intercept = trend_info[\"intercept\"]\n            \n            for i in range(1, periods + 1):\n                next_value = slope * (len(values) + i - 1) + intercept\n                extrapolated_values.append(next_value)\n        \n        elif method == \"mean\" and len(values) > 0:\n            # Use the mean of the last few values\n            window = min(len(values), 3)\n            mean_value = np.mean(values[-window:])\n            \n            for _ in range(periods):\n                extrapolated_values.append(mean_value)\n        \n        else:\n            # Default to using the last value\n            last_value = values[-1] if len(values) > 0 else 0.0\n            \n            for _ in range(periods):\n                extrapolated_values.append(last_value)\n        \n        # Create new time series data with original and extrapolated values\n        return TimeSeriesData(\n            dates=dates + extrapolated_dates,\n            values=values.tolist() + extrapolated_values,\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"extrapolation_method\": method,\n                \"extrapolation_periods\": periods,\n                \"original_length\": len(values),\n            },\n        )\n    \n    @staticmethod\n    def normalize(data: TimeSeriesData) -> TimeSeriesData:\n        \"\"\"\n        Normalize time series data to a 0-1 range.\n        \n        Args:\n            data: The time series data\n            \n        Returns:\n            New time series data with normalized values\n        \"\"\"\n        if not data.values:\n            return TimeSeriesData(dates=[], values=[])\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Calculate min and max\n        min_value = np.min(values)\n        max_value = np.max(values)\n        \n        # Normalize the values\n        if max_value > min_value:\n            normalized = (values - min_value) / (max_value - min_value)\n        else:\n            # If all values are the same, normalize to 0.5\n            normalized = np.full_like(values, 0.5)\n        \n        # Create new time series data with normalized values\n        return TimeSeriesData(\n            dates=data.dates,\n            values=normalized.tolist(),\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"normalization\": True,\n                \"original_min\": float(min_value),\n                \"original_max\": float(max_value),\n            },\n        )\n    \n    @staticmethod\n    def aggregate_by_period(\n        dates: List[Union[date, datetime]],\n        values: List[float],\n        granularity: TimeSeriesGranularity,\n        aggregation_fn: Callable[[List[float]], float] = lambda x: sum(x),\n    ) -> Tuple[List[Union[date, datetime]], List[float]]:\n        \"\"\"\n        Aggregate time series data by a specified granularity.\n        \n        Args:\n            dates: List of dates\n            values: List of values\n            granularity: The desired granularity\n            aggregation_fn: Function to aggregate values within a period\n            \n        Returns:\n            Tuple of (aggregated_dates, aggregated_values)\n        \"\"\"\n        if not dates or not values:\n            return [], []\n        \n        # Combine dates and values for sorting and grouping\n        data = list(zip(dates, values))\n        data.sort(key=lambda x: x[0])  # Sort by date\n        \n        # Group by the specified granularity\n        grouped_data = {}\n        \n        for dt, value in data:\n            # Convert to datetime if it's a date\n            if isinstance(dt, date) and not isinstance(dt, datetime):\n                dt = datetime.combine(dt, datetime.min.time())\n            \n            # Group based on granularity\n            if granularity == TimeSeriesGranularity.DAILY:\n                key = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n            elif granularity == TimeSeriesGranularity.WEEKLY:\n                # Get start of the week (Monday)\n                start_of_week = dt - timedelta(days=dt.weekday())\n                key = start_of_week.replace(hour=0, minute=0, second=0, microsecond=0)\n            elif granularity == TimeSeriesGranularity.MONTHLY:\n                key = dt.replace(day=1, hour=0, minute=0, second=0, microsecond=0)\n            elif granularity == TimeSeriesGranularity.QUARTERLY:\n                quarter = (dt.month - 1) // 3\n                key = dt.replace(month=quarter * 3 + 1, day=1, hour=0, minute=0, second=0, microsecond=0)\n            elif granularity == TimeSeriesGranularity.YEARLY:\n                key = dt.replace(month=1, day=1, hour=0, minute=0, second=0, microsecond=0)\n            else:\n                # Default to daily\n                key = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n            \n            # Add to the group\n            if key in grouped_data:\n                grouped_data[key].append(value)\n            else:\n                grouped_data[key] = [value]\n        \n        # Aggregate values within each group\n        aggregated_data = [\n            (key, aggregation_fn(values)) for key, values in grouped_data.items()\n        ]\n        \n        # Sort by date and separate dates and values\n        aggregated_data.sort(key=lambda x: x[0])\n        \n        # Convert datetime back to date if the input was dates\n        if all(isinstance(dt, date) and not isinstance(dt, datetime) for dt in dates):\n            aggregated_dates = [dt.date() for dt, _ in aggregated_data]\n        else:\n            aggregated_dates = [dt for dt, _ in aggregated_data]\n            \n        aggregated_values = [value for _, value in aggregated_data]\n        \n        return aggregated_dates, aggregated_values"
            ]
        }
    },
    "unified/common/core/utils/date_utils.py": {
        "logprobs": -854.936060906014,
        "metrics": {
            "loc": 411,
            "sloc": 168,
            "lloc": 162,
            "comments": 28,
            "multi": 117,
            "blank": 96,
            "cyclomatic": 54,
            "internal_imports": []
        }
    },
    "unified/common/__init__.py": {
        "logprobs": -200.5427359288745,
        "metrics": {
            "loc": 5,
            "sloc": 2,
            "lloc": 3,
            "comments": 0,
            "multi": 0,
            "blank": 2,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/common/core/analysis/time_series.py": {
        "logprobs": -1478.9334522777447,
        "metrics": {
            "loc": 469,
            "sloc": 255,
            "lloc": 219,
            "comments": 57,
            "multi": 69,
            "blank": 90,
            "cyclomatic": 73,
            "internal_imports": [
                "class BaseAnalyzer(Generic[T, R], ABC):\n    \"\"\"\n    Abstract base class for analysis engines.\n    \n    Defines the core interface and functionality for all analyzers\n    across different persona implementations.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the analyzer.\"\"\"\n        self._analysis_cache: Dict[str, R] = {}\n    \n    @abstractmethod\n    def analyze(\n        self, subject: T, parameters: Optional[AnalysisParameters] = None\n    ) -> R:\n        \"\"\"\n        Analyze a single subject.\n        \n        Args:\n            subject: The subject to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Analysis result\n        \"\"\"\n        pass\n    \n    def analyze_batch(\n        self, subjects: List[T], parameters: Optional[AnalysisParameters] = None\n    ) -> List[R]:\n        \"\"\"\n        Analyze multiple subjects.\n        \n        Args:\n            subjects: List of subjects to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            List of analysis results\n        \"\"\"\n        # Start performance timer\n        start_time = time.time()\n        \n        # Analyze each subject\n        results = []\n        for subject in subjects:\n            result = self.analyze(subject, parameters)\n            results.append(result)\n        \n        # Performance metrics\n        elapsed_time = time.time() - start_time\n        \n        return results\n    \n    def clear_cache(self) -> None:\n        \"\"\"Clear the analysis cache.\"\"\"\n        self._analysis_cache = {}\n    \n    def _generate_cache_key(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> str:\n        \"\"\"\n        Generate a cache key for a subject and parameters.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cache key string\n        \"\"\"\n        # Start with the subject ID\n        key = f\"subject_{subject_id}\"\n        \n        # Add parameter details if provided\n        if parameters:\n            param_dict = parameters.dict(exclude_none=True)\n            for k, v in sorted(param_dict.items()):\n                if k != \"custom_settings\":\n                    key += f\"_{k}_{v}\"\n                    \n            # Handle custom settings separately (they could be complex)\n            if parameters.custom_settings:\n                for k, v in sorted(parameters.custom_settings.items()):\n                    key += f\"_{k}_{v}\"\n        \n        return key\n    \n    def _get_from_cache(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> Optional[R]:\n        \"\"\"\n        Get a cached analysis result if available.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cached result or None if not found\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        return self._analysis_cache.get(cache_key)\n    \n    def _save_to_cache(\n        self, subject_id: Union[str, UUID], result: R, parameters: Optional[AnalysisParameters] = None\n    ) -> None:\n        \"\"\"\n        Save an analysis result to the cache.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            result: The analysis result to cache\n            parameters: Optional parameters to configure the analysis\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        self._analysis_cache[cache_key] = result",
                "class AnalysisResult(BaseModel, Generic[T]):\n    \"\"\"\n    Result of an analysis operation.\n    \n    Provides information about the analysis process and outcome.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    subject_id: Optional[Union[str, UUID]] = None\n    subject_type: str\n    analysis_type: str\n    analysis_date: datetime = Field(default_factory=datetime.now)\n    processing_time_ms: Optional[float] = None\n    result_summary: Dict[str, Any] = Field(default_factory=dict)\n    detailed_results: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class AnalysisParameters(BaseModel):\n    \"\"\"\n    Parameters for an analysis operation.\n    \n    Used to configure analysis options and settings.\n    \"\"\"\n    \n    period_start: Optional[Union[date, datetime]] = None\n    period_end: Optional[Union[date, datetime]] = None\n    include_details: bool = True\n    calculation_mode: str = \"standard\"  # \"standard\", \"detailed\", \"fast\"\n    grouping: Optional[str] = None\n    custom_settings: Dict[str, Any] = Field(default_factory=dict)"
            ]
        }
    },
    "unified/personal_finance_tracker/expense/models.py": {
        "logprobs": -1064.165037096348,
        "metrics": {
            "loc": 154,
            "sloc": 87,
            "lloc": 106,
            "comments": 11,
            "multi": 18,
            "blank": 34,
            "cyclomatic": 23,
            "internal_imports": [
                "class AuditRecord(BaseModel):\n    \"\"\"\n    Record of a categorization action for audit purposes.\n    \n    Tracks changes for accountability and analysis.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    item_id: Union[str, UUID]\n    action: str\n    timestamp: datetime = Field(default_factory=datetime.now)\n    previous_state: Dict[str, Any] = Field(default_factory=dict)\n    new_state: Dict[str, Any] = Field(default_factory=dict)\n    user_id: Optional[str] = None\n    notes: Optional[str] = None",
                "class CategorizationResult(BaseModel, Generic[T]):\n    \"\"\"\n    Result of a categorization operation.\n    \n    Provides information about the categorization process and outcome.\n    \"\"\"\n    \n    item_id: Union[str, UUID]\n    original_item: T\n    assigned_category: Optional[str] = None\n    confidence_score: float  # 0.0 to 1.0\n    matched_rule: Optional[Rule] = None\n    processing_time_ms: Optional[float] = None\n    notes: Optional[str] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class MixedUseItem(BaseModel):\n    \"\"\"\n    Model for tracking items that are partially business and partially personal.\n    \n    Used in expense categorization to handle items used for both business\n    and personal purposes.\n    \"\"\"\n    \n    id: Union[str, UUID]\n    name: str\n    category: str\n    business_use_percentage: float\n    description: Optional[str] = None",
                "class BaseTransaction(BaseModel):\n    \"\"\"\n    Base transaction model for all financial transactions.\n    \n    This abstract base class provides common fields for tracking\n    financial transactions across different persona implementations.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    date: Union[date, datetime]\n    amount: float\n    description: str\n    transaction_type: TransactionType\n    \n    # Optional fields\n    account_id: Optional[str] = None\n    category: Optional[str] = None\n    tags: List[str] = Field(default_factory=list)\n    notes: Optional[str] = None\n    \n    @validator(\"amount\")\n    def validate_amount(cls, v):\n        \"\"\"Validate that amount is a valid number.\"\"\"\n        if not isinstance(v, (int, float)):\n            raise ValueError(\"Amount must be a number\")\n        return v",
                "class BaseCategory(BaseModel):\n    \"\"\"\n    Base category model for all categorization systems.\n    \n    This abstract base class provides common fields for categorizing\n    financial data across different persona implementations.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    type: CategoryType\n    description: Optional[str] = None\n    parent_id: Optional[Union[str, UUID]] = None\n    is_active: bool = True\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True\n        \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert the category to a dictionary.\"\"\"\n        return self.dict()",
                "class ExpenseCategory(str, Enum):\n    \"\"\"Expense category enum.\"\"\"\n\n    BUSINESS_SUPPLIES = \"business_supplies\"\n    SOFTWARE = \"software\"\n    MARKETING = \"marketing\"\n    OFFICE_RENT = \"office_rent\"\n    UTILITIES = \"utilities\"\n    TRAVEL = \"travel\"\n    MEALS = \"meals\"\n    EQUIPMENT = \"equipment\"\n    PROFESSIONAL_DEVELOPMENT = \"professional_development\"\n    PROFESSIONAL_SERVICES = \"professional_services\"\n    HEALTH_INSURANCE = \"health_insurance\"\n    RETIREMENT = \"retirement\"\n    PHONE = \"phone\"\n    INTERNET = \"internet\"\n    CAR = \"car\"\n    HOME_OFFICE = \"home_office\"\n    PERSONAL = \"personal\"\n    OTHER = \"other\"",
                "class Transaction(BusinessTransaction):\n    \"\"\"\n    Transaction model for the Personal Finance Tracker.\n    \n    Extends the BusinessTransaction from the common library with\n    freelancer-specific fields and behaviors.\n    \"\"\"\n\n    # Override category field to use our specific ExpenseCategory enum\n    category: Optional[ExpenseCategory] = None\n    \n    # Make sure the account_id is required\n    account_id: str\n\n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        # This is necessary to allow field overrides\n        extra = \"allow\"",
                "class ExpenseRule(Rule):\n    \"\"\"Rule for expense categorization.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    name: str\n    category: ExpenseCategory\n    match_field: str = \"description\"  # Field that matches pattern\n    pattern: str = \"\"\n    created_at: datetime = Field(default_factory=datetime.now)\n    updated_at: Optional[datetime] = None\n    is_active: bool = True\n    priority: int = 0\n    \n    # Rule conditions (at least one must be provided)\n    keyword_patterns: List[str] = Field(default_factory=list)\n    merchant_patterns: List[str] = Field(default_factory=list)\n    amount_min: Optional[float] = None\n    amount_max: Optional[float] = None\n    \n    # Business use percentage\n    business_use_percentage: float = 100.0\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True\n    \n    @validator(\"business_use_percentage\")\n    def validate_percentage(cls, v):\n        \"\"\"Validate business use percentage is between 0 and 100.\"\"\"\n        if v < 0 or v > 100:\n            raise ValueError(\"Business use percentage must be between 0 and 100\")\n        return v\n    \n    def matches(self, item: Union[Transaction, BaseTransaction]) -> bool:\n        \"\"\"\n        Check if transaction matches this rule.\n        \n        Args:\n            item: The transaction to check\n            \n        Returns:\n            True if the rule matches, False otherwise\n        \"\"\"\n        # Skip if rule is inactive\n        if not self.is_active:\n            return False\n        \n        # Check amount range if specified\n        if self.amount_min is not None and item.amount < self.amount_min:\n            return False\n        \n        if self.amount_max is not None and item.amount > self.amount_max:\n            return False\n        \n        # Check description against keyword patterns\n        description_match = False\n        if not self.keyword_patterns:\n            description_match = True  # No patterns means automatic match\n        else:\n            for pattern in self.keyword_patterns:\n                if re.search(pattern, item.description, re.IGNORECASE):\n                    description_match = True\n                    break\n        \n        if not description_match:\n            return False\n        \n        # Check merchant name if available (assumed to be in tags)\n        merchant_match = False\n        if not self.merchant_patterns:\n            merchant_match = True  # No patterns means automatic match\n        else:\n            for tag in item.tags:\n                for pattern in self.merchant_patterns:\n                    if re.search(pattern, tag, re.IGNORECASE):\n                        merchant_match = True\n                        break\n                if merchant_match:\n                    break\n        \n        if not merchant_match:\n            return False\n        \n        # All conditions matched\n        return True\n    \n    def apply(self, item: Union[Transaction, BaseTransaction]) -> Dict[str, Any]:\n        \"\"\"\n        Apply this rule to a transaction by returning fields to update.\n        \n        Args:\n            item: The transaction to categorize\n            \n        Returns:\n            Dictionary with category and business use percentage\n        \"\"\"\n        return {\n            \"category\": self.category,\n            \"business_use_percentage\": self.business_use_percentage,\n            \"metadata\": {\n                \"rule_name\": self.name,\n                \"is_mixed_use\": self.business_use_percentage < 100.0,\n            }\n        }\n    \n    def get_match_metadata(self) -> Dict[str, Any]:\n        \"\"\"\n        Get metadata about this rule for matching purposes.\n        \n        Returns:\n            Dictionary with rule metadata\n        \"\"\"\n        return {\n            \"keyword_patterns\": self.keyword_patterns,\n            \"merchant_patterns\": self.merchant_patterns,\n            \"amount_min\": self.amount_min,\n            \"amount_max\": self.amount_max,\n            \"business_use_percentage\": self.business_use_percentage\n        }"
            ]
        }
    },
    "unified/personal_finance_tracker/expense/categorizer.py": {
        "logprobs": -1782.9576762960153,
        "metrics": {
            "loc": 516,
            "sloc": 266,
            "lloc": 175,
            "comments": 59,
            "multi": 91,
            "blank": 98,
            "cyclomatic": 57,
            "internal_imports": [
                "class BaseCategorizer(Generic[T, R], ABC):\n    \"\"\"\n    Abstract base class for categorization engines.\n    \n    Defines the core interface and functionality for all categorizers\n    across different persona implementations.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the categorizer.\"\"\"\n        self.rules: List[Rule] = []\n        self.audit_trail: List[AuditRecord] = []\n        self._categorization_cache: Dict[str, R] = {}\n        \n    def add_rule(self, rule: Rule) -> Rule:\n        \"\"\"\n        Add a new rule to the categorizer.\n        \n        Args:\n            rule: The rule to add\n            \n        Returns:\n            The added rule\n        \"\"\"\n        # Check for duplicate rule ID\n        if any(r.id == rule.id for r in self.rules):\n            raise ValueError(f\"Rule with ID {rule.id} already exists\")\n        \n        # Add the rule\n        self.rules.append(rule)\n        \n        # Sort rules by priority (highest first)\n        self.rules.sort(key=lambda r: r.priority, reverse=True)\n        \n        # Clear cache since rules have changed\n        self._categorization_cache = {}\n        \n        return rule\n    \n    def update_rule(self, rule: Rule) -> Rule:\n        \"\"\"\n        Update an existing rule.\n        \n        Args:\n            rule: The rule to update\n            \n        Returns:\n            The updated rule\n        \"\"\"\n        # Find the rule to update\n        for i, existing_rule in enumerate(self.rules):\n            if existing_rule.id == rule.id:\n                # Update the rule\n                rule.updated_at = datetime.now()\n                self.rules[i] = rule\n                \n                # Sort rules by priority (highest first)\n                self.rules.sort(key=lambda r: r.priority, reverse=True)\n                \n                # Clear cache since rules have changed\n                self._categorization_cache = {}\n                \n                return rule\n        \n        raise ValueError(f\"Rule with ID {rule.id} not found\")\n    \n    def remove_rule(self, rule_id: Union[str, UUID]) -> bool:\n        \"\"\"\n        Remove a rule.\n        \n        Args:\n            rule_id: ID of the rule to remove\n            \n        Returns:\n            True if the rule was removed, False otherwise\n        \"\"\"\n        # Find the rule to remove\n        for i, rule in enumerate(self.rules):\n            if rule.id == rule_id:\n                # Remove the rule\n                del self.rules[i]\n                \n                # Clear cache since rules have changed\n                self._categorization_cache = {}\n                \n                return True\n        \n        return False\n    \n    def get_rules(self) -> List[Rule]:\n        \"\"\"\n        Get all rules.\n        \n        Returns:\n            List of all rules\n        \"\"\"\n        return self.rules\n    \n    def get_audit_trail(\n        self, item_id: Optional[Union[str, UUID]] = None, limit: int = 100\n    ) -> List[AuditRecord]:\n        \"\"\"\n        Get the audit trail for categorization actions.\n        \n        Args:\n            item_id: Optional item ID to filter by\n            limit: Maximum number of records to return\n            \n        Returns:\n            List of audit records\n        \"\"\"\n        if item_id:\n            # Filter to specific item\n            filtered_trail = [\n                record\n                for record in self.audit_trail\n                if record.item_id == item_id\n            ]\n        else:\n            filtered_trail = self.audit_trail\n        \n        # Sort by timestamp (newest first) and limit\n        sorted_trail = sorted(filtered_trail, key=lambda r: r.timestamp, reverse=True)\n        \n        return sorted_trail[:limit]\n    \n    def clear_cache(self) -> None:\n        \"\"\"Clear the categorization cache.\"\"\"\n        self._categorization_cache = {}\n    \n    @abstractmethod\n    def categorize(self, item: T, recategorize: bool = False) -> R:\n        \"\"\"\n        Categorize a single item.\n        \n        Args:\n            item: The item to categorize\n            recategorize: Whether to recategorize even if already categorized\n            \n        Returns:\n            Categorization result\n        \"\"\"\n        pass\n    \n    def categorize_batch(self, items: List[T], recategorize: bool = False) -> List[R]:\n        \"\"\"\n        Categorize multiple items.\n        \n        Args:\n            items: List of items to categorize\n            recategorize: Whether to recategorize even if already categorized\n            \n        Returns:\n            List of categorization results\n        \"\"\"\n        # Start performance timer\n        start_time = time.time()\n        \n        # Categorize each item\n        results = []\n        for item in items:\n            result = self.categorize(item, recategorize)\n            results.append(result)\n        \n        # Performance metrics\n        elapsed_time = time.time() - start_time\n        \n        return results\n    \n    def record_audit(\n        self,\n        item_id: Union[str, UUID],\n        action: str,\n        previous_state: Dict[str, Any],\n        new_state: Dict[str, Any],\n        notes: Optional[str] = None,\n    ) -> AuditRecord:\n        \"\"\"\n        Record an action in the audit trail.\n        \n        Args:\n            item_id: ID of the item being modified\n            action: Type of action performed\n            previous_state: State before the action\n            new_state: State after the action\n            notes: Optional notes about the action\n            \n        Returns:\n            The created audit record\n        \"\"\"\n        audit_record = AuditRecord(\n            item_id=item_id,\n            action=action,\n            previous_state=previous_state,\n            new_state=new_state,\n            notes=notes,\n        )\n        \n        self.audit_trail.append(audit_record)\n        \n        return audit_record",
                "class CategorizationResult(BaseModel, Generic[T]):\n    \"\"\"\n    Result of a categorization operation.\n    \n    Provides information about the categorization process and outcome.\n    \"\"\"\n    \n    item_id: Union[str, UUID]\n    original_item: T\n    assigned_category: Optional[str] = None\n    confidence_score: float  # 0.0 to 1.0\n    matched_rule: Optional[Rule] = None\n    processing_time_ms: Optional[float] = None\n    notes: Optional[str] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class AuditRecord(BaseModel):\n    \"\"\"\n    Record of a categorization action for audit purposes.\n    \n    Tracks changes for accountability and analysis.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    item_id: Union[str, UUID]\n    action: str\n    timestamp: datetime = Field(default_factory=datetime.now)\n    previous_state: Dict[str, Any] = Field(default_factory=dict)\n    new_state: Dict[str, Any] = Field(default_factory=dict)\n    user_id: Optional[str] = None\n    notes: Optional[str] = None",
                "class TransactionCategorizer(BaseCategorizer[BaseTransaction, CategorizationResult[BaseTransaction]]):\n    \"\"\"\n    Categorizer for financial transactions.\n    \n    Handles categorization of transactions based on rules and mixed-use items.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the transaction categorizer.\"\"\"\n        super().__init__()\n        self.mixed_use_items: List[MixedUseItem] = []\n    \n    def add_mixed_use_item(self, item: MixedUseItem) -> MixedUseItem:\n        \"\"\"\n        Add a new mixed-use item.\n        \n        Args:\n            item: The mixed-use item to add\n            \n        Returns:\n            The added item\n        \"\"\"\n        # Check for duplicate item ID\n        if any(i.id == item.id for i in self.mixed_use_items):\n            raise ValueError(f\"Mixed-use item with ID {item.id} already exists\")\n        \n        # Add the item\n        self.mixed_use_items.append(item)\n        \n        # Clear cache\n        self._categorization_cache = {}\n        \n        return item\n    \n    def categorize(\n        self, transaction: BaseTransaction, recategorize: bool = False\n    ) -> CategorizationResult[BaseTransaction]:\n        \"\"\"\n        Categorize a transaction using the defined rules.\n        \n        Args:\n            transaction: The transaction to categorize\n            recategorize: Whether to recategorize even if already categorized\n            \n        Returns:\n            CategorizationResult with the categorization details\n        \"\"\"\n        # Start performance timer\n        start_time = time.time()\n        \n        # Skip non-expense transactions if desired\n        if hasattr(transaction, 'transaction_type'):\n            if getattr(transaction, 'transaction_type') != TransactionType.EXPENSE:\n                result = CategorizationResult(\n                    item_id=transaction.id,\n                    original_item=transaction,\n                    confidence_score=0.0,\n                    processing_time_ms=(time.time() - start_time) * 1000,\n                    notes=\"Non-expense transaction\",\n                )\n                return result\n        \n        # Check cache unless forced to recategorize\n        cache_key = str(transaction.id)\n        if not recategorize and cache_key in self._categorization_cache:\n            return self._categorization_cache[cache_key]\n        \n        # Skip if already categorized and not forced to recategorize\n        if (\n            not recategorize \n            and hasattr(transaction, 'category') \n            and getattr(transaction, 'category') is not None\n        ):\n            # For business transactions, check business use percentage\n            business_use_percentage = None\n            if hasattr(transaction, 'business_use_percentage'):\n                business_use_percentage = getattr(transaction, 'business_use_percentage')\n                \n            result = CategorizationResult(\n                item_id=transaction.id,\n                original_item=transaction,\n                assigned_category=transaction.category,\n                business_use_percentage=business_use_percentage,\n                confidence_score=1.0,  # Already categorized, so high confidence\n                processing_time_ms=(time.time() - start_time) * 1000,\n                notes=\"Transaction was already categorized\",\n            )\n            \n            self._categorization_cache[cache_key] = result\n            return result\n        \n        # Check if this matches a known mixed-use item\n        mixed_use_match = None\n        for item in self.mixed_use_items:\n            if (\n                hasattr(transaction, 'description') \n                and item.name.lower() in getattr(transaction, 'description', '').lower()\n            ):\n                mixed_use_match = item\n                break\n        \n        # Apply categorization rules\n        matched_rule = None\n        for rule in self.rules:\n            if rule.matches(transaction):\n                matched_rule = rule\n                break\n        \n        # Determine category and business use percentage\n        category = None\n        business_percentage = None\n        is_mixed_use = False\n        confidence = 0.5\n        notes = \"No matching rules or mixed-use items\"\n        metadata = {}\n        \n        if mixed_use_match:\n            category = mixed_use_match.category\n            business_percentage = mixed_use_match.business_use_percentage\n            is_mixed_use = True\n            confidence = 0.9\n            notes = f\"Matched mixed-use item: {mixed_use_match.name}\"\n            metadata[\"mixed_use_item_id\"] = str(mixed_use_match.id)\n        elif matched_rule:\n            # Extract category and business percentage from rule\n            rule_result = matched_rule.apply(transaction)\n            category = rule_result.get(\"category\")\n            \n            if \"business_use_percentage\" in rule_result:\n                business_percentage = rule_result.get(\"business_use_percentage\")\n                is_mixed_use = business_percentage < 100 and business_percentage > 0\n                \n            confidence = 0.8\n            notes = f\"Matched rule: {matched_rule.name}\"\n            metadata[\"rule_id\"] = str(matched_rule.id)\n            \n        # Finalize processing time\n        processing_time_ms = (time.time() - start_time) * 1000\n        \n        # Create result\n        result = CategorizationResult(\n            item_id=transaction.id,\n            original_item=transaction,\n            assigned_category=category,\n            confidence_score=confidence,\n            matched_rule=matched_rule,\n            processing_time_ms=processing_time_ms,\n            notes=notes,\n            metadata={\n                \"is_mixed_use\": is_mixed_use,\n                \"business_use_percentage\": business_percentage,\n                **metadata,\n            },\n        )\n        \n        # Record audit trail\n        previous_state = {}\n        if hasattr(transaction, 'category'):\n            previous_state[\"category\"] = getattr(transaction, 'category')\n        if hasattr(transaction, 'business_use_percentage'):\n            previous_state[\"business_use_percentage\"] = getattr(transaction, 'business_use_percentage')\n        \n        new_state = {\n            \"category\": category,\n            \"business_use_percentage\": business_percentage,\n        }\n        \n        self.record_audit(\n            item_id=transaction.id,\n            action=\"categorize\",\n            previous_state=previous_state,\n            new_state=new_state,\n        )\n        \n        # Update cache\n        self._categorization_cache[cache_key] = result\n        \n        return result\n    \n    def apply_categorization(\n        self, transaction: BaseTransaction, result: CategorizationResult\n    ) -> BaseTransaction:\n        \"\"\"\n        Apply a categorization result to a transaction.\n        \n        Args:\n            transaction: The transaction to update\n            result: The categorization result to apply\n            \n        Returns:\n            The updated transaction\n        \"\"\"\n        # Record previous state for audit\n        previous_state = {}\n        if hasattr(transaction, 'category'):\n            previous_state[\"category\"] = getattr(transaction, 'category')\n        if hasattr(transaction, 'business_use_percentage'):\n            previous_state[\"business_use_percentage\"] = getattr(transaction, 'business_use_percentage')\n        \n        # Apply categorization if possible\n        if hasattr(transaction, 'category') and result.assigned_category is not None:\n            setattr(transaction, 'category', result.assigned_category)\n            \n        if (\n            hasattr(transaction, 'business_use_percentage') \n            and result.metadata.get('business_use_percentage') is not None\n        ):\n            setattr(\n                transaction, \n                'business_use_percentage', \n                result.metadata['business_use_percentage']\n            )\n        \n        # Record audit trail\n        new_state = {}\n        if hasattr(transaction, 'category'):\n            new_state[\"category\"] = getattr(transaction, 'category')\n        if hasattr(transaction, 'business_use_percentage'):\n            new_state[\"business_use_percentage\"] = getattr(transaction, 'business_use_percentage')\n        \n        self.record_audit(\n            item_id=transaction.id,\n            action=\"apply_categorization\",\n            previous_state=previous_state,\n            new_state=new_state,\n        )\n        \n        # Clear cache for this transaction\n        cache_key = str(transaction.id)\n        if cache_key in self._categorization_cache:\n            del self._categorization_cache[cache_key]\n        \n        return transaction",
                "class MixedUseItem(BaseModel):\n    \"\"\"\n    Model for tracking items that are partially business and partially personal.\n    \n    Used in expense categorization to handle items used for both business\n    and personal purposes.\n    \"\"\"\n    \n    id: Union[str, UUID]\n    name: str\n    category: str\n    business_use_percentage: float\n    description: Optional[str] = None",
                "class Timer:\n    \"\"\"Utility for measuring execution time.\"\"\"\n    \n    def __init__(self, name: Optional[str] = None):\n        \"\"\"\n        Initialize the timer.\n        \n        Args:\n            name: Optional name for the timer\n        \"\"\"\n        self.name = name\n        self.start_time: Optional[float] = None\n        self.end_time: Optional[float] = None\n    \n    def __enter__(self) -> 'Timer':\n        \"\"\"Start the timer when entering a context.\"\"\"\n        self.start()\n        return self\n    \n    def __exit__(self, *args: Any) -> None:\n        \"\"\"Stop the timer when exiting a context.\"\"\"\n        self.stop()\n    \n    def start(self) -> None:\n        \"\"\"Start the timer.\"\"\"\n        self.start_time = time.time()\n        self.end_time = None\n    \n    def stop(self) -> float:\n        \"\"\"\n        Stop the timer.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        self.end_time = time.time()\n        return self.elapsed_time\n    \n    @property\n    def elapsed_time(self) -> float:\n        \"\"\"\n        Get the elapsed time.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        end = self.end_time if self.end_time is not None else time.time()\n        return end - self.start_time\n    \n    @property\n    def elapsed_milliseconds(self) -> float:\n        \"\"\"\n        Get the elapsed time in milliseconds.\n        \n        Returns:\n            Elapsed time in milliseconds\n        \"\"\"\n        return self.elapsed_time * 1000",
                "class ExpenseCategory(str, Enum):\n    \"\"\"Expense category enum.\"\"\"\n\n    BUSINESS_SUPPLIES = \"business_supplies\"\n    SOFTWARE = \"software\"\n    MARKETING = \"marketing\"\n    OFFICE_RENT = \"office_rent\"\n    UTILITIES = \"utilities\"\n    TRAVEL = \"travel\"\n    MEALS = \"meals\"\n    EQUIPMENT = \"equipment\"\n    PROFESSIONAL_DEVELOPMENT = \"professional_development\"\n    PROFESSIONAL_SERVICES = \"professional_services\"\n    HEALTH_INSURANCE = \"health_insurance\"\n    RETIREMENT = \"retirement\"\n    PHONE = \"phone\"\n    INTERNET = \"internet\"\n    CAR = \"car\"\n    HOME_OFFICE = \"home_office\"\n    PERSONAL = \"personal\"\n    OTHER = \"other\"",
                "class Transaction(BusinessTransaction):\n    \"\"\"\n    Transaction model for the Personal Finance Tracker.\n    \n    Extends the BusinessTransaction from the common library with\n    freelancer-specific fields and behaviors.\n    \"\"\"\n\n    # Override category field to use our specific ExpenseCategory enum\n    category: Optional[ExpenseCategory] = None\n    \n    # Make sure the account_id is required\n    account_id: str\n\n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        # This is necessary to allow field overrides\n        extra = \"allow\"",
                "class MixedUseItem(CommonMixedUseItem):\n    \"\"\"Item with mixed business and personal use.\n    \n    Extends the common library's MixedUseItem with freelancer-specific functionality.\n    \"\"\"\n\n    # Override category field to use ExpenseCategory\n    category: ExpenseCategory\n    \n    # Additional freelancer-specific fields\n    documentation: Optional[str] = None\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class MixedUseItem(CommonMixedUseItem):\n    \"\"\"Item with mixed business and personal use.\n    \n    Extends the common library's MixedUseItem with freelancer-specific functionality.\n    \"\"\"\n\n    # Override category field to use ExpenseCategory\n    category: ExpenseCategory\n    \n    # Additional freelancer-specific fields\n    documentation: Optional[str] = None\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class MixedUseItem(CommonMixedUseItem):\n    \"\"\"Item with mixed business and personal use.\n    \n    Extends the common library's MixedUseItem with freelancer-specific functionality.\n    \"\"\"\n\n    # Override category field to use ExpenseCategory\n    category: ExpenseCategory\n    \n    # Additional freelancer-specific fields\n    documentation: Optional[str] = None\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class CategorizationResult(BaseModel):\n    \"\"\"Result of an expense categorization.\"\"\"\n\n    transaction_id: UUID\n    original_transaction: Transaction\n    assigned_category: Optional[ExpenseCategory] = None\n    business_use_percentage: Optional[float] = None\n    confidence_score: float = 0.0  # 0-1 confidence in categorization\n    is_mixed_use: bool = False\n    categorization_date: datetime = Field(default_factory=datetime.now)\n    notes: Optional[str] = None\n    matched_rule: Optional[Any] = None  # We don't use the type directly to avoid circular imports\n\n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True\n\n    @validator(\"confidence_score\")\n    def validate_confidence(cls, v):\n        \"\"\"Validate confidence score is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Confidence score must be between 0 and 1\")\n        return v\n\n    @validator(\"business_use_percentage\")\n    def validate_percentage(cls, v):\n        \"\"\"Validate business use percentage is between 0 and 100.\"\"\"\n        if v is not None and (v < 0 or v > 100):\n            raise ValueError(\"Business use percentage must be between 0 and 100\")\n        return v\n\n    @classmethod\n    def from_common_result(cls, result: CommonCategorizationResult, transaction_id: UUID = None) -> \"CategorizationResult\":\n        \"\"\"\n        Convert a common CategorizationResult to our specialized version.\n        \n        Args:\n            result: The common result to convert\n            transaction_id: Optional transaction ID override\n            \n        Returns:\n            Our specialized CategorizationResult\n        \"\"\"\n        # Extract business use percentage from metadata\n        business_use_percentage = None\n        if hasattr(result, 'metadata') and result.metadata:\n            business_use_percentage = result.metadata.get(\"business_use_percentage\")\n        \n        # Extract is_mixed_use from metadata\n        is_mixed_use = False\n        if hasattr(result, 'metadata') and result.metadata:\n            is_mixed_use = result.metadata.get(\"is_mixed_use\", False)\n        \n        return cls(\n            transaction_id=transaction_id or result.item_id,\n            original_transaction=result.original_item,\n            matched_rule=result.matched_rule,\n            assigned_category=result.assigned_category,\n            business_use_percentage=business_use_percentage,\n            confidence_score=result.confidence_score,\n            is_mixed_use=is_mixed_use,\n            notes=result.notes,\n        )",
                "class CategorizationResult(BaseModel):\n    \"\"\"Result of an expense categorization.\"\"\"\n\n    transaction_id: UUID\n    original_transaction: Transaction\n    assigned_category: Optional[ExpenseCategory] = None\n    business_use_percentage: Optional[float] = None\n    confidence_score: float = 0.0  # 0-1 confidence in categorization\n    is_mixed_use: bool = False\n    categorization_date: datetime = Field(default_factory=datetime.now)\n    notes: Optional[str] = None\n    matched_rule: Optional[Any] = None  # We don't use the type directly to avoid circular imports\n\n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True\n\n    @validator(\"confidence_score\")\n    def validate_confidence(cls, v):\n        \"\"\"Validate confidence score is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Confidence score must be between 0 and 1\")\n        return v\n\n    @validator(\"business_use_percentage\")\n    def validate_percentage(cls, v):\n        \"\"\"Validate business use percentage is between 0 and 100.\"\"\"\n        if v is not None and (v < 0 or v > 100):\n            raise ValueError(\"Business use percentage must be between 0 and 100\")\n        return v\n\n    @classmethod\n    def from_common_result(cls, result: CommonCategorizationResult, transaction_id: UUID = None) -> \"CategorizationResult\":\n        \"\"\"\n        Convert a common CategorizationResult to our specialized version.\n        \n        Args:\n            result: The common result to convert\n            transaction_id: Optional transaction ID override\n            \n        Returns:\n            Our specialized CategorizationResult\n        \"\"\"\n        # Extract business use percentage from metadata\n        business_use_percentage = None\n        if hasattr(result, 'metadata') and result.metadata:\n            business_use_percentage = result.metadata.get(\"business_use_percentage\")\n        \n        # Extract is_mixed_use from metadata\n        is_mixed_use = False\n        if hasattr(result, 'metadata') and result.metadata:\n            is_mixed_use = result.metadata.get(\"is_mixed_use\", False)\n        \n        return cls(\n            transaction_id=transaction_id or result.item_id,\n            original_transaction=result.original_item,\n            matched_rule=result.matched_rule,\n            assigned_category=result.assigned_category,\n            business_use_percentage=business_use_percentage,\n            confidence_score=result.confidence_score,\n            is_mixed_use=is_mixed_use,\n            notes=result.notes,\n        )",
                "class CategorizationResult(BaseModel):\n    \"\"\"Result of an expense categorization.\"\"\"\n\n    transaction_id: UUID\n    original_transaction: Transaction\n    assigned_category: Optional[ExpenseCategory] = None\n    business_use_percentage: Optional[float] = None\n    confidence_score: float = 0.0  # 0-1 confidence in categorization\n    is_mixed_use: bool = False\n    categorization_date: datetime = Field(default_factory=datetime.now)\n    notes: Optional[str] = None\n    matched_rule: Optional[Any] = None  # We don't use the type directly to avoid circular imports\n\n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True\n\n    @validator(\"confidence_score\")\n    def validate_confidence(cls, v):\n        \"\"\"Validate confidence score is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Confidence score must be between 0 and 1\")\n        return v\n\n    @validator(\"business_use_percentage\")\n    def validate_percentage(cls, v):\n        \"\"\"Validate business use percentage is between 0 and 100.\"\"\"\n        if v is not None and (v < 0 or v > 100):\n            raise ValueError(\"Business use percentage must be between 0 and 100\")\n        return v\n\n    @classmethod\n    def from_common_result(cls, result: CommonCategorizationResult, transaction_id: UUID = None) -> \"CategorizationResult\":\n        \"\"\"\n        Convert a common CategorizationResult to our specialized version.\n        \n        Args:\n            result: The common result to convert\n            transaction_id: Optional transaction ID override\n            \n        Returns:\n            Our specialized CategorizationResult\n        \"\"\"\n        # Extract business use percentage from metadata\n        business_use_percentage = None\n        if hasattr(result, 'metadata') and result.metadata:\n            business_use_percentage = result.metadata.get(\"business_use_percentage\")\n        \n        # Extract is_mixed_use from metadata\n        is_mixed_use = False\n        if hasattr(result, 'metadata') and result.metadata:\n            is_mixed_use = result.metadata.get(\"is_mixed_use\", False)\n        \n        return cls(\n            transaction_id=transaction_id or result.item_id,\n            original_transaction=result.original_item,\n            matched_rule=result.matched_rule,\n            assigned_category=result.assigned_category,\n            business_use_percentage=business_use_percentage,\n            confidence_score=result.confidence_score,\n            is_mixed_use=is_mixed_use,\n            notes=result.notes,\n        )",
                "class ExpenseSummary(BaseModel):\n    \"\"\"Summary of expenses by category.\"\"\"\n\n    period_start: datetime\n    period_end: datetime\n    total_expenses: float\n    business_expenses: float\n    personal_expenses: float\n    by_category: Dict[ExpenseCategory, float] = Field(default_factory=dict)\n    generation_date: datetime = Field(default_factory=datetime.now)",
                "class ExpenseSummary(BaseModel):\n    \"\"\"Summary of expenses by category.\"\"\"\n\n    period_start: datetime\n    period_end: datetime\n    total_expenses: float\n    business_expenses: float\n    personal_expenses: float\n    by_category: Dict[ExpenseCategory, float] = Field(default_factory=dict)\n    generation_date: datetime = Field(default_factory=datetime.now)",
                "class ExpenseSummary(BaseModel):\n    \"\"\"Summary of expenses by category.\"\"\"\n\n    period_start: datetime\n    period_end: datetime\n    total_expenses: float\n    business_expenses: float\n    personal_expenses: float\n    by_category: Dict[ExpenseCategory, float] = Field(default_factory=dict)\n    generation_date: datetime = Field(default_factory=datetime.now)",
                "class AuditRecord(BaseModel):\n    \"\"\"Audit record for expense categorization.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    transaction_id: UUID\n    timestamp: datetime = Field(default_factory=datetime.now)\n    action: str  # e.g., \"categorize\", \"recategorize\", \"mark_business\", \"mark_personal\"\n    previous_state: Optional[Dict] = None\n    new_state: Dict\n    user_id: Optional[str] = None\n    notes: Optional[str] = None\n    \n    @classmethod\n    def from_common_audit(cls, record: CommonAuditRecord) -> \"AuditRecord\":\n        \"\"\"\n        Convert a common AuditRecord to our specialized version.\n        \n        Args:\n            record: The common audit record to convert\n            \n        Returns:\n            Our specialized AuditRecord\n        \"\"\"\n        return cls(\n            id=record.id,\n            transaction_id=record.item_id,\n            timestamp=record.timestamp,\n            action=record.action,\n            previous_state=record.previous_state,\n            new_state=record.new_state,\n            user_id=record.user_id,\n            notes=record.notes,\n        )",
                "class AuditRecord(BaseModel):\n    \"\"\"Audit record for expense categorization.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    transaction_id: UUID\n    timestamp: datetime = Field(default_factory=datetime.now)\n    action: str  # e.g., \"categorize\", \"recategorize\", \"mark_business\", \"mark_personal\"\n    previous_state: Optional[Dict] = None\n    new_state: Dict\n    user_id: Optional[str] = None\n    notes: Optional[str] = None\n    \n    @classmethod\n    def from_common_audit(cls, record: CommonAuditRecord) -> \"AuditRecord\":\n        \"\"\"\n        Convert a common AuditRecord to our specialized version.\n        \n        Args:\n            record: The common audit record to convert\n            \n        Returns:\n            Our specialized AuditRecord\n        \"\"\"\n        return cls(\n            id=record.id,\n            transaction_id=record.item_id,\n            timestamp=record.timestamp,\n            action=record.action,\n            previous_state=record.previous_state,\n            new_state=record.new_state,\n            user_id=record.user_id,\n            notes=record.notes,\n        )",
                "class AuditRecord(BaseModel):\n    \"\"\"Audit record for expense categorization.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    transaction_id: UUID\n    timestamp: datetime = Field(default_factory=datetime.now)\n    action: str  # e.g., \"categorize\", \"recategorize\", \"mark_business\", \"mark_personal\"\n    previous_state: Optional[Dict] = None\n    new_state: Dict\n    user_id: Optional[str] = None\n    notes: Optional[str] = None\n    \n    @classmethod\n    def from_common_audit(cls, record: CommonAuditRecord) -> \"AuditRecord\":\n        \"\"\"\n        Convert a common AuditRecord to our specialized version.\n        \n        Args:\n            record: The common audit record to convert\n            \n        Returns:\n            Our specialized AuditRecord\n        \"\"\"\n        return cls(\n            id=record.id,\n            transaction_id=record.item_id,\n            timestamp=record.timestamp,\n            action=record.action,\n            previous_state=record.previous_state,\n            new_state=record.new_state,\n            user_id=record.user_id,\n            notes=record.notes,\n        )",
                "class ExpenseRule(Rule):\n    \"\"\"Rule for expense categorization.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    name: str\n    category: ExpenseCategory\n    match_field: str = \"description\"  # Field that matches pattern\n    pattern: str = \"\"\n    created_at: datetime = Field(default_factory=datetime.now)\n    updated_at: Optional[datetime] = None\n    is_active: bool = True\n    priority: int = 0\n    \n    # Rule conditions (at least one must be provided)\n    keyword_patterns: List[str] = Field(default_factory=list)\n    merchant_patterns: List[str] = Field(default_factory=list)\n    amount_min: Optional[float] = None\n    amount_max: Optional[float] = None\n    \n    # Business use percentage\n    business_use_percentage: float = 100.0\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True\n    \n    @validator(\"business_use_percentage\")\n    def validate_percentage(cls, v):\n        \"\"\"Validate business use percentage is between 0 and 100.\"\"\"\n        if v < 0 or v > 100:\n            raise ValueError(\"Business use percentage must be between 0 and 100\")\n        return v\n    \n    def matches(self, item: Union[Transaction, BaseTransaction]) -> bool:\n        \"\"\"\n        Check if transaction matches this rule.\n        \n        Args:\n            item: The transaction to check\n            \n        Returns:\n            True if the rule matches, False otherwise\n        \"\"\"\n        # Skip if rule is inactive\n        if not self.is_active:\n            return False\n        \n        # Check amount range if specified\n        if self.amount_min is not None and item.amount < self.amount_min:\n            return False\n        \n        if self.amount_max is not None and item.amount > self.amount_max:\n            return False\n        \n        # Check description against keyword patterns\n        description_match = False\n        if not self.keyword_patterns:\n            description_match = True  # No patterns means automatic match\n        else:\n            for pattern in self.keyword_patterns:\n                if re.search(pattern, item.description, re.IGNORECASE):\n                    description_match = True\n                    break\n        \n        if not description_match:\n            return False\n        \n        # Check merchant name if available (assumed to be in tags)\n        merchant_match = False\n        if not self.merchant_patterns:\n            merchant_match = True  # No patterns means automatic match\n        else:\n            for tag in item.tags:\n                for pattern in self.merchant_patterns:\n                    if re.search(pattern, tag, re.IGNORECASE):\n                        merchant_match = True\n                        break\n                if merchant_match:\n                    break\n        \n        if not merchant_match:\n            return False\n        \n        # All conditions matched\n        return True\n    \n    def apply(self, item: Union[Transaction, BaseTransaction]) -> Dict[str, Any]:\n        \"\"\"\n        Apply this rule to a transaction by returning fields to update.\n        \n        Args:\n            item: The transaction to categorize\n            \n        Returns:\n            Dictionary with category and business use percentage\n        \"\"\"\n        return {\n            \"category\": self.category,\n            \"business_use_percentage\": self.business_use_percentage,\n            \"metadata\": {\n                \"rule_name\": self.name,\n                \"is_mixed_use\": self.business_use_percentage < 100.0,\n            }\n        }\n    \n    def get_match_metadata(self) -> Dict[str, Any]:\n        \"\"\"\n        Get metadata about this rule for matching purposes.\n        \n        Returns:\n            Dictionary with rule metadata\n        \"\"\"\n        return {\n            \"keyword_patterns\": self.keyword_patterns,\n            \"merchant_patterns\": self.merchant_patterns,\n            \"amount_min\": self.amount_min,\n            \"amount_max\": self.amount_max,\n            \"business_use_percentage\": self.business_use_percentage\n        }"
            ]
        }
    },
    "unified/personal_finance_tracker/project/profitability_analyzer.py": {
        "logprobs": -1259.5433836518803,
        "metrics": {
            "loc": 202,
            "sloc": 101,
            "lloc": 56,
            "comments": 20,
            "multi": 44,
            "blank": 35,
            "cyclomatic": 34,
            "internal_imports": [
                "class Project(BaseModel):\n    \"\"\"\n    Project model for tracking client projects.\n    \n    Used for organizing work, time tracking, and financial analysis\n    across multiple persona implementations.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    client_id: Optional[str] = None\n    start_date: Union[date, datetime]\n    end_date: Optional[Union[date, datetime]] = None\n    status: ProjectStatus = ProjectStatus.ACTIVE\n    hourly_rate: Optional[float] = None\n    fixed_price: Optional[float] = None\n    estimated_hours: Optional[float] = None\n    description: Optional[str] = None\n    tags: List[str] = Field(default_factory=list)\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    @validator(\"end_date\")\n    def validate_end_date(cls, v, values):\n        \"\"\"Validate that end_date is after start_date if both are provided.\"\"\"\n        if v is not None and \"start_date\" in values:\n            start = values[\"start_date\"]\n            if start > v:\n                raise ValueError(\"End date must be after start date\")\n        return v\n    \n    @validator(\"hourly_rate\", \"fixed_price\", \"estimated_hours\")\n    def validate_positive_numbers(cls, v):\n        \"\"\"Validate that financial amounts are positive numbers.\"\"\"\n        if v is not None and v < 0:\n            raise ValueError(\"Value must be a positive number\")\n        return v",
                "class Client(BaseModel):\n    \"\"\"\n    Client model for tracking information about clients.\n    \n    Used for organizing projects and managing client relationships.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    contact_email: Optional[str] = None\n    contact_phone: Optional[str] = None\n    address: Optional[str] = None\n    notes: Optional[str] = None\n    active: bool = True\n    metadata: Dict[str, Any] = Field(default_factory=dict)",
                "class TimeEntry(BaseModel):\n    \"\"\"\n    Time entry model for tracking hours worked on projects.\n    \n    Used for billing, project profitability analysis, and reporting.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    project_id: str\n    start_time: datetime\n    end_time: Optional[datetime] = None\n    duration_minutes: Optional[float] = None\n    description: str\n    billable: bool = True\n    tags: List[str] = Field(default_factory=list)\n    user_id: Optional[str] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    @validator(\"duration_minutes\", always=True)\n    def calculate_duration(cls, v, values):\n        \"\"\"Calculate duration from start and end time if not provided.\"\"\"\n        if v is not None:\n            return v\n        if (\n            \"start_time\" in values\n            and \"end_time\" in values\n            and values[\"end_time\"] is not None\n        ):\n            delta = values[\"end_time\"] - values[\"start_time\"]\n            return delta.total_seconds() / 60\n        return None\n    \n    @validator(\"end_time\")\n    def validate_end_time(cls, v, values):\n        \"\"\"Validate that end_time is after start_time if both are provided.\"\"\"\n        if v is not None and \"start_time\" in values:\n            if values[\"start_time\"] > v:\n                raise ValueError(\"End time must be after start time\")\n        return v",
                "class Invoice(BaseModel):\n    \"\"\"\n    Invoice model for tracking client billing.\n    \n    Used for revenue tracking, client relationship management, and tax reporting.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    client_id: str\n    project_id: Optional[str] = None\n    issue_date: Union[date, datetime]\n    due_date: Union[date, datetime]\n    amount: float\n    status: str  # e.g., \"draft\", \"sent\", \"paid\", \"overdue\"\n    payment_date: Optional[Union[date, datetime]] = None\n    description: Optional[str] = None\n    line_items: List[Dict[str, Any]] = Field(default_factory=list)\n    \n    @validator(\"due_date\")\n    def validate_due_date(cls, v, values):\n        \"\"\"Validate that due_date is after issue_date.\"\"\"\n        if \"issue_date\" in values:\n            if v < values[\"issue_date\"]:\n                raise ValueError(\"Due date must be after issue date\")\n        return v\n    \n    @validator(\"amount\")\n    def validate_amount(cls, v):\n        \"\"\"Validate that amount is a positive number.\"\"\"\n        if v < 0:\n            raise ValueError(\"Invoice amount must be a positive number\")\n        return v",
                "class BusinessTransaction(BaseTransaction):\n    \"\"\"\n    Transaction model for business transactions with additional fields.\n    \n    Extends the base transaction model with business-specific fields.\n    \"\"\"\n\n    business_use_percentage: Optional[float] = None\n    project_id: Optional[str] = None\n    client_id: Optional[str] = None\n    invoice_id: Optional[str] = None\n    receipt_path: Optional[str] = None\n    \n    @validator(\"business_use_percentage\")\n    def validate_business_percentage(cls, v):\n        \"\"\"Validate that business use percentage is between 0 and 100.\"\"\"\n        if v is not None and (v < 0 or v > 100):\n            raise ValueError(\"Business use percentage must be between 0 and 100\")\n        return v",
                "class TransactionType(str, Enum):\n    \"\"\"Transaction type enum for all financial transactions.\"\"\"\n\n    INCOME = \"income\"\n    EXPENSE = \"expense\"\n    TAX_PAYMENT = \"tax_payment\"\n    TRANSFER = \"transfer\"\n    INVESTMENT = \"investment\"\n    DIVIDEND = \"dividend\"\n    INTEREST = \"interest\"",
                "class ProjectMetricType(str, Enum):\n    \"\"\"Types of project profitability metrics.\"\"\"\n\n    HOURLY_RATE = \"hourly_rate\"\n    TOTAL_PROFIT = \"total_profit\"\n    PROFIT_MARGIN = \"profit_margin\"\n    ROI = \"roi\"",
                "class ProjectProfitability(BaseModel):\n    \"\"\"Project profitability analysis result.\"\"\"\n\n    project_id: str\n    project_name: str\n    client_id: str\n    start_date: datetime\n    end_date: Optional[datetime] = None\n    total_hours: float\n    total_revenue: float\n    total_expenses: float\n    total_profit: float\n    effective_hourly_rate: float\n    profit_margin: float  # Percentage\n    roi: float  # Return on investment\n    is_completed: bool\n    calculation_date: datetime = Field(default_factory=datetime.now)\n    metrics: List[ProfitabilityMetric] = Field(default_factory=list)\n\n    @validator(\"effective_hourly_rate\", \"profit_margin\", \"roi\", pre=True, always=True)\n    def validate_rates(cls, v, values):\n        \"\"\"Ensure rates are calculated correctly.\"\"\"\n        if v is not None:\n            return v\n\n        # If we have all required values, calculate the field\n        if (\n            \"total_hours\" in values\n            and \"total_revenue\" in values\n            and \"total_expenses\" in values\n        ):\n            hours = values[\"total_hours\"]\n            revenue = values[\"total_revenue\"]\n            expenses = values[\"total_expenses\"]\n\n            if values[\"current_field_name\"] == \"effective_hourly_rate\":\n                return revenue / max(hours, 0.01)  # Avoid division by zero\n\n            if values[\"current_field_name\"] == \"profit_margin\":\n                return 100 * (revenue - expenses) / max(revenue, 0.01)\n\n            if values[\"current_field_name\"] == \"roi\":\n                return (revenue - expenses) / max(expenses, 0.01)\n\n        return 0.0",
                "class ClientProfitability(BaseModel):\n    \"\"\"Client profitability analysis result.\"\"\"\n\n    client_id: str\n    client_name: str\n    number_of_projects: int\n    total_hours: float\n    total_revenue: float\n    total_expenses: float\n    total_profit: float\n    average_hourly_rate: float\n    average_profit_margin: float\n    average_invoice_payment_days: Optional[float] = None\n    projects: List[ProjectProfitability] = Field(default_factory=list)\n    calculation_date: datetime = Field(default_factory=datetime.now)",
                "class TrendAnalysis(BaseModel):\n    \"\"\"Trend analysis for project profitability over time.\"\"\"\n\n    metric_type: ProjectMetricType\n    project_id: Optional[str] = None\n    client_id: Optional[str] = None\n    period: str  # \"weekly\", \"monthly\", \"quarterly\", \"yearly\"\n    start_date: datetime\n    end_date: datetime\n    data_points: List[TrendPoint] = Field(default_factory=list)\n    calculation_date: datetime = Field(default_factory=datetime.now)\n    description: Optional[str] = None",
                "class TrendPoint(BaseModel):\n    \"\"\"Point in a trend analysis.\"\"\"\n\n    date: datetime\n    value: float",
                "class ProjectAnalyzer(BaseAnalyzer, Generic[T]):\n    \"\"\"\n    Project profitability analyzer for tracking project performance.\n    \n    This class analyzes project profitability based on time tracking, expenses,\n    and revenue data to help make informed business decisions.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the project analyzer.\"\"\"\n        super().__init__()\n        self._profitability_cache = Cache(max_size=100, expiration_seconds=3600)\n        \n    def analyze(self, subject: Any, parameters: Optional[Any] = None) -> Any:\n        \"\"\"\n        Analyze a subject based on parameters.\n        \n        This is a basic implementation of the abstract method from BaseAnalyzer.\n        Derived classes should override this with specific implementation.\n        \n        Args:\n            subject: The subject to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Analysis result\n        \"\"\"\n        if isinstance(subject, Project):\n            # If no specific parameters and subject is a Project,\n            # try to analyze project profitability with empty data\n            return self.analyze_project_profitability(\n                project=subject,\n                time_entries=[],\n                transactions=[],\n                invoices=[],\n                force_recalculation=True\n            )\n        \n        # Default implementation just returns a simple analysis result\n        return {\n            \"subject_id\": str(getattr(subject, \"id\", \"unknown\")),\n            \"subject_type\": type(subject).__name__,\n            \"analysis_type\": \"default\",\n            \"result\": \"No specific analysis available\"\n        }\n    \n    def analyze_project_profitability(\n        self,\n        project: Project,\n        time_entries: List[TimeEntry],\n        transactions: List[T],\n        invoices: List[Invoice],\n        force_recalculation: bool = False,\n    ) -> ProjectProfitability:\n        \"\"\"\n        Analyze the profitability of a single project.\n        \n        Args:\n            project: Project to analyze\n            time_entries: Time entries associated with the project\n            transactions: Transactions associated with the project\n            invoices: Invoices associated with the project\n            force_recalculation: Whether to force recalculation\n            \n        Returns:\n            ProjectProfitability analysis result\n        \"\"\"\n        # Performance measurement\n        with Timer(\"project_profitability_analysis\"):\n            # Check cache unless forced\n            cache_key = f\"project_{project.id}\"\n            if not force_recalculation:\n                cached_result = self._profitability_cache.get(cache_key)\n                if cached_result:\n                    return cached_result\n            \n            # Filter to entries for this project\n            project_time_entries = [e for e in time_entries if e.project_id == str(project.id)]\n            \n            # Calculate total hours\n            total_hours = sum(\n                entry.duration_minutes / 60\n                for entry in project_time_entries\n                if entry.duration_minutes is not None\n            )\n            \n            # Calculate total revenue from invoices\n            project_invoices = [i for i in invoices if i.project_id == str(project.id)]\n            paid_invoices = [i for i in project_invoices if i.status == \"paid\"]\n            total_revenue = sum(invoice.amount for invoice in paid_invoices)\n            \n            # Calculate total expenses - implementation-specific logic\n            project_expenses = self._filter_project_expenses(transactions, project.id)\n            total_expenses = sum(t.amount for t in project_expenses)\n            \n            # Calculate profitability metrics\n            total_profit = total_revenue - total_expenses\n            \n            # Avoid division by zero\n            effective_hourly_rate = total_revenue / max(total_hours, 0.01)\n            profit_margin = 100 * total_profit / max(total_revenue, 0.01)\n            roi = total_profit / max(total_expenses, 0.01)\n            \n            # Determine if project is completed\n            is_completed = (\n                project.end_date is not None and \n                (isinstance(project.end_date, datetime) and project.end_date <= datetime.now() or\n                 not isinstance(project.end_date, datetime) and project.end_date <= datetime.now().date())\n            )\n            \n            # Create project profitability result\n            result = ProjectProfitability(\n                project_id=str(project.id),\n                project_name=project.name,\n                client_id=str(project.client_id) if project.client_id else \"\",\n                start_date=project.start_date if isinstance(project.start_date, datetime) else \n                           datetime.combine(project.start_date, datetime.min.time()),\n                end_date=project.end_date if project.end_date is None or isinstance(project.end_date, datetime) else \n                         datetime.combine(project.end_date, datetime.min.time()),\n                total_hours=total_hours,\n                total_revenue=total_revenue,\n                total_expenses=total_expenses,\n                total_profit=total_profit,\n                effective_hourly_rate=effective_hourly_rate,\n                profit_margin=profit_margin,\n                roi=roi,\n                is_completed=is_completed,\n                calculation_date=datetime.now(),\n                metrics=[\n                    ProfitabilityMetric(\n                        project_id=str(project.id),\n                        metric_type=ProjectMetricType.HOURLY_RATE,\n                        value=effective_hourly_rate,\n                    ),\n                    ProfitabilityMetric(\n                        project_id=str(project.id),\n                        metric_type=ProjectMetricType.TOTAL_PROFIT,\n                        value=total_profit,\n                    ),\n                    ProfitabilityMetric(\n                        project_id=str(project.id),\n                        metric_type=ProjectMetricType.PROFIT_MARGIN,\n                        value=profit_margin,\n                    ),\n                    ProfitabilityMetric(\n                        project_id=str(project.id), \n                        metric_type=ProjectMetricType.ROI, \n                        value=roi\n                    ),\n                ],\n            )\n            \n            # Cache the result\n            self._profitability_cache.set(cache_key, result)\n        \n        return result\n    \n    def analyze_client_profitability(\n        self,\n        client: Client,\n        projects: List[Project],\n        time_entries: List[TimeEntry],\n        transactions: List[T],\n        invoices: List[Invoice],\n        force_recalculation: bool = False,\n    ) -> ClientProfitability:\n        \"\"\"\n        Analyze the profitability of all projects for a client.\n        \n        Args:\n            client: Client to analyze\n            projects: All projects\n            time_entries: All time entries\n            transactions: All transactions\n            invoices: All invoices\n            force_recalculation: Whether to force recalculation\n            \n        Returns:\n            ClientProfitability analysis result\n        \"\"\"\n        # Performance measurement\n        with Timer(\"client_profitability_analysis\"):\n            # Check cache unless forced\n            cache_key = f\"client_{client.id}\"\n            if not force_recalculation:\n                cached_result = self._profitability_cache.get(cache_key)\n                if cached_result:\n                    return cached_result\n            \n            # Filter to client's projects\n            client_projects = [p for p in projects if p.client_id == str(client.id)]\n            \n            if not client_projects:\n                return ClientProfitability(\n                    client_id=str(client.id),\n                    client_name=client.name,\n                    number_of_projects=0,\n                    total_hours=0.0,\n                    total_revenue=0.0,\n                    total_expenses=0.0,\n                    total_profit=0.0,\n                    average_hourly_rate=0.0,\n                    average_profit_margin=0.0,\n                )\n            \n            # Analyze each project\n            project_analyses = []\n            for project in client_projects:\n                analysis = self.analyze_project_profitability(\n                    project, time_entries, transactions, invoices, force_recalculation\n                )\n                project_analyses.append(analysis)\n            \n            # Calculate client-level metrics\n            total_hours = sum(p.total_hours for p in project_analyses)\n            total_revenue = sum(p.total_revenue for p in project_analyses)\n            total_expenses = sum(p.total_expenses for p in project_analyses)\n            total_profit = sum(p.total_profit for p in project_analyses)\n            \n            # Calculate averages\n            avg_hourly_rate = total_revenue / max(total_hours, 0.01)\n            avg_profit_margin = 100 * total_profit / max(total_revenue, 0.01)\n            \n            # Calculate average invoice payment time\n            client_invoices = [\n                i for i in invoices if i.client_id == str(client.id) and i.status == \"paid\"\n            ]\n            payment_days = []\n            \n            for invoice in client_invoices:\n                if invoice.payment_date and invoice.issue_date:\n                    # Convert to datetime if needed\n                    issue_date = invoice.issue_date\n                    if not isinstance(issue_date, datetime):\n                        issue_date = datetime.combine(issue_date, datetime.min.time())\n                    \n                    payment_date = invoice.payment_date\n                    if not isinstance(payment_date, datetime):\n                        payment_date = datetime.combine(payment_date, datetime.min.time())\n                    \n                    days = (payment_date - issue_date).days\n                    payment_days.append(days)\n            \n            avg_payment_days = None\n            if payment_days:\n                avg_payment_days = sum(payment_days) / len(payment_days)\n            \n            # Create client profitability result\n            result = ClientProfitability(\n                client_id=str(client.id),\n                client_name=client.name,\n                number_of_projects=len(client_projects),\n                total_hours=total_hours,\n                total_revenue=total_revenue,\n                total_expenses=total_expenses,\n                total_profit=total_profit,\n                average_hourly_rate=avg_hourly_rate,\n                average_profit_margin=avg_profit_margin,\n                average_invoice_payment_days=avg_payment_days,\n                projects=project_analyses,\n            )\n            \n            # Cache the result\n            self._profitability_cache.set(cache_key, result)\n        \n        return result\n    \n    def analyze_all_projects(\n        self,\n        projects: List[Project],\n        time_entries: List[TimeEntry],\n        transactions: List[T],\n        invoices: List[Invoice],\n        force_recalculation: bool = False,\n    ) -> List[ProjectProfitability]:\n        \"\"\"\n        Analyze profitability for all projects.\n        \n        Args:\n            projects: All projects to analyze\n            time_entries: All time entries\n            transactions: All transactions\n            invoices: All invoices\n            force_recalculation: Whether to force recalculation\n            \n        Returns:\n            List of ProjectProfitability analysis results\n        \"\"\"\n        # Performance measurement\n        with Timer(\"all_projects_analysis\"):\n            # Analyze each project\n            results = []\n            for project in projects:\n                analysis = self.analyze_project_profitability(\n                    project, time_entries, transactions, invoices, force_recalculation\n                )\n                results.append(analysis)\n            \n            # Sort by profitability (highest first)\n            results.sort(key=lambda x: x.total_profit, reverse=True)\n        \n        return results\n    \n    def generate_trend_analysis(\n        self,\n        metric_type: ProjectMetricType,\n        start_date: datetime,\n        end_date: datetime,\n        period: str = \"monthly\",\n        project_id: Optional[str] = None,\n        client_id: Optional[str] = None,\n        projects: Optional[List[Project]] = None,\n        time_entries: Optional[List[TimeEntry]] = None,\n        transactions: Optional[List[T]] = None,\n        invoices: Optional[List[Invoice]] = None,\n    ) -> TrendAnalysis:\n        \"\"\"\n        Generate trend analysis for project metrics over time.\n        \n        Args:\n            metric_type: Type of metric to analyze\n            start_date: Start date for analysis\n            end_date: End date for analysis\n            period: Period for grouping (\"weekly\", \"monthly\", \"quarterly\", \"yearly\")\n            project_id: Optional project ID to filter\n            client_id: Optional client ID to filter\n            projects: Optional list of projects\n            time_entries: Optional list of time entries\n            transactions: Optional list of transactions\n            invoices: Optional list of invoices\n            \n        Returns:\n            TrendAnalysis result\n        \"\"\"\n        with Timer(\"project_trend_analysis\"):\n            if not projects or not time_entries or not transactions or not invoices:\n                return TrendAnalysis(\n                    metric_type=metric_type,\n                    project_id=project_id,\n                    client_id=client_id,\n                    period=period,\n                    start_date=start_date,\n                    end_date=end_date,\n                    data_points=[],\n                )\n            \n            # Filter projects\n            filtered_projects = projects\n            if project_id:\n                filtered_projects = [p for p in projects if str(p.id) == project_id]\n            elif client_id:\n                filtered_projects = [p for p in projects if str(p.client_id) == client_id]\n            \n            if not filtered_projects:\n                return TrendAnalysis(\n                    metric_type=metric_type,\n                    project_id=project_id,\n                    client_id=client_id,\n                    period=period,\n                    start_date=start_date,\n                    end_date=end_date,\n                    data_points=[],\n                )\n            \n            # Get project IDs for filtering\n            project_ids = {str(p.id) for p in filtered_projects}\n            \n            # Prepare time periods based on specified period\n            if period == \"weekly\":\n                freq = \"W-MON\"\n                period_name = \"Weekly\"\n            elif period == \"monthly\":\n                freq = \"MS\"\n                period_name = \"Monthly\"\n            elif period == \"quarterly\":\n                freq = \"QS\"\n                period_name = \"Quarterly\"\n            elif period == \"yearly\":\n                freq = \"AS\"\n                period_name = \"Yearly\"\n            else:\n                freq = \"MS\"  # Default to monthly\n                period_name = \"Monthly\"\n            \n            # Generate time periods\n            period_dates = pd.date_range(start=start_date, end=end_date, freq=freq)\n            periods = [d.to_pydatetime() for d in period_dates]\n            \n            # Calculate metric for each period\n            data_points = []\n            \n            for i in range(len(periods) - 1):\n                period_start = periods[i]\n                period_end = periods[i + 1] - timedelta(days=1)\n                \n                # Filter data for this period\n                period_time_entries = [\n                    e\n                    for e in time_entries\n                    if (\n                        e.project_id in project_ids\n                        and e.start_time >= period_start\n                        and e.start_time <= period_end\n                    )\n                ]\n                \n                period_transactions = self._filter_period_transactions(\n                    transactions, project_ids, period_start, period_end\n                )\n                \n                period_invoices = [\n                    i\n                    for i in invoices\n                    if (\n                        i.project_id in project_ids\n                        and self._is_date_in_range(i.issue_date, period_start, period_end)\n                        and i.status == \"paid\"\n                    )\n                ]\n                \n                # Calculate metrics for this period\n                total_hours = sum(\n                    entry.duration_minutes / 60\n                    for entry in period_time_entries\n                    if entry.duration_minutes is not None\n                )\n                \n                total_revenue = sum(invoice.amount for invoice in period_invoices)\n                \n                total_expenses = sum(t.amount for t in period_transactions)\n                \n                total_profit = total_revenue - total_expenses\n                \n                # Determine metric value based on type\n                metric_value = 0.0\n                \n                if metric_type == ProjectMetricType.HOURLY_RATE:\n                    metric_value = total_revenue / max(total_hours, 0.01)\n                elif metric_type == ProjectMetricType.TOTAL_PROFIT:\n                    metric_value = total_profit\n                elif metric_type == ProjectMetricType.PROFIT_MARGIN:\n                    metric_value = 100 * total_profit / max(total_revenue, 0.01)\n                elif metric_type == ProjectMetricType.ROI:\n                    metric_value = total_profit / max(total_expenses, 0.01)\n                \n                # Add data point\n                data_point = TrendPoint(\n                    date=period_start,\n                    value=metric_value\n                )\n                data_points.append(data_point)\n            \n            # Use TimeSeriesData and TimeSeriesAnalyzer for advanced trend analysis\n            dates = [point.date for point in data_points]\n            values = [point.value for point in data_points]\n            \n            # Only proceed with trend analysis if we have data points\n            trend_direction = \"none\"\n            trend_strength = 0.0\n            \n            if dates and values:\n                # Create TimeSeriesData object\n                time_series_data = TimeSeriesData(dates=dates, values=values)\n                \n                # Apply trend detection\n                trend_info = TimeSeriesAnalyzer.detect_trend(time_series_data)\n                trend_direction = trend_info[\"trend_direction\"]\n                trend_strength = trend_info[\"trend_strength\"]\n            \n            # Create trend analysis\n            trend = TrendAnalysis(\n                metric_type=metric_type,\n                project_id=project_id,\n                client_id=client_id,\n                period=period,\n                start_date=start_date,\n                end_date=end_date,\n                data_points=data_points,\n                description=(\n                    f\"{period_name} trend of {metric_type.value} from {start_date.date()} \"\n                    f\"to {end_date.date()}. Trend direction: {trend_direction}, \"\n                    f\"strength: {trend_strength:.2f}\"\n                ),\n            )\n        \n        return trend\n    \n    def _filter_project_expenses(self, transactions: List[T], project_id: Union[str, UUID]) -> List[T]:\n        \"\"\"\n        Filter transactions to find project expenses.\n        This method should be overridden by derived classes to implement\n        project-specific filtering logic.\n        \n        Args:\n            transactions: List of transactions to filter\n            project_id: Project ID to filter by\n            \n        Returns:\n            List of expense transactions for the project\n        \"\"\"\n        # Default implementation - derived classes should override\n        # to provide specific transaction filtering logic\n        project_expenses = [\n            t for t in transactions\n            if hasattr(t, \"project_id\") and str(t.project_id) == str(project_id)\n        ]\n        return project_expenses\n    \n    def _filter_period_transactions(\n        self, \n        transactions: List[T], \n        project_ids: set, \n        period_start: datetime, \n        period_end: datetime\n    ) -> List[T]:\n        \"\"\"\n        Filter transactions for a specific period and projects.\n        This method should be overridden by derived classes to implement\n        specific filtering logic.\n        \n        Args:\n            transactions: List of transactions to filter\n            project_ids: Set of project IDs to include\n            period_start: Start date for the period\n            period_end: End date for the period\n            \n        Returns:\n            List of transactions for the period and projects\n        \"\"\"\n        # Default implementation - derived classes should override\n        # to provide specific transaction filtering logic\n        period_transactions = [\n            t for t in transactions\n            if (\n                hasattr(t, \"project_id\") and str(t.project_id) in project_ids\n                and hasattr(t, \"date\") and self._is_date_in_range(t.date, period_start, period_end)\n            )\n        ]\n        return period_transactions\n    \n    def _is_date_in_range(\n        self, \n        date_value: Union[datetime, date], \n        start_date: datetime, \n        end_date: datetime\n    ) -> bool:\n        \"\"\"\n        Check if a date is within a range.\n        \n        Args:\n            date_value: Date to check\n            start_date: Start of range\n            end_date: End of range\n            \n        Returns:\n            True if date is in range, False otherwise\n        \"\"\"\n        # Convert to datetime if needed\n        if not isinstance(date_value, datetime):\n            date_value = datetime.combine(date_value, datetime.min.time())\n        \n        return start_date <= date_value <= end_date",
                "class Timer:\n    \"\"\"Utility for measuring execution time.\"\"\"\n    \n    def __init__(self, name: Optional[str] = None):\n        \"\"\"\n        Initialize the timer.\n        \n        Args:\n            name: Optional name for the timer\n        \"\"\"\n        self.name = name\n        self.start_time: Optional[float] = None\n        self.end_time: Optional[float] = None\n    \n    def __enter__(self) -> 'Timer':\n        \"\"\"Start the timer when entering a context.\"\"\"\n        self.start()\n        return self\n    \n    def __exit__(self, *args: Any) -> None:\n        \"\"\"Stop the timer when exiting a context.\"\"\"\n        self.stop()\n    \n    def start(self) -> None:\n        \"\"\"Start the timer.\"\"\"\n        self.start_time = time.time()\n        self.end_time = None\n    \n    def stop(self) -> float:\n        \"\"\"\n        Stop the timer.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        self.end_time = time.time()\n        return self.elapsed_time\n    \n    @property\n    def elapsed_time(self) -> float:\n        \"\"\"\n        Get the elapsed time.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        end = self.end_time if self.end_time is not None else time.time()\n        return end - self.start_time\n    \n    @property\n    def elapsed_milliseconds(self) -> float:\n        \"\"\"\n        Get the elapsed time in milliseconds.\n        \n        Returns:\n            Elapsed time in milliseconds\n        \"\"\"\n        return self.elapsed_time * 1000"
            ]
        }
    },
    "unified/tests/freelancer/projection/__init__.py": {
        "logprobs": -191.0744433451,
        "metrics": {
            "loc": 1,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 0,
            "blank": 0,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/personal_finance_tracker/projection/models.py": {
        "logprobs": -1052.0093563814448,
        "metrics": {
            "loc": 173,
            "sloc": 117,
            "lloc": 175,
            "comments": 14,
            "multi": 8,
            "blank": 34,
            "cyclomatic": 29,
            "internal_imports": [
                "class ProjectionScenario(str, Enum):\n    \"\"\"Scenario types for financial projections.\"\"\"\n    \n    OPTIMISTIC = \"optimistic\"\n    BASELINE = \"baseline\"\n    CONSERVATIVE = \"conservative\"\n    STRESS_TEST = \"stress_test\"",
                "class ProjectionParameters(AnalysisParameters):\n    \"\"\"\n    Parameters for financial projections.\n    \n    Used to configure projection options and settings.\n    \"\"\"\n    \n    projection_length: int = 12  # months\n    scenario: ProjectionScenario = ProjectionScenario.BASELINE\n    include_income: bool = True\n    include_expenses: bool = True\n    include_investments: bool = True\n    income_growth_rate: float = 0.0\n    expense_growth_rate: float = 0.0\n    investment_return_rate: float = 0.05\n    emergency_fund_months: int = 6\n    tax_rate: float = 0.25",
                "class CashFlow(BaseModel):\n    \"\"\"\n    Model for cash flow data.\n    \n    Used for tracking income, expenses, and net cash flow over time.\n    \"\"\"\n    \n    date: Union[date, datetime]\n    income: float = 0.0\n    expenses: float = 0.0\n    net: float = 0.0\n    cumulative: float = 0.0\n    \n    def __init__(self, **data):\n        \"\"\"Initialize with automatic net and cumulative calculation.\"\"\"\n        super().__init__(**data)\n        if \"net\" not in data:\n            self.net = self.income - self.expenses",
                "class Projection(BaseModel):\n    \"\"\"\n    Financial projection model.\n    \n    Used for forecasting future financial states based on different scenarios.\n    \"\"\"\n    \n    scenario: ProjectionScenario\n    start_date: Union[date, datetime]\n    end_date: Union[date, datetime]\n    starting_balance: float\n    cash_flows: List[CashFlow] = Field(default_factory=list)\n    final_balance: float\n    lowest_balance: float\n    highest_balance: float\n    runway_months: Optional[float] = None\n    emergency_fund_status: str = \"insufficient\"\n    tax_liability: Dict[str, float] = Field(default_factory=dict)\n    confidence_level: float = 0.8\n    metadata: Dict[str, Any] = Field(default_factory=dict)",
                "class ProjectionResult(AnalysisResult):\n    \"\"\"\n    Result of a financial projection analysis.\n    \n    Provides projected financial states across different scenarios.\n    \"\"\"\n    \n    baseline: Projection\n    optimistic: Optional[Projection] = None\n    conservative: Optional[Projection] = None\n    stress_test: Optional[Projection] = None\n    recommended_actions: List[str] = Field(default_factory=list)"
            ]
        }
    },
    "unified/personal_finance_tracker/projection/financial_projector.py": {
        "logprobs": -3539.8963755954264,
        "metrics": {
            "loc": 817,
            "sloc": 557,
            "lloc": 313,
            "comments": 99,
            "multi": 73,
            "blank": 102,
            "cyclomatic": 109,
            "internal_imports": [
                "class AnalysisResult(BaseModel, Generic[T]):\n    \"\"\"\n    Result of an analysis operation.\n    \n    Provides information about the analysis process and outcome.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    subject_id: Optional[Union[str, UUID]] = None\n    subject_type: str\n    analysis_type: str\n    analysis_date: datetime = Field(default_factory=datetime.now)\n    processing_time_ms: Optional[float] = None\n    result_summary: Dict[str, Any] = Field(default_factory=dict)\n    detailed_results: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class AnalysisParameters(BaseModel):\n    \"\"\"\n    Parameters for an analysis operation.\n    \n    Used to configure analysis options and settings.\n    \"\"\"\n    \n    period_start: Optional[Union[date, datetime]] = None\n    period_end: Optional[Union[date, datetime]] = None\n    include_details: bool = True\n    calculation_mode: str = \"standard\"  # \"standard\", \"detailed\", \"fast\"\n    grouping: Optional[str] = None\n    custom_settings: Dict[str, Any] = Field(default_factory=dict)",
                "class FinancialProjector:\n    \"\"\"\n    Financial projection model for freelancers.\n\n    This class provides cash flow forecasting, runway calculations,\n    what-if analysis, and emergency fund assessment.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the financial projector.\"\"\"\n        self._projection_cache = {}\n        self._common_projector = CommonFinancialProjector()\n        self.timer = Timer()\n\n    def project_cash_flow(\n        self,\n        starting_balance: float,\n        current_date: datetime,\n        months_ahead: int,\n        revenue_sources: List[RevenueSource],\n        expense_items: List[ExpenseItem],\n        scenario: ProjectionScenario = ProjectionScenario.BASELINE,\n        historical_transactions: Optional[List[Transaction]] = None,\n        confidence_interval: float = 0.8,\n    ) -> CashFlowProjection:\n        \"\"\"\n        Project cash flow for a specific timeframe.\n\n        Args:\n            starting_balance: Current cash balance\n            current_date: Start date for projection\n            months_ahead: Number of months to project\n            revenue_sources: Expected revenue sources\n            expense_items: Expected expenses\n            scenario: Projection scenario\n            historical_transactions: Optional historical transactions for trend analysis\n            confidence_interval: Confidence interval for projections\n\n        Returns:\n            CashFlowProjection object with detailed cash flow projection\n        \"\"\"\n        # Start performance timer\n        self.timer.start()\n\n        # Calculate dates\n        start_date = datetime(current_date.year, current_date.month, 1)\n        end_month = current_date.month + months_ahead\n        end_year = current_date.year + (end_month - 1) // 12\n        end_month = ((end_month - 1) % 12) + 1\n        end_date = datetime(\n            end_year, end_month, calendar.monthrange(end_year, end_month)[1]\n        )\n\n        # Create historical time series data if provided\n        historical_data = None\n        if historical_transactions:\n            # Extract dates and net cash flow values from transactions\n            dates = []\n            values = []\n            \n            for tx in sorted(historical_transactions, key=lambda t: t.date):\n                dates.append(tx.date)\n                # Income adds to cash flow, expenses subtract\n                value = tx.amount if tx.transaction_type == TransactionType.INCOME else -tx.amount\n                values.append(value)\n            \n            historical_data = TimeSeriesData(dates=dates, values=values)\n        else:\n            # Create minimal historical data with just the starting balance\n            historical_data = TimeSeriesData(\n                dates=[current_date],\n                values=[starting_balance]\n            )\n\n        # Create projection parameters\n        params = ProjectionParameters(\n            projection_length=months_ahead,\n            scenario=scenario,\n            income_growth_rate=0.0,  # Will be handled in revenue sources\n            expense_growth_rate=0.0,  # Will be handled in expense items\n        )\n\n        # Prepare income and expenses for the common projector\n        # This is needed to convert our revenue sources and expense items format\n        # to the common library's expected format\n        monthly_income = {}\n        monthly_expenses = {}\n        \n        # Process revenue sources\n        for revenue in revenue_sources:\n            if revenue.recurring:\n                self._add_recurring_item_to_dict(\n                    monthly_dict=monthly_income,\n                    item=revenue,\n                    start_date=start_date,\n                    end_date=end_date,\n                    multiplier=self._get_scenario_income_multiplier(scenario)\n                )\n            elif revenue.expected_date:\n                month_key = revenue.expected_date.strftime(\"%Y-%m\")\n                adjusted_amount = revenue.amount * (revenue.probability / 100) * self._get_scenario_income_multiplier(scenario)\n                monthly_income[month_key] = monthly_income.get(month_key, 0) + adjusted_amount\n\n        # Process expenses\n        for expense in expense_items:\n            if expense.recurring:\n                self._add_recurring_item_to_dict(\n                    monthly_dict=monthly_expenses,\n                    item=expense,\n                    start_date=start_date,\n                    end_date=end_date,\n                    multiplier=self._get_scenario_expense_multiplier(scenario)\n                )\n            elif expense.due_date:\n                month_key = expense.due_date.strftime(\"%Y-%m\")\n                adjusted_amount = expense.amount * self._get_scenario_expense_multiplier(scenario)\n                monthly_expenses[month_key] = monthly_expenses.get(month_key, 0) + adjusted_amount\n\n        # Convert to time series format\n        month_strings = []\n        current_month = start_date\n        while current_month <= end_date:\n            month_strings.append(current_month.strftime(\"%Y-%m\"))\n            # Move to next month\n            month = current_month.month + 1\n            year = current_month.year + (month - 1) // 12\n            month = ((month - 1) % 12) + 1\n            current_month = datetime(year, month, 1)\n\n        # Generate all dates for the projection period\n        projection_dates = []\n        projection_income = []\n        projection_expenses = []\n        \n        for month in month_strings:\n            year, month_num = map(int, month.split('-'))\n            projection_date = datetime(year, int(month_num), 1)\n            projection_dates.append(projection_date)\n            projection_income.append(monthly_income.get(month, 0))\n            projection_expenses.append(monthly_expenses.get(month, 0))\n\n        # Use the common financial projector to create projections\n        # We create our own custom projection from the results\n        projection_result = self._create_custom_projection(\n            starting_balance=starting_balance,\n            projection_dates=projection_dates,\n            projection_income=projection_income,\n            projection_expenses=projection_expenses,\n            scenario=scenario\n        )\n\n        # Calculate totals\n        total_income = sum(monthly_income.get(month, 0) for month in month_strings)\n        total_expenses = sum(monthly_expenses.get(month, 0) for month in month_strings)\n        net_cash_flow = total_income - total_expenses\n        ending_balance = starting_balance + net_cash_flow\n\n        # Create monthly breakdown structure for compatibility\n        monthly_breakdown = {}\n        for i, month in enumerate(month_strings):\n            monthly_breakdown[month] = {\n                \"income\": projection_income[i],\n                \"expenses\": projection_expenses[i],\n                \"balance\": 0  # Will be calculated below\n            }\n\n        # Calculate running balance for each month\n        running_balance = starting_balance\n        for month in month_strings:\n            income = monthly_breakdown[month][\"income\"]\n            expenses = monthly_breakdown[month][\"expenses\"]\n            net = income - expenses\n            running_balance += net\n            monthly_breakdown[month][\"balance\"] = running_balance\n\n        # Create projection for return\n        projection = CashFlowProjection(\n            start_date=start_date,\n            end_date=end_date,\n            scenario=scenario,\n            starting_balance=starting_balance,\n            ending_balance=ending_balance,\n            total_income=total_income,\n            total_expenses=total_expenses,\n            net_cash_flow=net_cash_flow,\n            monthly_breakdown=monthly_breakdown,\n            confidence_interval=confidence_interval,\n        )\n\n        # Stop timer\n        elapsed_time = self.timer.stop()\n\n        return projection\n\n    def _create_custom_projection(\n        self,\n        starting_balance: float,\n        projection_dates: List[datetime],\n        projection_income: List[float],\n        projection_expenses: List[float],\n        scenario: ProjectionScenario\n    ) -> Projection:\n        \"\"\"\n        Create a custom projection using the common library.\n        \n        Args:\n            starting_balance: Current cash balance\n            projection_dates: List of dates for projection\n            projection_income: List of income values\n            projection_expenses: List of expense values\n            scenario: Projection scenario\n            \n        Returns:\n            Projection object\n        \"\"\"\n        # Create cash flows\n        cash_flows = []\n        cumulative_balance = starting_balance\n        lowest_balance = starting_balance\n        highest_balance = starting_balance\n        \n        for i, date in enumerate(projection_dates):\n            income = projection_income[i]\n            expenses = projection_expenses[i]\n            net = income - expenses\n            cumulative_balance += net\n            \n            # Track min/max balances\n            lowest_balance = min(lowest_balance, cumulative_balance)\n            highest_balance = max(highest_balance, cumulative_balance)\n            \n            # Create cash flow\n            cash_flow = CashFlow(\n                date=date,\n                income=income,\n                expenses=expenses,\n                net=net,\n                cumulative=cumulative_balance\n            )\n            cash_flows.append(cash_flow)\n        \n        # Calculate runway months\n        runway_months = None\n        avg_expenses = sum(projection_expenses) / len(projection_expenses) if projection_expenses else 0\n        \n        if avg_expenses > 0:\n            for i, cf in enumerate(cash_flows):\n                if cf.cumulative <= 0:\n                    runway_months = i\n                    break\n            \n            if runway_months is None and lowest_balance > 0:\n                if cash_flows[-1].net < 0:\n                    runway_months = len(projection_dates) + (cash_flows[-1].cumulative / -cash_flows[-1].net)\n                else:\n                    runway_months = float('inf')  # Sustainable cash flow\n        \n        # Determine emergency fund status\n        emergency_fund_months = 6  # Default value\n        emergency_fund_status = \"insufficient\"\n        if lowest_balance >= avg_expenses * emergency_fund_months:\n            emergency_fund_status = \"adequate\"\n        elif lowest_balance >= avg_expenses * (emergency_fund_months / 2):\n            emergency_fund_status = \"partial\"\n            \n        # Create the projection\n        return Projection(\n            scenario=scenario,\n            start_date=projection_dates[0],\n            end_date=projection_dates[-1],\n            starting_balance=starting_balance,\n            cash_flows=cash_flows,\n            final_balance=cash_flows[-1].cumulative if cash_flows else starting_balance,\n            lowest_balance=lowest_balance,\n            highest_balance=highest_balance,\n            runway_months=runway_months,\n            emergency_fund_status=emergency_fund_status,\n            tax_liability={},  # Not used in this implementation\n            confidence_level=0.8,\n            metadata={\n                \"avg_monthly_income\": sum(projection_income) / len(projection_income) if projection_income else 0,\n                \"avg_monthly_expenses\": avg_expenses,\n            }\n        )\n\n    def _add_recurring_item_to_dict(\n        self,\n        monthly_dict: Dict[str, float],\n        item: Union[RevenueSource, ExpenseItem],\n        start_date: datetime,\n        end_date: datetime,\n        multiplier: float = 1.0,\n    ) -> None:\n        \"\"\"Add a recurring item to monthly dictionary.\"\"\"\n        # Handle different recurrence frequencies\n        months_interval = 1  # Default to monthly\n        frequency_multiplier = 1.0\n\n        if item.recurrence_frequency == \"quarterly\":\n            months_interval = 3\n        elif item.recurrence_frequency == \"biannual\":\n            months_interval = 6\n        elif item.recurrence_frequency == \"annual\":\n            months_interval = 12\n        elif item.recurrence_frequency == \"biweekly\":\n            # Approximate biweekly as 2.17 payments per month\n            frequency_multiplier = 2.17\n        elif item.recurrence_frequency == \"weekly\":\n            # Approximate weekly as 4.33 payments per month\n            frequency_multiplier = 4.33\n\n        # Determine start month (use expected_date if available)\n        current_month = None\n        if hasattr(item, \"expected_date\") and item.expected_date:\n            current_month = item.expected_date\n        else:\n            current_month = start_date\n\n        # Add to each applicable month\n        while current_month <= end_date:\n            month_key = current_month.strftime(\"%Y-%m\")\n\n            # Apply probability adjustment for revenue\n            if hasattr(item, \"probability\"):\n                adjusted_amount = item.amount * (item.probability / 100) * multiplier * frequency_multiplier\n            else:\n                adjusted_amount = item.amount * multiplier * frequency_multiplier\n\n            monthly_dict[month_key] = monthly_dict.get(month_key, 0) + adjusted_amount\n\n            # Move to next applicable month\n            month = current_month.month + months_interval\n            year = current_month.year + (month - 1) // 12\n            month = ((month - 1) % 12) + 1\n            current_month = datetime(year, month, 1)\n\n    def _get_scenario_income_multiplier(self, scenario: ProjectionScenario) -> float:\n        \"\"\"Get income multiplier based on scenario.\"\"\"\n        if scenario == ProjectionScenario.STRESS_TEST:\n            return 0.7  # 70% of expected income\n        elif scenario == ProjectionScenario.CONSERVATIVE:\n            return 0.85  # 85% of expected income\n        elif scenario == ProjectionScenario.BASELINE:\n            return 1.0  # 100% of expected income\n        elif scenario == ProjectionScenario.OPTIMISTIC:\n            return 1.15  # 115% of expected income\n        return 1.0\n\n    def _get_scenario_expense_multiplier(self, scenario: ProjectionScenario) -> float:\n        \"\"\"Get expense multiplier based on scenario.\"\"\"\n        if scenario == ProjectionScenario.STRESS_TEST:\n            return 1.15  # 115% of expected expenses\n        elif scenario == ProjectionScenario.CONSERVATIVE:\n            return 1.05  # 105% of expected expenses\n        elif scenario == ProjectionScenario.BASELINE:\n            return 1.0  # 100% of expected expenses\n        elif scenario == ProjectionScenario.OPTIMISTIC:\n            return 0.95  # 95% of expected expenses\n        return 1.0\n\n    def calculate_runway(\n        self,\n        current_balance: float,\n        spending_level: SpendingLevel,\n        monthly_expenses: Optional[float] = None,\n        historical_transactions: Optional[List[Transaction]] = None,\n        expected_revenue: Optional[Dict[str, float]] = None,\n        confidence_level: float = 0.8,\n    ) -> RunwayProjection:\n        \"\"\"\n        Calculate how long current funds will last at different spending levels.\n\n        Args:\n            current_balance: Current cash balance\n            spending_level: Level of spending to project\n            monthly_expenses: Optional override for monthly expense rate\n            historical_transactions: Optional historical transactions for expense analysis\n            expected_revenue: Optional expected future revenue by month\n            confidence_level: Confidence level for projection\n\n        Returns:\n            RunwayProjection with detailed runway information\n        \"\"\"\n        # Performance measurement\n        self.timer.start()\n\n        # Determine monthly expense rate\n        monthly_expense_rate = 0.0\n\n        if monthly_expenses is not None:\n            # Use provided expense rate\n            monthly_expense_rate = monthly_expenses\n        elif historical_transactions:\n            # Calculate from historical data (last 3 months)\n            now = datetime.now()\n            three_months_ago = datetime(now.year, now.month, 1) - timedelta(days=90)\n\n            # Filter to expenses in the last 3 months\n            recent_expenses = [\n                t\n                for t in historical_transactions\n                if (\n                    t.transaction_type == TransactionType.EXPENSE\n                    and t.date >= three_months_ago\n                )\n            ]\n\n            # Group by month and calculate average\n            expenses_by_month = {}\n            for expense in recent_expenses:\n                month_key = expense.date.strftime(\"%Y-%m\")\n                if month_key not in expenses_by_month:\n                    expenses_by_month[month_key] = 0\n                expenses_by_month[month_key] += expense.amount\n\n            if expenses_by_month:\n                monthly_expense_rate = sum(expenses_by_month.values()) / len(\n                    expenses_by_month\n                )\n            else:\n                raise ValueError(\"No historical expense data available\")\n        else:\n            raise ValueError(\n                \"Either monthly_expenses or historical_transactions must be provided\"\n            )\n\n        # Apply spending level adjustment\n        adjusted_expense_rate = self._adjust_for_spending_level(\n            monthly_expense_rate, spending_level\n        )\n\n        # Calculate runway without expected revenue\n        bare_runway_months = (\n            current_balance / adjusted_expense_rate\n            if adjusted_expense_rate > 0\n            else float(\"inf\")\n        )\n\n        # Include expected revenue if provided\n        if expected_revenue:\n            # Get expected revenue by month\n            sorted_months = sorted(expected_revenue.keys())\n\n            # Calculate runway with revenue\n            balance = current_balance\n            months = 0\n            depletion_date = None\n\n            while balance > 0 and months < 60:  # Cap at 5 years\n                # Current month index\n                current_month_idx = months % len(sorted_months)\n                current_month = sorted_months[current_month_idx]\n\n                # Subtract expenses and add revenue\n                balance -= adjusted_expense_rate\n                if current_month in expected_revenue:\n                    balance += expected_revenue[current_month]\n\n                months += 1\n\n                # Calculate depletion date\n                if balance <= 0:\n                    now = datetime.now()\n                    depletion_date = datetime(\n                        now.year + (now.month + months - 1) // 12,\n                        ((now.month + months - 1) % 12) + 1,\n                        1,\n                    )\n                    break\n\n            # If we reached the cap without depleting, set to infinity\n            runway_months = months if months < 60 else float(\"inf\")\n        else:\n            # Without expected revenue, use simple calculation\n            runway_months = bare_runway_months\n\n            # Calculate depletion date\n            if runway_months < float(\"inf\"):\n                now = datetime.now()\n                months_to_add = math.floor(runway_months)\n                depletion_date = datetime(\n                    now.year + (now.month + months_to_add - 1) // 12,\n                    ((now.month + months_to_add - 1) % 12) + 1,\n                    1,\n                )\n            else:\n                depletion_date = None\n\n        # Create result\n        result = RunwayProjection(\n            calculation_date=datetime.now(),\n            starting_balance=current_balance,\n            spending_level=spending_level,\n            monthly_expense_rate=adjusted_expense_rate,\n            expected_income=expected_revenue or {},\n            runway_months=runway_months,\n            depletion_date=depletion_date,\n            confidence_level=confidence_level,\n        )\n\n        # Verify performance\n        elapsed_time = self.timer.stop()\n\n        return result\n\n    def _adjust_for_spending_level(\n        self, base_expense_rate: float, spending_level: SpendingLevel\n    ) -> float:\n        \"\"\"Adjust expense rate based on spending level.\"\"\"\n        if spending_level == SpendingLevel.MINIMAL:\n            return base_expense_rate * 0.6  # 60% of normal expenses\n        elif spending_level == SpendingLevel.REDUCED:\n            return base_expense_rate * 0.8  # 80% of normal expenses\n        elif spending_level == SpendingLevel.NORMAL:\n            return base_expense_rate  # 100% of normal expenses\n        elif spending_level == SpendingLevel.INCREASED:\n            return base_expense_rate * 1.2  # 120% of normal expenses\n        return base_expense_rate\n\n    def create_what_if_scenario(\n        self,\n        name: str,\n        base_scenario: ProjectionScenario,\n        parameters: List[ScenarioParameter],\n        description: Optional[str] = None,\n    ) -> WhatIfScenario:\n        \"\"\"\n        Create a what-if scenario for financial planning.\n\n        Args:\n            name: Name for the scenario\n            base_scenario: Base projection scenario\n            parameters: Parameters for the scenario\n            description: Optional description\n\n        Returns:\n            WhatIfScenario object\n        \"\"\"\n        # Create the scenario\n        scenario = WhatIfScenario(\n            name=name,\n            description=description,\n            base_scenario=base_scenario,\n            parameters=parameters,\n            creation_date=datetime.now(),\n        )\n\n        return scenario\n\n    def evaluate_what_if_scenario(\n        self,\n        scenario: WhatIfScenario,\n        starting_balance: float,\n        revenue_sources: List[RevenueSource],\n        expense_items: List[ExpenseItem],\n        months_ahead: int = 12,\n    ) -> Tuple[WhatIfScenario, CashFlowProjection]:\n        \"\"\"\n        Evaluate a what-if scenario and calculate its impact.\n\n        Args:\n            scenario: What-if scenario to evaluate\n            starting_balance: Current cash balance\n            revenue_sources: Expected revenue sources\n            expense_items: Expected expenses\n            months_ahead: Number of months to project\n\n        Returns:\n            Tuple of (updated scenario with results, cash flow projection)\n        \"\"\"\n        # Apply parameter adjustments to revenue and expenses\n        adjusted_revenue = list(revenue_sources)\n        adjusted_expenses = list(expense_items)\n\n        # Track adjustments made for each parameter\n        adjustments = {}\n\n        for param in scenario.parameters:\n            # Store original value\n            adjustments[param.name] = param.current_value\n\n            # Apply parameter adjustments based on name patterns\n            if \"hourly_rate\" in param.name.lower():\n                # Adjust revenue based on hourly rate change\n                for i, revenue in enumerate(adjusted_revenue):\n                    if \"hourly\" in revenue.name.lower():\n                        # Create a new object with updated amount\n                        new_revenue = RevenueSource(\n                            name=revenue.name,\n                            amount=param.current_value,\n                            probability=revenue.probability,\n                            expected_date=revenue.expected_date,\n                            recurring=revenue.recurring,\n                            recurrence_frequency=revenue.recurrence_frequency,\n                            notes=revenue.notes,\n                        )\n                        adjusted_revenue[i] = new_revenue\n\n            elif \"monthly_income\" in param.name.lower():\n                # Adjust monthly income\n                for i, revenue in enumerate(adjusted_revenue):\n                    if revenue.recurring and revenue.recurrence_frequency == \"monthly\":\n                        # Create a new object with updated amount\n                        new_revenue = RevenueSource(\n                            name=revenue.name,\n                            amount=param.current_value,\n                            probability=revenue.probability,\n                            expected_date=revenue.expected_date,\n                            recurring=revenue.recurring,\n                            recurrence_frequency=revenue.recurrence_frequency,\n                            notes=revenue.notes,\n                        )\n                        adjusted_revenue[i] = new_revenue\n\n            elif \"expense_reduction\" in param.name.lower():\n                # Apply expense reduction percentage\n                reduction_factor = 1.0 - (param.current_value / 100)\n                for i, expense in enumerate(adjusted_expenses):\n                    # Create a new object with updated amount\n                    new_expense = ExpenseItem(\n                        name=expense.name,\n                        amount=expense.amount * reduction_factor,\n                        category=expense.category,\n                        due_date=expense.due_date,\n                        recurring=expense.recurring,\n                        recurrence_frequency=expense.recurrence_frequency,\n                        essential=expense.essential,\n                        notes=expense.notes,\n                    )\n                    adjusted_expenses[i] = new_expense\n\n            # Add more parameter handling as needed\n\n        # Run projection with adjusted values\n        projection = self.project_cash_flow(\n            starting_balance=starting_balance,\n            current_date=datetime.now(),\n            months_ahead=months_ahead,\n            revenue_sources=adjusted_revenue,\n            expense_items=adjusted_expenses,\n            scenario=scenario.base_scenario,\n        )\n\n        # Calculate result metrics\n        result_metrics = {\n            \"ending_balance\": projection.ending_balance,\n            \"net_cash_flow\": projection.net_cash_flow,\n            \"total_income\": projection.total_income,\n            \"total_expenses\": projection.total_expenses,\n        }\n\n        # Update scenario with results\n        # Create a new scenario with updated result metrics\n        updated_scenario = WhatIfScenario(\n            id=scenario.id,\n            name=scenario.name,\n            description=scenario.description,\n            base_scenario=scenario.base_scenario,\n            parameters=scenario.parameters,\n            result_metrics=result_metrics,\n            creation_date=scenario.creation_date,\n            notes=scenario.notes,\n        )\n\n        return updated_scenario, projection\n\n    def assess_emergency_fund(\n        self,\n        current_fund_balance: float,\n        monthly_expenses: Optional[float] = None,\n        historical_transactions: Optional[List[Transaction]] = None,\n        recommended_months: float = 6.0,\n    ) -> EmergencyFundAssessment:\n        \"\"\"\n        Assess the adequacy of an emergency fund.\n\n        Args:\n            current_fund_balance: Current emergency fund balance\n            monthly_expenses: Optional override for monthly expenses\n            historical_transactions: Optional historical transactions for expense analysis\n            recommended_months: Recommended number of months coverage\n\n        Returns:\n            EmergencyFundAssessment with detailed assessment\n        \"\"\"\n        # Determine monthly essential expenses\n        monthly_essential = 0.0\n\n        if monthly_expenses is not None:\n            # Use provided expense amount\n            monthly_essential = monthly_expenses\n        elif historical_transactions:\n            # Calculate from historical data (last 3 months)\n            now = datetime.now()\n            three_months_ago = datetime(now.year, now.month, 1) - timedelta(days=90)\n\n            # Filter to essential expenses in the last 3 months\n            essential_expenses = [\n                t\n                for t in historical_transactions\n                if (\n                    t.transaction_type == TransactionType.EXPENSE\n                    and t.date >= three_months_ago\n                    and t.category\n                    in [\n                        ExpenseCategory.UTILITIES,\n                        ExpenseCategory.HEALTH_INSURANCE,\n                        ExpenseCategory.OFFICE_RENT,\n                        ExpenseCategory.INTERNET,\n                        ExpenseCategory.PHONE,\n                    ]\n                )\n            ]\n\n            # Group by month and calculate average\n            expenses_by_month = {}\n            for expense in essential_expenses:\n                month_key = expense.date.strftime(\"%Y-%m\")\n                if month_key not in expenses_by_month:\n                    expenses_by_month[month_key] = 0\n                expenses_by_month[month_key] += expense.amount\n\n            if expenses_by_month:\n                monthly_essential = sum(expenses_by_month.values()) / len(\n                    expenses_by_month\n                )\n            else:\n                raise ValueError(\"No historical essential expense data available\")\n        else:\n            raise ValueError(\n                \"Either monthly_expenses or historical_transactions must be provided\"\n            )\n\n        # Calculate recommended fund size\n        recommended_fund_size = monthly_essential * recommended_months\n\n        # Calculate current coverage\n        current_coverage_months = (\n            current_fund_balance / monthly_essential if monthly_essential > 0 else 0\n        )\n\n        # Determine adequacy level\n        if current_coverage_months < 1:\n            adequacy_level = \"inadequate\"\n            funding_plan = (\n                \"Immediate action needed: Build to 1 month coverage as soon as possible\"\n            )\n        elif current_coverage_months < 3:\n            adequacy_level = \"minimal\"\n            funding_plan = \"Continue building: Aim for 3 months coverage\"\n        elif current_coverage_months < recommended_months:\n            adequacy_level = \"adequate\"\n            funding_plan = f\"Good progress: Continue building toward {recommended_months} months coverage\"\n        else:\n            adequacy_level = \"excellent\"\n            funding_plan = (\n                \"Well funded: Maintain current level or consider other financial goals\"\n            )\n\n        # Create assessment\n        assessment = EmergencyFundAssessment(\n            assessment_date=datetime.now(),\n            current_fund_balance=current_fund_balance,\n            monthly_essential_expenses=monthly_essential,\n            recommended_months_coverage=recommended_months,\n            recommended_fund_size=recommended_fund_size,\n            current_coverage_months=current_coverage_months,\n            adequacy_level=adequacy_level,\n            funding_plan=funding_plan,\n        )\n\n        return assessment",
                "class FinancialProjector(BaseAnalyzer[TimeSeriesData, ProjectionResult]):\n    \"\"\"\n    Analyzer for financial projections.\n    \n    Used for forecasting future financial states and scenario analysis.\n    \"\"\"\n    \n    def analyze(\n        self, historical_data: TimeSeriesData, parameters: Optional[ProjectionParameters] = None\n    ) -> ProjectionResult:\n        \"\"\"\n        Project future financial states based on historical data.\n        \n        Args:\n            historical_data: Historical financial data\n            parameters: Optional parameters to configure the projection\n            \n        Returns:\n            ProjectionResult with different scenario projections\n        \"\"\"\n        # Start timing for performance benchmarking\n        start_time = time.time()\n        \n        # Set default parameters if not provided\n        if parameters is None:\n            parameters = ProjectionParameters()\n        \n        # Check cache\n        cached_result = self._get_from_cache(UUID(), parameters)\n        if cached_result:\n            return cached_result\n        \n        # Calculate starting balance (last cumulative value)\n        starting_balance = (\n            historical_data.values[-1] if historical_data.values else 0.0\n        )\n        \n        # Generate projections for baseline scenario\n        baseline = self._generate_projection(\n            historical_data,\n            ProjectionScenario.BASELINE,\n            parameters,\n            income_factor=1.0,\n            expense_factor=1.0,\n            investment_factor=1.0,\n        )\n        \n        # Generate projections for optimistic scenario\n        optimistic = self._generate_projection(\n            historical_data,\n            ProjectionScenario.OPTIMISTIC,\n            parameters,\n            income_factor=1.1,\n            expense_factor=0.9,\n            investment_factor=1.2,\n        )\n        \n        # Generate projections for conservative scenario\n        conservative = self._generate_projection(\n            historical_data,\n            ProjectionScenario.CONSERVATIVE,\n            parameters,\n            income_factor=0.9,\n            expense_factor=1.1,\n            investment_factor=0.8,\n        )\n        \n        # Generate projections for stress test scenario\n        stress_test = self._generate_projection(\n            historical_data,\n            ProjectionScenario.STRESS_TEST,\n            parameters,\n            income_factor=0.7,\n            expense_factor=1.2,\n            investment_factor=0.5,\n        )\n        \n        # Generate recommended actions\n        recommended_actions = self._generate_recommendations(\n            baseline, conservative, stress_test, parameters\n        )\n        \n        # Calculate processing time\n        processing_time_ms = (time.time() - start_time) * 1000\n        \n        # Create the result\n        result = ProjectionResult(\n            id=UUID(),\n            subject_id=UUID(),\n            subject_type=\"financial_data\",\n            analysis_type=\"projection\",\n            analysis_date=datetime.now(),\n            processing_time_ms=processing_time_ms,\n            result_summary={\n                \"starting_balance\": starting_balance,\n                \"baseline_final_balance\": baseline.final_balance,\n                \"runway_months\": baseline.runway_months,\n                \"emergency_fund_status\": baseline.emergency_fund_status,\n            },\n            detailed_results={\n                \"projection_length\": parameters.projection_length,\n                \"scenarios\": [s.value for s in ProjectionScenario],\n                \"historical_data_points\": len(historical_data.values),\n            },\n            baseline=baseline,\n            optimistic=optimistic,\n            conservative=conservative,\n            stress_test=stress_test,\n            recommended_actions=recommended_actions,\n        )\n        \n        # Save to cache\n        self._save_to_cache(UUID(), result, parameters)\n        \n        return result\n    \n    def _generate_projection(\n        self,\n        historical_data: TimeSeriesData,\n        scenario: ProjectionScenario,\n        parameters: ProjectionParameters,\n        income_factor: float = 1.0,\n        expense_factor: float = 1.0,\n        investment_factor: float = 1.0,\n    ) -> Projection:\n        \"\"\"\n        Generate a financial projection for a specific scenario.\n        \n        Args:\n            historical_data: Historical financial data\n            scenario: The projection scenario\n            parameters: Projection parameters\n            income_factor: Adjustment factor for income\n            expense_factor: Adjustment factor for expenses\n            investment_factor: Adjustment factor for investment returns\n            \n        Returns:\n            Projection for the specified scenario\n        \"\"\"\n        # Calculate starting balance (last cumulative value)\n        starting_balance = (\n            historical_data.values[-1] if historical_data.values else 0.0\n        )\n        \n        # Determine start and end dates\n        if historical_data.dates:\n            start_date = historical_data.dates[-1]\n            # Add 1 month to avoid overlap with historical data\n            if isinstance(start_date, datetime):\n                start_date = start_date.replace(\n                    day=1, hour=0, minute=0, second=0, microsecond=0\n                )\n                start_date = (start_date.replace(day=28) + timedelta(days=4)).replace(day=1)\n            else:\n                # For date objects\n                year = start_date.year + ((start_date.month) // 12)\n                month = (start_date.month % 12) + 1\n                start_date = date(year, month, 1)\n        else:\n            start_date = datetime.now().replace(\n                day=1, hour=0, minute=0, second=0, microsecond=0\n            )\n        \n        # Generate projection dates (monthly)\n        projection_dates = []\n        current_date = start_date\n        for _ in range(parameters.projection_length):\n            projection_dates.append(current_date)\n            if isinstance(current_date, datetime):\n                current_date = (current_date.replace(day=28) + timedelta(days=4)).replace(day=1)\n            else:\n                # For date objects\n                year = current_date.year + ((current_date.month) // 12)\n                month = (current_date.month % 12) + 1\n                current_date = date(year, month, 1)\n        \n        end_date = projection_dates[-1]\n        \n        # Adjust rates based on scenario\n        income_growth = parameters.income_growth_rate * income_factor\n        expense_growth = parameters.expense_growth_rate * expense_factor\n        investment_return = parameters.investment_return_rate * investment_factor\n        \n        # Calculate historical averages\n        avg_income, avg_expenses = self._calculate_historical_averages(historical_data)\n        \n        # Generate cash flows\n        cash_flows = []\n        cumulative_balance = starting_balance\n        lowest_balance = starting_balance\n        highest_balance = starting_balance\n        \n        for i, projection_date in enumerate(projection_dates):\n            # Calculate projected income with growth\n            income = avg_income * (1 + income_growth) ** (i / 12) if parameters.include_income else 0\n            \n            # Calculate projected expenses with growth\n            expenses = avg_expenses * (1 + expense_growth) ** (i / 12) if parameters.include_expenses else 0\n            \n            # Calculate investment returns (monthly)\n            investment_income = (\n                cumulative_balance * (investment_return / 12)\n                if parameters.include_investments and cumulative_balance > 0\n                else 0\n            )\n            \n            # Add investment income to total income\n            income += investment_income\n            \n            # Calculate net and update cumulative\n            net = income - expenses\n            cumulative_balance += net\n            \n            # Track lowest and highest balances\n            lowest_balance = min(lowest_balance, cumulative_balance)\n            highest_balance = max(highest_balance, cumulative_balance)\n            \n            # Create cash flow record\n            cash_flow = CashFlow(\n                date=projection_date,\n                income=income,\n                expenses=expenses,\n                net=net,\n                cumulative=cumulative_balance,\n            )\n            \n            cash_flows.append(cash_flow)\n        \n        # Calculate runway months (how long until funds are depleted)\n        runway_months = None\n        if avg_expenses > 0:\n            for i, cf in enumerate(cash_flows):\n                if cf.cumulative <= 0:\n                    runway_months = i\n                    break\n            \n            if runway_months is None and lowest_balance > 0:\n                # If we didn't go negative, estimate based on final balance and burn rate\n                if cash_flows[-1].net < 0:\n                    runway_months = parameters.projection_length + (cash_flows[-1].cumulative / -cash_flows[-1].net)\n                else:\n                    runway_months = float('inf')  # Sustainable cash flow\n        \n        # Determine emergency fund status\n        emergency_fund_status = \"insufficient\"\n        if lowest_balance >= avg_expenses * parameters.emergency_fund_months:\n            emergency_fund_status = \"adequate\"\n        elif lowest_balance >= avg_expenses * (parameters.emergency_fund_months / 2):\n            emergency_fund_status = \"partial\"\n        \n        # Calculate projected tax liability\n        tax_liability = self._calculate_tax_liability(cash_flows, parameters.tax_rate)\n        \n        # Create the projection\n        return Projection(\n            scenario=scenario,\n            start_date=start_date,\n            end_date=end_date,\n            starting_balance=starting_balance,\n            cash_flows=cash_flows,\n            final_balance=cash_flows[-1].cumulative if cash_flows else starting_balance,\n            lowest_balance=lowest_balance,\n            highest_balance=highest_balance,\n            runway_months=runway_months,\n            emergency_fund_status=emergency_fund_status,\n            tax_liability=tax_liability,\n            confidence_level=self._calculate_confidence_level(scenario),\n            metadata={\n                \"income_growth_rate\": income_growth,\n                \"expense_growth_rate\": expense_growth,\n                \"investment_return_rate\": investment_return,\n                \"avg_monthly_income\": avg_income,\n                \"avg_monthly_expenses\": avg_expenses,\n            },\n        )\n    \n    def _calculate_historical_averages(\n        self, historical_data: TimeSeriesData\n    ) -> Tuple[float, float]:\n        \"\"\"\n        Calculate average monthly income and expenses from historical data.\n        \n        Args:\n            historical_data: Historical financial data\n            \n        Returns:\n            Tuple of (avg_income, avg_expenses)\n        \"\"\"\n        # In a real implementation, the historical data would likely contain\n        # separate income and expense data. Here we'll simulate it.\n        \n        # If we don't have historical data, use reasonable defaults\n        if not historical_data.values:\n            return 5000.0, 4000.0  # Default monthly income and expenses\n        \n        # Normally we would split the historical cash flows into income and expenses\n        # For now, we'll use a heuristic based on the net cash flow\n        \n        # Assuming the TimeSeriesData values are net cash flows\n        avg_net = np.mean(historical_data.values[-6:]) if len(historical_data.values) >= 6 else np.mean(historical_data.values)\n        \n        # Assuming expenses are about 80% of income on average\n        avg_income = max(avg_net * 1.8, 0)\n        avg_expenses = max(avg_income - avg_net, 0)\n        \n        return avg_income, avg_expenses\n    \n    def _calculate_tax_liability(\n        self, cash_flows: List[CashFlow], tax_rate: float\n    ) -> Dict[str, float]:\n        \"\"\"\n        Calculate projected tax liability.\n        \n        Args:\n            cash_flows: List of projected cash flows\n            tax_rate: The effective tax rate\n            \n        Returns:\n            Dictionary with tax liability information\n        \"\"\"\n        # Group by year\n        yearly_income = {}\n        \n        for cf in cash_flows:\n            year = cf.date.year\n            if year not in yearly_income:\n                yearly_income[year] = 0\n            \n            yearly_income[year] += cf.income\n        \n        # Calculate tax for each year\n        yearly_tax = {year: income * tax_rate for year, income in yearly_income.items()}\n        \n        # Calculate total and average\n        total_tax = sum(yearly_tax.values())\n        avg_monthly_tax = total_tax / len(cash_flows) if cash_flows else 0\n        \n        return {\n            \"yearly\": yearly_tax,\n            \"total\": total_tax,\n            \"avg_monthly\": avg_monthly_tax,\n            \"effective_rate\": tax_rate,\n        }\n    \n    def _calculate_confidence_level(self, scenario: ProjectionScenario) -> float:\n        \"\"\"\n        Calculate confidence level for a scenario.\n        \n        Args:\n            scenario: The projection scenario\n            \n        Returns:\n            Confidence level between 0 and 1\n        \"\"\"\n        # Assign confidence levels based on the scenario\n        if scenario == ProjectionScenario.BASELINE:\n            return 0.8\n        elif scenario == ProjectionScenario.OPTIMISTIC:\n            return 0.2\n        elif scenario == ProjectionScenario.CONSERVATIVE:\n            return 0.6\n        elif scenario == ProjectionScenario.STRESS_TEST:\n            return 0.1\n        \n        return 0.5  # Default\n    \n    def _generate_recommendations(\n        self,\n        baseline: Projection,\n        conservative: Projection,\n        stress_test: Projection,\n        parameters: ProjectionParameters,\n    ) -> List[str]:\n        \"\"\"\n        Generate financial recommendations based on projections.\n        \n        Args:\n            baseline: Baseline scenario projection\n            conservative: Conservative scenario projection\n            stress_test: Stress test scenario projection\n            parameters: Projection parameters\n            \n        Returns:\n            List of recommendation strings\n        \"\"\"\n        recommendations = []\n        \n        # Emergency fund recommendations\n        if baseline.emergency_fund_status == \"insufficient\":\n            recommendations.append(\n                f\"Build an emergency fund of {parameters.emergency_fund_months} months of expenses \"\n                f\"(approximately ${parameters.emergency_fund_months * baseline.metadata['avg_monthly_expenses']:,.2f}).\"\n            )\n        elif baseline.emergency_fund_status == \"partial\":\n            months_needed = parameters.emergency_fund_months\n            current_months = baseline.lowest_balance / baseline.metadata[\"avg_monthly_expenses\"]\n            recommendations.append(\n                f\"Increase your emergency fund from {current_months:.1f} months to {months_needed} months \"\n                f\"(add approximately ${(months_needed - current_months) * baseline.metadata['avg_monthly_expenses']:,.2f}).\"\n            )\n        \n        # Cash flow recommendations\n        if baseline.cash_flows and baseline.cash_flows[-1].net < 0:\n            recommendations.append(\n                \"Your expenses exceed your income. Consider reducing expenses or increasing income \"\n                f\"to close the monthly gap of ${-baseline.cash_flows[-1].net:,.2f}.\"\n            )\n        \n        # Runway concerns\n        if baseline.runway_months is not None and baseline.runway_months < parameters.projection_length:\n            recommendations.append(\n                f\"Based on current projections, your funds will be depleted in approximately {baseline.runway_months:.1f} months. \"\n                \"Take immediate action to increase income or reduce expenses.\"\n            )\n        elif conservative.runway_months is not None and conservative.runway_months < parameters.projection_length:\n            recommendations.append(\n                f\"In a conservative scenario, your funds could be depleted in approximately {conservative.runway_months:.1f} months. \"\n                \"Consider building additional reserves or reducing discretionary expenses.\"\n            )\n        \n        # Investment recommendations\n        if parameters.include_investments and baseline.metadata[\"avg_monthly_expenses\"] > 0:\n            # Calculate months of expenses covered by investments\n            investment_coverage = baseline.final_balance / baseline.metadata[\"avg_monthly_expenses\"]\n            if investment_coverage > 24:\n                recommendations.append(\n                    f\"Your projected balance exceeds 24 months of expenses. Consider investing a portion for long-term growth.\"\n                )\n        \n        # Tax planning\n        if baseline.tax_liability[\"total\"] > 0:\n            recommendations.append(\n                f\"Set aside approximately ${baseline.tax_liability['avg_monthly']:,.2f} monthly for taxes, \"\n                f\"with an estimated annual liability of ${baseline.tax_liability['yearly'].get(datetime.now().year, 0):,.2f}.\"\n            )\n        \n        # Stress test preparedness\n        if stress_test.lowest_balance < 0:\n            recommendations.append(\n                \"Your financial position is vulnerable to economic stress. Consider building additional reserves \"\n                f\"of at least ${-stress_test.lowest_balance:,.2f} to withstand worst-case scenarios.\"\n            )\n        \n        return recommendations",
                "class ProjectionScenario(str, Enum):\n    \"\"\"Scenario types for financial projections.\"\"\"\n    \n    OPTIMISTIC = \"optimistic\"\n    BASELINE = \"baseline\"\n    CONSERVATIVE = \"conservative\"\n    STRESS_TEST = \"stress_test\"",
                "class ProjectionParameters(AnalysisParameters):\n    \"\"\"\n    Parameters for financial projections.\n    \n    Used to configure projection options and settings.\n    \"\"\"\n    \n    projection_length: int = 12  # months\n    scenario: ProjectionScenario = ProjectionScenario.BASELINE\n    include_income: bool = True\n    include_expenses: bool = True\n    include_investments: bool = True\n    income_growth_rate: float = 0.0\n    expense_growth_rate: float = 0.0\n    investment_return_rate: float = 0.05\n    emergency_fund_months: int = 6\n    tax_rate: float = 0.25",
                "class ProjectionResult(AnalysisResult):\n    \"\"\"\n    Result of a financial projection analysis.\n    \n    Provides projected financial states across different scenarios.\n    \"\"\"\n    \n    baseline: Projection\n    optimistic: Optional[Projection] = None\n    conservative: Optional[Projection] = None\n    stress_test: Optional[Projection] = None\n    recommended_actions: List[str] = Field(default_factory=list)",
                "class CashFlow(BaseModel):\n    \"\"\"\n    Model for cash flow data.\n    \n    Used for tracking income, expenses, and net cash flow over time.\n    \"\"\"\n    \n    date: Union[date, datetime]\n    income: float = 0.0\n    expenses: float = 0.0\n    net: float = 0.0\n    cumulative: float = 0.0\n    \n    def __init__(self, **data):\n        \"\"\"Initialize with automatic net and cumulative calculation.\"\"\"\n        super().__init__(**data)\n        if \"net\" not in data:\n            self.net = self.income - self.expenses",
                "class Projection(BaseModel):\n    \"\"\"\n    Financial projection model.\n    \n    Used for forecasting future financial states based on different scenarios.\n    \"\"\"\n    \n    scenario: ProjectionScenario\n    start_date: Union[date, datetime]\n    end_date: Union[date, datetime]\n    starting_balance: float\n    cash_flows: List[CashFlow] = Field(default_factory=list)\n    final_balance: float\n    lowest_balance: float\n    highest_balance: float\n    runway_months: Optional[float] = None\n    emergency_fund_status: str = \"insufficient\"\n    tax_liability: Dict[str, float] = Field(default_factory=dict)\n    confidence_level: float = 0.8\n    metadata: Dict[str, Any] = Field(default_factory=dict)",
                "class TimeSeriesData(BaseModel):\n    \"\"\"\n    Model for time series data.\n    \n    Used for storing and manipulating time series data for analysis.\n    \"\"\"\n    \n    dates: List[Union[date, datetime]]\n    values: List[float]\n    labels: Optional[List[str]] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Timer:\n    \"\"\"Utility for measuring execution time.\"\"\"\n    \n    def __init__(self, name: Optional[str] = None):\n        \"\"\"\n        Initialize the timer.\n        \n        Args:\n            name: Optional name for the timer\n        \"\"\"\n        self.name = name\n        self.start_time: Optional[float] = None\n        self.end_time: Optional[float] = None\n    \n    def __enter__(self) -> 'Timer':\n        \"\"\"Start the timer when entering a context.\"\"\"\n        self.start()\n        return self\n    \n    def __exit__(self, *args: Any) -> None:\n        \"\"\"Stop the timer when exiting a context.\"\"\"\n        self.stop()\n    \n    def start(self) -> None:\n        \"\"\"Start the timer.\"\"\"\n        self.start_time = time.time()\n        self.end_time = None\n    \n    def stop(self) -> float:\n        \"\"\"\n        Stop the timer.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        self.end_time = time.time()\n        return self.elapsed_time\n    \n    @property\n    def elapsed_time(self) -> float:\n        \"\"\"\n        Get the elapsed time.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        end = self.end_time if self.end_time is not None else time.time()\n        return end - self.start_time\n    \n    @property\n    def elapsed_milliseconds(self) -> float:\n        \"\"\"\n        Get the elapsed time in milliseconds.\n        \n        Returns:\n            Elapsed time in milliseconds\n        \"\"\"\n        return self.elapsed_time * 1000",
                "class AccountBalance(BaseModel):\n    \"\"\"Account balance model.\"\"\"\n\n    account_id: str\n    account_name: str\n    account_type: AccountType\n    balance: float\n    as_of_date: datetime",
                "class ExpenseCategory(str, Enum):\n    \"\"\"Expense category enum.\"\"\"\n\n    BUSINESS_SUPPLIES = \"business_supplies\"\n    SOFTWARE = \"software\"\n    MARKETING = \"marketing\"\n    OFFICE_RENT = \"office_rent\"\n    UTILITIES = \"utilities\"\n    TRAVEL = \"travel\"\n    MEALS = \"meals\"\n    EQUIPMENT = \"equipment\"\n    PROFESSIONAL_DEVELOPMENT = \"professional_development\"\n    PROFESSIONAL_SERVICES = \"professional_services\"\n    HEALTH_INSURANCE = \"health_insurance\"\n    RETIREMENT = \"retirement\"\n    PHONE = \"phone\"\n    INTERNET = \"internet\"\n    CAR = \"car\"\n    HOME_OFFICE = \"home_office\"\n    PERSONAL = \"personal\"\n    OTHER = \"other\"",
                "class Transaction(BusinessTransaction):\n    \"\"\"\n    Transaction model for the Personal Finance Tracker.\n    \n    Extends the BusinessTransaction from the common library with\n    freelancer-specific fields and behaviors.\n    \"\"\"\n\n    # Override category field to use our specific ExpenseCategory enum\n    category: Optional[ExpenseCategory] = None\n    \n    # Make sure the account_id is required\n    account_id: str\n\n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        # This is necessary to allow field overrides\n        extra = \"allow\"",
                "class RevenueForecast(BaseModel):\n    \"\"\"Revenue forecast model.\"\"\"\n\n    month: datetime\n    expected_income: float\n    lower_bound: float\n    upper_bound: float\n    confidence_interval: float\n    sources: Dict[str, float] = Field(default_factory=dict)  # Client/project breakdown\n    notes: Optional[str] = None",
                "class RevenueForecast(BaseModel):\n    \"\"\"Revenue forecast model.\"\"\"\n\n    month: datetime\n    expected_income: float\n    lower_bound: float\n    upper_bound: float\n    confidence_interval: float\n    sources: Dict[str, float] = Field(default_factory=dict)  # Client/project breakdown\n    notes: Optional[str] = None",
                "class RevenueForecast(BaseModel):\n    \"\"\"Revenue forecast model.\"\"\"\n\n    month: datetime\n    expected_income: float\n    lower_bound: float\n    upper_bound: float\n    confidence_interval: float\n    sources: Dict[str, float] = Field(default_factory=dict)  # Client/project breakdown\n    notes: Optional[str] = None",
                "class RevenueForecast(BaseModel):\n    \"\"\"Revenue forecast model.\"\"\"\n\n    month: datetime\n    expected_income: float\n    lower_bound: float\n    upper_bound: float\n    confidence_interval: float\n    sources: Dict[str, float] = Field(default_factory=dict)  # Client/project breakdown\n    notes: Optional[str] = None",
                "class RevenueForecast(BaseModel):\n    \"\"\"Revenue forecast model.\"\"\"\n\n    month: datetime\n    expected_income: float\n    lower_bound: float\n    upper_bound: float\n    confidence_interval: float\n    sources: Dict[str, float] = Field(default_factory=dict)  # Client/project breakdown\n    notes: Optional[str] = None",
                "class SmoothedIncome(BaseModel):\n    \"\"\"Smoothed income calculation result.\"\"\"\n\n    period_start: datetime\n    period_end: datetime\n    actual_income: float\n    smoothed_income: float\n    method: SmoothingMethod\n    configuration: SmoothingConfig\n    income_deficit: float = 0.0  # Negative when actual < smoothed\n    income_surplus: float = 0.0  # Positive when actual > smoothed\n    notes: Optional[str] = None",
                "class SmoothedIncome(BaseModel):\n    \"\"\"Smoothed income calculation result.\"\"\"\n\n    period_start: datetime\n    period_end: datetime\n    actual_income: float\n    smoothed_income: float\n    method: SmoothingMethod\n    configuration: SmoothingConfig\n    income_deficit: float = 0.0  # Negative when actual < smoothed\n    income_surplus: float = 0.0  # Positive when actual > smoothed\n    notes: Optional[str] = None",
                "class SmoothedIncome(BaseModel):\n    \"\"\"Smoothed income calculation result.\"\"\"\n\n    period_start: datetime\n    period_end: datetime\n    actual_income: float\n    smoothed_income: float\n    method: SmoothingMethod\n    configuration: SmoothingConfig\n    income_deficit: float = 0.0  # Negative when actual < smoothed\n    income_surplus: float = 0.0  # Positive when actual > smoothed\n    notes: Optional[str] = None",
                "class SmoothedIncome(BaseModel):\n    \"\"\"Smoothed income calculation result.\"\"\"\n\n    period_start: datetime\n    period_end: datetime\n    actual_income: float\n    smoothed_income: float\n    method: SmoothingMethod\n    configuration: SmoothingConfig\n    income_deficit: float = 0.0  # Negative when actual < smoothed\n    income_surplus: float = 0.0  # Positive when actual > smoothed\n    notes: Optional[str] = None",
                "class SmoothedIncome(BaseModel):\n    \"\"\"Smoothed income calculation result.\"\"\"\n\n    period_start: datetime\n    period_end: datetime\n    actual_income: float\n    smoothed_income: float\n    method: SmoothingMethod\n    configuration: SmoothingConfig\n    income_deficit: float = 0.0  # Negative when actual < smoothed\n    income_surplus: float = 0.0  # Positive when actual > smoothed\n    notes: Optional[str] = None",
                "class SpendingLevel(str, Enum):\n    \"\"\"Spending level for cash runway projections.\"\"\"\n\n    MINIMAL = \"minimal\"  # Essential expenses only\n    REDUCED = \"reduced\"  # Reduced discretionary spending\n    NORMAL = \"normal\"  # Normal spending patterns\n    INCREASED = \"increased\"",
                "class SpendingLevel(str, Enum):\n    \"\"\"Spending level for cash runway projections.\"\"\"\n\n    MINIMAL = \"minimal\"  # Essential expenses only\n    REDUCED = \"reduced\"  # Reduced discretionary spending\n    NORMAL = \"normal\"  # Normal spending patterns\n    INCREASED = \"increased\"",
                "class SpendingLevel(str, Enum):\n    \"\"\"Spending level for cash runway projections.\"\"\"\n\n    MINIMAL = \"minimal\"  # Essential expenses only\n    REDUCED = \"reduced\"  # Reduced discretionary spending\n    NORMAL = \"normal\"  # Normal spending patterns\n    INCREASED = \"increased\"",
                "class SpendingLevel(str, Enum):\n    \"\"\"Spending level for cash runway projections.\"\"\"\n\n    MINIMAL = \"minimal\"  # Essential expenses only\n    REDUCED = \"reduced\"  # Reduced discretionary spending\n    NORMAL = \"normal\"  # Normal spending patterns\n    INCREASED = \"increased\"",
                "class RevenueSource(BaseModel):\n    \"\"\"Revenue source for cash flow projections.\"\"\"\n\n    name: str\n    amount: float\n    probability: float = 100.0  # Percentage probability of receiving this income\n    expected_date: Optional[datetime] = None\n    recurring: bool = False\n    recurrence_frequency: Optional[str] = None  # e.g., \"monthly\", \"quarterly\"\n    notes: Optional[str] = None\n\n    @validator(\"probability\")\n    def validate_probability(cls, v):\n        \"\"\"Validate probability is between 0 and 100.\"\"\"\n        if v < 0 or v > 100:\n            raise ValueError(\"Probability must be between 0 and 100\")\n        return v",
                "class RevenueSource(BaseModel):\n    \"\"\"Revenue source for cash flow projections.\"\"\"\n\n    name: str\n    amount: float\n    probability: float = 100.0  # Percentage probability of receiving this income\n    expected_date: Optional[datetime] = None\n    recurring: bool = False\n    recurrence_frequency: Optional[str] = None  # e.g., \"monthly\", \"quarterly\"\n    notes: Optional[str] = None\n\n    @validator(\"probability\")\n    def validate_probability(cls, v):\n        \"\"\"Validate probability is between 0 and 100.\"\"\"\n        if v < 0 or v > 100:\n            raise ValueError(\"Probability must be between 0 and 100\")\n        return v",
                "class RevenueSource(BaseModel):\n    \"\"\"Revenue source for cash flow projections.\"\"\"\n\n    name: str\n    amount: float\n    probability: float = 100.0  # Percentage probability of receiving this income\n    expected_date: Optional[datetime] = None\n    recurring: bool = False\n    recurrence_frequency: Optional[str] = None  # e.g., \"monthly\", \"quarterly\"\n    notes: Optional[str] = None\n\n    @validator(\"probability\")\n    def validate_probability(cls, v):\n        \"\"\"Validate probability is between 0 and 100.\"\"\"\n        if v < 0 or v > 100:\n            raise ValueError(\"Probability must be between 0 and 100\")\n        return v",
                "class RevenueSource(BaseModel):\n    \"\"\"Revenue source for cash flow projections.\"\"\"\n\n    name: str\n    amount: float\n    probability: float = 100.0  # Percentage probability of receiving this income\n    expected_date: Optional[datetime] = None\n    recurring: bool = False\n    recurrence_frequency: Optional[str] = None  # e.g., \"monthly\", \"quarterly\"\n    notes: Optional[str] = None\n\n    @validator(\"probability\")\n    def validate_probability(cls, v):\n        \"\"\"Validate probability is between 0 and 100.\"\"\"\n        if v < 0 or v > 100:\n            raise ValueError(\"Probability must be between 0 and 100\")\n        return v",
                "class ExpenseItem(BaseModel):\n    \"\"\"Expense item for cash flow projections.\"\"\"\n\n    name: str\n    amount: float\n    category: str\n    due_date: Optional[datetime] = None\n    recurring: bool = False\n    recurrence_frequency: Optional[str] = None  # e.g., \"monthly\", \"quarterly\"\n    essential: bool = False  # Whether this is an essential expense\n    notes: Optional[str] = None",
                "class ExpenseItem(BaseModel):\n    \"\"\"Expense item for cash flow projections.\"\"\"\n\n    name: str\n    amount: float\n    category: str\n    due_date: Optional[datetime] = None\n    recurring: bool = False\n    recurrence_frequency: Optional[str] = None  # e.g., \"monthly\", \"quarterly\"\n    essential: bool = False  # Whether this is an essential expense\n    notes: Optional[str] = None",
                "class ExpenseItem(BaseModel):\n    \"\"\"Expense item for cash flow projections.\"\"\"\n\n    name: str\n    amount: float\n    category: str\n    due_date: Optional[datetime] = None\n    recurring: bool = False\n    recurrence_frequency: Optional[str] = None  # e.g., \"monthly\", \"quarterly\"\n    essential: bool = False  # Whether this is an essential expense\n    notes: Optional[str] = None",
                "class ExpenseItem(BaseModel):\n    \"\"\"Expense item for cash flow projections.\"\"\"\n\n    name: str\n    amount: float\n    category: str\n    due_date: Optional[datetime] = None\n    recurring: bool = False\n    recurrence_frequency: Optional[str] = None  # e.g., \"monthly\", \"quarterly\"\n    essential: bool = False  # Whether this is an essential expense\n    notes: Optional[str] = None",
                "class CashFlowProjection(BaseModel):\n    \"\"\"Cash flow projection for a specific timeframe.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    start_date: datetime\n    end_date: datetime\n    scenario: ProjectionScenario = ProjectionScenario.BASELINE\n    starting_balance: float\n    ending_balance: float\n    total_income: float\n    total_expenses: float\n    net_cash_flow: float\n    monthly_breakdown: Dict[str, Dict[str, float]] = Field(default_factory=dict)\n    confidence_interval: float = 0.8  # 80% confidence interval by default\n    notes: Optional[str] = None\n\n    @validator(\"confidence_interval\")\n    def validate_confidence(cls, v):\n        \"\"\"Validate confidence interval is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Confidence interval must be between 0 and 1\")\n        return v\n    \n    @classmethod\n    def from_common_projection(cls, projection: Projection, monthly_breakdown: Dict[str, Dict[str, float]]) -> \"CashFlowProjection\":\n        \"\"\"\n        Convert a common Projection to our specialized CashFlowProjection.\n        \n        Args:\n            projection: The common projection to convert\n            monthly_breakdown: Monthly breakdown of income, expenses, and balance\n            \n        Returns:\n            Our specialized CashFlowProjection\n        \"\"\"\n        # Calculate total income and expenses\n        total_income = sum(cf.income for cf in projection.cash_flows)\n        total_expenses = sum(cf.expenses for cf in projection.cash_flows)\n        \n        return cls(\n            start_date=projection.start_date,\n            end_date=projection.end_date,\n            scenario=projection.scenario,\n            starting_balance=projection.starting_balance,\n            ending_balance=projection.final_balance,\n            total_income=total_income,\n            total_expenses=total_expenses,\n            net_cash_flow=total_income - total_expenses,\n            monthly_breakdown=monthly_breakdown,\n            confidence_interval=projection.confidence_level,\n        )",
                "class CashFlowProjection(BaseModel):\n    \"\"\"Cash flow projection for a specific timeframe.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    start_date: datetime\n    end_date: datetime\n    scenario: ProjectionScenario = ProjectionScenario.BASELINE\n    starting_balance: float\n    ending_balance: float\n    total_income: float\n    total_expenses: float\n    net_cash_flow: float\n    monthly_breakdown: Dict[str, Dict[str, float]] = Field(default_factory=dict)\n    confidence_interval: float = 0.8  # 80% confidence interval by default\n    notes: Optional[str] = None\n\n    @validator(\"confidence_interval\")\n    def validate_confidence(cls, v):\n        \"\"\"Validate confidence interval is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Confidence interval must be between 0 and 1\")\n        return v\n    \n    @classmethod\n    def from_common_projection(cls, projection: Projection, monthly_breakdown: Dict[str, Dict[str, float]]) -> \"CashFlowProjection\":\n        \"\"\"\n        Convert a common Projection to our specialized CashFlowProjection.\n        \n        Args:\n            projection: The common projection to convert\n            monthly_breakdown: Monthly breakdown of income, expenses, and balance\n            \n        Returns:\n            Our specialized CashFlowProjection\n        \"\"\"\n        # Calculate total income and expenses\n        total_income = sum(cf.income for cf in projection.cash_flows)\n        total_expenses = sum(cf.expenses for cf in projection.cash_flows)\n        \n        return cls(\n            start_date=projection.start_date,\n            end_date=projection.end_date,\n            scenario=projection.scenario,\n            starting_balance=projection.starting_balance,\n            ending_balance=projection.final_balance,\n            total_income=total_income,\n            total_expenses=total_expenses,\n            net_cash_flow=total_income - total_expenses,\n            monthly_breakdown=monthly_breakdown,\n            confidence_interval=projection.confidence_level,\n        )",
                "class CashFlowProjection(BaseModel):\n    \"\"\"Cash flow projection for a specific timeframe.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    start_date: datetime\n    end_date: datetime\n    scenario: ProjectionScenario = ProjectionScenario.BASELINE\n    starting_balance: float\n    ending_balance: float\n    total_income: float\n    total_expenses: float\n    net_cash_flow: float\n    monthly_breakdown: Dict[str, Dict[str, float]] = Field(default_factory=dict)\n    confidence_interval: float = 0.8  # 80% confidence interval by default\n    notes: Optional[str] = None\n\n    @validator(\"confidence_interval\")\n    def validate_confidence(cls, v):\n        \"\"\"Validate confidence interval is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Confidence interval must be between 0 and 1\")\n        return v\n    \n    @classmethod\n    def from_common_projection(cls, projection: Projection, monthly_breakdown: Dict[str, Dict[str, float]]) -> \"CashFlowProjection\":\n        \"\"\"\n        Convert a common Projection to our specialized CashFlowProjection.\n        \n        Args:\n            projection: The common projection to convert\n            monthly_breakdown: Monthly breakdown of income, expenses, and balance\n            \n        Returns:\n            Our specialized CashFlowProjection\n        \"\"\"\n        # Calculate total income and expenses\n        total_income = sum(cf.income for cf in projection.cash_flows)\n        total_expenses = sum(cf.expenses for cf in projection.cash_flows)\n        \n        return cls(\n            start_date=projection.start_date,\n            end_date=projection.end_date,\n            scenario=projection.scenario,\n            starting_balance=projection.starting_balance,\n            ending_balance=projection.final_balance,\n            total_income=total_income,\n            total_expenses=total_expenses,\n            net_cash_flow=total_income - total_expenses,\n            monthly_breakdown=monthly_breakdown,\n            confidence_interval=projection.confidence_level,\n        )",
                "class CashFlowProjection(BaseModel):\n    \"\"\"Cash flow projection for a specific timeframe.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    start_date: datetime\n    end_date: datetime\n    scenario: ProjectionScenario = ProjectionScenario.BASELINE\n    starting_balance: float\n    ending_balance: float\n    total_income: float\n    total_expenses: float\n    net_cash_flow: float\n    monthly_breakdown: Dict[str, Dict[str, float]] = Field(default_factory=dict)\n    confidence_interval: float = 0.8  # 80% confidence interval by default\n    notes: Optional[str] = None\n\n    @validator(\"confidence_interval\")\n    def validate_confidence(cls, v):\n        \"\"\"Validate confidence interval is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Confidence interval must be between 0 and 1\")\n        return v\n    \n    @classmethod\n    def from_common_projection(cls, projection: Projection, monthly_breakdown: Dict[str, Dict[str, float]]) -> \"CashFlowProjection\":\n        \"\"\"\n        Convert a common Projection to our specialized CashFlowProjection.\n        \n        Args:\n            projection: The common projection to convert\n            monthly_breakdown: Monthly breakdown of income, expenses, and balance\n            \n        Returns:\n            Our specialized CashFlowProjection\n        \"\"\"\n        # Calculate total income and expenses\n        total_income = sum(cf.income for cf in projection.cash_flows)\n        total_expenses = sum(cf.expenses for cf in projection.cash_flows)\n        \n        return cls(\n            start_date=projection.start_date,\n            end_date=projection.end_date,\n            scenario=projection.scenario,\n            starting_balance=projection.starting_balance,\n            ending_balance=projection.final_balance,\n            total_income=total_income,\n            total_expenses=total_expenses,\n            net_cash_flow=total_income - total_expenses,\n            monthly_breakdown=monthly_breakdown,\n            confidence_interval=projection.confidence_level,\n        )",
                "class RunwayProjection(BaseModel):\n    \"\"\"Cash runway projection showing how long funds will last.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    calculation_date: datetime = Field(default_factory=datetime.now)\n    starting_balance: float\n    spending_level: SpendingLevel\n    monthly_expense_rate: float\n    expected_income: Dict[str, float] = Field(default_factory=dict)  # Month -> amount\n    runway_months: float\n    depletion_date: Optional[datetime] = None\n    confidence_level: float = 0.8\n    notes: Optional[str] = None\n\n    @validator(\"confidence_level\")\n    def validate_confidence(cls, v):\n        \"\"\"Validate confidence level is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Confidence level must be between 0 and 1\")\n        return v",
                "class RunwayProjection(BaseModel):\n    \"\"\"Cash runway projection showing how long funds will last.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    calculation_date: datetime = Field(default_factory=datetime.now)\n    starting_balance: float\n    spending_level: SpendingLevel\n    monthly_expense_rate: float\n    expected_income: Dict[str, float] = Field(default_factory=dict)  # Month -> amount\n    runway_months: float\n    depletion_date: Optional[datetime] = None\n    confidence_level: float = 0.8\n    notes: Optional[str] = None\n\n    @validator(\"confidence_level\")\n    def validate_confidence(cls, v):\n        \"\"\"Validate confidence level is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Confidence level must be between 0 and 1\")\n        return v",
                "class RunwayProjection(BaseModel):\n    \"\"\"Cash runway projection showing how long funds will last.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    calculation_date: datetime = Field(default_factory=datetime.now)\n    starting_balance: float\n    spending_level: SpendingLevel\n    monthly_expense_rate: float\n    expected_income: Dict[str, float] = Field(default_factory=dict)  # Month -> amount\n    runway_months: float\n    depletion_date: Optional[datetime] = None\n    confidence_level: float = 0.8\n    notes: Optional[str] = None\n\n    @validator(\"confidence_level\")\n    def validate_confidence(cls, v):\n        \"\"\"Validate confidence level is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Confidence level must be between 0 and 1\")\n        return v",
                "class RunwayProjection(BaseModel):\n    \"\"\"Cash runway projection showing how long funds will last.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    calculation_date: datetime = Field(default_factory=datetime.now)\n    starting_balance: float\n    spending_level: SpendingLevel\n    monthly_expense_rate: float\n    expected_income: Dict[str, float] = Field(default_factory=dict)  # Month -> amount\n    runway_months: float\n    depletion_date: Optional[datetime] = None\n    confidence_level: float = 0.8\n    notes: Optional[str] = None\n\n    @validator(\"confidence_level\")\n    def validate_confidence(cls, v):\n        \"\"\"Validate confidence level is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Confidence level must be between 0 and 1\")\n        return v",
                "class ScenarioParameter(BaseModel):\n    \"\"\"Parameter for what-if scenario analysis.\"\"\"\n\n    name: str\n    description: Optional[str] = None\n    current_value: float\n    min_value: float\n    max_value: float\n    step_size: float = 1.0\n    unit: Optional[str] = None",
                "class ScenarioParameter(BaseModel):\n    \"\"\"Parameter for what-if scenario analysis.\"\"\"\n\n    name: str\n    description: Optional[str] = None\n    current_value: float\n    min_value: float\n    max_value: float\n    step_size: float = 1.0\n    unit: Optional[str] = None",
                "class ScenarioParameter(BaseModel):\n    \"\"\"Parameter for what-if scenario analysis.\"\"\"\n\n    name: str\n    description: Optional[str] = None\n    current_value: float\n    min_value: float\n    max_value: float\n    step_size: float = 1.0\n    unit: Optional[str] = None",
                "class ScenarioParameter(BaseModel):\n    \"\"\"Parameter for what-if scenario analysis.\"\"\"\n\n    name: str\n    description: Optional[str] = None\n    current_value: float\n    min_value: float\n    max_value: float\n    step_size: float = 1.0\n    unit: Optional[str] = None",
                "class WhatIfScenario(BaseModel):\n    \"\"\"What-if scenario for financial planning.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    name: str\n    description: Optional[str] = None\n    base_scenario: ProjectionScenario\n    parameters: List[ScenarioParameter] = Field(default_factory=list)\n    result_metrics: Dict[str, float] = Field(default_factory=dict)\n    creation_date: datetime = Field(default_factory=datetime.now)\n    notes: Optional[str] = None",
                "class WhatIfScenario(BaseModel):\n    \"\"\"What-if scenario for financial planning.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    name: str\n    description: Optional[str] = None\n    base_scenario: ProjectionScenario\n    parameters: List[ScenarioParameter] = Field(default_factory=list)\n    result_metrics: Dict[str, float] = Field(default_factory=dict)\n    creation_date: datetime = Field(default_factory=datetime.now)\n    notes: Optional[str] = None",
                "class WhatIfScenario(BaseModel):\n    \"\"\"What-if scenario for financial planning.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    name: str\n    description: Optional[str] = None\n    base_scenario: ProjectionScenario\n    parameters: List[ScenarioParameter] = Field(default_factory=list)\n    result_metrics: Dict[str, float] = Field(default_factory=dict)\n    creation_date: datetime = Field(default_factory=datetime.now)\n    notes: Optional[str] = None",
                "class WhatIfScenario(BaseModel):\n    \"\"\"What-if scenario for financial planning.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    name: str\n    description: Optional[str] = None\n    base_scenario: ProjectionScenario\n    parameters: List[ScenarioParameter] = Field(default_factory=list)\n    result_metrics: Dict[str, float] = Field(default_factory=dict)\n    creation_date: datetime = Field(default_factory=datetime.now)\n    notes: Optional[str] = None",
                "class EmergencyFundAssessment(BaseModel):\n    \"\"\"Assessment of emergency fund adequacy.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    assessment_date: datetime = Field(default_factory=datetime.now)\n    current_fund_balance: float\n    monthly_essential_expenses: float\n    recommended_months_coverage: float = 6.0\n    recommended_fund_size: float\n    current_coverage_months: float\n    adequacy_level: str  # e.g., \"inadequate\", \"minimal\", \"adequate\", \"excellent\"\n    funding_plan: Optional[str] = None\n    notes: Optional[str] = None",
                "class EmergencyFundAssessment(BaseModel):\n    \"\"\"Assessment of emergency fund adequacy.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    assessment_date: datetime = Field(default_factory=datetime.now)\n    current_fund_balance: float\n    monthly_essential_expenses: float\n    recommended_months_coverage: float = 6.0\n    recommended_fund_size: float\n    current_coverage_months: float\n    adequacy_level: str  # e.g., \"inadequate\", \"minimal\", \"adequate\", \"excellent\"\n    funding_plan: Optional[str] = None\n    notes: Optional[str] = None",
                "class EmergencyFundAssessment(BaseModel):\n    \"\"\"Assessment of emergency fund adequacy.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    assessment_date: datetime = Field(default_factory=datetime.now)\n    current_fund_balance: float\n    monthly_essential_expenses: float\n    recommended_months_coverage: float = 6.0\n    recommended_fund_size: float\n    current_coverage_months: float\n    adequacy_level: str  # e.g., \"inadequate\", \"minimal\", \"adequate\", \"excellent\"\n    funding_plan: Optional[str] = None\n    notes: Optional[str] = None",
                "class EmergencyFundAssessment(BaseModel):\n    \"\"\"Assessment of emergency fund adequacy.\"\"\"\n\n    id: UUID = Field(default_factory=uuid4)\n    assessment_date: datetime = Field(default_factory=datetime.now)\n    current_fund_balance: float\n    monthly_essential_expenses: float\n    recommended_months_coverage: float = 6.0\n    recommended_fund_size: float\n    current_coverage_months: float\n    adequacy_level: str  # e.g., \"inadequate\", \"minimal\", \"adequate\", \"excellent\"\n    funding_plan: Optional[str] = None\n    notes: Optional[str] = None"
            ]
        }
    },
    "unified/ethical_finance/models.py": {
        "logprobs": -1045.6315144885593,
        "metrics": {
            "loc": 219,
            "sloc": 112,
            "lloc": 100,
            "comments": 42,
            "multi": 0,
            "blank": 43,
            "cyclomatic": 17,
            "internal_imports": [
                "class Investment(BaseModel):\n    \"\"\"\n    Investment model representing an investment opportunity.\n    \n    Used for tracking investment options, ESG ratings, and performance.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    sector: str\n    industry: str\n    market_cap: float\n    price: float\n    esg_ratings: ESGRating\n    carbon_footprint: float\n    renewable_energy_use: float\n    diversity_score: float\n    board_independence: float\n    controversies: List[str] = Field(default_factory=list)\n    positive_practices: List[str] = Field(default_factory=list)\n    \n    @property\n    def has_major_controversies(self) -> bool:\n        \"\"\"Check if the investment has major controversies.\"\"\"\n        major_issues = [\"human_rights\", \"fraud\", \"corruption\", \"environmental_disaster\"]\n        return any(issue in self.controversies for issue in major_issues)\n    \n    @validator(\"market_cap\", \"price\", \"carbon_footprint\")\n    def validate_positive_numbers(cls, v):\n        \"\"\"Validate that financial amounts are positive numbers.\"\"\"\n        if v < 0:\n            raise ValueError(\"Value must be a positive number\")\n        return v\n    \n    @validator(\"renewable_energy_use\", \"diversity_score\", \"board_independence\")\n    def validate_percentage(cls, v):\n        \"\"\"Validate that percentages are between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Value must be between 0 and 1\")\n        return v",
                "class ESGRating(BaseModel):\n    \"\"\"Environmental, Social, and Governance ratings for an investment.\"\"\"\n    \n    environmental: int\n    social: int\n    governance: int\n    overall: int\n    \n    @root_validator(skip_on_failure=True)\n    def validate_overall_score(cls, values):\n        \"\"\"Validate that the overall score is consistent with component scores.\"\"\"\n        env = values.get(\"environmental\", 0)\n        soc = values.get(\"social\", 0) \n        gov = values.get(\"governance\", 0)\n        overall = values.get(\"overall\", 0)\n        \n        # Check if overall is within a reasonable range of the average\n        component_avg = (env + soc + gov) / 3\n        if abs(overall - component_avg) > 15:  # Allow some variation in methodology\n            raise ValueError(\n                f\"Overall score {overall} is too different from component average {component_avg:.1f}\"\n            )\n        return values",
                "class InvestmentHolding(BaseModel):\n    \"\"\"\n    Investment holding model for tracking specific holdings in a portfolio.\n    \n    Used for tracking portfolio composition, performance, and value.\n    \"\"\"\n\n    investment_id: str\n    shares: float\n    purchase_price: float\n    purchase_date: Union[date, datetime]\n    current_price: float\n    current_value: float\n    \n    @root_validator(skip_on_failure=True)\n    def validate_current_value(cls, values):\n        \"\"\"Validate that current_value = shares * current_price.\"\"\"\n        shares = values.get(\"shares\", 0)\n        current_price = values.get(\"current_price\", 0)\n        current_value = values.get(\"current_value\", 0)\n        \n        expected_value = shares * current_price\n        if abs(current_value - expected_value) > 0.01:  # Allow for small rounding errors\n            raise ValueError(\n                f\"Current value {current_value} does not match shares * price {expected_value}\"\n            )\n        return values\n    \n    @property\n    def return_percentage(self) -> float:\n        \"\"\"Calculate the percentage return on this holding.\"\"\"\n        return (self.current_price / self.purchase_price - 1) * 100",
                "class Portfolio(BaseModel):\n    \"\"\"\n    Portfolio model for tracking a collection of investment holdings.\n    \n    Used for portfolio analysis, performance tracking, and reporting.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    holdings: List[InvestmentHolding] = Field(default_factory=list)\n    total_value: float\n    cash_balance: float\n    creation_date: Union[date, datetime]\n    last_updated: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    @root_validator(skip_on_failure=True)\n    def validate_total_value(cls, values):\n        \"\"\"Validate that total_value equals the sum of all holdings' values.\"\"\"\n        holdings = values.get(\"holdings\", [])\n        total_value = values.get(\"total_value\", 0)\n        \n        if not holdings:\n            # If no holdings, total value should equal cash balance\n            cash_balance = values.get(\"cash_balance\", 0)\n            if abs(total_value - cash_balance) > 0.01:  # Allow for small rounding errors\n                raise ValueError(\n                    f\"Total value {total_value} does not match cash balance {cash_balance}\"\n                )\n        else:\n            # If there are holdings, validate total value\n            holdings_sum = sum(holding.current_value for holding in holdings)\n            if abs(total_value - holdings_sum) > 0.01:  # Allow for small rounding errors\n                raise ValueError(\n                    f\"Total value {total_value} does not match holdings sum {holdings_sum}\"\n                )\n        \n        return values\n    \n    @property\n    def total_assets(self) -> float:\n        \"\"\"Calculate total assets including cash.\"\"\"\n        return self.total_value + self.cash_balance\n    \n    def get_asset_allocation(self) -> Dict[str, float]:\n        \"\"\"Calculate the allocation percentage for each asset.\"\"\"\n        if not self.holdings:\n            return {\"cash\": 100.0}\n        \n        allocation = {}\n        total_assets = self.total_assets\n        \n        # Add cash allocation\n        cash_percent = (self.cash_balance / total_assets) * 100\n        allocation[\"cash\"] = cash_percent\n        \n        # Add investment allocations\n        for holding in self.holdings:\n            holding_percent = (holding.current_value / total_assets) * 100\n            allocation[holding.investment_id] = holding_percent\n            \n        return allocation",
                "class EthicalCriteria(BaseModel):\n    \"\"\"\n    Ethical screening criteria for investments.\n    \n    Used for evaluating investments against personalized ethical standards.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    environmental: Dict[str, Any]\n    social: Dict[str, Any]\n    governance: Dict[str, Any]\n    min_overall_score: float\n    exclusions: List[str] = Field(default_factory=list)\n    inclusions: List[str] = Field(default_factory=list)\n    \n    @root_validator(skip_on_failure=True)\n    def validate_criteria_weights(cls, values):\n        \"\"\"Validate that criteria weights are included and sum approximately to 1.\"\"\"\n        for field_name in ['environmental', 'social', 'governance']:\n            field_value = values.get(field_name, {})\n            \n            # Check that weight exists\n            if 'weight' not in field_value:\n                raise ValueError(f\"{field_name} criteria must include a weight\")\n            \n            # Ensure weight is between 0 and 1\n            if field_value['weight'] < 0 or field_value['weight'] > 1:\n                raise ValueError(f\"{field_name} weight must be between 0 and 1\")\n        \n        # Check that weights sum to approximately 1\n        weights_sum = (\n            values.get('environmental', {}).get('weight', 0) + \n            values.get('social', {}).get('weight', 0) + \n            values.get('governance', {}).get('weight', 0)\n        )\n        \n        if abs(weights_sum - 1.0) > 0.01:  # Allow for small rounding errors\n            raise ValueError(f\"Criteria weights sum to {weights_sum}, expected 1.0\")\n            \n        return values",
                "class ImpactMetric(BaseModel):\n    \"\"\"\n    Impact metric model for defining and tracking non-financial impacts.\n    \n    Used for measuring the social and environmental impact of investments.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    category: str\n    unit: str\n    description: str\n    higher_is_better: bool\n    data_source: str",
                "class ImpactData(BaseModel):\n    \"\"\"\n    Impact data for a specific investment in a specific year.\n    \n    Used for tracking the actual impact of investments over time.\n    \"\"\"\n\n    investment_id: str\n    year: int\n    metrics: Dict[str, float]\n    \n    @validator(\"year\")\n    def validate_year(cls, v):\n        \"\"\"Validate that year is reasonable.\"\"\"\n        current_year = datetime.now().year\n        if v < 1900 or v > current_year + 1:\n            raise ValueError(f\"Year {v} is outside reasonable range\")\n        return v",
                "class BaseTransaction(BaseModel):\n    \"\"\"\n    Base transaction model for all financial transactions.\n    \n    This abstract base class provides common fields for tracking\n    financial transactions across different persona implementations.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    date: Union[date, datetime]\n    amount: float\n    description: str\n    transaction_type: TransactionType\n    \n    # Optional fields\n    account_id: Optional[str] = None\n    category: Optional[str] = None\n    tags: List[str] = Field(default_factory=list)\n    notes: Optional[str] = None\n    \n    @validator(\"amount\")\n    def validate_amount(cls, v):\n        \"\"\"Validate that amount is a valid number.\"\"\"\n        if not isinstance(v, (int, float)):\n            raise ValueError(\"Amount must be a number\")\n        return v"
            ]
        }
    },
    "unified/common/core/analysis/__init__.py": {
        "logprobs": -404.7923068338186,
        "metrics": {
            "loc": 61,
            "sloc": 52,
            "lloc": 6,
            "comments": 4,
            "multi": 0,
            "blank": 8,
            "cyclomatic": 0,
            "internal_imports": [
                "class BaseAnalyzer(Generic[T, R], ABC):\n    \"\"\"\n    Abstract base class for analysis engines.\n    \n    Defines the core interface and functionality for all analyzers\n    across different persona implementations.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the analyzer.\"\"\"\n        self._analysis_cache: Dict[str, R] = {}\n    \n    @abstractmethod\n    def analyze(\n        self, subject: T, parameters: Optional[AnalysisParameters] = None\n    ) -> R:\n        \"\"\"\n        Analyze a single subject.\n        \n        Args:\n            subject: The subject to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Analysis result\n        \"\"\"\n        pass\n    \n    def analyze_batch(\n        self, subjects: List[T], parameters: Optional[AnalysisParameters] = None\n    ) -> List[R]:\n        \"\"\"\n        Analyze multiple subjects.\n        \n        Args:\n            subjects: List of subjects to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            List of analysis results\n        \"\"\"\n        # Start performance timer\n        start_time = time.time()\n        \n        # Analyze each subject\n        results = []\n        for subject in subjects:\n            result = self.analyze(subject, parameters)\n            results.append(result)\n        \n        # Performance metrics\n        elapsed_time = time.time() - start_time\n        \n        return results\n    \n    def clear_cache(self) -> None:\n        \"\"\"Clear the analysis cache.\"\"\"\n        self._analysis_cache = {}\n    \n    def _generate_cache_key(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> str:\n        \"\"\"\n        Generate a cache key for a subject and parameters.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cache key string\n        \"\"\"\n        # Start with the subject ID\n        key = f\"subject_{subject_id}\"\n        \n        # Add parameter details if provided\n        if parameters:\n            param_dict = parameters.dict(exclude_none=True)\n            for k, v in sorted(param_dict.items()):\n                if k != \"custom_settings\":\n                    key += f\"_{k}_{v}\"\n                    \n            # Handle custom settings separately (they could be complex)\n            if parameters.custom_settings:\n                for k, v in sorted(parameters.custom_settings.items()):\n                    key += f\"_{k}_{v}\"\n        \n        return key\n    \n    def _get_from_cache(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> Optional[R]:\n        \"\"\"\n        Get a cached analysis result if available.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cached result or None if not found\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        return self._analysis_cache.get(cache_key)\n    \n    def _save_to_cache(\n        self, subject_id: Union[str, UUID], result: R, parameters: Optional[AnalysisParameters] = None\n    ) -> None:\n        \"\"\"\n        Save an analysis result to the cache.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            result: The analysis result to cache\n            parameters: Optional parameters to configure the analysis\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        self._analysis_cache[cache_key] = result",
                "class AnalysisResult(BaseModel, Generic[T]):\n    \"\"\"\n    Result of an analysis operation.\n    \n    Provides information about the analysis process and outcome.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    subject_id: Optional[Union[str, UUID]] = None\n    subject_type: str\n    analysis_type: str\n    analysis_date: datetime = Field(default_factory=datetime.now)\n    processing_time_ms: Optional[float] = None\n    result_summary: Dict[str, Any] = Field(default_factory=dict)\n    detailed_results: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class AnalysisParameters(BaseModel):\n    \"\"\"\n    Parameters for an analysis operation.\n    \n    Used to configure analysis options and settings.\n    \"\"\"\n    \n    period_start: Optional[Union[date, datetime]] = None\n    period_end: Optional[Union[date, datetime]] = None\n    include_details: bool = True\n    calculation_mode: str = \"standard\"  # \"standard\", \"detailed\", \"fast\"\n    grouping: Optional[str] = None\n    custom_settings: Dict[str, Any] = Field(default_factory=dict)",
                "class TimeSeriesGranularity(str, Enum):\n    \"\"\"Granularity for time series data.\"\"\"\n    \n    DAILY = \"daily\"\n    WEEKLY = \"weekly\"\n    MONTHLY = \"monthly\"\n    QUARTERLY = \"quarterly\"\n    YEARLY = \"yearly\"",
                "class TimeSeriesData(BaseModel):\n    \"\"\"\n    Model for time series data.\n    \n    Used for storing and manipulating time series data for analysis.\n    \"\"\"\n    \n    dates: List[Union[date, datetime]]\n    values: List[float]\n    labels: Optional[List[str]] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class TimeSeriesParameters(AnalysisParameters):\n    \"\"\"\n    Parameters for time series analysis.\n    \n    Used to configure time series analysis options and settings.\n    \"\"\"\n    \n    granularity: TimeSeriesGranularity = TimeSeriesGranularity.MONTHLY\n    smoothing_method: Optional[str] = None  # \"moving_avg\", \"exponential\", \"seasonal\"\n    window_size: int = 3  # For moving average\n    alpha: float = 0.3  # For exponential smoothing\n    seasonal_period: int = 12  # For seasonal adjustment\n    fill_missing: bool = True\n    normalize: bool = False\n    extrapolate: bool = False\n    extrapolation_periods: int = 3",
                "class TimeSeriesAnalyzer:\n    \"\"\"\n    Utility class for analyzing time series data.\n    \n    Provides methods for smoothing, trend detection, and forecasting.\n    \"\"\"\n    \n    @staticmethod\n    def moving_average(\n        data: TimeSeriesData, window_size: int = 3\n    ) -> TimeSeriesData:\n        \"\"\"\n        Calculate the moving average of time series data.\n        \n        Args:\n            data: The time series data\n            window_size: The window size for the moving average\n            \n        Returns:\n            New time series data with smoothed values\n        \"\"\"\n        if not data.values:\n            return TimeSeriesData(dates=[], values=[])\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Calculate the cumulative sum of values\n        cumsum = np.cumsum(values)\n        \n        # Calculate the moving average using the window\n        smoothed = np.zeros_like(values)\n        \n        # Handle the start of the array (where we don't have a full window)\n        for i in range(min(window_size, len(values))):\n            smoothed[i] = cumsum[i] / (i + 1)\n        \n        # Handle the rest of the array\n        for i in range(window_size, len(values)):\n            smoothed[i] = (cumsum[i] - cumsum[i - window_size]) / window_size\n        \n        # Create new time series data with smoothed values\n        return TimeSeriesData(\n            dates=data.dates,\n            values=smoothed.tolist(),\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"smoothing_method\": \"moving_average\",\n                \"window_size\": window_size,\n            },\n        )\n    \n    @staticmethod\n    def exponential_smoothing(\n        data: TimeSeriesData, alpha: float = 0.3\n    ) -> TimeSeriesData:\n        \"\"\"\n        Apply exponential smoothing to time series data.\n        \n        Args:\n            data: The time series data\n            alpha: The smoothing factor (0 < alpha < 1)\n            \n        Returns:\n            New time series data with smoothed values\n        \"\"\"\n        if not data.values:\n            return TimeSeriesData(dates=[], values=[])\n        \n        # Ensure alpha is between 0 and 1\n        alpha = max(0.01, min(0.99, alpha))\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Initialize the smoothed array with the first value\n        smoothed = np.zeros_like(values)\n        smoothed[0] = values[0]\n        \n        # Apply exponential smoothing\n        for i in range(1, len(values)):\n            smoothed[i] = alpha * values[i] + (1 - alpha) * smoothed[i - 1]\n        \n        # Create new time series data with smoothed values\n        return TimeSeriesData(\n            dates=data.dates,\n            values=smoothed.tolist(),\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"smoothing_method\": \"exponential\",\n                \"alpha\": alpha,\n            },\n        )\n    \n    @staticmethod\n    def seasonal_adjustment(\n        data: TimeSeriesData, period: int = 12\n    ) -> TimeSeriesData:\n        \"\"\"\n        Apply seasonal adjustment to time series data.\n        \n        Args:\n            data: The time series data\n            period: The seasonal period (e.g., 12 for monthly data with yearly seasonality)\n            \n        Returns:\n            New time series data with seasonally adjusted values\n        \"\"\"\n        if not data.values or len(data.values) < period * 2:\n            # Not enough data for seasonal adjustment\n            return data\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Calculate the seasonal indices\n        seasonal_indices = np.zeros(period)\n        seasonal_data = []\n        \n        # Organize data by season\n        for i in range(period):\n            seasonal_data.append(values[i::period])\n        \n        # Calculate average for each season\n        for i in range(period):\n            if len(seasonal_data[i]) > 0:\n                seasonal_indices[i] = np.mean(seasonal_data[i])\n        \n        # Normalize the seasonal indices\n        if np.sum(seasonal_indices) > 0:\n            seasonal_indices = seasonal_indices * period / np.sum(seasonal_indices)\n        \n        # Apply the seasonal adjustment\n        adjusted = np.zeros_like(values)\n        for i in range(len(values)):\n            season_idx = i % period\n            if seasonal_indices[season_idx] > 0:\n                adjusted[i] = values[i] / seasonal_indices[season_idx]\n            else:\n                adjusted[i] = values[i]\n        \n        # Create new time series data with adjusted values\n        return TimeSeriesData(\n            dates=data.dates,\n            values=adjusted.tolist(),\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"smoothing_method\": \"seasonal\",\n                \"period\": period,\n                \"seasonal_indices\": seasonal_indices.tolist(),\n            },\n        )\n    \n    @staticmethod\n    def detect_trend(data: TimeSeriesData) -> Dict[str, Any]:\n        \"\"\"\n        Detect trends in time series data.\n        \n        Args:\n            data: The time series data\n            \n        Returns:\n            Dictionary with trend information\n        \"\"\"\n        if not data.values or len(data.values) < 2:\n            return {\n                \"has_trend\": False,\n                \"trend_direction\": \"none\",\n                \"trend_strength\": 0.0,\n            }\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Simple linear regression\n        x = np.arange(len(values))\n        A = np.vstack([x, np.ones(len(x))]).T\n        \n        # Solve for the best fit line\n        try:\n            slope, intercept = np.linalg.lstsq(A, values, rcond=None)[0]\n        except:\n            # Fallback if linear algebra fails\n            slope = 0.0\n            intercept = np.mean(values) if len(values) > 0 else 0.0\n        \n        # Calculate trend strength (R-squared)\n        y_hat = slope * x + intercept\n        ss_total = np.sum((values - np.mean(values)) ** 2)\n        ss_residual = np.sum((values - y_hat) ** 2)\n        r_squared = 1 - (ss_residual / ss_total) if ss_total > 0 else 0.0\n        \n        # Determine trend direction\n        trend_direction = \"up\" if slope > 0 else \"down\" if slope < 0 else \"none\"\n        \n        return {\n            \"has_trend\": abs(slope) > 0.01,\n            \"trend_direction\": trend_direction,\n            \"trend_strength\": r_squared,\n            \"slope\": slope,\n            \"intercept\": intercept,\n        }\n    \n    @staticmethod\n    def extrapolate(\n        data: TimeSeriesData, periods: int = 3, method: str = \"linear\"\n    ) -> TimeSeriesData:\n        \"\"\"\n        Extrapolate time series data into the future.\n        \n        Args:\n            data: The time series data\n            periods: The number of periods to extrapolate\n            method: The extrapolation method (\"linear\", \"mean\", \"last\")\n            \n        Returns:\n            New time series data with extrapolated values\n        \"\"\"\n        if not data.values or periods <= 0:\n            return data\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        dates = data.dates.copy()\n        \n        # Determine the date increment\n        if len(dates) >= 2:\n            if isinstance(dates[0], datetime):\n                # For datetime objects\n                date_diff = dates[1] - dates[0]\n            else:\n                # For date objects\n                date_diff = timedelta(days=(dates[1] - dates[0]).days)\n        else:\n            # Default to daily if we can't determine\n            date_diff = timedelta(days=1)\n        \n        # Extrapolate dates\n        last_date = dates[-1]\n        extrapolated_dates = []\n        \n        for i in range(1, periods + 1):\n            if isinstance(last_date, datetime):\n                next_date = last_date + date_diff * i\n            else:\n                # Convert to datetime for easier arithmetic, then back to date\n                next_date = (datetime.combine(last_date, datetime.min.time()) + date_diff * i).date()\n            \n            extrapolated_dates.append(next_date)\n        \n        # Extrapolate values based on the method\n        extrapolated_values = []\n        \n        if method == \"linear\" and len(values) >= 2:\n            # Simple linear extrapolation\n            trend_info = TimeSeriesAnalyzer.detect_trend(data)\n            slope = trend_info[\"slope\"]\n            intercept = trend_info[\"intercept\"]\n            \n            for i in range(1, periods + 1):\n                next_value = slope * (len(values) + i - 1) + intercept\n                extrapolated_values.append(next_value)\n        \n        elif method == \"mean\" and len(values) > 0:\n            # Use the mean of the last few values\n            window = min(len(values), 3)\n            mean_value = np.mean(values[-window:])\n            \n            for _ in range(periods):\n                extrapolated_values.append(mean_value)\n        \n        else:\n            # Default to using the last value\n            last_value = values[-1] if len(values) > 0 else 0.0\n            \n            for _ in range(periods):\n                extrapolated_values.append(last_value)\n        \n        # Create new time series data with original and extrapolated values\n        return TimeSeriesData(\n            dates=dates + extrapolated_dates,\n            values=values.tolist() + extrapolated_values,\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"extrapolation_method\": method,\n                \"extrapolation_periods\": periods,\n                \"original_length\": len(values),\n            },\n        )\n    \n    @staticmethod\n    def normalize(data: TimeSeriesData) -> TimeSeriesData:\n        \"\"\"\n        Normalize time series data to a 0-1 range.\n        \n        Args:\n            data: The time series data\n            \n        Returns:\n            New time series data with normalized values\n        \"\"\"\n        if not data.values:\n            return TimeSeriesData(dates=[], values=[])\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Calculate min and max\n        min_value = np.min(values)\n        max_value = np.max(values)\n        \n        # Normalize the values\n        if max_value > min_value:\n            normalized = (values - min_value) / (max_value - min_value)\n        else:\n            # If all values are the same, normalize to 0.5\n            normalized = np.full_like(values, 0.5)\n        \n        # Create new time series data with normalized values\n        return TimeSeriesData(\n            dates=data.dates,\n            values=normalized.tolist(),\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"normalization\": True,\n                \"original_min\": float(min_value),\n                \"original_max\": float(max_value),\n            },\n        )\n    \n    @staticmethod\n    def aggregate_by_period(\n        dates: List[Union[date, datetime]],\n        values: List[float],\n        granularity: TimeSeriesGranularity,\n        aggregation_fn: Callable[[List[float]], float] = lambda x: sum(x),\n    ) -> Tuple[List[Union[date, datetime]], List[float]]:\n        \"\"\"\n        Aggregate time series data by a specified granularity.\n        \n        Args:\n            dates: List of dates\n            values: List of values\n            granularity: The desired granularity\n            aggregation_fn: Function to aggregate values within a period\n            \n        Returns:\n            Tuple of (aggregated_dates, aggregated_values)\n        \"\"\"\n        if not dates or not values:\n            return [], []\n        \n        # Combine dates and values for sorting and grouping\n        data = list(zip(dates, values))\n        data.sort(key=lambda x: x[0])  # Sort by date\n        \n        # Group by the specified granularity\n        grouped_data = {}\n        \n        for dt, value in data:\n            # Convert to datetime if it's a date\n            if isinstance(dt, date) and not isinstance(dt, datetime):\n                dt = datetime.combine(dt, datetime.min.time())\n            \n            # Group based on granularity\n            if granularity == TimeSeriesGranularity.DAILY:\n                key = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n            elif granularity == TimeSeriesGranularity.WEEKLY:\n                # Get start of the week (Monday)\n                start_of_week = dt - timedelta(days=dt.weekday())\n                key = start_of_week.replace(hour=0, minute=0, second=0, microsecond=0)\n            elif granularity == TimeSeriesGranularity.MONTHLY:\n                key = dt.replace(day=1, hour=0, minute=0, second=0, microsecond=0)\n            elif granularity == TimeSeriesGranularity.QUARTERLY:\n                quarter = (dt.month - 1) // 3\n                key = dt.replace(month=quarter * 3 + 1, day=1, hour=0, minute=0, second=0, microsecond=0)\n            elif granularity == TimeSeriesGranularity.YEARLY:\n                key = dt.replace(month=1, day=1, hour=0, minute=0, second=0, microsecond=0)\n            else:\n                # Default to daily\n                key = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n            \n            # Add to the group\n            if key in grouped_data:\n                grouped_data[key].append(value)\n            else:\n                grouped_data[key] = [value]\n        \n        # Aggregate values within each group\n        aggregated_data = [\n            (key, aggregation_fn(values)) for key, values in grouped_data.items()\n        ]\n        \n        # Sort by date and separate dates and values\n        aggregated_data.sort(key=lambda x: x[0])\n        \n        # Convert datetime back to date if the input was dates\n        if all(isinstance(dt, date) and not isinstance(dt, datetime) for dt in dates):\n            aggregated_dates = [dt.date() for dt, _ in aggregated_data]\n        else:\n            aggregated_dates = [dt for dt, _ in aggregated_data]\n            \n        aggregated_values = [value for _, value in aggregated_data]\n        \n        return aggregated_dates, aggregated_values",
                "class PortfolioAnalysisParameters(AnalysisParameters):\n    \"\"\"\n    Parameters for portfolio analysis.\n    \n    Used to configure portfolio analysis options and settings.\n    \"\"\"\n    \n    include_sector_breakdown: bool = True\n    include_esg_analysis: bool = True\n    include_performance_metrics: bool = True\n    compare_to_benchmark: bool = False\n    benchmark_id: Optional[str] = None\n    risk_free_rate: float = 0.02",
                "class PortfolioBreakdown(BaseModel):\n    \"\"\"\n    Breakdown of a portfolio by different dimensions.\n    \n    Used for analyzing portfolio composition and diversity.\n    \"\"\"\n    \n    by_sector: Dict[str, float] = Field(default_factory=dict)\n    by_industry: Dict[str, float] = Field(default_factory=dict)\n    by_market_cap: Dict[str, float] = Field(default_factory=dict)\n    by_esg_rating: Dict[str, float] = Field(default_factory=dict)\n    by_region: Dict[str, float] = Field(default_factory=dict)\n    concentration_metrics: Dict[str, float] = Field(default_factory=dict)",
                "class PortfolioPerformance(BaseModel):\n    \"\"\"\n    Performance metrics for a portfolio.\n    \n    Used for analyzing historical and risk-adjusted returns.\n    \"\"\"\n    \n    total_return: float\n    annualized_return: float\n    volatility: float\n    sharpe_ratio: float\n    max_drawdown: float\n    alpha: Optional[float] = None\n    beta: Optional[float] = None\n    correlation_to_benchmark: Optional[float] = None",
                "class PortfolioESGMetrics(BaseModel):\n    \"\"\"\n    ESG metrics for a portfolio.\n    \n    Used for analyzing environmental, social, and governance characteristics.\n    \"\"\"\n    \n    overall_esg_score: float\n    environmental_score: float\n    social_score: float\n    governance_score: float\n    carbon_footprint: float\n    renewable_energy_exposure: float\n    diversity_score: float\n    controversy_exposure: float\n    impact_metrics: Dict[str, float] = Field(default_factory=dict)",
                "class PortfolioAnalysisResult(AnalysisResult):\n    \"\"\"\n    Result of a portfolio analysis operation.\n    \n    Provides detailed information about portfolio composition and performance.\n    \"\"\"\n    \n    breakdown: PortfolioBreakdown\n    performance: Optional[PortfolioPerformance] = None\n    esg_metrics: Optional[PortfolioESGMetrics] = None\n    diversification_score: float\n    risk_exposure: Dict[str, float] = Field(default_factory=dict)\n    recommendations: List[str] = Field(default_factory=list)",
                "class PortfolioAnalyzer(BaseAnalyzer[Portfolio, PortfolioAnalysisResult]):\n    \"\"\"\n    Analyzer for investment portfolios.\n    \n    Used for portfolio composition, performance, and ESG analysis.\n    \"\"\"\n    \n    def __init__(self, investments: Dict[str, Investment]):\n        \"\"\"\n        Initialize with a database of available investments.\n        \n        Args:\n            investments: Dictionary mapping investment IDs to Investment objects\n        \"\"\"\n        super().__init__()\n        self.investments = investments\n    \n    def analyze(\n        self, portfolio: Portfolio, parameters: Optional[PortfolioAnalysisParameters] = None\n    ) -> PortfolioAnalysisResult:\n        \"\"\"\n        Analyze a portfolio.\n        \n        Args:\n            portfolio: The portfolio to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Portfolio analysis result\n        \"\"\"\n        # Start timing for performance benchmarking\n        start_time = time.time()\n        \n        # Set default parameters if not provided\n        if parameters is None:\n            parameters = PortfolioAnalysisParameters()\n        \n        # Check cache unless details have changed\n        cached_result = self._get_from_cache(portfolio.id, parameters)\n        if cached_result and cached_result.analysis_date > portfolio.last_updated:\n            return cached_result\n        \n        # Build the portfolio breakdown\n        breakdown = self._calculate_portfolio_breakdown(portfolio)\n        \n        # Calculate performance metrics if requested\n        performance = None\n        if parameters.include_performance_metrics:\n            performance = self._calculate_performance_metrics(\n                portfolio, parameters.risk_free_rate, parameters.benchmark_id\n            )\n        \n        # Calculate ESG metrics if requested\n        esg_metrics = None\n        if parameters.include_esg_analysis:\n            esg_metrics = self._calculate_esg_metrics(portfolio)\n        \n        # Calculate diversification score\n        diversification_score = self._calculate_diversification_score(breakdown)\n        \n        # Identify risk exposures\n        risk_exposure = self._identify_risk_exposures(portfolio, breakdown)\n        \n        # Generate recommendations\n        recommendations = self._generate_recommendations(\n            portfolio, breakdown, diversification_score, risk_exposure\n        )\n        \n        # Calculate processing time\n        processing_time_ms = (time.time() - start_time) * 1000\n        \n        # Create the result\n        result = PortfolioAnalysisResult(\n            id=UUID(),\n            subject_id=portfolio.id,\n            subject_type=\"portfolio\",\n            analysis_type=\"comprehensive\",\n            analysis_date=datetime.now(),\n            processing_time_ms=processing_time_ms,\n            result_summary={\n                \"total_value\": portfolio.total_value,\n                \"num_holdings\": len(portfolio.holdings),\n                \"diversification_score\": diversification_score,\n                \"top_sector\": self._get_top_category(breakdown.by_sector),\n                \"top_industry\": self._get_top_category(breakdown.by_industry),\n            },\n            detailed_results={\n                \"holdings\": [\n                    {\n                        \"investment_id\": h.investment_id,\n                        \"weight\": (h.current_value / portfolio.total_value) if portfolio.total_value > 0 else 0,\n                    }\n                    for h in portfolio.holdings\n                ],\n            },\n            breakdown=breakdown,\n            performance=performance,\n            esg_metrics=esg_metrics,\n            diversification_score=diversification_score,\n            risk_exposure=risk_exposure,\n            recommendations=recommendations,\n        )\n        \n        # Save to cache\n        self._save_to_cache(portfolio.id, result, parameters)\n        \n        return result\n    \n    def _calculate_portfolio_breakdown(self, portfolio: Portfolio) -> PortfolioBreakdown:\n        \"\"\"\n        Calculate the breakdown of a portfolio by different dimensions.\n        \n        Args:\n            portfolio: The portfolio to analyze\n            \n        Returns:\n            PortfolioBreakdown with composition details\n        \"\"\"\n        # Initialize counters\n        by_sector = {}\n        by_industry = {}\n        by_market_cap = {}\n        by_esg_rating = {}\n        by_region = {}\n        \n        # Calculate the weight of each holding\n        total_value = portfolio.total_value\n        if total_value <= 0:\n            # Return empty breakdown for empty portfolio\n            return PortfolioBreakdown()\n        \n        # Analyze each holding\n        for holding in portfolio.holdings:\n            weight = holding.current_value / total_value\n            investment = self.investments.get(holding.investment_id)\n            \n            if investment:\n                # Sector breakdown\n                sector = investment.sector\n                by_sector[sector] = by_sector.get(sector, 0) + weight\n                \n                # Industry breakdown\n                industry = investment.industry\n                by_industry[industry] = by_industry.get(industry, 0) + weight\n                \n                # Market cap breakdown\n                market_cap_category = self._categorize_market_cap(investment.market_cap)\n                by_market_cap[market_cap_category] = by_market_cap.get(market_cap_category, 0) + weight\n                \n                # ESG rating breakdown\n                esg_category = self._categorize_esg_rating(investment.esg_ratings.overall)\n                by_esg_rating[esg_category] = by_esg_rating.get(esg_category, 0) + weight\n                \n                # Region breakdown (placeholder - would need region data)\n                region = \"unknown\"\n                by_region[region] = by_region.get(region, 0) + weight\n        \n        # Calculate concentration metrics\n        concentration_metrics = {\n            \"herfindahl_index\": self._calculate_herfindahl_index(by_sector),\n            \"top_5_holdings_weight\": self._calculate_top_n_weight(portfolio.holdings, total_value, 5),\n            \"sector_count\": len(by_sector),\n            \"industry_count\": len(by_industry),\n        }\n        \n        return PortfolioBreakdown(\n            by_sector=by_sector,\n            by_industry=by_industry,\n            by_market_cap=by_market_cap,\n            by_esg_rating=by_esg_rating,\n            by_region=by_region,\n            concentration_metrics=concentration_metrics,\n        )\n    \n    def _calculate_performance_metrics(\n        self, portfolio: Portfolio, risk_free_rate: float, benchmark_id: Optional[str]\n    ) -> PortfolioPerformance:\n        \"\"\"\n        Calculate performance metrics for a portfolio.\n        \n        Args:\n            portfolio: The portfolio to analyze\n            risk_free_rate: The risk-free rate for Sharpe ratio calculation\n            benchmark_id: Optional benchmark portfolio ID for comparison\n            \n        Returns:\n            PortfolioPerformance with performance metrics\n        \"\"\"\n        # This would require historical price data, which we don't have.\n        # In a real implementation, we would retrieve historical data and calculate returns.\n        # For now, we'll use placeholder values.\n        \n        # Get total return from current data\n        total_return = 0.0\n        total_investment = 0.0\n        \n        for holding in portfolio.holdings:\n            total_investment += holding.shares * holding.purchase_price\n            total_return += holding.shares * (holding.current_price - holding.purchase_price)\n        \n        return_pct = (total_return / total_investment) if total_investment > 0 else 0.0\n        \n        # Placeholder values for other metrics\n        annualized_return = return_pct  # Simplified\n        volatility = 0.15  # Placeholder\n        sharpe_ratio = (annualized_return - risk_free_rate) / volatility if volatility > 0 else 0\n        max_drawdown = 0.1  # Placeholder\n        \n        return PortfolioPerformance(\n            total_return=return_pct,\n            annualized_return=annualized_return,\n            volatility=volatility,\n            sharpe_ratio=sharpe_ratio,\n            max_drawdown=max_drawdown,\n        )\n    \n    def _calculate_esg_metrics(self, portfolio: Portfolio) -> PortfolioESGMetrics:\n        \"\"\"\n        Calculate ESG metrics for a portfolio.\n        \n        Args:\n            portfolio: The portfolio to analyze\n            \n        Returns:\n            PortfolioESGMetrics with ESG characteristics\n        \"\"\"\n        # Initialize counters for weighted average calculation\n        weighted_env_score = 0.0\n        weighted_social_score = 0.0\n        weighted_gov_score = 0.0\n        weighted_overall_score = 0.0\n        weighted_carbon_footprint = 0.0\n        weighted_renewable_energy = 0.0\n        weighted_diversity = 0.0\n        weighted_controversy = 0.0\n        \n        # Calculate the weight of each holding\n        total_value = portfolio.total_value\n        if total_value <= 0:\n            # Return default metrics for empty portfolio\n            return PortfolioESGMetrics(\n                overall_esg_score=0.0,\n                environmental_score=0.0,\n                social_score=0.0,\n                governance_score=0.0,\n                carbon_footprint=0.0,\n                renewable_energy_exposure=0.0,\n                diversity_score=0.0,\n                controversy_exposure=0.0,\n            )\n        \n        # Calculate weighted ESG metrics\n        for holding in portfolio.holdings:\n            weight = holding.current_value / total_value\n            investment = self.investments.get(holding.investment_id)\n            \n            if investment:\n                weighted_env_score += investment.esg_ratings.environmental * weight\n                weighted_social_score += investment.esg_ratings.social * weight\n                weighted_gov_score += investment.esg_ratings.governance * weight\n                weighted_overall_score += investment.esg_ratings.overall * weight\n                weighted_carbon_footprint += investment.carbon_footprint * weight\n                weighted_renewable_energy += investment.renewable_energy_use * weight\n                weighted_diversity += investment.diversity_score * weight\n                weighted_controversy += len(investment.controversies) * weight\n        \n        return PortfolioESGMetrics(\n            overall_esg_score=weighted_overall_score,\n            environmental_score=weighted_env_score,\n            social_score=weighted_social_score,\n            governance_score=weighted_gov_score,\n            carbon_footprint=weighted_carbon_footprint,\n            renewable_energy_exposure=weighted_renewable_energy,\n            diversity_score=weighted_diversity,\n            controversy_exposure=weighted_controversy,\n            impact_metrics={\n                \"carbon_reduction\": weighted_renewable_energy * 100,\n                \"social_impact\": weighted_social_score,\n            },\n        )\n    \n    def _calculate_diversification_score(self, breakdown: PortfolioBreakdown) -> float:\n        \"\"\"\n        Calculate a diversification score for a portfolio.\n        \n        Args:\n            breakdown: The portfolio breakdown\n            \n        Returns:\n            Diversification score between 0 and 1\n        \"\"\"\n        # Calculate based on Herfindahl index (1 - concentration)\n        herfindahl = breakdown.concentration_metrics.get(\"herfindahl_index\", 1.0)\n        sector_score = 1.0 - herfindahl\n        \n        # Adjust based on number of sectors and industries\n        sector_count = breakdown.concentration_metrics.get(\"sector_count\", 0)\n        industry_count = breakdown.concentration_metrics.get(\"industry_count\", 0)\n        \n        sector_factor = min(1.0, sector_count / 10)\n        industry_factor = min(1.0, industry_count / 20)\n        \n        # Final score is a weighted average\n        return 0.5 * sector_score + 0.3 * sector_factor + 0.2 * industry_factor\n    \n    def _identify_risk_exposures(\n        self, portfolio: Portfolio, breakdown: PortfolioBreakdown\n    ) -> Dict[str, float]:\n        \"\"\"\n        Identify key risk exposures in a portfolio.\n        \n        Args:\n            portfolio: The portfolio to analyze\n            breakdown: The portfolio breakdown\n            \n        Returns:\n            Dictionary mapping risk types to exposure levels\n        \"\"\"\n        risk_exposure = {}\n        \n        # Concentration risk\n        top_5_weight = breakdown.concentration_metrics.get(\"top_5_holdings_weight\", 0.0)\n        risk_exposure[\"concentration_risk\"] = top_5_weight\n        \n        # Sector concentration risk\n        top_sector = self._get_top_category(breakdown.by_sector)\n        top_sector_weight = breakdown.by_sector.get(top_sector, 0.0) if top_sector else 0.0\n        risk_exposure[\"sector_concentration_risk\"] = top_sector_weight\n        \n        # ESG risk\n        if \"Lowest\" in breakdown.by_esg_rating:\n            risk_exposure[\"esg_risk\"] = breakdown.by_esg_rating[\"Lowest\"]\n        else:\n            risk_exposure[\"esg_risk\"] = 0.0\n        \n        # Market cap risk\n        if \"Small\" in breakdown.by_market_cap:\n            risk_exposure[\"small_cap_risk\"] = breakdown.by_market_cap[\"Small\"]\n        else:\n            risk_exposure[\"small_cap_risk\"] = 0.0\n        \n        return risk_exposure\n    \n    def _generate_recommendations(\n        self,\n        portfolio: Portfolio,\n        breakdown: PortfolioBreakdown,\n        diversification_score: float,\n        risk_exposure: Dict[str, float],\n    ) -> List[str]:\n        \"\"\"\n        Generate portfolio improvement recommendations.\n        \n        Args:\n            portfolio: The portfolio to analyze\n            breakdown: The portfolio breakdown\n            diversification_score: The calculated diversification score\n            risk_exposure: The identified risk exposures\n            \n        Returns:\n            List of recommendation strings\n        \"\"\"\n        recommendations = []\n        \n        # Diversification recommendations\n        if diversification_score < 0.4:\n            recommendations.append(\n                \"Low diversification detected. Consider adding investments from more sectors.\"\n            )\n        elif diversification_score < 0.7:\n            recommendations.append(\n                \"Moderate diversification. Consider reducing exposure to your top sector.\"\n            )\n        \n        # Concentration risk\n        if risk_exposure.get(\"concentration_risk\", 0.0) > 0.6:\n            recommendations.append(\n                \"High concentration in top holdings. Consider rebalancing for better risk management.\"\n            )\n        \n        # Sector concentration\n        if risk_exposure.get(\"sector_concentration_risk\", 0.0) > 0.4:\n            top_sector = self._get_top_category(breakdown.by_sector)\n            recommendations.append(\n                f\"High exposure to {top_sector} sector. Consider diversifying into other sectors.\"\n            )\n        \n        # ESG recommendations\n        if risk_exposure.get(\"esg_risk\", 0.0) > 0.2:\n            recommendations.append(\n                \"Significant exposure to low-rated ESG investments. Consider alternatives with better ESG profiles.\"\n            )\n        \n        return recommendations\n    \n    def _categorize_market_cap(self, market_cap: float) -> str:\n        \"\"\"\n        Categorize an investment by market cap.\n        \n        Args:\n            market_cap: The market capitalization value\n            \n        Returns:\n            Market cap category string\n        \"\"\"\n        if market_cap >= 10_000_000_000:\n            return \"Large\"\n        elif market_cap >= 2_000_000_000:\n            return \"Mid\"\n        else:\n            return \"Small\"\n    \n    def _categorize_esg_rating(self, rating: int) -> str:\n        \"\"\"\n        Categorize an investment by ESG rating.\n        \n        Args:\n            rating: The ESG rating value\n            \n        Returns:\n            ESG rating category string\n        \"\"\"\n        if rating >= 80:\n            return \"Highest\"\n        elif rating >= 60:\n            return \"High\"\n        elif rating >= 40:\n            return \"Medium\"\n        elif rating >= 20:\n            return \"Low\"\n        else:\n            return \"Lowest\"\n    \n    def _calculate_herfindahl_index(self, weights: Dict[str, float]) -> float:\n        \"\"\"\n        Calculate the Herfindahl index (measure of concentration).\n        \n        Args:\n            weights: Dictionary mapping categories to weights\n            \n        Returns:\n            Herfindahl index value between 0 and 1\n        \"\"\"\n        return sum(weight ** 2 for weight in weights.values())\n    \n    def _calculate_top_n_weight(\n        self, holdings: List[InvestmentHolding], total_value: float, n: int\n    ) -> float:\n        \"\"\"\n        Calculate the weight of the top N holdings.\n        \n        Args:\n            holdings: List of investment holdings\n            total_value: Total portfolio value\n            n: Number of top holdings to consider\n            \n        Returns:\n            Total weight of top N holdings\n        \"\"\"\n        if not holdings or total_value <= 0:\n            return 0.0\n        \n        # Sort holdings by value (descending)\n        sorted_holdings = sorted(\n            holdings, key=lambda h: h.current_value, reverse=True\n        )\n        \n        # Get the top N holdings\n        top_n = sorted_holdings[:min(n, len(sorted_holdings))]\n        \n        # Calculate their total weight\n        top_n_value = sum(h.current_value for h in top_n)\n        \n        return top_n_value / total_value\n    \n    def _get_top_category(self, categories: Dict[str, float]) -> Optional[str]:\n        \"\"\"\n        Get the top category by weight.\n        \n        Args:\n            categories: Dictionary mapping categories to weights\n            \n        Returns:\n            The top category or None if empty\n        \"\"\"\n        if not categories:\n            return None\n        \n        return max(categories.items(), key=lambda x: x[1])[0]",
                "class ProjectionScenario(str, Enum):\n    \"\"\"Scenario types for financial projections.\"\"\"\n    \n    OPTIMISTIC = \"optimistic\"\n    BASELINE = \"baseline\"\n    CONSERVATIVE = \"conservative\"\n    STRESS_TEST = \"stress_test\"",
                "class ProjectionParameters(AnalysisParameters):\n    \"\"\"\n    Parameters for financial projections.\n    \n    Used to configure projection options and settings.\n    \"\"\"\n    \n    projection_length: int = 12  # months\n    scenario: ProjectionScenario = ProjectionScenario.BASELINE\n    include_income: bool = True\n    include_expenses: bool = True\n    include_investments: bool = True\n    income_growth_rate: float = 0.0\n    expense_growth_rate: float = 0.0\n    investment_return_rate: float = 0.05\n    emergency_fund_months: int = 6\n    tax_rate: float = 0.25",
                "class CashFlow(BaseModel):\n    \"\"\"\n    Model for cash flow data.\n    \n    Used for tracking income, expenses, and net cash flow over time.\n    \"\"\"\n    \n    date: Union[date, datetime]\n    income: float = 0.0\n    expenses: float = 0.0\n    net: float = 0.0\n    cumulative: float = 0.0\n    \n    def __init__(self, **data):\n        \"\"\"Initialize with automatic net and cumulative calculation.\"\"\"\n        super().__init__(**data)\n        if \"net\" not in data:\n            self.net = self.income - self.expenses",
                "class Projection(BaseModel):\n    \"\"\"\n    Financial projection model.\n    \n    Used for forecasting future financial states based on different scenarios.\n    \"\"\"\n    \n    scenario: ProjectionScenario\n    start_date: Union[date, datetime]\n    end_date: Union[date, datetime]\n    starting_balance: float\n    cash_flows: List[CashFlow] = Field(default_factory=list)\n    final_balance: float\n    lowest_balance: float\n    highest_balance: float\n    runway_months: Optional[float] = None\n    emergency_fund_status: str = \"insufficient\"\n    tax_liability: Dict[str, float] = Field(default_factory=dict)\n    confidence_level: float = 0.8\n    metadata: Dict[str, Any] = Field(default_factory=dict)",
                "class ProjectionResult(AnalysisResult):\n    \"\"\"\n    Result of a financial projection analysis.\n    \n    Provides projected financial states across different scenarios.\n    \"\"\"\n    \n    baseline: Projection\n    optimistic: Optional[Projection] = None\n    conservative: Optional[Projection] = None\n    stress_test: Optional[Projection] = None\n    recommended_actions: List[str] = Field(default_factory=list)",
                "class FinancialProjector:\n    \"\"\"\n    Financial projection model for freelancers.\n\n    This class provides cash flow forecasting, runway calculations,\n    what-if analysis, and emergency fund assessment.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the financial projector.\"\"\"\n        self._projection_cache = {}\n        self._common_projector = CommonFinancialProjector()\n        self.timer = Timer()\n\n    def project_cash_flow(\n        self,\n        starting_balance: float,\n        current_date: datetime,\n        months_ahead: int,\n        revenue_sources: List[RevenueSource],\n        expense_items: List[ExpenseItem],\n        scenario: ProjectionScenario = ProjectionScenario.BASELINE,\n        historical_transactions: Optional[List[Transaction]] = None,\n        confidence_interval: float = 0.8,\n    ) -> CashFlowProjection:\n        \"\"\"\n        Project cash flow for a specific timeframe.\n\n        Args:\n            starting_balance: Current cash balance\n            current_date: Start date for projection\n            months_ahead: Number of months to project\n            revenue_sources: Expected revenue sources\n            expense_items: Expected expenses\n            scenario: Projection scenario\n            historical_transactions: Optional historical transactions for trend analysis\n            confidence_interval: Confidence interval for projections\n\n        Returns:\n            CashFlowProjection object with detailed cash flow projection\n        \"\"\"\n        # Start performance timer\n        self.timer.start()\n\n        # Calculate dates\n        start_date = datetime(current_date.year, current_date.month, 1)\n        end_month = current_date.month + months_ahead\n        end_year = current_date.year + (end_month - 1) // 12\n        end_month = ((end_month - 1) % 12) + 1\n        end_date = datetime(\n            end_year, end_month, calendar.monthrange(end_year, end_month)[1]\n        )\n\n        # Create historical time series data if provided\n        historical_data = None\n        if historical_transactions:\n            # Extract dates and net cash flow values from transactions\n            dates = []\n            values = []\n            \n            for tx in sorted(historical_transactions, key=lambda t: t.date):\n                dates.append(tx.date)\n                # Income adds to cash flow, expenses subtract\n                value = tx.amount if tx.transaction_type == TransactionType.INCOME else -tx.amount\n                values.append(value)\n            \n            historical_data = TimeSeriesData(dates=dates, values=values)\n        else:\n            # Create minimal historical data with just the starting balance\n            historical_data = TimeSeriesData(\n                dates=[current_date],\n                values=[starting_balance]\n            )\n\n        # Create projection parameters\n        params = ProjectionParameters(\n            projection_length=months_ahead,\n            scenario=scenario,\n            income_growth_rate=0.0,  # Will be handled in revenue sources\n            expense_growth_rate=0.0,  # Will be handled in expense items\n        )\n\n        # Prepare income and expenses for the common projector\n        # This is needed to convert our revenue sources and expense items format\n        # to the common library's expected format\n        monthly_income = {}\n        monthly_expenses = {}\n        \n        # Process revenue sources\n        for revenue in revenue_sources:\n            if revenue.recurring:\n                self._add_recurring_item_to_dict(\n                    monthly_dict=monthly_income,\n                    item=revenue,\n                    start_date=start_date,\n                    end_date=end_date,\n                    multiplier=self._get_scenario_income_multiplier(scenario)\n                )\n            elif revenue.expected_date:\n                month_key = revenue.expected_date.strftime(\"%Y-%m\")\n                adjusted_amount = revenue.amount * (revenue.probability / 100) * self._get_scenario_income_multiplier(scenario)\n                monthly_income[month_key] = monthly_income.get(month_key, 0) + adjusted_amount\n\n        # Process expenses\n        for expense in expense_items:\n            if expense.recurring:\n                self._add_recurring_item_to_dict(\n                    monthly_dict=monthly_expenses,\n                    item=expense,\n                    start_date=start_date,\n                    end_date=end_date,\n                    multiplier=self._get_scenario_expense_multiplier(scenario)\n                )\n            elif expense.due_date:\n                month_key = expense.due_date.strftime(\"%Y-%m\")\n                adjusted_amount = expense.amount * self._get_scenario_expense_multiplier(scenario)\n                monthly_expenses[month_key] = monthly_expenses.get(month_key, 0) + adjusted_amount\n\n        # Convert to time series format\n        month_strings = []\n        current_month = start_date\n        while current_month <= end_date:\n            month_strings.append(current_month.strftime(\"%Y-%m\"))\n            # Move to next month\n            month = current_month.month + 1\n            year = current_month.year + (month - 1) // 12\n            month = ((month - 1) % 12) + 1\n            current_month = datetime(year, month, 1)\n\n        # Generate all dates for the projection period\n        projection_dates = []\n        projection_income = []\n        projection_expenses = []\n        \n        for month in month_strings:\n            year, month_num = map(int, month.split('-'))\n            projection_date = datetime(year, int(month_num), 1)\n            projection_dates.append(projection_date)\n            projection_income.append(monthly_income.get(month, 0))\n            projection_expenses.append(monthly_expenses.get(month, 0))\n\n        # Use the common financial projector to create projections\n        # We create our own custom projection from the results\n        projection_result = self._create_custom_projection(\n            starting_balance=starting_balance,\n            projection_dates=projection_dates,\n            projection_income=projection_income,\n            projection_expenses=projection_expenses,\n            scenario=scenario\n        )\n\n        # Calculate totals\n        total_income = sum(monthly_income.get(month, 0) for month in month_strings)\n        total_expenses = sum(monthly_expenses.get(month, 0) for month in month_strings)\n        net_cash_flow = total_income - total_expenses\n        ending_balance = starting_balance + net_cash_flow\n\n        # Create monthly breakdown structure for compatibility\n        monthly_breakdown = {}\n        for i, month in enumerate(month_strings):\n            monthly_breakdown[month] = {\n                \"income\": projection_income[i],\n                \"expenses\": projection_expenses[i],\n                \"balance\": 0  # Will be calculated below\n            }\n\n        # Calculate running balance for each month\n        running_balance = starting_balance\n        for month in month_strings:\n            income = monthly_breakdown[month][\"income\"]\n            expenses = monthly_breakdown[month][\"expenses\"]\n            net = income - expenses\n            running_balance += net\n            monthly_breakdown[month][\"balance\"] = running_balance\n\n        # Create projection for return\n        projection = CashFlowProjection(\n            start_date=start_date,\n            end_date=end_date,\n            scenario=scenario,\n            starting_balance=starting_balance,\n            ending_balance=ending_balance,\n            total_income=total_income,\n            total_expenses=total_expenses,\n            net_cash_flow=net_cash_flow,\n            monthly_breakdown=monthly_breakdown,\n            confidence_interval=confidence_interval,\n        )\n\n        # Stop timer\n        elapsed_time = self.timer.stop()\n\n        return projection\n\n    def _create_custom_projection(\n        self,\n        starting_balance: float,\n        projection_dates: List[datetime],\n        projection_income: List[float],\n        projection_expenses: List[float],\n        scenario: ProjectionScenario\n    ) -> Projection:\n        \"\"\"\n        Create a custom projection using the common library.\n        \n        Args:\n            starting_balance: Current cash balance\n            projection_dates: List of dates for projection\n            projection_income: List of income values\n            projection_expenses: List of expense values\n            scenario: Projection scenario\n            \n        Returns:\n            Projection object\n        \"\"\"\n        # Create cash flows\n        cash_flows = []\n        cumulative_balance = starting_balance\n        lowest_balance = starting_balance\n        highest_balance = starting_balance\n        \n        for i, date in enumerate(projection_dates):\n            income = projection_income[i]\n            expenses = projection_expenses[i]\n            net = income - expenses\n            cumulative_balance += net\n            \n            # Track min/max balances\n            lowest_balance = min(lowest_balance, cumulative_balance)\n            highest_balance = max(highest_balance, cumulative_balance)\n            \n            # Create cash flow\n            cash_flow = CashFlow(\n                date=date,\n                income=income,\n                expenses=expenses,\n                net=net,\n                cumulative=cumulative_balance\n            )\n            cash_flows.append(cash_flow)\n        \n        # Calculate runway months\n        runway_months = None\n        avg_expenses = sum(projection_expenses) / len(projection_expenses) if projection_expenses else 0\n        \n        if avg_expenses > 0:\n            for i, cf in enumerate(cash_flows):\n                if cf.cumulative <= 0:\n                    runway_months = i\n                    break\n            \n            if runway_months is None and lowest_balance > 0:\n                if cash_flows[-1].net < 0:\n                    runway_months = len(projection_dates) + (cash_flows[-1].cumulative / -cash_flows[-1].net)\n                else:\n                    runway_months = float('inf')  # Sustainable cash flow\n        \n        # Determine emergency fund status\n        emergency_fund_months = 6  # Default value\n        emergency_fund_status = \"insufficient\"\n        if lowest_balance >= avg_expenses * emergency_fund_months:\n            emergency_fund_status = \"adequate\"\n        elif lowest_balance >= avg_expenses * (emergency_fund_months / 2):\n            emergency_fund_status = \"partial\"\n            \n        # Create the projection\n        return Projection(\n            scenario=scenario,\n            start_date=projection_dates[0],\n            end_date=projection_dates[-1],\n            starting_balance=starting_balance,\n            cash_flows=cash_flows,\n            final_balance=cash_flows[-1].cumulative if cash_flows else starting_balance,\n            lowest_balance=lowest_balance,\n            highest_balance=highest_balance,\n            runway_months=runway_months,\n            emergency_fund_status=emergency_fund_status,\n            tax_liability={},  # Not used in this implementation\n            confidence_level=0.8,\n            metadata={\n                \"avg_monthly_income\": sum(projection_income) / len(projection_income) if projection_income else 0,\n                \"avg_monthly_expenses\": avg_expenses,\n            }\n        )\n\n    def _add_recurring_item_to_dict(\n        self,\n        monthly_dict: Dict[str, float],\n        item: Union[RevenueSource, ExpenseItem],\n        start_date: datetime,\n        end_date: datetime,\n        multiplier: float = 1.0,\n    ) -> None:\n        \"\"\"Add a recurring item to monthly dictionary.\"\"\"\n        # Handle different recurrence frequencies\n        months_interval = 1  # Default to monthly\n        frequency_multiplier = 1.0\n\n        if item.recurrence_frequency == \"quarterly\":\n            months_interval = 3\n        elif item.recurrence_frequency == \"biannual\":\n            months_interval = 6\n        elif item.recurrence_frequency == \"annual\":\n            months_interval = 12\n        elif item.recurrence_frequency == \"biweekly\":\n            # Approximate biweekly as 2.17 payments per month\n            frequency_multiplier = 2.17\n        elif item.recurrence_frequency == \"weekly\":\n            # Approximate weekly as 4.33 payments per month\n            frequency_multiplier = 4.33\n\n        # Determine start month (use expected_date if available)\n        current_month = None\n        if hasattr(item, \"expected_date\") and item.expected_date:\n            current_month = item.expected_date\n        else:\n            current_month = start_date\n\n        # Add to each applicable month\n        while current_month <= end_date:\n            month_key = current_month.strftime(\"%Y-%m\")\n\n            # Apply probability adjustment for revenue\n            if hasattr(item, \"probability\"):\n                adjusted_amount = item.amount * (item.probability / 100) * multiplier * frequency_multiplier\n            else:\n                adjusted_amount = item.amount * multiplier * frequency_multiplier\n\n            monthly_dict[month_key] = monthly_dict.get(month_key, 0) + adjusted_amount\n\n            # Move to next applicable month\n            month = current_month.month + months_interval\n            year = current_month.year + (month - 1) // 12\n            month = ((month - 1) % 12) + 1\n            current_month = datetime(year, month, 1)\n\n    def _get_scenario_income_multiplier(self, scenario: ProjectionScenario) -> float:\n        \"\"\"Get income multiplier based on scenario.\"\"\"\n        if scenario == ProjectionScenario.STRESS_TEST:\n            return 0.7  # 70% of expected income\n        elif scenario == ProjectionScenario.CONSERVATIVE:\n            return 0.85  # 85% of expected income\n        elif scenario == ProjectionScenario.BASELINE:\n            return 1.0  # 100% of expected income\n        elif scenario == ProjectionScenario.OPTIMISTIC:\n            return 1.15  # 115% of expected income\n        return 1.0\n\n    def _get_scenario_expense_multiplier(self, scenario: ProjectionScenario) -> float:\n        \"\"\"Get expense multiplier based on scenario.\"\"\"\n        if scenario == ProjectionScenario.STRESS_TEST:\n            return 1.15  # 115% of expected expenses\n        elif scenario == ProjectionScenario.CONSERVATIVE:\n            return 1.05  # 105% of expected expenses\n        elif scenario == ProjectionScenario.BASELINE:\n            return 1.0  # 100% of expected expenses\n        elif scenario == ProjectionScenario.OPTIMISTIC:\n            return 0.95  # 95% of expected expenses\n        return 1.0\n\n    def calculate_runway(\n        self,\n        current_balance: float,\n        spending_level: SpendingLevel,\n        monthly_expenses: Optional[float] = None,\n        historical_transactions: Optional[List[Transaction]] = None,\n        expected_revenue: Optional[Dict[str, float]] = None,\n        confidence_level: float = 0.8,\n    ) -> RunwayProjection:\n        \"\"\"\n        Calculate how long current funds will last at different spending levels.\n\n        Args:\n            current_balance: Current cash balance\n            spending_level: Level of spending to project\n            monthly_expenses: Optional override for monthly expense rate\n            historical_transactions: Optional historical transactions for expense analysis\n            expected_revenue: Optional expected future revenue by month\n            confidence_level: Confidence level for projection\n\n        Returns:\n            RunwayProjection with detailed runway information\n        \"\"\"\n        # Performance measurement\n        self.timer.start()\n\n        # Determine monthly expense rate\n        monthly_expense_rate = 0.0\n\n        if monthly_expenses is not None:\n            # Use provided expense rate\n            monthly_expense_rate = monthly_expenses\n        elif historical_transactions:\n            # Calculate from historical data (last 3 months)\n            now = datetime.now()\n            three_months_ago = datetime(now.year, now.month, 1) - timedelta(days=90)\n\n            # Filter to expenses in the last 3 months\n            recent_expenses = [\n                t\n                for t in historical_transactions\n                if (\n                    t.transaction_type == TransactionType.EXPENSE\n                    and t.date >= three_months_ago\n                )\n            ]\n\n            # Group by month and calculate average\n            expenses_by_month = {}\n            for expense in recent_expenses:\n                month_key = expense.date.strftime(\"%Y-%m\")\n                if month_key not in expenses_by_month:\n                    expenses_by_month[month_key] = 0\n                expenses_by_month[month_key] += expense.amount\n\n            if expenses_by_month:\n                monthly_expense_rate = sum(expenses_by_month.values()) / len(\n                    expenses_by_month\n                )\n            else:\n                raise ValueError(\"No historical expense data available\")\n        else:\n            raise ValueError(\n                \"Either monthly_expenses or historical_transactions must be provided\"\n            )\n\n        # Apply spending level adjustment\n        adjusted_expense_rate = self._adjust_for_spending_level(\n            monthly_expense_rate, spending_level\n        )\n\n        # Calculate runway without expected revenue\n        bare_runway_months = (\n            current_balance / adjusted_expense_rate\n            if adjusted_expense_rate > 0\n            else float(\"inf\")\n        )\n\n        # Include expected revenue if provided\n        if expected_revenue:\n            # Get expected revenue by month\n            sorted_months = sorted(expected_revenue.keys())\n\n            # Calculate runway with revenue\n            balance = current_balance\n            months = 0\n            depletion_date = None\n\n            while balance > 0 and months < 60:  # Cap at 5 years\n                # Current month index\n                current_month_idx = months % len(sorted_months)\n                current_month = sorted_months[current_month_idx]\n\n                # Subtract expenses and add revenue\n                balance -= adjusted_expense_rate\n                if current_month in expected_revenue:\n                    balance += expected_revenue[current_month]\n\n                months += 1\n\n                # Calculate depletion date\n                if balance <= 0:\n                    now = datetime.now()\n                    depletion_date = datetime(\n                        now.year + (now.month + months - 1) // 12,\n                        ((now.month + months - 1) % 12) + 1,\n                        1,\n                    )\n                    break\n\n            # If we reached the cap without depleting, set to infinity\n            runway_months = months if months < 60 else float(\"inf\")\n        else:\n            # Without expected revenue, use simple calculation\n            runway_months = bare_runway_months\n\n            # Calculate depletion date\n            if runway_months < float(\"inf\"):\n                now = datetime.now()\n                months_to_add = math.floor(runway_months)\n                depletion_date = datetime(\n                    now.year + (now.month + months_to_add - 1) // 12,\n                    ((now.month + months_to_add - 1) % 12) + 1,\n                    1,\n                )\n            else:\n                depletion_date = None\n\n        # Create result\n        result = RunwayProjection(\n            calculation_date=datetime.now(),\n            starting_balance=current_balance,\n            spending_level=spending_level,\n            monthly_expense_rate=adjusted_expense_rate,\n            expected_income=expected_revenue or {},\n            runway_months=runway_months,\n            depletion_date=depletion_date,\n            confidence_level=confidence_level,\n        )\n\n        # Verify performance\n        elapsed_time = self.timer.stop()\n\n        return result\n\n    def _adjust_for_spending_level(\n        self, base_expense_rate: float, spending_level: SpendingLevel\n    ) -> float:\n        \"\"\"Adjust expense rate based on spending level.\"\"\"\n        if spending_level == SpendingLevel.MINIMAL:\n            return base_expense_rate * 0.6  # 60% of normal expenses\n        elif spending_level == SpendingLevel.REDUCED:\n            return base_expense_rate * 0.8  # 80% of normal expenses\n        elif spending_level == SpendingLevel.NORMAL:\n            return base_expense_rate  # 100% of normal expenses\n        elif spending_level == SpendingLevel.INCREASED:\n            return base_expense_rate * 1.2  # 120% of normal expenses\n        return base_expense_rate\n\n    def create_what_if_scenario(\n        self,\n        name: str,\n        base_scenario: ProjectionScenario,\n        parameters: List[ScenarioParameter],\n        description: Optional[str] = None,\n    ) -> WhatIfScenario:\n        \"\"\"\n        Create a what-if scenario for financial planning.\n\n        Args:\n            name: Name for the scenario\n            base_scenario: Base projection scenario\n            parameters: Parameters for the scenario\n            description: Optional description\n\n        Returns:\n            WhatIfScenario object\n        \"\"\"\n        # Create the scenario\n        scenario = WhatIfScenario(\n            name=name,\n            description=description,\n            base_scenario=base_scenario,\n            parameters=parameters,\n            creation_date=datetime.now(),\n        )\n\n        return scenario\n\n    def evaluate_what_if_scenario(\n        self,\n        scenario: WhatIfScenario,\n        starting_balance: float,\n        revenue_sources: List[RevenueSource],\n        expense_items: List[ExpenseItem],\n        months_ahead: int = 12,\n    ) -> Tuple[WhatIfScenario, CashFlowProjection]:\n        \"\"\"\n        Evaluate a what-if scenario and calculate its impact.\n\n        Args:\n            scenario: What-if scenario to evaluate\n            starting_balance: Current cash balance\n            revenue_sources: Expected revenue sources\n            expense_items: Expected expenses\n            months_ahead: Number of months to project\n\n        Returns:\n            Tuple of (updated scenario with results, cash flow projection)\n        \"\"\"\n        # Apply parameter adjustments to revenue and expenses\n        adjusted_revenue = list(revenue_sources)\n        adjusted_expenses = list(expense_items)\n\n        # Track adjustments made for each parameter\n        adjustments = {}\n\n        for param in scenario.parameters:\n            # Store original value\n            adjustments[param.name] = param.current_value\n\n            # Apply parameter adjustments based on name patterns\n            if \"hourly_rate\" in param.name.lower():\n                # Adjust revenue based on hourly rate change\n                for i, revenue in enumerate(adjusted_revenue):\n                    if \"hourly\" in revenue.name.lower():\n                        # Create a new object with updated amount\n                        new_revenue = RevenueSource(\n                            name=revenue.name,\n                            amount=param.current_value,\n                            probability=revenue.probability,\n                            expected_date=revenue.expected_date,\n                            recurring=revenue.recurring,\n                            recurrence_frequency=revenue.recurrence_frequency,\n                            notes=revenue.notes,\n                        )\n                        adjusted_revenue[i] = new_revenue\n\n            elif \"monthly_income\" in param.name.lower():\n                # Adjust monthly income\n                for i, revenue in enumerate(adjusted_revenue):\n                    if revenue.recurring and revenue.recurrence_frequency == \"monthly\":\n                        # Create a new object with updated amount\n                        new_revenue = RevenueSource(\n                            name=revenue.name,\n                            amount=param.current_value,\n                            probability=revenue.probability,\n                            expected_date=revenue.expected_date,\n                            recurring=revenue.recurring,\n                            recurrence_frequency=revenue.recurrence_frequency,\n                            notes=revenue.notes,\n                        )\n                        adjusted_revenue[i] = new_revenue\n\n            elif \"expense_reduction\" in param.name.lower():\n                # Apply expense reduction percentage\n                reduction_factor = 1.0 - (param.current_value / 100)\n                for i, expense in enumerate(adjusted_expenses):\n                    # Create a new object with updated amount\n                    new_expense = ExpenseItem(\n                        name=expense.name,\n                        amount=expense.amount * reduction_factor,\n                        category=expense.category,\n                        due_date=expense.due_date,\n                        recurring=expense.recurring,\n                        recurrence_frequency=expense.recurrence_frequency,\n                        essential=expense.essential,\n                        notes=expense.notes,\n                    )\n                    adjusted_expenses[i] = new_expense\n\n            # Add more parameter handling as needed\n\n        # Run projection with adjusted values\n        projection = self.project_cash_flow(\n            starting_balance=starting_balance,\n            current_date=datetime.now(),\n            months_ahead=months_ahead,\n            revenue_sources=adjusted_revenue,\n            expense_items=adjusted_expenses,\n            scenario=scenario.base_scenario,\n        )\n\n        # Calculate result metrics\n        result_metrics = {\n            \"ending_balance\": projection.ending_balance,\n            \"net_cash_flow\": projection.net_cash_flow,\n            \"total_income\": projection.total_income,\n            \"total_expenses\": projection.total_expenses,\n        }\n\n        # Update scenario with results\n        # Create a new scenario with updated result metrics\n        updated_scenario = WhatIfScenario(\n            id=scenario.id,\n            name=scenario.name,\n            description=scenario.description,\n            base_scenario=scenario.base_scenario,\n            parameters=scenario.parameters,\n            result_metrics=result_metrics,\n            creation_date=scenario.creation_date,\n            notes=scenario.notes,\n        )\n\n        return updated_scenario, projection\n\n    def assess_emergency_fund(\n        self,\n        current_fund_balance: float,\n        monthly_expenses: Optional[float] = None,\n        historical_transactions: Optional[List[Transaction]] = None,\n        recommended_months: float = 6.0,\n    ) -> EmergencyFundAssessment:\n        \"\"\"\n        Assess the adequacy of an emergency fund.\n\n        Args:\n            current_fund_balance: Current emergency fund balance\n            monthly_expenses: Optional override for monthly expenses\n            historical_transactions: Optional historical transactions for expense analysis\n            recommended_months: Recommended number of months coverage\n\n        Returns:\n            EmergencyFundAssessment with detailed assessment\n        \"\"\"\n        # Determine monthly essential expenses\n        monthly_essential = 0.0\n\n        if monthly_expenses is not None:\n            # Use provided expense amount\n            monthly_essential = monthly_expenses\n        elif historical_transactions:\n            # Calculate from historical data (last 3 months)\n            now = datetime.now()\n            three_months_ago = datetime(now.year, now.month, 1) - timedelta(days=90)\n\n            # Filter to essential expenses in the last 3 months\n            essential_expenses = [\n                t\n                for t in historical_transactions\n                if (\n                    t.transaction_type == TransactionType.EXPENSE\n                    and t.date >= three_months_ago\n                    and t.category\n                    in [\n                        ExpenseCategory.UTILITIES,\n                        ExpenseCategory.HEALTH_INSURANCE,\n                        ExpenseCategory.OFFICE_RENT,\n                        ExpenseCategory.INTERNET,\n                        ExpenseCategory.PHONE,\n                    ]\n                )\n            ]\n\n            # Group by month and calculate average\n            expenses_by_month = {}\n            for expense in essential_expenses:\n                month_key = expense.date.strftime(\"%Y-%m\")\n                if month_key not in expenses_by_month:\n                    expenses_by_month[month_key] = 0\n                expenses_by_month[month_key] += expense.amount\n\n            if expenses_by_month:\n                monthly_essential = sum(expenses_by_month.values()) / len(\n                    expenses_by_month\n                )\n            else:\n                raise ValueError(\"No historical essential expense data available\")\n        else:\n            raise ValueError(\n                \"Either monthly_expenses or historical_transactions must be provided\"\n            )\n\n        # Calculate recommended fund size\n        recommended_fund_size = monthly_essential * recommended_months\n\n        # Calculate current coverage\n        current_coverage_months = (\n            current_fund_balance / monthly_essential if monthly_essential > 0 else 0\n        )\n\n        # Determine adequacy level\n        if current_coverage_months < 1:\n            adequacy_level = \"inadequate\"\n            funding_plan = (\n                \"Immediate action needed: Build to 1 month coverage as soon as possible\"\n            )\n        elif current_coverage_months < 3:\n            adequacy_level = \"minimal\"\n            funding_plan = \"Continue building: Aim for 3 months coverage\"\n        elif current_coverage_months < recommended_months:\n            adequacy_level = \"adequate\"\n            funding_plan = f\"Good progress: Continue building toward {recommended_months} months coverage\"\n        else:\n            adequacy_level = \"excellent\"\n            funding_plan = (\n                \"Well funded: Maintain current level or consider other financial goals\"\n            )\n\n        # Create assessment\n        assessment = EmergencyFundAssessment(\n            assessment_date=datetime.now(),\n            current_fund_balance=current_fund_balance,\n            monthly_essential_expenses=monthly_essential,\n            recommended_months_coverage=recommended_months,\n            recommended_fund_size=recommended_fund_size,\n            current_coverage_months=current_coverage_months,\n            adequacy_level=adequacy_level,\n            funding_plan=funding_plan,\n        )\n\n        return assessment",
                "class FinancialProjector(BaseAnalyzer[TimeSeriesData, ProjectionResult]):\n    \"\"\"\n    Analyzer for financial projections.\n    \n    Used for forecasting future financial states and scenario analysis.\n    \"\"\"\n    \n    def analyze(\n        self, historical_data: TimeSeriesData, parameters: Optional[ProjectionParameters] = None\n    ) -> ProjectionResult:\n        \"\"\"\n        Project future financial states based on historical data.\n        \n        Args:\n            historical_data: Historical financial data\n            parameters: Optional parameters to configure the projection\n            \n        Returns:\n            ProjectionResult with different scenario projections\n        \"\"\"\n        # Start timing for performance benchmarking\n        start_time = time.time()\n        \n        # Set default parameters if not provided\n        if parameters is None:\n            parameters = ProjectionParameters()\n        \n        # Check cache\n        cached_result = self._get_from_cache(UUID(), parameters)\n        if cached_result:\n            return cached_result\n        \n        # Calculate starting balance (last cumulative value)\n        starting_balance = (\n            historical_data.values[-1] if historical_data.values else 0.0\n        )\n        \n        # Generate projections for baseline scenario\n        baseline = self._generate_projection(\n            historical_data,\n            ProjectionScenario.BASELINE,\n            parameters,\n            income_factor=1.0,\n            expense_factor=1.0,\n            investment_factor=1.0,\n        )\n        \n        # Generate projections for optimistic scenario\n        optimistic = self._generate_projection(\n            historical_data,\n            ProjectionScenario.OPTIMISTIC,\n            parameters,\n            income_factor=1.1,\n            expense_factor=0.9,\n            investment_factor=1.2,\n        )\n        \n        # Generate projections for conservative scenario\n        conservative = self._generate_projection(\n            historical_data,\n            ProjectionScenario.CONSERVATIVE,\n            parameters,\n            income_factor=0.9,\n            expense_factor=1.1,\n            investment_factor=0.8,\n        )\n        \n        # Generate projections for stress test scenario\n        stress_test = self._generate_projection(\n            historical_data,\n            ProjectionScenario.STRESS_TEST,\n            parameters,\n            income_factor=0.7,\n            expense_factor=1.2,\n            investment_factor=0.5,\n        )\n        \n        # Generate recommended actions\n        recommended_actions = self._generate_recommendations(\n            baseline, conservative, stress_test, parameters\n        )\n        \n        # Calculate processing time\n        processing_time_ms = (time.time() - start_time) * 1000\n        \n        # Create the result\n        result = ProjectionResult(\n            id=UUID(),\n            subject_id=UUID(),\n            subject_type=\"financial_data\",\n            analysis_type=\"projection\",\n            analysis_date=datetime.now(),\n            processing_time_ms=processing_time_ms,\n            result_summary={\n                \"starting_balance\": starting_balance,\n                \"baseline_final_balance\": baseline.final_balance,\n                \"runway_months\": baseline.runway_months,\n                \"emergency_fund_status\": baseline.emergency_fund_status,\n            },\n            detailed_results={\n                \"projection_length\": parameters.projection_length,\n                \"scenarios\": [s.value for s in ProjectionScenario],\n                \"historical_data_points\": len(historical_data.values),\n            },\n            baseline=baseline,\n            optimistic=optimistic,\n            conservative=conservative,\n            stress_test=stress_test,\n            recommended_actions=recommended_actions,\n        )\n        \n        # Save to cache\n        self._save_to_cache(UUID(), result, parameters)\n        \n        return result\n    \n    def _generate_projection(\n        self,\n        historical_data: TimeSeriesData,\n        scenario: ProjectionScenario,\n        parameters: ProjectionParameters,\n        income_factor: float = 1.0,\n        expense_factor: float = 1.0,\n        investment_factor: float = 1.0,\n    ) -> Projection:\n        \"\"\"\n        Generate a financial projection for a specific scenario.\n        \n        Args:\n            historical_data: Historical financial data\n            scenario: The projection scenario\n            parameters: Projection parameters\n            income_factor: Adjustment factor for income\n            expense_factor: Adjustment factor for expenses\n            investment_factor: Adjustment factor for investment returns\n            \n        Returns:\n            Projection for the specified scenario\n        \"\"\"\n        # Calculate starting balance (last cumulative value)\n        starting_balance = (\n            historical_data.values[-1] if historical_data.values else 0.0\n        )\n        \n        # Determine start and end dates\n        if historical_data.dates:\n            start_date = historical_data.dates[-1]\n            # Add 1 month to avoid overlap with historical data\n            if isinstance(start_date, datetime):\n                start_date = start_date.replace(\n                    day=1, hour=0, minute=0, second=0, microsecond=0\n                )\n                start_date = (start_date.replace(day=28) + timedelta(days=4)).replace(day=1)\n            else:\n                # For date objects\n                year = start_date.year + ((start_date.month) // 12)\n                month = (start_date.month % 12) + 1\n                start_date = date(year, month, 1)\n        else:\n            start_date = datetime.now().replace(\n                day=1, hour=0, minute=0, second=0, microsecond=0\n            )\n        \n        # Generate projection dates (monthly)\n        projection_dates = []\n        current_date = start_date\n        for _ in range(parameters.projection_length):\n            projection_dates.append(current_date)\n            if isinstance(current_date, datetime):\n                current_date = (current_date.replace(day=28) + timedelta(days=4)).replace(day=1)\n            else:\n                # For date objects\n                year = current_date.year + ((current_date.month) // 12)\n                month = (current_date.month % 12) + 1\n                current_date = date(year, month, 1)\n        \n        end_date = projection_dates[-1]\n        \n        # Adjust rates based on scenario\n        income_growth = parameters.income_growth_rate * income_factor\n        expense_growth = parameters.expense_growth_rate * expense_factor\n        investment_return = parameters.investment_return_rate * investment_factor\n        \n        # Calculate historical averages\n        avg_income, avg_expenses = self._calculate_historical_averages(historical_data)\n        \n        # Generate cash flows\n        cash_flows = []\n        cumulative_balance = starting_balance\n        lowest_balance = starting_balance\n        highest_balance = starting_balance\n        \n        for i, projection_date in enumerate(projection_dates):\n            # Calculate projected income with growth\n            income = avg_income * (1 + income_growth) ** (i / 12) if parameters.include_income else 0\n            \n            # Calculate projected expenses with growth\n            expenses = avg_expenses * (1 + expense_growth) ** (i / 12) if parameters.include_expenses else 0\n            \n            # Calculate investment returns (monthly)\n            investment_income = (\n                cumulative_balance * (investment_return / 12)\n                if parameters.include_investments and cumulative_balance > 0\n                else 0\n            )\n            \n            # Add investment income to total income\n            income += investment_income\n            \n            # Calculate net and update cumulative\n            net = income - expenses\n            cumulative_balance += net\n            \n            # Track lowest and highest balances\n            lowest_balance = min(lowest_balance, cumulative_balance)\n            highest_balance = max(highest_balance, cumulative_balance)\n            \n            # Create cash flow record\n            cash_flow = CashFlow(\n                date=projection_date,\n                income=income,\n                expenses=expenses,\n                net=net,\n                cumulative=cumulative_balance,\n            )\n            \n            cash_flows.append(cash_flow)\n        \n        # Calculate runway months (how long until funds are depleted)\n        runway_months = None\n        if avg_expenses > 0:\n            for i, cf in enumerate(cash_flows):\n                if cf.cumulative <= 0:\n                    runway_months = i\n                    break\n            \n            if runway_months is None and lowest_balance > 0:\n                # If we didn't go negative, estimate based on final balance and burn rate\n                if cash_flows[-1].net < 0:\n                    runway_months = parameters.projection_length + (cash_flows[-1].cumulative / -cash_flows[-1].net)\n                else:\n                    runway_months = float('inf')  # Sustainable cash flow\n        \n        # Determine emergency fund status\n        emergency_fund_status = \"insufficient\"\n        if lowest_balance >= avg_expenses * parameters.emergency_fund_months:\n            emergency_fund_status = \"adequate\"\n        elif lowest_balance >= avg_expenses * (parameters.emergency_fund_months / 2):\n            emergency_fund_status = \"partial\"\n        \n        # Calculate projected tax liability\n        tax_liability = self._calculate_tax_liability(cash_flows, parameters.tax_rate)\n        \n        # Create the projection\n        return Projection(\n            scenario=scenario,\n            start_date=start_date,\n            end_date=end_date,\n            starting_balance=starting_balance,\n            cash_flows=cash_flows,\n            final_balance=cash_flows[-1].cumulative if cash_flows else starting_balance,\n            lowest_balance=lowest_balance,\n            highest_balance=highest_balance,\n            runway_months=runway_months,\n            emergency_fund_status=emergency_fund_status,\n            tax_liability=tax_liability,\n            confidence_level=self._calculate_confidence_level(scenario),\n            metadata={\n                \"income_growth_rate\": income_growth,\n                \"expense_growth_rate\": expense_growth,\n                \"investment_return_rate\": investment_return,\n                \"avg_monthly_income\": avg_income,\n                \"avg_monthly_expenses\": avg_expenses,\n            },\n        )\n    \n    def _calculate_historical_averages(\n        self, historical_data: TimeSeriesData\n    ) -> Tuple[float, float]:\n        \"\"\"\n        Calculate average monthly income and expenses from historical data.\n        \n        Args:\n            historical_data: Historical financial data\n            \n        Returns:\n            Tuple of (avg_income, avg_expenses)\n        \"\"\"\n        # In a real implementation, the historical data would likely contain\n        # separate income and expense data. Here we'll simulate it.\n        \n        # If we don't have historical data, use reasonable defaults\n        if not historical_data.values:\n            return 5000.0, 4000.0  # Default monthly income and expenses\n        \n        # Normally we would split the historical cash flows into income and expenses\n        # For now, we'll use a heuristic based on the net cash flow\n        \n        # Assuming the TimeSeriesData values are net cash flows\n        avg_net = np.mean(historical_data.values[-6:]) if len(historical_data.values) >= 6 else np.mean(historical_data.values)\n        \n        # Assuming expenses are about 80% of income on average\n        avg_income = max(avg_net * 1.8, 0)\n        avg_expenses = max(avg_income - avg_net, 0)\n        \n        return avg_income, avg_expenses\n    \n    def _calculate_tax_liability(\n        self, cash_flows: List[CashFlow], tax_rate: float\n    ) -> Dict[str, float]:\n        \"\"\"\n        Calculate projected tax liability.\n        \n        Args:\n            cash_flows: List of projected cash flows\n            tax_rate: The effective tax rate\n            \n        Returns:\n            Dictionary with tax liability information\n        \"\"\"\n        # Group by year\n        yearly_income = {}\n        \n        for cf in cash_flows:\n            year = cf.date.year\n            if year not in yearly_income:\n                yearly_income[year] = 0\n            \n            yearly_income[year] += cf.income\n        \n        # Calculate tax for each year\n        yearly_tax = {year: income * tax_rate for year, income in yearly_income.items()}\n        \n        # Calculate total and average\n        total_tax = sum(yearly_tax.values())\n        avg_monthly_tax = total_tax / len(cash_flows) if cash_flows else 0\n        \n        return {\n            \"yearly\": yearly_tax,\n            \"total\": total_tax,\n            \"avg_monthly\": avg_monthly_tax,\n            \"effective_rate\": tax_rate,\n        }\n    \n    def _calculate_confidence_level(self, scenario: ProjectionScenario) -> float:\n        \"\"\"\n        Calculate confidence level for a scenario.\n        \n        Args:\n            scenario: The projection scenario\n            \n        Returns:\n            Confidence level between 0 and 1\n        \"\"\"\n        # Assign confidence levels based on the scenario\n        if scenario == ProjectionScenario.BASELINE:\n            return 0.8\n        elif scenario == ProjectionScenario.OPTIMISTIC:\n            return 0.2\n        elif scenario == ProjectionScenario.CONSERVATIVE:\n            return 0.6\n        elif scenario == ProjectionScenario.STRESS_TEST:\n            return 0.1\n        \n        return 0.5  # Default\n    \n    def _generate_recommendations(\n        self,\n        baseline: Projection,\n        conservative: Projection,\n        stress_test: Projection,\n        parameters: ProjectionParameters,\n    ) -> List[str]:\n        \"\"\"\n        Generate financial recommendations based on projections.\n        \n        Args:\n            baseline: Baseline scenario projection\n            conservative: Conservative scenario projection\n            stress_test: Stress test scenario projection\n            parameters: Projection parameters\n            \n        Returns:\n            List of recommendation strings\n        \"\"\"\n        recommendations = []\n        \n        # Emergency fund recommendations\n        if baseline.emergency_fund_status == \"insufficient\":\n            recommendations.append(\n                f\"Build an emergency fund of {parameters.emergency_fund_months} months of expenses \"\n                f\"(approximately ${parameters.emergency_fund_months * baseline.metadata['avg_monthly_expenses']:,.2f}).\"\n            )\n        elif baseline.emergency_fund_status == \"partial\":\n            months_needed = parameters.emergency_fund_months\n            current_months = baseline.lowest_balance / baseline.metadata[\"avg_monthly_expenses\"]\n            recommendations.append(\n                f\"Increase your emergency fund from {current_months:.1f} months to {months_needed} months \"\n                f\"(add approximately ${(months_needed - current_months) * baseline.metadata['avg_monthly_expenses']:,.2f}).\"\n            )\n        \n        # Cash flow recommendations\n        if baseline.cash_flows and baseline.cash_flows[-1].net < 0:\n            recommendations.append(\n                \"Your expenses exceed your income. Consider reducing expenses or increasing income \"\n                f\"to close the monthly gap of ${-baseline.cash_flows[-1].net:,.2f}.\"\n            )\n        \n        # Runway concerns\n        if baseline.runway_months is not None and baseline.runway_months < parameters.projection_length:\n            recommendations.append(\n                f\"Based on current projections, your funds will be depleted in approximately {baseline.runway_months:.1f} months. \"\n                \"Take immediate action to increase income or reduce expenses.\"\n            )\n        elif conservative.runway_months is not None and conservative.runway_months < parameters.projection_length:\n            recommendations.append(\n                f\"In a conservative scenario, your funds could be depleted in approximately {conservative.runway_months:.1f} months. \"\n                \"Consider building additional reserves or reducing discretionary expenses.\"\n            )\n        \n        # Investment recommendations\n        if parameters.include_investments and baseline.metadata[\"avg_monthly_expenses\"] > 0:\n            # Calculate months of expenses covered by investments\n            investment_coverage = baseline.final_balance / baseline.metadata[\"avg_monthly_expenses\"]\n            if investment_coverage > 24:\n                recommendations.append(\n                    f\"Your projected balance exceeds 24 months of expenses. Consider investing a portion for long-term growth.\"\n                )\n        \n        # Tax planning\n        if baseline.tax_liability[\"total\"] > 0:\n            recommendations.append(\n                f\"Set aside approximately ${baseline.tax_liability['avg_monthly']:,.2f} monthly for taxes, \"\n                f\"with an estimated annual liability of ${baseline.tax_liability['yearly'].get(datetime.now().year, 0):,.2f}.\"\n            )\n        \n        # Stress test preparedness\n        if stress_test.lowest_balance < 0:\n            recommendations.append(\n                \"Your financial position is vulnerable to economic stress. Consider building additional reserves \"\n                f\"of at least ${-stress_test.lowest_balance:,.2f} to withstand worst-case scenarios.\"\n            )\n        \n        return recommendations"
            ]
        }
    },
    "unified/personal_finance_tracker/expense/rules.py": {
        "logprobs": -769.3958747102618,
        "metrics": {
            "loc": 137,
            "sloc": 81,
            "lloc": 88,
            "comments": 10,
            "multi": 19,
            "blank": 26,
            "cyclomatic": 27,
            "internal_imports": [
                "class Rule(BaseModel, ABC):\n    \"\"\"\n    Abstract base class for categorization rules.\n    \n    Defines the interface for all rules used in categorization\n    across different persona implementations.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    description: Optional[str] = None\n    priority: int = 0  # Higher numbers have higher priority\n    created_at: datetime = Field(default_factory=datetime.now)\n    updated_at: datetime = Field(default_factory=datetime.now)\n    is_active: bool = True\n    \n    @abstractmethod\n    def matches(self, item: Any) -> bool:\n        \"\"\"\n        Check if this rule matches the given item.\n        \n        Args:\n            item: The item to check against this rule\n            \n        Returns:\n            True if the rule matches, False otherwise\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def apply(self, item: Any) -> Any:\n        \"\"\"\n        Apply this rule to the given item.\n        \n        Args:\n            item: The item to apply this rule to\n            \n        Returns:\n            The result of applying the rule\n        \"\"\"\n        pass\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class BaseTransaction(BaseModel):\n    \"\"\"\n    Base transaction model for all financial transactions.\n    \n    This abstract base class provides common fields for tracking\n    financial transactions across different persona implementations.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    date: Union[date, datetime]\n    amount: float\n    description: str\n    transaction_type: TransactionType\n    \n    # Optional fields\n    account_id: Optional[str] = None\n    category: Optional[str] = None\n    tags: List[str] = Field(default_factory=list)\n    notes: Optional[str] = None\n    \n    @validator(\"amount\")\n    def validate_amount(cls, v):\n        \"\"\"Validate that amount is a valid number.\"\"\"\n        if not isinstance(v, (int, float)):\n            raise ValueError(\"Amount must be a number\")\n        return v",
                "class ExpenseCategory(str, Enum):\n    \"\"\"Expense category enum.\"\"\"\n\n    BUSINESS_SUPPLIES = \"business_supplies\"\n    SOFTWARE = \"software\"\n    MARKETING = \"marketing\"\n    OFFICE_RENT = \"office_rent\"\n    UTILITIES = \"utilities\"\n    TRAVEL = \"travel\"\n    MEALS = \"meals\"\n    EQUIPMENT = \"equipment\"\n    PROFESSIONAL_DEVELOPMENT = \"professional_development\"\n    PROFESSIONAL_SERVICES = \"professional_services\"\n    HEALTH_INSURANCE = \"health_insurance\"\n    RETIREMENT = \"retirement\"\n    PHONE = \"phone\"\n    INTERNET = \"internet\"\n    CAR = \"car\"\n    HOME_OFFICE = \"home_office\"\n    PERSONAL = \"personal\"\n    OTHER = \"other\"",
                "class Transaction(BusinessTransaction):\n    \"\"\"\n    Transaction model for the Personal Finance Tracker.\n    \n    Extends the BusinessTransaction from the common library with\n    freelancer-specific fields and behaviors.\n    \"\"\"\n\n    # Override category field to use our specific ExpenseCategory enum\n    category: Optional[ExpenseCategory] = None\n    \n    # Make sure the account_id is required\n    account_id: str\n\n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        # This is necessary to allow field overrides\n        extra = \"allow\""
            ]
        }
    },
    "unified/ethical_finance/ethical_screening/screening.py": {
        "logprobs": -2543.197801292998,
        "metrics": {
            "loc": 572,
            "sloc": 322,
            "lloc": 242,
            "comments": 62,
            "multi": 79,
            "blank": 107,
            "cyclomatic": 81,
            "internal_imports": [
                "class BaseAnalyzer(Generic[T, R], ABC):\n    \"\"\"\n    Abstract base class for analysis engines.\n    \n    Defines the core interface and functionality for all analyzers\n    across different persona implementations.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the analyzer.\"\"\"\n        self._analysis_cache: Dict[str, R] = {}\n    \n    @abstractmethod\n    def analyze(\n        self, subject: T, parameters: Optional[AnalysisParameters] = None\n    ) -> R:\n        \"\"\"\n        Analyze a single subject.\n        \n        Args:\n            subject: The subject to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Analysis result\n        \"\"\"\n        pass\n    \n    def analyze_batch(\n        self, subjects: List[T], parameters: Optional[AnalysisParameters] = None\n    ) -> List[R]:\n        \"\"\"\n        Analyze multiple subjects.\n        \n        Args:\n            subjects: List of subjects to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            List of analysis results\n        \"\"\"\n        # Start performance timer\n        start_time = time.time()\n        \n        # Analyze each subject\n        results = []\n        for subject in subjects:\n            result = self.analyze(subject, parameters)\n            results.append(result)\n        \n        # Performance metrics\n        elapsed_time = time.time() - start_time\n        \n        return results\n    \n    def clear_cache(self) -> None:\n        \"\"\"Clear the analysis cache.\"\"\"\n        self._analysis_cache = {}\n    \n    def _generate_cache_key(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> str:\n        \"\"\"\n        Generate a cache key for a subject and parameters.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cache key string\n        \"\"\"\n        # Start with the subject ID\n        key = f\"subject_{subject_id}\"\n        \n        # Add parameter details if provided\n        if parameters:\n            param_dict = parameters.dict(exclude_none=True)\n            for k, v in sorted(param_dict.items()):\n                if k != \"custom_settings\":\n                    key += f\"_{k}_{v}\"\n                    \n            # Handle custom settings separately (they could be complex)\n            if parameters.custom_settings:\n                for k, v in sorted(parameters.custom_settings.items()):\n                    key += f\"_{k}_{v}\"\n        \n        return key\n    \n    def _get_from_cache(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> Optional[R]:\n        \"\"\"\n        Get a cached analysis result if available.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cached result or None if not found\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        return self._analysis_cache.get(cache_key)\n    \n    def _save_to_cache(\n        self, subject_id: Union[str, UUID], result: R, parameters: Optional[AnalysisParameters] = None\n    ) -> None:\n        \"\"\"\n        Save an analysis result to the cache.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            result: The analysis result to cache\n            parameters: Optional parameters to configure the analysis\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        self._analysis_cache[cache_key] = result",
                "class AnalysisParameters(BaseModel):\n    \"\"\"\n    Parameters for an analysis operation.\n    \n    Used to configure analysis options and settings.\n    \"\"\"\n    \n    period_start: Optional[Union[date, datetime]] = None\n    period_end: Optional[Union[date, datetime]] = None\n    include_details: bool = True\n    calculation_mode: str = \"standard\"  # \"standard\", \"detailed\", \"fast\"\n    grouping: Optional[str] = None\n    custom_settings: Dict[str, Any] = Field(default_factory=dict)",
                "class AnalysisResult(BaseModel, Generic[T]):\n    \"\"\"\n    Result of an analysis operation.\n    \n    Provides information about the analysis process and outcome.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    subject_id: Optional[Union[str, UUID]] = None\n    subject_type: str\n    analysis_type: str\n    analysis_date: datetime = Field(default_factory=datetime.now)\n    processing_time_ms: Optional[float] = None\n    result_summary: Dict[str, Any] = Field(default_factory=dict)\n    detailed_results: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Timer:\n    \"\"\"Utility for measuring execution time.\"\"\"\n    \n    def __init__(self, name: Optional[str] = None):\n        \"\"\"\n        Initialize the timer.\n        \n        Args:\n            name: Optional name for the timer\n        \"\"\"\n        self.name = name\n        self.start_time: Optional[float] = None\n        self.end_time: Optional[float] = None\n    \n    def __enter__(self) -> 'Timer':\n        \"\"\"Start the timer when entering a context.\"\"\"\n        self.start()\n        return self\n    \n    def __exit__(self, *args: Any) -> None:\n        \"\"\"Stop the timer when exiting a context.\"\"\"\n        self.stop()\n    \n    def start(self) -> None:\n        \"\"\"Start the timer.\"\"\"\n        self.start_time = time.time()\n        self.end_time = None\n    \n    def stop(self) -> float:\n        \"\"\"\n        Stop the timer.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        self.end_time = time.time()\n        return self.elapsed_time\n    \n    @property\n    def elapsed_time(self) -> float:\n        \"\"\"\n        Get the elapsed time.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        end = self.end_time if self.end_time is not None else time.time()\n        return end - self.start_time\n    \n    @property\n    def elapsed_milliseconds(self) -> float:\n        \"\"\"\n        Get the elapsed time in milliseconds.\n        \n        Returns:\n            Elapsed time in milliseconds\n        \"\"\"\n        return self.elapsed_time * 1000",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Investment(CommonInvestment):\n    \"\"\"Model representing an investment opportunity with ESG attributes.\"\"\"\n    \n    # We're inheriting all fields from CommonInvestment:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # name: str\n    # sector: str\n    # industry: str\n    # market_cap: float\n    # price: float\n    # esg_ratings: ESGRating\n    # carbon_footprint: float \n    # renewable_energy_use: float\n    # diversity_score: float\n    # board_independence: float\n    # controversies: List[str] = Field(default_factory=list)\n    # positive_practices: List[str] = Field(default_factory=list)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class EthicalCriteria(CommonEthicalCriteria):\n    \"\"\"Customizable ethical screening criteria for investments.\"\"\"\n    \n    # Converting from criteria_id to id (common model uses id)\n    criteria_id: Optional[str] = None\n    \n    @classmethod\n    def from_common_criteria(cls, common_criteria: CommonEthicalCriteria) -> \"EthicalCriteria\":\n        \"\"\"Convert from common model to specialized model.\"\"\"\n        return cls(\n            id=common_criteria.id,\n            criteria_id=str(common_criteria.id),  # For backward compatibility\n            name=common_criteria.name,\n            environmental=common_criteria.environmental,\n            social=common_criteria.social,\n            governance=common_criteria.governance,\n            min_overall_score=common_criteria.min_overall_score,\n            exclusions=common_criteria.exclusions,\n            inclusions=common_criteria.inclusions\n        )\n    \n    def to_common_criteria(self) -> CommonEthicalCriteria:\n        \"\"\"Convert to common model.\"\"\"\n        return CommonEthicalCriteria(\n            id=self.id,\n            name=self.name,\n            environmental=self.environmental,\n            social=self.social,\n            governance=self.governance,\n            min_overall_score=self.min_overall_score,\n            exclusions=self.exclusions,\n            inclusions=self.inclusions\n        )\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class EthicalCriteria(CommonEthicalCriteria):\n    \"\"\"Customizable ethical screening criteria for investments.\"\"\"\n    \n    # Converting from criteria_id to id (common model uses id)\n    criteria_id: Optional[str] = None\n    \n    @classmethod\n    def from_common_criteria(cls, common_criteria: CommonEthicalCriteria) -> \"EthicalCriteria\":\n        \"\"\"Convert from common model to specialized model.\"\"\"\n        return cls(\n            id=common_criteria.id,\n            criteria_id=str(common_criteria.id),  # For backward compatibility\n            name=common_criteria.name,\n            environmental=common_criteria.environmental,\n            social=common_criteria.social,\n            governance=common_criteria.governance,\n            min_overall_score=common_criteria.min_overall_score,\n            exclusions=common_criteria.exclusions,\n            inclusions=common_criteria.inclusions\n        )\n    \n    def to_common_criteria(self) -> CommonEthicalCriteria:\n        \"\"\"Convert to common model.\"\"\"\n        return CommonEthicalCriteria(\n            id=self.id,\n            name=self.name,\n            environmental=self.environmental,\n            social=self.social,\n            governance=self.governance,\n            min_overall_score=self.min_overall_score,\n            exclusions=self.exclusions,\n            inclusions=self.inclusions\n        )\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class EthicalCriteria(CommonEthicalCriteria):\n    \"\"\"Customizable ethical screening criteria for investments.\"\"\"\n    \n    # Converting from criteria_id to id (common model uses id)\n    criteria_id: Optional[str] = None\n    \n    @classmethod\n    def from_common_criteria(cls, common_criteria: CommonEthicalCriteria) -> \"EthicalCriteria\":\n        \"\"\"Convert from common model to specialized model.\"\"\"\n        return cls(\n            id=common_criteria.id,\n            criteria_id=str(common_criteria.id),  # For backward compatibility\n            name=common_criteria.name,\n            environmental=common_criteria.environmental,\n            social=common_criteria.social,\n            governance=common_criteria.governance,\n            min_overall_score=common_criteria.min_overall_score,\n            exclusions=common_criteria.exclusions,\n            inclusions=common_criteria.inclusions\n        )\n    \n    def to_common_criteria(self) -> CommonEthicalCriteria:\n        \"\"\"Convert to common model.\"\"\"\n        return CommonEthicalCriteria(\n            id=self.id,\n            name=self.name,\n            environmental=self.environmental,\n            social=self.social,\n            governance=self.governance,\n            min_overall_score=self.min_overall_score,\n            exclusions=self.exclusions,\n            inclusions=self.inclusions\n        )\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class EthicalCriteria(CommonEthicalCriteria):\n    \"\"\"Customizable ethical screening criteria for investments.\"\"\"\n    \n    # Converting from criteria_id to id (common model uses id)\n    criteria_id: Optional[str] = None\n    \n    @classmethod\n    def from_common_criteria(cls, common_criteria: CommonEthicalCriteria) -> \"EthicalCriteria\":\n        \"\"\"Convert from common model to specialized model.\"\"\"\n        return cls(\n            id=common_criteria.id,\n            criteria_id=str(common_criteria.id),  # For backward compatibility\n            name=common_criteria.name,\n            environmental=common_criteria.environmental,\n            social=common_criteria.social,\n            governance=common_criteria.governance,\n            min_overall_score=common_criteria.min_overall_score,\n            exclusions=common_criteria.exclusions,\n            inclusions=common_criteria.inclusions\n        )\n    \n    def to_common_criteria(self) -> CommonEthicalCriteria:\n        \"\"\"Convert to common model.\"\"\"\n        return CommonEthicalCriteria(\n            id=self.id,\n            name=self.name,\n            environmental=self.environmental,\n            social=self.social,\n            governance=self.governance,\n            min_overall_score=self.min_overall_score,\n            exclusions=self.exclusions,\n            inclusions=self.inclusions\n        )\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class EthicalCriteria(CommonEthicalCriteria):\n    \"\"\"Customizable ethical screening criteria for investments.\"\"\"\n    \n    # Converting from criteria_id to id (common model uses id)\n    criteria_id: Optional[str] = None\n    \n    @classmethod\n    def from_common_criteria(cls, common_criteria: CommonEthicalCriteria) -> \"EthicalCriteria\":\n        \"\"\"Convert from common model to specialized model.\"\"\"\n        return cls(\n            id=common_criteria.id,\n            criteria_id=str(common_criteria.id),  # For backward compatibility\n            name=common_criteria.name,\n            environmental=common_criteria.environmental,\n            social=common_criteria.social,\n            governance=common_criteria.governance,\n            min_overall_score=common_criteria.min_overall_score,\n            exclusions=common_criteria.exclusions,\n            inclusions=common_criteria.inclusions\n        )\n    \n    def to_common_criteria(self) -> CommonEthicalCriteria:\n        \"\"\"Convert to common model.\"\"\"\n        return CommonEthicalCriteria(\n            id=self.id,\n            name=self.name,\n            environmental=self.environmental,\n            social=self.social,\n            governance=self.governance,\n            min_overall_score=self.min_overall_score,\n            exclusions=self.exclusions,\n            inclusions=self.inclusions\n        )\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class EthicalCriteria(CommonEthicalCriteria):\n    \"\"\"Customizable ethical screening criteria for investments.\"\"\"\n    \n    # Converting from criteria_id to id (common model uses id)\n    criteria_id: Optional[str] = None\n    \n    @classmethod\n    def from_common_criteria(cls, common_criteria: CommonEthicalCriteria) -> \"EthicalCriteria\":\n        \"\"\"Convert from common model to specialized model.\"\"\"\n        return cls(\n            id=common_criteria.id,\n            criteria_id=str(common_criteria.id),  # For backward compatibility\n            name=common_criteria.name,\n            environmental=common_criteria.environmental,\n            social=common_criteria.social,\n            governance=common_criteria.governance,\n            min_overall_score=common_criteria.min_overall_score,\n            exclusions=common_criteria.exclusions,\n            inclusions=common_criteria.inclusions\n        )\n    \n    def to_common_criteria(self) -> CommonEthicalCriteria:\n        \"\"\"Convert to common model.\"\"\"\n        return CommonEthicalCriteria(\n            id=self.id,\n            name=self.name,\n            environmental=self.environmental,\n            social=self.social,\n            governance=self.governance,\n            min_overall_score=self.min_overall_score,\n            exclusions=self.exclusions,\n            inclusions=self.inclusions\n        )\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class EthicalCriteria(BaseModel):\n    \"\"\"\n    Ethical screening criteria for investments.\n    \n    Used for evaluating investments against personalized ethical standards.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    name: str\n    environmental: Dict[str, Any]\n    social: Dict[str, Any]\n    governance: Dict[str, Any]\n    min_overall_score: float\n    exclusions: List[str] = Field(default_factory=list)\n    inclusions: List[str] = Field(default_factory=list)\n    \n    @root_validator(skip_on_failure=True)\n    def validate_criteria_weights(cls, values):\n        \"\"\"Validate that criteria weights are included and sum approximately to 1.\"\"\"\n        for field_name in ['environmental', 'social', 'governance']:\n            field_value = values.get(field_name, {})\n            \n            # Check that weight exists\n            if 'weight' not in field_value:\n                raise ValueError(f\"{field_name} criteria must include a weight\")\n            \n            # Ensure weight is between 0 and 1\n            if field_value['weight'] < 0 or field_value['weight'] > 1:\n                raise ValueError(f\"{field_name} weight must be between 0 and 1\")\n        \n        # Check that weights sum to approximately 1\n        weights_sum = (\n            values.get('environmental', {}).get('weight', 0) + \n            values.get('social', {}).get('weight', 0) + \n            values.get('governance', {}).get('weight', 0)\n        )\n        \n        if abs(weights_sum - 1.0) > 0.01:  # Allow for small rounding errors\n            raise ValueError(f\"Criteria weights sum to {weights_sum}, expected 1.0\")\n            \n        return values"
            ]
        }
    },
    "unified/tests/freelancer/conftest.py": {
        "logprobs": -1464.8893444073685,
        "metrics": {
            "loc": 363,
            "sloc": 296,
            "lloc": 109,
            "comments": 22,
            "multi": 0,
            "blank": 46,
            "cyclomatic": 36,
            "internal_imports": [
                "class Client(CommonClient):\n    \"\"\"\n    Client model for Personal Finance Tracker.\n    \n    Extends the Client model from the common library.\n    \"\"\"\n    pass",
                "class ExpenseCategory(str, Enum):\n    \"\"\"Expense category enum.\"\"\"\n\n    BUSINESS_SUPPLIES = \"business_supplies\"\n    SOFTWARE = \"software\"\n    MARKETING = \"marketing\"\n    OFFICE_RENT = \"office_rent\"\n    UTILITIES = \"utilities\"\n    TRAVEL = \"travel\"\n    MEALS = \"meals\"\n    EQUIPMENT = \"equipment\"\n    PROFESSIONAL_DEVELOPMENT = \"professional_development\"\n    PROFESSIONAL_SERVICES = \"professional_services\"\n    HEALTH_INSURANCE = \"health_insurance\"\n    RETIREMENT = \"retirement\"\n    PHONE = \"phone\"\n    INTERNET = \"internet\"\n    CAR = \"car\"\n    HOME_OFFICE = \"home_office\"\n    PERSONAL = \"personal\"\n    OTHER = \"other\"",
                "class Invoice(CommonInvoice):\n    \"\"\"\n    Invoice model for Personal Finance Tracker.\n    \n    Extends the Invoice model from the common library.\n    \"\"\"\n    # Make client_id required\n    client_id: str",
                "class Project(CommonProject):\n    \"\"\"\n    Project model for Personal Finance Tracker.\n    \n    Extends the Project model from the common library.\n    \"\"\"\n    # Override status field to be more flexible for backward compatibility\n    status: Union[str, ProjectStatus] = ProjectStatus.ACTIVE\n    \n    # Make client_id required\n    client_id: str",
                "class TimeEntry(CommonTimeEntry):\n    \"\"\"\n    Time entry model for tracking hours worked on projects.\n    \n    Extends the TimeEntry model from the common library.\n    \"\"\"\n    pass",
                "class Transaction(BusinessTransaction):\n    \"\"\"\n    Transaction model for the Personal Finance Tracker.\n    \n    Extends the BusinessTransaction from the common library with\n    freelancer-specific fields and behaviors.\n    \"\"\"\n\n    # Override category field to use our specific ExpenseCategory enum\n    category: Optional[ExpenseCategory] = None\n    \n    # Make sure the account_id is required\n    account_id: str\n\n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        # This is necessary to allow field overrides\n        extra = \"allow\""
            ]
        }
    },
    "unified/setup.py": {
        "logprobs": -285.4336631287994,
        "metrics": {
            "loc": 9,
            "sloc": 8,
            "lloc": 2,
            "comments": 0,
            "multi": 0,
            "blank": 1,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/personal_finance_tracker/income/income_manager.py": {
        "logprobs": -2165.852655814714,
        "metrics": {
            "loc": 488,
            "sloc": 291,
            "lloc": 193,
            "comments": 58,
            "multi": 62,
            "blank": 74,
            "cyclomatic": 74,
            "internal_imports": [
                "class TimeSeriesData(BaseModel):\n    \"\"\"\n    Model for time series data.\n    \n    Used for storing and manipulating time series data for analysis.\n    \"\"\"\n    \n    dates: List[Union[date, datetime]]\n    values: List[float]\n    labels: Optional[List[str]] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class TimeSeriesAnalyzer:\n    \"\"\"\n    Utility class for analyzing time series data.\n    \n    Provides methods for smoothing, trend detection, and forecasting.\n    \"\"\"\n    \n    @staticmethod\n    def moving_average(\n        data: TimeSeriesData, window_size: int = 3\n    ) -> TimeSeriesData:\n        \"\"\"\n        Calculate the moving average of time series data.\n        \n        Args:\n            data: The time series data\n            window_size: The window size for the moving average\n            \n        Returns:\n            New time series data with smoothed values\n        \"\"\"\n        if not data.values:\n            return TimeSeriesData(dates=[], values=[])\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Calculate the cumulative sum of values\n        cumsum = np.cumsum(values)\n        \n        # Calculate the moving average using the window\n        smoothed = np.zeros_like(values)\n        \n        # Handle the start of the array (where we don't have a full window)\n        for i in range(min(window_size, len(values))):\n            smoothed[i] = cumsum[i] / (i + 1)\n        \n        # Handle the rest of the array\n        for i in range(window_size, len(values)):\n            smoothed[i] = (cumsum[i] - cumsum[i - window_size]) / window_size\n        \n        # Create new time series data with smoothed values\n        return TimeSeriesData(\n            dates=data.dates,\n            values=smoothed.tolist(),\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"smoothing_method\": \"moving_average\",\n                \"window_size\": window_size,\n            },\n        )\n    \n    @staticmethod\n    def exponential_smoothing(\n        data: TimeSeriesData, alpha: float = 0.3\n    ) -> TimeSeriesData:\n        \"\"\"\n        Apply exponential smoothing to time series data.\n        \n        Args:\n            data: The time series data\n            alpha: The smoothing factor (0 < alpha < 1)\n            \n        Returns:\n            New time series data with smoothed values\n        \"\"\"\n        if not data.values:\n            return TimeSeriesData(dates=[], values=[])\n        \n        # Ensure alpha is between 0 and 1\n        alpha = max(0.01, min(0.99, alpha))\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Initialize the smoothed array with the first value\n        smoothed = np.zeros_like(values)\n        smoothed[0] = values[0]\n        \n        # Apply exponential smoothing\n        for i in range(1, len(values)):\n            smoothed[i] = alpha * values[i] + (1 - alpha) * smoothed[i - 1]\n        \n        # Create new time series data with smoothed values\n        return TimeSeriesData(\n            dates=data.dates,\n            values=smoothed.tolist(),\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"smoothing_method\": \"exponential\",\n                \"alpha\": alpha,\n            },\n        )\n    \n    @staticmethod\n    def seasonal_adjustment(\n        data: TimeSeriesData, period: int = 12\n    ) -> TimeSeriesData:\n        \"\"\"\n        Apply seasonal adjustment to time series data.\n        \n        Args:\n            data: The time series data\n            period: The seasonal period (e.g., 12 for monthly data with yearly seasonality)\n            \n        Returns:\n            New time series data with seasonally adjusted values\n        \"\"\"\n        if not data.values or len(data.values) < period * 2:\n            # Not enough data for seasonal adjustment\n            return data\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Calculate the seasonal indices\n        seasonal_indices = np.zeros(period)\n        seasonal_data = []\n        \n        # Organize data by season\n        for i in range(period):\n            seasonal_data.append(values[i::period])\n        \n        # Calculate average for each season\n        for i in range(period):\n            if len(seasonal_data[i]) > 0:\n                seasonal_indices[i] = np.mean(seasonal_data[i])\n        \n        # Normalize the seasonal indices\n        if np.sum(seasonal_indices) > 0:\n            seasonal_indices = seasonal_indices * period / np.sum(seasonal_indices)\n        \n        # Apply the seasonal adjustment\n        adjusted = np.zeros_like(values)\n        for i in range(len(values)):\n            season_idx = i % period\n            if seasonal_indices[season_idx] > 0:\n                adjusted[i] = values[i] / seasonal_indices[season_idx]\n            else:\n                adjusted[i] = values[i]\n        \n        # Create new time series data with adjusted values\n        return TimeSeriesData(\n            dates=data.dates,\n            values=adjusted.tolist(),\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"smoothing_method\": \"seasonal\",\n                \"period\": period,\n                \"seasonal_indices\": seasonal_indices.tolist(),\n            },\n        )\n    \n    @staticmethod\n    def detect_trend(data: TimeSeriesData) -> Dict[str, Any]:\n        \"\"\"\n        Detect trends in time series data.\n        \n        Args:\n            data: The time series data\n            \n        Returns:\n            Dictionary with trend information\n        \"\"\"\n        if not data.values or len(data.values) < 2:\n            return {\n                \"has_trend\": False,\n                \"trend_direction\": \"none\",\n                \"trend_strength\": 0.0,\n            }\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Simple linear regression\n        x = np.arange(len(values))\n        A = np.vstack([x, np.ones(len(x))]).T\n        \n        # Solve for the best fit line\n        try:\n            slope, intercept = np.linalg.lstsq(A, values, rcond=None)[0]\n        except:\n            # Fallback if linear algebra fails\n            slope = 0.0\n            intercept = np.mean(values) if len(values) > 0 else 0.0\n        \n        # Calculate trend strength (R-squared)\n        y_hat = slope * x + intercept\n        ss_total = np.sum((values - np.mean(values)) ** 2)\n        ss_residual = np.sum((values - y_hat) ** 2)\n        r_squared = 1 - (ss_residual / ss_total) if ss_total > 0 else 0.0\n        \n        # Determine trend direction\n        trend_direction = \"up\" if slope > 0 else \"down\" if slope < 0 else \"none\"\n        \n        return {\n            \"has_trend\": abs(slope) > 0.01,\n            \"trend_direction\": trend_direction,\n            \"trend_strength\": r_squared,\n            \"slope\": slope,\n            \"intercept\": intercept,\n        }\n    \n    @staticmethod\n    def extrapolate(\n        data: TimeSeriesData, periods: int = 3, method: str = \"linear\"\n    ) -> TimeSeriesData:\n        \"\"\"\n        Extrapolate time series data into the future.\n        \n        Args:\n            data: The time series data\n            periods: The number of periods to extrapolate\n            method: The extrapolation method (\"linear\", \"mean\", \"last\")\n            \n        Returns:\n            New time series data with extrapolated values\n        \"\"\"\n        if not data.values or periods <= 0:\n            return data\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        dates = data.dates.copy()\n        \n        # Determine the date increment\n        if len(dates) >= 2:\n            if isinstance(dates[0], datetime):\n                # For datetime objects\n                date_diff = dates[1] - dates[0]\n            else:\n                # For date objects\n                date_diff = timedelta(days=(dates[1] - dates[0]).days)\n        else:\n            # Default to daily if we can't determine\n            date_diff = timedelta(days=1)\n        \n        # Extrapolate dates\n        last_date = dates[-1]\n        extrapolated_dates = []\n        \n        for i in range(1, periods + 1):\n            if isinstance(last_date, datetime):\n                next_date = last_date + date_diff * i\n            else:\n                # Convert to datetime for easier arithmetic, then back to date\n                next_date = (datetime.combine(last_date, datetime.min.time()) + date_diff * i).date()\n            \n            extrapolated_dates.append(next_date)\n        \n        # Extrapolate values based on the method\n        extrapolated_values = []\n        \n        if method == \"linear\" and len(values) >= 2:\n            # Simple linear extrapolation\n            trend_info = TimeSeriesAnalyzer.detect_trend(data)\n            slope = trend_info[\"slope\"]\n            intercept = trend_info[\"intercept\"]\n            \n            for i in range(1, periods + 1):\n                next_value = slope * (len(values) + i - 1) + intercept\n                extrapolated_values.append(next_value)\n        \n        elif method == \"mean\" and len(values) > 0:\n            # Use the mean of the last few values\n            window = min(len(values), 3)\n            mean_value = np.mean(values[-window:])\n            \n            for _ in range(periods):\n                extrapolated_values.append(mean_value)\n        \n        else:\n            # Default to using the last value\n            last_value = values[-1] if len(values) > 0 else 0.0\n            \n            for _ in range(periods):\n                extrapolated_values.append(last_value)\n        \n        # Create new time series data with original and extrapolated values\n        return TimeSeriesData(\n            dates=dates + extrapolated_dates,\n            values=values.tolist() + extrapolated_values,\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"extrapolation_method\": method,\n                \"extrapolation_periods\": periods,\n                \"original_length\": len(values),\n            },\n        )\n    \n    @staticmethod\n    def normalize(data: TimeSeriesData) -> TimeSeriesData:\n        \"\"\"\n        Normalize time series data to a 0-1 range.\n        \n        Args:\n            data: The time series data\n            \n        Returns:\n            New time series data with normalized values\n        \"\"\"\n        if not data.values:\n            return TimeSeriesData(dates=[], values=[])\n        \n        # Convert to numpy array for efficient calculation\n        values = np.array(data.values)\n        \n        # Calculate min and max\n        min_value = np.min(values)\n        max_value = np.max(values)\n        \n        # Normalize the values\n        if max_value > min_value:\n            normalized = (values - min_value) / (max_value - min_value)\n        else:\n            # If all values are the same, normalize to 0.5\n            normalized = np.full_like(values, 0.5)\n        \n        # Create new time series data with normalized values\n        return TimeSeriesData(\n            dates=data.dates,\n            values=normalized.tolist(),\n            labels=data.labels,\n            metadata={\n                **data.metadata,\n                \"normalization\": True,\n                \"original_min\": float(min_value),\n                \"original_max\": float(max_value),\n            },\n        )\n    \n    @staticmethod\n    def aggregate_by_period(\n        dates: List[Union[date, datetime]],\n        values: List[float],\n        granularity: TimeSeriesGranularity,\n        aggregation_fn: Callable[[List[float]], float] = lambda x: sum(x),\n    ) -> Tuple[List[Union[date, datetime]], List[float]]:\n        \"\"\"\n        Aggregate time series data by a specified granularity.\n        \n        Args:\n            dates: List of dates\n            values: List of values\n            granularity: The desired granularity\n            aggregation_fn: Function to aggregate values within a period\n            \n        Returns:\n            Tuple of (aggregated_dates, aggregated_values)\n        \"\"\"\n        if not dates or not values:\n            return [], []\n        \n        # Combine dates and values for sorting and grouping\n        data = list(zip(dates, values))\n        data.sort(key=lambda x: x[0])  # Sort by date\n        \n        # Group by the specified granularity\n        grouped_data = {}\n        \n        for dt, value in data:\n            # Convert to datetime if it's a date\n            if isinstance(dt, date) and not isinstance(dt, datetime):\n                dt = datetime.combine(dt, datetime.min.time())\n            \n            # Group based on granularity\n            if granularity == TimeSeriesGranularity.DAILY:\n                key = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n            elif granularity == TimeSeriesGranularity.WEEKLY:\n                # Get start of the week (Monday)\n                start_of_week = dt - timedelta(days=dt.weekday())\n                key = start_of_week.replace(hour=0, minute=0, second=0, microsecond=0)\n            elif granularity == TimeSeriesGranularity.MONTHLY:\n                key = dt.replace(day=1, hour=0, minute=0, second=0, microsecond=0)\n            elif granularity == TimeSeriesGranularity.QUARTERLY:\n                quarter = (dt.month - 1) // 3\n                key = dt.replace(month=quarter * 3 + 1, day=1, hour=0, minute=0, second=0, microsecond=0)\n            elif granularity == TimeSeriesGranularity.YEARLY:\n                key = dt.replace(month=1, day=1, hour=0, minute=0, second=0, microsecond=0)\n            else:\n                # Default to daily\n                key = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n            \n            # Add to the group\n            if key in grouped_data:\n                grouped_data[key].append(value)\n            else:\n                grouped_data[key] = [value]\n        \n        # Aggregate values within each group\n        aggregated_data = [\n            (key, aggregation_fn(values)) for key, values in grouped_data.items()\n        ]\n        \n        # Sort by date and separate dates and values\n        aggregated_data.sort(key=lambda x: x[0])\n        \n        # Convert datetime back to date if the input was dates\n        if all(isinstance(dt, date) and not isinstance(dt, datetime) for dt in dates):\n            aggregated_dates = [dt.date() for dt, _ in aggregated_data]\n        else:\n            aggregated_dates = [dt for dt, _ in aggregated_data]\n            \n        aggregated_values = [value for _, value in aggregated_data]\n        \n        return aggregated_dates, aggregated_values",
                "class TimeSeriesGranularity(str, Enum):\n    \"\"\"Granularity for time series data.\"\"\"\n    \n    DAILY = \"daily\"\n    WEEKLY = \"weekly\"\n    MONTHLY = \"monthly\"\n    QUARTERLY = \"quarterly\"\n    YEARLY = \"yearly\"",
                "class Invoice(BaseModel):\n    \"\"\"\n    Invoice model for tracking client billing.\n    \n    Used for revenue tracking, client relationship management, and tax reporting.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    client_id: str\n    project_id: Optional[str] = None\n    issue_date: Union[date, datetime]\n    due_date: Union[date, datetime]\n    amount: float\n    status: str  # e.g., \"draft\", \"sent\", \"paid\", \"overdue\"\n    payment_date: Optional[Union[date, datetime]] = None\n    description: Optional[str] = None\n    line_items: List[Dict[str, Any]] = Field(default_factory=list)\n    \n    @validator(\"due_date\")\n    def validate_due_date(cls, v, values):\n        \"\"\"Validate that due_date is after issue_date.\"\"\"\n        if \"issue_date\" in values:\n            if v < values[\"issue_date\"]:\n                raise ValueError(\"Due date must be after issue date\")\n        return v\n    \n    @validator(\"amount\")\n    def validate_amount(cls, v):\n        \"\"\"Validate that amount is a positive number.\"\"\"\n        if v < 0:\n            raise ValueError(\"Invoice amount must be a positive number\")\n        return v",
                "def get_first_day_of_month(dt: Union[date, datetime]) -> date:\n    \"\"\"\n    Get the first day of the month for a given date.\n    \n    Args:\n        dt: The input date\n        \n    Returns:\n        Date representing the first day of the month\n    \"\"\"\n    return date(dt.year, dt.month, 1)",
                "def get_last_day_of_month(dt: Union[date, datetime]) -> date:\n    \"\"\"\n    Get the last day of the month for a given date.\n    \n    Args:\n        dt: The input date\n        \n    Returns:\n        Date representing the last day of the month\n    \"\"\"\n    # Get the number of days in the month\n    days_in_month = calendar.monthrange(dt.year, dt.month)[1]\n    return date(dt.year, dt.month, days_in_month)",
                "def month_range(\n    start_date: Union[date, datetime],\n    end_date: Union[date, datetime],\n) -> Generator[date, None, None]:\n    \"\"\"\n    Generate a range of month start dates.\n    \n    Args:\n        start_date: The start date\n        end_date: The end date\n        \n    Yields:\n        First day of each month in the range\n    \"\"\"\n    # Convert to date if datetime\n    if isinstance(start_date, datetime):\n        start_date = start_date.date()\n    if isinstance(end_date, datetime):\n        end_date = end_date.date()\n    \n    # Start from the first day of the month\n    current_month = get_first_day_of_month(start_date)\n    \n    # Generate month start dates\n    while current_month <= end_date:\n        yield current_month\n        \n        # Move to the next month\n        if current_month.month == 12:\n            current_month = date(current_month.year + 1, 1, 1)\n        else:\n            current_month = date(current_month.year, current_month.month + 1, 1)",
                "class Timer:\n    \"\"\"Utility for measuring execution time.\"\"\"\n    \n    def __init__(self, name: Optional[str] = None):\n        \"\"\"\n        Initialize the timer.\n        \n        Args:\n            name: Optional name for the timer\n        \"\"\"\n        self.name = name\n        self.start_time: Optional[float] = None\n        self.end_time: Optional[float] = None\n    \n    def __enter__(self) -> 'Timer':\n        \"\"\"Start the timer when entering a context.\"\"\"\n        self.start()\n        return self\n    \n    def __exit__(self, *args: Any) -> None:\n        \"\"\"Stop the timer when exiting a context.\"\"\"\n        self.stop()\n    \n    def start(self) -> None:\n        \"\"\"Start the timer.\"\"\"\n        self.start_time = time.time()\n        self.end_time = None\n    \n    def stop(self) -> float:\n        \"\"\"\n        Stop the timer.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        self.end_time = time.time()\n        return self.elapsed_time\n    \n    @property\n    def elapsed_time(self) -> float:\n        \"\"\"\n        Get the elapsed time.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        end = self.end_time if self.end_time is not None else time.time()\n        return end - self.start_time\n    \n    @property\n    def elapsed_milliseconds(self) -> float:\n        \"\"\"\n        Get the elapsed time in milliseconds.\n        \n        Returns:\n            Elapsed time in milliseconds\n        \"\"\"\n        return self.elapsed_time * 1000",
                "class Transaction(BusinessTransaction):\n    \"\"\"\n    Transaction model for the Personal Finance Tracker.\n    \n    Extends the BusinessTransaction from the common library with\n    freelancer-specific fields and behaviors.\n    \"\"\"\n\n    # Override category field to use our specific ExpenseCategory enum\n    category: Optional[ExpenseCategory] = None\n    \n    # Make sure the account_id is required\n    account_id: str\n\n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        # This is necessary to allow field overrides\n        extra = \"allow\"",
                "class SmoothingConfig(BaseModel):\n    \"\"\"Configuration for income smoothing algorithms.\"\"\"\n\n    method: SmoothingMethod = SmoothingMethod.MOVING_AVERAGE\n    window_size: int = 3  # Number of months for moving average\n    alpha: float = 0.3  # For exponential smoothing\n    seasonal_periods: int = 12  # For seasonal adjustment\n    percentile: float = 25.0  # Percentile for percentile-based method\n    min_history_months: int = 3  # Minimum months of data required\n    target_monthly_income: Optional[float] = None  # Override calculated smoothed income\n    emergency_buffer_months: float = 2.0  # Buffer for lean months\n    confidence_interval: float = 0.8  # For prediction intervals\n    granularity: TimeSeriesGranularity = TimeSeriesGranularity.MONTHLY  # Time series granularity\n\n    @validator(\"window_size\")\n    def validate_window_size(cls, v):\n        \"\"\"Validate window size is positive.\"\"\"\n        if v <= 0:\n            raise ValueError(\"Window size must be positive\")\n        return v\n\n    @validator(\"alpha\")\n    def validate_alpha(cls, v):\n        \"\"\"Validate alpha is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Alpha must be between 0 and 1\")\n        return v\n\n    @validator(\"percentile\")\n    def validate_percentile(cls, v):\n        \"\"\"Validate percentile is between 0 and 100.\"\"\"\n        if v < 0 or v > 100:\n            raise ValueError(\"Percentile must be between 0 and 100\")\n        return v\n\n    @validator(\"emergency_buffer_months\")\n    def validate_buffer(cls, v):\n        \"\"\"Validate buffer is non-negative.\"\"\"\n        if v < 0:\n            raise ValueError(\"Emergency buffer months must be non-negative\")\n        return v\n\n    @validator(\"confidence_interval\")\n    def validate_confidence(cls, v):\n        \"\"\"Validate confidence interval is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Confidence interval must be between 0 and 1\")\n        return v",
                "class SmoothingConfig(BaseModel):\n    \"\"\"Configuration for income smoothing algorithms.\"\"\"\n\n    method: SmoothingMethod = SmoothingMethod.MOVING_AVERAGE\n    window_size: int = 3  # Number of months for moving average\n    alpha: float = 0.3  # For exponential smoothing\n    seasonal_periods: int = 12  # For seasonal adjustment\n    percentile: float = 25.0  # Percentile for percentile-based method\n    min_history_months: int = 3  # Minimum months of data required\n    target_monthly_income: Optional[float] = None  # Override calculated smoothed income\n    emergency_buffer_months: float = 2.0  # Buffer for lean months\n    confidence_interval: float = 0.8  # For prediction intervals\n    granularity: TimeSeriesGranularity = TimeSeriesGranularity.MONTHLY  # Time series granularity\n\n    @validator(\"window_size\")\n    def validate_window_size(cls, v):\n        \"\"\"Validate window size is positive.\"\"\"\n        if v <= 0:\n            raise ValueError(\"Window size must be positive\")\n        return v\n\n    @validator(\"alpha\")\n    def validate_alpha(cls, v):\n        \"\"\"Validate alpha is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Alpha must be between 0 and 1\")\n        return v\n\n    @validator(\"percentile\")\n    def validate_percentile(cls, v):\n        \"\"\"Validate percentile is between 0 and 100.\"\"\"\n        if v < 0 or v > 100:\n            raise ValueError(\"Percentile must be between 0 and 100\")\n        return v\n\n    @validator(\"emergency_buffer_months\")\n    def validate_buffer(cls, v):\n        \"\"\"Validate buffer is non-negative.\"\"\"\n        if v < 0:\n            raise ValueError(\"Emergency buffer months must be non-negative\")\n        return v\n\n    @validator(\"confidence_interval\")\n    def validate_confidence(cls, v):\n        \"\"\"Validate confidence interval is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Confidence interval must be between 0 and 1\")\n        return v",
                "class SmoothingConfig(BaseModel):\n    \"\"\"Configuration for income smoothing algorithms.\"\"\"\n\n    method: SmoothingMethod = SmoothingMethod.MOVING_AVERAGE\n    window_size: int = 3  # Number of months for moving average\n    alpha: float = 0.3  # For exponential smoothing\n    seasonal_periods: int = 12  # For seasonal adjustment\n    percentile: float = 25.0  # Percentile for percentile-based method\n    min_history_months: int = 3  # Minimum months of data required\n    target_monthly_income: Optional[float] = None  # Override calculated smoothed income\n    emergency_buffer_months: float = 2.0  # Buffer for lean months\n    confidence_interval: float = 0.8  # For prediction intervals\n    granularity: TimeSeriesGranularity = TimeSeriesGranularity.MONTHLY  # Time series granularity\n\n    @validator(\"window_size\")\n    def validate_window_size(cls, v):\n        \"\"\"Validate window size is positive.\"\"\"\n        if v <= 0:\n            raise ValueError(\"Window size must be positive\")\n        return v\n\n    @validator(\"alpha\")\n    def validate_alpha(cls, v):\n        \"\"\"Validate alpha is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Alpha must be between 0 and 1\")\n        return v\n\n    @validator(\"percentile\")\n    def validate_percentile(cls, v):\n        \"\"\"Validate percentile is between 0 and 100.\"\"\"\n        if v < 0 or v > 100:\n            raise ValueError(\"Percentile must be between 0 and 100\")\n        return v\n\n    @validator(\"emergency_buffer_months\")\n    def validate_buffer(cls, v):\n        \"\"\"Validate buffer is non-negative.\"\"\"\n        if v < 0:\n            raise ValueError(\"Emergency buffer months must be non-negative\")\n        return v\n\n    @validator(\"confidence_interval\")\n    def validate_confidence(cls, v):\n        \"\"\"Validate confidence interval is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Confidence interval must be between 0 and 1\")\n        return v",
                "class SmoothingConfig(BaseModel):\n    \"\"\"Configuration for income smoothing algorithms.\"\"\"\n\n    method: SmoothingMethod = SmoothingMethod.MOVING_AVERAGE\n    window_size: int = 3  # Number of months for moving average\n    alpha: float = 0.3  # For exponential smoothing\n    seasonal_periods: int = 12  # For seasonal adjustment\n    percentile: float = 25.0  # Percentile for percentile-based method\n    min_history_months: int = 3  # Minimum months of data required\n    target_monthly_income: Optional[float] = None  # Override calculated smoothed income\n    emergency_buffer_months: float = 2.0  # Buffer for lean months\n    confidence_interval: float = 0.8  # For prediction intervals\n    granularity: TimeSeriesGranularity = TimeSeriesGranularity.MONTHLY  # Time series granularity\n\n    @validator(\"window_size\")\n    def validate_window_size(cls, v):\n        \"\"\"Validate window size is positive.\"\"\"\n        if v <= 0:\n            raise ValueError(\"Window size must be positive\")\n        return v\n\n    @validator(\"alpha\")\n    def validate_alpha(cls, v):\n        \"\"\"Validate alpha is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Alpha must be between 0 and 1\")\n        return v\n\n    @validator(\"percentile\")\n    def validate_percentile(cls, v):\n        \"\"\"Validate percentile is between 0 and 100.\"\"\"\n        if v < 0 or v > 100:\n            raise ValueError(\"Percentile must be between 0 and 100\")\n        return v\n\n    @validator(\"emergency_buffer_months\")\n    def validate_buffer(cls, v):\n        \"\"\"Validate buffer is non-negative.\"\"\"\n        if v < 0:\n            raise ValueError(\"Emergency buffer months must be non-negative\")\n        return v\n\n    @validator(\"confidence_interval\")\n    def validate_confidence(cls, v):\n        \"\"\"Validate confidence interval is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Confidence interval must be between 0 and 1\")\n        return v",
                "class SmoothingConfig(BaseModel):\n    \"\"\"Configuration for income smoothing algorithms.\"\"\"\n\n    method: SmoothingMethod = SmoothingMethod.MOVING_AVERAGE\n    window_size: int = 3  # Number of months for moving average\n    alpha: float = 0.3  # For exponential smoothing\n    seasonal_periods: int = 12  # For seasonal adjustment\n    percentile: float = 25.0  # Percentile for percentile-based method\n    min_history_months: int = 3  # Minimum months of data required\n    target_monthly_income: Optional[float] = None  # Override calculated smoothed income\n    emergency_buffer_months: float = 2.0  # Buffer for lean months\n    confidence_interval: float = 0.8  # For prediction intervals\n    granularity: TimeSeriesGranularity = TimeSeriesGranularity.MONTHLY  # Time series granularity\n\n    @validator(\"window_size\")\n    def validate_window_size(cls, v):\n        \"\"\"Validate window size is positive.\"\"\"\n        if v <= 0:\n            raise ValueError(\"Window size must be positive\")\n        return v\n\n    @validator(\"alpha\")\n    def validate_alpha(cls, v):\n        \"\"\"Validate alpha is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Alpha must be between 0 and 1\")\n        return v\n\n    @validator(\"percentile\")\n    def validate_percentile(cls, v):\n        \"\"\"Validate percentile is between 0 and 100.\"\"\"\n        if v < 0 or v > 100:\n            raise ValueError(\"Percentile must be between 0 and 100\")\n        return v\n\n    @validator(\"emergency_buffer_months\")\n    def validate_buffer(cls, v):\n        \"\"\"Validate buffer is non-negative.\"\"\"\n        if v < 0:\n            raise ValueError(\"Emergency buffer months must be non-negative\")\n        return v\n\n    @validator(\"confidence_interval\")\n    def validate_confidence(cls, v):\n        \"\"\"Validate confidence interval is between 0 and 1.\"\"\"\n        if v < 0 or v > 1:\n            raise ValueError(\"Confidence interval must be between 0 and 1\")\n        return v",
                "class SmoothingMethod(str, Enum):\n    \"\"\"Income smoothing method enum.\"\"\"\n\n    MOVING_AVERAGE = \"moving_average\"\n    EXPONENTIAL_SMOOTHING = \"exponential_smoothing\"\n    SEASONAL_ADJUSTMENT = \"seasonal_adjustment\"\n    PERCENTILE_BASED = \"percentile_based\"\n    ROLLING_MEDIAN = \"rolling_median\"",
                "class SmoothingMethod(str, Enum):\n    \"\"\"Income smoothing method enum.\"\"\"\n\n    MOVING_AVERAGE = \"moving_average\"\n    EXPONENTIAL_SMOOTHING = \"exponential_smoothing\"\n    SEASONAL_ADJUSTMENT = \"seasonal_adjustment\"\n    PERCENTILE_BASED = \"percentile_based\"\n    ROLLING_MEDIAN = \"rolling_median\"",
                "class SmoothingMethod(str, Enum):\n    \"\"\"Income smoothing method enum.\"\"\"\n\n    MOVING_AVERAGE = \"moving_average\"\n    EXPONENTIAL_SMOOTHING = \"exponential_smoothing\"\n    SEASONAL_ADJUSTMENT = \"seasonal_adjustment\"\n    PERCENTILE_BASED = \"percentile_based\"\n    ROLLING_MEDIAN = \"rolling_median\"",
                "class SmoothingMethod(str, Enum):\n    \"\"\"Income smoothing method enum.\"\"\"\n\n    MOVING_AVERAGE = \"moving_average\"\n    EXPONENTIAL_SMOOTHING = \"exponential_smoothing\"\n    SEASONAL_ADJUSTMENT = \"seasonal_adjustment\"\n    PERCENTILE_BASED = \"percentile_based\"\n    ROLLING_MEDIAN = \"rolling_median\"",
                "class SmoothingMethod(str, Enum):\n    \"\"\"Income smoothing method enum.\"\"\"\n\n    MOVING_AVERAGE = \"moving_average\"\n    EXPONENTIAL_SMOOTHING = \"exponential_smoothing\"\n    SEASONAL_ADJUSTMENT = \"seasonal_adjustment\"\n    PERCENTILE_BASED = \"percentile_based\"\n    ROLLING_MEDIAN = \"rolling_median\"",
                "class SmoothedIncome(BaseModel):\n    \"\"\"Smoothed income calculation result.\"\"\"\n\n    period_start: datetime\n    period_end: datetime\n    actual_income: float\n    smoothed_income: float\n    method: SmoothingMethod\n    configuration: SmoothingConfig\n    income_deficit: float = 0.0  # Negative when actual < smoothed\n    income_surplus: float = 0.0  # Positive when actual > smoothed\n    notes: Optional[str] = None",
                "class SmoothedIncome(BaseModel):\n    \"\"\"Smoothed income calculation result.\"\"\"\n\n    period_start: datetime\n    period_end: datetime\n    actual_income: float\n    smoothed_income: float\n    method: SmoothingMethod\n    configuration: SmoothingConfig\n    income_deficit: float = 0.0  # Negative when actual < smoothed\n    income_surplus: float = 0.0  # Positive when actual > smoothed\n    notes: Optional[str] = None",
                "class SmoothedIncome(BaseModel):\n    \"\"\"Smoothed income calculation result.\"\"\"\n\n    period_start: datetime\n    period_end: datetime\n    actual_income: float\n    smoothed_income: float\n    method: SmoothingMethod\n    configuration: SmoothingConfig\n    income_deficit: float = 0.0  # Negative when actual < smoothed\n    income_surplus: float = 0.0  # Positive when actual > smoothed\n    notes: Optional[str] = None",
                "class SmoothedIncome(BaseModel):\n    \"\"\"Smoothed income calculation result.\"\"\"\n\n    period_start: datetime\n    period_end: datetime\n    actual_income: float\n    smoothed_income: float\n    method: SmoothingMethod\n    configuration: SmoothingConfig\n    income_deficit: float = 0.0  # Negative when actual < smoothed\n    income_surplus: float = 0.0  # Positive when actual > smoothed\n    notes: Optional[str] = None",
                "class SmoothedIncome(BaseModel):\n    \"\"\"Smoothed income calculation result.\"\"\"\n\n    period_start: datetime\n    period_end: datetime\n    actual_income: float\n    smoothed_income: float\n    method: SmoothingMethod\n    configuration: SmoothingConfig\n    income_deficit: float = 0.0  # Negative when actual < smoothed\n    income_surplus: float = 0.0  # Positive when actual > smoothed\n    notes: Optional[str] = None",
                "class RevenueForecast(BaseModel):\n    \"\"\"Revenue forecast model.\"\"\"\n\n    month: datetime\n    expected_income: float\n    lower_bound: float\n    upper_bound: float\n    confidence_interval: float\n    sources: Dict[str, float] = Field(default_factory=dict)  # Client/project breakdown\n    notes: Optional[str] = None",
                "class RevenueForecast(BaseModel):\n    \"\"\"Revenue forecast model.\"\"\"\n\n    month: datetime\n    expected_income: float\n    lower_bound: float\n    upper_bound: float\n    confidence_interval: float\n    sources: Dict[str, float] = Field(default_factory=dict)  # Client/project breakdown\n    notes: Optional[str] = None",
                "class RevenueForecast(BaseModel):\n    \"\"\"Revenue forecast model.\"\"\"\n\n    month: datetime\n    expected_income: float\n    lower_bound: float\n    upper_bound: float\n    confidence_interval: float\n    sources: Dict[str, float] = Field(default_factory=dict)  # Client/project breakdown\n    notes: Optional[str] = None",
                "class RevenueForecast(BaseModel):\n    \"\"\"Revenue forecast model.\"\"\"\n\n    month: datetime\n    expected_income: float\n    lower_bound: float\n    upper_bound: float\n    confidence_interval: float\n    sources: Dict[str, float] = Field(default_factory=dict)  # Client/project breakdown\n    notes: Optional[str] = None",
                "class RevenueForecast(BaseModel):\n    \"\"\"Revenue forecast model.\"\"\"\n\n    month: datetime\n    expected_income: float\n    lower_bound: float\n    upper_bound: float\n    confidence_interval: float\n    sources: Dict[str, float] = Field(default_factory=dict)  # Client/project breakdown\n    notes: Optional[str] = None"
            ]
        }
    },
    "unified/personal_finance_tracker/expense/__init__.py": {
        "logprobs": -261.55025721372,
        "metrics": {
            "loc": 5,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 4,
            "blank": 1,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/common/core/models/project.py": {
        "logprobs": -692.8480185194599,
        "metrics": {
            "loc": 148,
            "sloc": 96,
            "lloc": 144,
            "comments": 1,
            "multi": 17,
            "blank": 27,
            "cyclomatic": 38,
            "internal_imports": []
        }
    },
    "unified/personal_finance_tracker/models/__init__.py": {
        "logprobs": -199.827398541279,
        "metrics": {
            "loc": 1,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 0,
            "blank": 0,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/conftest.py": {
        "logprobs": -247.85248017783002,
        "metrics": {
            "loc": 4,
            "sloc": 1,
            "lloc": 2,
            "comments": 1,
            "multi": 0,
            "blank": 1,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/tests/freelancer/tax/__init__.py": {
        "logprobs": -189.02395534739603,
        "metrics": {
            "loc": 1,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 0,
            "blank": 0,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/tests/freelancer/income/__init__.py": {
        "logprobs": -185.68769836905,
        "metrics": {
            "loc": 1,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 0,
            "blank": 0,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/ethical_finance/values_budgeting/budgeting.py": {
        "logprobs": -5423.8132111846135,
        "metrics": {
            "loc": 1259,
            "sloc": 851,
            "lloc": 557,
            "comments": 142,
            "multi": 84,
            "blank": 189,
            "cyclomatic": 237,
            "internal_imports": [
                "class BaseAnalyzer(Generic[T, R], ABC):\n    \"\"\"\n    Abstract base class for analysis engines.\n    \n    Defines the core interface and functionality for all analyzers\n    across different persona implementations.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the analyzer.\"\"\"\n        self._analysis_cache: Dict[str, R] = {}\n    \n    @abstractmethod\n    def analyze(\n        self, subject: T, parameters: Optional[AnalysisParameters] = None\n    ) -> R:\n        \"\"\"\n        Analyze a single subject.\n        \n        Args:\n            subject: The subject to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Analysis result\n        \"\"\"\n        pass\n    \n    def analyze_batch(\n        self, subjects: List[T], parameters: Optional[AnalysisParameters] = None\n    ) -> List[R]:\n        \"\"\"\n        Analyze multiple subjects.\n        \n        Args:\n            subjects: List of subjects to analyze\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            List of analysis results\n        \"\"\"\n        # Start performance timer\n        start_time = time.time()\n        \n        # Analyze each subject\n        results = []\n        for subject in subjects:\n            result = self.analyze(subject, parameters)\n            results.append(result)\n        \n        # Performance metrics\n        elapsed_time = time.time() - start_time\n        \n        return results\n    \n    def clear_cache(self) -> None:\n        \"\"\"Clear the analysis cache.\"\"\"\n        self._analysis_cache = {}\n    \n    def _generate_cache_key(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> str:\n        \"\"\"\n        Generate a cache key for a subject and parameters.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cache key string\n        \"\"\"\n        # Start with the subject ID\n        key = f\"subject_{subject_id}\"\n        \n        # Add parameter details if provided\n        if parameters:\n            param_dict = parameters.dict(exclude_none=True)\n            for k, v in sorted(param_dict.items()):\n                if k != \"custom_settings\":\n                    key += f\"_{k}_{v}\"\n                    \n            # Handle custom settings separately (they could be complex)\n            if parameters.custom_settings:\n                for k, v in sorted(parameters.custom_settings.items()):\n                    key += f\"_{k}_{v}\"\n        \n        return key\n    \n    def _get_from_cache(\n        self, subject_id: Union[str, UUID], parameters: Optional[AnalysisParameters] = None\n    ) -> Optional[R]:\n        \"\"\"\n        Get a cached analysis result if available.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            parameters: Optional parameters to configure the analysis\n            \n        Returns:\n            Cached result or None if not found\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        return self._analysis_cache.get(cache_key)\n    \n    def _save_to_cache(\n        self, subject_id: Union[str, UUID], result: R, parameters: Optional[AnalysisParameters] = None\n    ) -> None:\n        \"\"\"\n        Save an analysis result to the cache.\n        \n        Args:\n            subject_id: ID of the subject being analyzed\n            result: The analysis result to cache\n            parameters: Optional parameters to configure the analysis\n        \"\"\"\n        cache_key = self._generate_cache_key(subject_id, parameters)\n        self._analysis_cache[cache_key] = result",
                "class AnalysisParameters(BaseModel):\n    \"\"\"\n    Parameters for an analysis operation.\n    \n    Used to configure analysis options and settings.\n    \"\"\"\n    \n    period_start: Optional[Union[date, datetime]] = None\n    period_end: Optional[Union[date, datetime]] = None\n    include_details: bool = True\n    calculation_mode: str = \"standard\"  # \"standard\", \"detailed\", \"fast\"\n    grouping: Optional[str] = None\n    custom_settings: Dict[str, Any] = Field(default_factory=dict)",
                "class AnalysisResult(BaseModel, Generic[T]):\n    \"\"\"\n    Result of an analysis operation.\n    \n    Provides information about the analysis process and outcome.\n    \"\"\"\n    \n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    subject_id: Optional[Union[str, UUID]] = None\n    subject_type: str\n    analysis_type: str\n    analysis_date: datetime = Field(default_factory=datetime.now)\n    processing_time_ms: Optional[float] = None\n    result_summary: Dict[str, Any] = Field(default_factory=dict)\n    detailed_results: Dict[str, Any] = Field(default_factory=dict)\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Timer:\n    \"\"\"Utility for measuring execution time.\"\"\"\n    \n    def __init__(self, name: Optional[str] = None):\n        \"\"\"\n        Initialize the timer.\n        \n        Args:\n            name: Optional name for the timer\n        \"\"\"\n        self.name = name\n        self.start_time: Optional[float] = None\n        self.end_time: Optional[float] = None\n    \n    def __enter__(self) -> 'Timer':\n        \"\"\"Start the timer when entering a context.\"\"\"\n        self.start()\n        return self\n    \n    def __exit__(self, *args: Any) -> None:\n        \"\"\"Stop the timer when exiting a context.\"\"\"\n        self.stop()\n    \n    def start(self) -> None:\n        \"\"\"Start the timer.\"\"\"\n        self.start_time = time.time()\n        self.end_time = None\n    \n    def stop(self) -> float:\n        \"\"\"\n        Stop the timer.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        self.end_time = time.time()\n        return self.elapsed_time\n    \n    @property\n    def elapsed_time(self) -> float:\n        \"\"\"\n        Get the elapsed time.\n        \n        Returns:\n            Elapsed time in seconds\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\"Timer has not been started\")\n        \n        end = self.end_time if self.end_time is not None else time.time()\n        return end - self.start_time\n    \n    @property\n    def elapsed_milliseconds(self) -> float:\n        \"\"\"\n        Get the elapsed time in milliseconds.\n        \n        Returns:\n            Elapsed time in milliseconds\n        \"\"\"\n        return self.elapsed_time * 1000",
                "def memoize(func: F = None, *, max_size: int = 1000, ttl_seconds: Optional[int] = None) -> F:\n    \"\"\"\n    Decorator to memoize a function's return value with optional max size and TTL.\n    \n    Can be used with or without arguments:\n    @memoize  # No arguments\n    def func():\n        ...\n        \n    @memoize(max_size=100, ttl_seconds=3600)  # With arguments\n    def func():\n        ...\n    \n    Args:\n        func: The function to memoize (when used without arguments)\n        max_size: Maximum number of items to store in cache (default: 1000)\n        ttl_seconds: Time-to-live in seconds (default: None, meaning no expiration)\n        \n    Returns:\n        Memoized function\n    \"\"\"\n    def decorator(f: F) -> F:\n        # Cache stores tuples of (result, timestamp) if TTL is specified, otherwise just result\n        cache: Dict[str, Union[Any, Tuple[Any, float]]] = {}\n        \n        @functools.wraps(f)\n        def wrapper(*args: Any, **kwargs: Any) -> Any:\n            # Create a cache key from the function arguments\n            key = _create_cache_key(f, args, kwargs)\n            \n            # Check if we need to enforce max size\n            if len(cache) >= max_size and key not in cache:\n                # Remove oldest item (simple implementation)\n                if ttl_seconds is not None:\n                    # If using TTL, find oldest by timestamp\n                    oldest_key = min(cache.items(), key=lambda x: x[1][1])[0]\n                else:\n                    # Otherwise just remove the first key\n                    oldest_key = next(iter(cache))\n                del cache[oldest_key]\n            \n            # Check if result is in cache\n            if key in cache:\n                if ttl_seconds is not None:\n                    # Check if expired when using TTL\n                    result, timestamp = cache[key]  # type: ignore\n                    if time.time() - timestamp < ttl_seconds:\n                        return result\n                    # If expired, remove from cache and recalculate\n                else:\n                    # No TTL, just return cached result\n                    return cache[key]\n            \n            # Call the function and cache the result\n            result = f(*args, **kwargs)\n            \n            if ttl_seconds is not None:\n                # Store with timestamp if using TTL\n                cache[key] = (result, time.time())\n            else:\n                # Store just the result otherwise\n                cache[key] = result\n            \n            return result\n        \n        # Add cache management functions\n        wrapper.cache = cache  # type: ignore\n        wrapper.cache_clear = cache.clear  # type: ignore\n        wrapper.cache_size = lambda: len(cache)  # type: ignore\n        \n        return cast(F, wrapper)\n    \n    # Handle both @memoize and @memoize(args) syntax\n    if func is None:\n        return decorator\n    return decorator(func)",
                "def validate_date_range(\n    start: Union[date, datetime], end: Union[date, datetime]\n) -> Tuple[Union[date, datetime], Union[date, datetime]]:\n    \"\"\"\n    Validate that a date range is valid (start <= end).\n    \n    Args:\n        start: Start date\n        end: End date\n        \n    Returns:\n        Tuple of (start, end) if valid\n        \n    Raises:\n        ValueError: If the start date is after the end date\n    \"\"\"\n    if start > end:\n        raise ValueError(\"Start date cannot be after end date\")\n    return start, end",
                "class Transaction(BaseTransaction):\n    \"\"\"Model representing a personal financial transaction.\"\"\"\n    \n    # These fields come from BaseTransaction:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # date: Union[date, datetime]\n    # amount: float\n    # description: str\n    # transaction_type: Optional[str] = None\n    # tags: List[str] = Field(default_factory=list)\n    \n    # Add ethical-specific fields\n    vendor: str\n    category: str\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Transaction(BaseTransaction):\n    \"\"\"Model representing a personal financial transaction.\"\"\"\n    \n    # These fields come from BaseTransaction:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # date: Union[date, datetime]\n    # amount: float\n    # description: str\n    # transaction_type: Optional[str] = None\n    # tags: List[str] = Field(default_factory=list)\n    \n    # Add ethical-specific fields\n    vendor: str\n    category: str\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Transaction(BaseTransaction):\n    \"\"\"Model representing a personal financial transaction.\"\"\"\n    \n    # These fields come from BaseTransaction:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # date: Union[date, datetime]\n    # amount: float\n    # description: str\n    # transaction_type: Optional[str] = None\n    # tags: List[str] = Field(default_factory=list)\n    \n    # Add ethical-specific fields\n    vendor: str\n    category: str\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Transaction(BaseTransaction):\n    \"\"\"Model representing a personal financial transaction.\"\"\"\n    \n    # These fields come from BaseTransaction:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # date: Union[date, datetime]\n    # amount: float\n    # description: str\n    # transaction_type: Optional[str] = None\n    # tags: List[str] = Field(default_factory=list)\n    \n    # Add ethical-specific fields\n    vendor: str\n    category: str\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Transaction(BaseTransaction):\n    \"\"\"Model representing a personal financial transaction.\"\"\"\n    \n    # These fields come from BaseTransaction:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # date: Union[date, datetime]\n    # amount: float\n    # description: str\n    # transaction_type: Optional[str] = None\n    # tags: List[str] = Field(default_factory=list)\n    \n    # Add ethical-specific fields\n    vendor: str\n    category: str\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True",
                "class Transaction(BaseTransaction):\n    \"\"\"Model representing a personal financial transaction.\"\"\"\n    \n    # These fields come from BaseTransaction:\n    # id: Union[str, UUID] = Field(default_factory=uuid4)\n    # date: Union[date, datetime]\n    # amount: float\n    # description: str\n    # transaction_type: Optional[str] = None\n    # tags: List[str] = Field(default_factory=list)\n    \n    # Add ethical-specific fields\n    vendor: str\n    category: str\n    \n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        arbitrary_types_allowed = True"
            ]
        }
    },
    "unified/common/core/models/tax.py": {
        "logprobs": -636.9901550804757,
        "metrics": {
            "loc": 150,
            "sloc": 95,
            "lloc": 142,
            "comments": 3,
            "multi": 16,
            "blank": 28,
            "cyclomatic": 44,
            "internal_imports": []
        }
    },
    "unified/ethical_finance/__init__.py": {
        "logprobs": -214.787088875916,
        "metrics": {
            "loc": 3,
            "sloc": 1,
            "lloc": 2,
            "comments": 0,
            "multi": 0,
            "blank": 1,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/common/core/models/investment.py": {
        "logprobs": -1338.9743488091865,
        "metrics": {
            "loc": 251,
            "sloc": 153,
            "lloc": 209,
            "comments": 13,
            "multi": 24,
            "blank": 53,
            "cyclomatic": 55,
            "internal_imports": []
        }
    },
    "unified/common/core/models/project_metrics.py": {
        "logprobs": -639.94523117424,
        "metrics": {
            "loc": 112,
            "sloc": 77,
            "lloc": 124,
            "comments": 6,
            "multi": 0,
            "blank": 26,
            "cyclomatic": 22,
            "internal_imports": []
        }
    },
    "unified/tests/socially_responsible_investor/test_impact_measurement/__init__.py": {
        "logprobs": -183.86320114615998,
        "metrics": {
            "loc": 1,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 0,
            "blank": 0,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/tests/socially_responsible_investor/conftest.py": {
        "logprobs": -1881.462511947117,
        "metrics": {
            "loc": 385,
            "sloc": 366,
            "lloc": 53,
            "comments": 12,
            "multi": 0,
            "blank": 11,
            "cyclomatic": 9,
            "internal_imports": []
        }
    },
    "unified/tests/socially_responsible_investor/__init__.py": {
        "logprobs": -178.24490213593003,
        "metrics": {
            "loc": 1,
            "sloc": 0,
            "lloc": 1,
            "comments": 0,
            "multi": 0,
            "blank": 0,
            "cyclomatic": 0,
            "internal_imports": []
        }
    },
    "unified/personal_finance_tracker/tax/models.py": {
        "logprobs": -962.2332272220324,
        "metrics": {
            "loc": 164,
            "sloc": 109,
            "lloc": 157,
            "comments": 11,
            "multi": 11,
            "blank": 32,
            "cyclomatic": 31,
            "internal_imports": [
                "class TaxLiability(BaseModel):\n    \"\"\"\n    Tax liability model for tracking calculated tax obligations.\n    \n    Used for tax planning, compliance, and financial projections.\n    \"\"\"\n\n    id: Union[str, UUID] = Field(default_factory=uuid4)\n    tax_year: int\n    jurisdiction: str = \"federal\"\n    income: float\n    deductions: float\n    taxable_income: float\n    tax_amount: float\n    payments_made: float = 0.0\n    remaining_balance: float\n    calculation_date: Union[date, datetime] = Field(default_factory=datetime.now)\n    \n    @validator(\"income\", \"tax_amount\", \"payments_made\")\n    def validate_positive_numbers(cls, v):\n        \"\"\"Validate that financial amounts are positive numbers.\"\"\"\n        if v < 0:\n            raise ValueError(\"Value must be a positive number\")\n        return v\n    \n    @validator(\"tax_year\")\n    def validate_tax_year(cls, v):\n        \"\"\"Validate that tax year is reasonable.\"\"\"\n        current_year = datetime.now().year\n        if v < 1900 or v > current_year + 1:\n            raise ValueError(f\"Tax year {v} is outside reasonable range\")\n        return v\n    \n    @validator(\"remaining_balance\", always=True)\n    def calculate_remaining_balance(cls, v, values):\n        \"\"\"Calculate remaining balance if not provided.\"\"\"\n        if \"tax_amount\" in values and \"payments_made\" in values:\n            return values[\"tax_amount\"] - values[\"payments_made\"]\n        return v",
                "class TaxRate(CommonTaxRate):\n    \"\"\"\n    Tax rate model for Personal Finance Tracker.\n    \n    Extends the TaxRate model from the common library.\n    \"\"\"\n    pass",
                "class TaxPayment(CommonTaxPayment):\n    \"\"\"\n    Tax payment model for Personal Finance Tracker.\n    \n    Extends the TaxPayment model from the common library.\n    \"\"\"\n    quarter: int",
                "class TaxDeduction(CommonTaxDeduction):\n    \"\"\"\n    Tax deduction model for Personal Finance Tracker.\n    \n    Extends the TaxDeduction model from the common library.\n    \"\"\"\n    pass"
            ]
        }
    },
    "total_loc": 17202,
    "total_sloc": 10335,
    "total_lloc": 7443,
    "total_comments": 1620,
    "total_multi": 2245,
    "total_blank": 2975,
    "total_cyclomatic": 2512,
    "total_internal_imports": 494
}