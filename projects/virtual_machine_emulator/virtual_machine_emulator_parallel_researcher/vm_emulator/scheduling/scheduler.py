"""Scheduler implementations for the VM."""

import random
from abc import ABC, abstractmethod
from enum import Enum, auto
from typing import Dict, List, Optional, Set, Tuple, Any, Union

from vm_emulator.core.processor import ProcessorState
from vm_emulator.threading.thread import Thread, ThreadPriority


class SchedulingPolicy(Enum):
    """Available scheduling policies."""
    ROUND_ROBIN = auto()
    PRIORITY = auto()
    SHORTEST_JOB_FIRST = auto()
    SHORTEST_REMAINING_TIME = auto()
    MULTILEVEL_FEEDBACK_QUEUE = auto()
    AFFINITY = auto()
    FAIR_SHARE = auto()
    CUSTOM = auto()


class Scheduler(ABC):
    """Base class for scheduler implementations."""
    
    def __init__(self, num_processors: int, time_slice: int = 10, random_seed: Optional[int] = None):
        """
        Initialize the scheduler.
        
        Args:
            num_processors: Number of available processor cores
            time_slice: Default time slice for preemptive scheduling
            random_seed: Seed for deterministic scheduling
        """
        self.num_processors = num_processors
        self.time_slice = time_slice
        self.random_seed = random_seed
        
        if random_seed is not None:
            random.seed(random_seed)
        
        # Scheduling statistics
        self.schedule_calls = 0
        self.context_switches = 0
        self.preemptions = 0
        
        # Thread time tracking
        self.thread_run_times: Dict[str, int] = {}  # thread_id -> cycles
        self.thread_wait_times: Dict[str, int] = {}  # thread_id -> cycles
        
        # For tracking thread-to-processor mappings
        self.processor_assignments: Dict[int, Optional[str]] = {i: None for i in range(num_processors)}
        self.thread_to_processor: Dict[str, Optional[int]] = {}
        
        # Time slice tracking for preemptive scheduling
        self.time_slice_remaining: Dict[str, int] = {}
        
        # Scheduling trace
        self.scheduling_trace: List[Dict[str, Any]] = []
    
    @abstractmethod
    def select_thread(
        self, available_threads: List[Thread], processor_id: int, timestamp: int
    ) -> Optional[Thread]:
        """
        Select the next thread to run on a processor.
        
        Args:
            available_threads: List of available threads
            processor_id: ID of the processor
            timestamp: Current global clock value
            
        Returns:
            Selected thread, or None if no thread should run
        """
        pass
    
    def should_preempt(
        self, running_thread: Thread, available_threads: List[Thread], timestamp: int
    ) -> bool:
        """
        Determine if a running thread should be preempted.
        
        Args:
            running_thread: Currently running thread
            available_threads: List of available threads
            timestamp: Current global clock value
            
        Returns:
            True if the thread should be preempted
        """
        if running_thread.thread_id not in self.time_slice_remaining:
            self.time_slice_remaining[running_thread.thread_id] = self.time_slice
        
        # Decrement time slice
        self.time_slice_remaining[running_thread.thread_id] -= 1
        
        # Preempt if time slice expired
        if self.time_slice_remaining[running_thread.thread_id] <= 0:
            # Reset time slice for next run
            self.time_slice_remaining[running_thread.thread_id] = self.time_slice
            return True
        
        return False
    
    def schedule(
        self,
        threads: Dict[str, Thread],
        ready_queue: List[str],
        processors: List[Any],
        timestamp: int,
    ) -> Tuple[Dict[int, Optional[str]], List[str]]:
        """
        Schedule threads onto processors.
        
        Args:
            threads: Dictionary of all threads
            ready_queue: List of ready thread IDs
            processors: List of processors
            timestamp: Current global clock value
            
        Returns:
            Tuple of (processor_assignments, new_ready_queue)
        """
        self.schedule_calls += 1
        
        # Check each processor
        for i, processor in enumerate(processors):
            # Skip if processor is busy and shouldn't be preempted
            if processor.is_busy():
                current_thread_id = processor.current_thread_id
                current_thread = threads[current_thread_id]
                
                # Update running time for this thread
                if current_thread_id not in self.thread_run_times:
                    self.thread_run_times[current_thread_id] = 0
                self.thread_run_times[current_thread_id] += 1
                
                # Check if the thread should be preempted
                available_threads = [threads[tid] for tid in ready_queue]
                if self.should_preempt(current_thread, available_threads, timestamp):
                    # Preempt the thread
                    processor.state = ProcessorState.WAITING
                    current_thread.state = ProcessorState.WAITING
                    
                    # Add back to ready queue
                    ready_queue.append(current_thread_id)
                    
                    # Update assignments
                    self.processor_assignments[i] = None
                    self.thread_to_processor[current_thread_id] = None
                    
                    # Record statistics
                    self.preemptions += 1
                    
                    # Record in scheduling trace
                    self.scheduling_trace.append({
                        "timestamp": timestamp,
                        "event": "thread_preempted",
                        "thread_id": current_thread_id,
                        "processor_id": i,
                        "run_time": self.thread_run_times.get(current_thread_id, 0),
                    })
                else:
                    # Thread continues running
                    continue
            
            # Processor is available, select a thread
            if ready_queue:
                # Convert thread IDs to Thread objects
                available_threads = [threads[tid] for tid in ready_queue]
                selected_thread = self.select_thread(available_threads, i, timestamp)
                
                if selected_thread:
                    # Assign the thread to the processor
                    thread_id = selected_thread.thread_id
                    
                    # Remove from ready queue
                    ready_queue.remove(thread_id)
                    
                    # Update thread state
                    selected_thread.state = ProcessorState.RUNNING
                    selected_thread.processor_id = i
                    
                    # Update processor state
                    processor.state = ProcessorState.RUNNING
                    processor.current_thread_id = thread_id
                    
                    # Update assignments
                    self.processor_assignments[i] = thread_id
                    self.thread_to_processor[thread_id] = i
                    
                    # Initialize time slice
                    self.time_slice_remaining[thread_id] = self.time_slice
                    
                    # Record context switch
                    self.context_switches += 1
                    
                    # Record in scheduling trace
                    self.scheduling_trace.append({
                        "timestamp": timestamp,
                        "event": "thread_scheduled",
                        "thread_id": thread_id,
                        "processor_id": i,
                        "priority": selected_thread.priority.name,
                    })
        
        # Update wait times for threads in the ready queue
        for thread_id in ready_queue:
            if thread_id not in self.thread_wait_times:
                self.thread_wait_times[thread_id] = 0
            self.thread_wait_times[thread_id] += 1
        
        return self.processor_assignments, ready_queue
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        Get scheduler statistics.
        
        Returns:
            Dictionary of statistics
        """
        # Calculate average wait time
        avg_wait_time = 0
        if self.thread_wait_times:
            total_wait_time = sum(self.thread_wait_times.values())
            avg_wait_time = total_wait_time / len(self.thread_wait_times)
        
        # Calculate average run time
        avg_run_time = 0
        if self.thread_run_times:
            total_run_time = sum(self.thread_run_times.values())
            avg_run_time = total_run_time / len(self.thread_run_times)
        
        return {
            "policy": self.__class__.__name__,
            "time_slice": self.time_slice,
            "schedule_calls": self.schedule_calls,
            "context_switches": self.context_switches,
            "preemptions": self.preemptions,
            "avg_wait_time": avg_wait_time,
            "avg_run_time": avg_run_time,
            "num_processors": self.num_processors,
        }
    
    def get_thread_statistics(self, thread_id: str) -> Dict[str, Any]:
        """
        Get statistics for a specific thread.
        
        Args:
            thread_id: ID of the thread
            
        Returns:
            Dictionary of thread statistics
        """
        return {
            "thread_id": thread_id,
            "run_time": self.thread_run_times.get(thread_id, 0),
            "wait_time": self.thread_wait_times.get(thread_id, 0),
            "processor_assignment": self.thread_to_processor.get(thread_id),
            "time_slice_remaining": self.time_slice_remaining.get(thread_id, 0),
        }
    
    def get_scheduling_trace(
        self,
        thread_id: Optional[str] = None,
        processor_id: Optional[int] = None,
        event_type: Optional[str] = None,
        start_time: Optional[int] = None,
        end_time: Optional[int] = None,
    ) -> List[Dict[str, Any]]:
        """
        Get filtered scheduling trace.
        
        Args:
            thread_id: Filter by thread ID
            processor_id: Filter by processor ID
            event_type: Filter by event type
            start_time: Filter by start timestamp
            end_time: Filter by end timestamp
            
        Returns:
            Filtered scheduling trace
        """
        result = self.scheduling_trace
        
        if thread_id is not None:
            result = [e for e in result if e.get("thread_id") == thread_id]
        
        if processor_id is not None:
            result = [e for e in result if e.get("processor_id") == processor_id]
        
        if event_type is not None:
            result = [e for e in result if e.get("event") == event_type]
        
        if start_time is not None:
            result = [e for e in result if e.get("timestamp", 0) >= start_time]
        
        if end_time is not None:
            result = [e for e in result if e.get("timestamp", 0) <= end_time]
        
        return result
    
    def analyze_processor_utilization(self) -> Dict[int, float]:
        """
        Analyze processor utilization.
        
        Returns:
            Dictionary of processor_id -> utilization percentage
        """
        # Count scheduling events per processor
        scheduled_events = {}
        for event in self.scheduling_trace:
            if event["event"] == "thread_scheduled":
                processor_id = event["processor_id"]
                scheduled_events[processor_id] = scheduled_events.get(processor_id, 0) + 1
        
        # Calculate utilization based on scheduling calls
        utilization = {}
        for i in range(self.num_processors):
            events = scheduled_events.get(i, 0)
            utilization[i] = (events / self.schedule_calls) * 100 if self.schedule_calls > 0 else 0
        
        return utilization


class RoundRobinScheduler(Scheduler):
    """Round-robin scheduler implementation."""
    
    def select_thread(
        self, available_threads: List[Thread], processor_id: int, timestamp: int
    ) -> Optional[Thread]:
        """
        Select the next thread using round-robin policy.
        
        Args:
            available_threads: List of available threads
            processor_id: ID of the processor
            timestamp: Current global clock value
            
        Returns:
            Selected thread, or None if no thread available
        """
        if not available_threads:
            return None
        
        # Simple round-robin just takes the first available thread
        return available_threads[0]


class PriorityScheduler(Scheduler):
    """Priority-based scheduler implementation."""
    
    def __init__(
        self,
        num_processors: int,
        time_slice: int = 10,
        random_seed: Optional[int] = None,
        preemptive: bool = True,
    ):
        """
        Initialize the priority scheduler.
        
        Args:
            num_processors: Number of available processor cores
            time_slice: Default time slice for preemptive scheduling
            random_seed: Seed for deterministic scheduling
            preemptive: Whether to use preemptive scheduling
        """
        super().__init__(num_processors, time_slice, random_seed)
        self.preemptive = preemptive
    
    def select_thread(
        self, available_threads: List[Thread], processor_id: int, timestamp: int
    ) -> Optional[Thread]:
        """
        Select the next thread using priority policy.
        
        Args:
            available_threads: List of available threads
            processor_id: ID of the processor
            timestamp: Current global clock value
            
        Returns:
            Selected thread, or None if no thread available
        """
        if not available_threads:
            return None
        
        # Sort by priority (higher values = higher priority)
        sorted_threads = sorted(
            available_threads,
            key=lambda t: t.priority.value,
            reverse=True,
        )
        
        # Take the highest priority thread
        return sorted_threads[0]
    
    def should_preempt(
        self, running_thread: Thread, available_threads: List[Thread], timestamp: int
    ) -> bool:
        """
        Determine if a running thread should be preempted.
        
        Args:
            running_thread: Currently running thread
            available_threads: List of available threads
            timestamp: Current global clock value
            
        Returns:
            True if the thread should be preempted
        """
        # Check time slice first
        time_slice_expired = super().should_preempt(running_thread, available_threads, timestamp)
        
        if self.preemptive:
            # Check if there's a higher priority thread waiting
            for thread in available_threads:
                if thread.priority.value > running_thread.priority.value:
                    return True
        
        return time_slice_expired


class ShortestJobFirstScheduler(Scheduler):
    """Shortest job first scheduler implementation."""
    
    def __init__(
        self,
        num_processors: int,
        time_slice: int = 10,
        random_seed: Optional[int] = None,
        estimated_run_times: Optional[Dict[str, int]] = None,
    ):
        """
        Initialize the shortest job first scheduler.
        
        Args:
            num_processors: Number of available processor cores
            time_slice: Default time slice for preemptive scheduling
            random_seed: Seed for deterministic scheduling
            estimated_run_times: Dictionary of thread_id -> estimated run time
        """
        super().__init__(num_processors, time_slice, random_seed)
        self.estimated_run_times = estimated_run_times or {}
    
    def select_thread(
        self, available_threads: List[Thread], processor_id: int, timestamp: int
    ) -> Optional[Thread]:
        """
        Select the next thread using shortest job first policy.
        
        Args:
            available_threads: List of available threads
            processor_id: ID of the processor
            timestamp: Current global clock value
            
        Returns:
            Selected thread, or None if no thread available
        """
        if not available_threads:
            return None
        
        # Sort by estimated run time
        sorted_threads = sorted(
            available_threads,
            key=lambda t: self.estimated_run_times.get(t.thread_id, float('inf')),
        )
        
        # Take the shortest job
        return sorted_threads[0]
    
    def update_estimated_run_time(self, thread_id: str, estimated_time: int) -> None:
        """
        Update the estimated run time for a thread.
        
        Args:
            thread_id: ID of the thread
            estimated_time: Estimated run time
        """
        self.estimated_run_times[thread_id] = estimated_time


class ShortestRemainingTimeScheduler(Scheduler):
    """Shortest remaining time first scheduler implementation."""
    
    def __init__(
        self,
        num_processors: int,
        time_slice: int = 10,
        random_seed: Optional[int] = None,
        estimated_run_times: Optional[Dict[str, int]] = None,
    ):
        """
        Initialize the shortest remaining time scheduler.
        
        Args:
            num_processors: Number of available processor cores
            time_slice: Default time slice for preemptive scheduling
            random_seed: Seed for deterministic scheduling
            estimated_run_times: Dictionary of thread_id -> estimated run time
        """
        super().__init__(num_processors, time_slice, random_seed)
        self.estimated_run_times = estimated_run_times or {}
        self.executed_time = {}  # thread_id -> executed time
    
    def select_thread(
        self, available_threads: List[Thread], processor_id: int, timestamp: int
    ) -> Optional[Thread]:
        """
        Select the next thread using shortest remaining time policy.
        
        Args:
            available_threads: List of available threads
            processor_id: ID of the processor
            timestamp: Current global clock value
            
        Returns:
            Selected thread, or None if no thread available
        """
        if not available_threads:
            return None
        
        # Sort by remaining time
        sorted_threads = sorted(
            available_threads,
            key=lambda t: (
                self.estimated_run_times.get(t.thread_id, float('inf')) -
                self.executed_time.get(t.thread_id, 0)
            ),
        )
        
        # Take the thread with shortest remaining time
        return sorted_threads[0]
    
    def should_preempt(
        self, running_thread: Thread, available_threads: List[Thread], timestamp: int
    ) -> bool:
        """
        Determine if a running thread should be preempted.
        
        Args:
            running_thread: Currently running thread
            available_threads: List of available threads
            timestamp: Current global clock value
            
        Returns:
            True if the thread should be preempted
        """
        # Update executed time for the running thread
        if running_thread.thread_id not in self.executed_time:
            self.executed_time[running_thread.thread_id] = 0
        self.executed_time[running_thread.thread_id] += 1
        
        # Calculate remaining time for the running thread
        estimated_time = self.estimated_run_times.get(running_thread.thread_id, float('inf'))
        executed_time = self.executed_time.get(running_thread.thread_id, 0)
        remaining_time = estimated_time - executed_time
        
        # Check if there's a thread with shorter remaining time
        for thread in available_threads:
            thread_estimated_time = self.estimated_run_times.get(thread.thread_id, float('inf'))
            thread_executed_time = self.executed_time.get(thread.thread_id, 0)
            thread_remaining_time = thread_estimated_time - thread_executed_time
            
            if thread_remaining_time < remaining_time:
                return True
        
        # Check time slice as a fallback
        return super().should_preempt(running_thread, available_threads, timestamp)
    
    def update_estimated_run_time(self, thread_id: str, estimated_time: int) -> None:
        """
        Update the estimated run time for a thread.
        
        Args:
            thread_id: ID of the thread
            estimated_time: Estimated run time
        """
        self.estimated_run_times[thread_id] = estimated_time


class MultiLevelFeedbackQueueScheduler(Scheduler):
    """Multi-level feedback queue scheduler implementation."""
    
    def __init__(
        self,
        num_processors: int,
        time_slice: int = 10,
        random_seed: Optional[int] = None,
        num_queues: int = 3,
        queue_time_slices: Optional[List[int]] = None,
    ):
        """
        Initialize the multi-level feedback queue scheduler.
        
        Args:
            num_processors: Number of available processor cores
            time_slice: Default time slice for preemptive scheduling
            random_seed: Seed for deterministic scheduling
            num_queues: Number of priority queues
            queue_time_slices: Time slice for each queue
        """
        super().__init__(num_processors, time_slice, random_seed)
        self.num_queues = num_queues
        
        # Set up time slices for each queue (typically increasing)
        if queue_time_slices:
            self.queue_time_slices = queue_time_slices
        else:
            # Default: exponentially increasing time slices
            self.queue_time_slices = [time_slice * (2 ** i) for i in range(num_queues)]
        
        # Thread queue assignments (higher index = lower priority)
        self.thread_queue: Dict[str, int] = {}
    
    def select_thread(
        self, available_threads: List[Thread], processor_id: int, timestamp: int
    ) -> Optional[Thread]:
        """
        Select the next thread using multi-level feedback queue policy.
        
        Args:
            available_threads: List of available threads
            processor_id: ID of the processor
            timestamp: Current global clock value
            
        Returns:
            Selected thread, or None if no thread available
        """
        if not available_threads:
            return None
        
        # Assign any new threads to the highest priority queue
        for thread in available_threads:
            if thread.thread_id not in self.thread_queue:
                self.thread_queue[thread.thread_id] = 0
        
        # Go through the queues from highest to lowest priority
        for queue_idx in range(self.num_queues):
            # Find threads in this queue
            queue_threads = [
                t for t in available_threads
                if self.thread_queue.get(t.thread_id, 0) == queue_idx
            ]
            
            if queue_threads:
                # If there are threads in this queue, take the first one
                return queue_threads[0]
        
        # If we get here, all threads are in queues beyond our limit
        # Just take the first available thread
        return available_threads[0]
    
    def should_preempt(
        self, running_thread: Thread, available_threads: List[Thread], timestamp: int
    ) -> bool:
        """
        Determine if a running thread should be preempted.
        
        Args:
            running_thread: Currently running thread
            available_threads: List of available threads
            timestamp: Current global clock value
            
        Returns:
            True if the thread should be preempted
        """
        # Get the queue for this thread
        queue_idx = self.thread_queue.get(running_thread.thread_id, 0)
        
        # Get time slice for this queue
        if queue_idx < len(self.queue_time_slices):
            time_slice = self.queue_time_slices[queue_idx]
        else:
            time_slice = self.queue_time_slices[-1]
        
        # Initialize time slice remaining if needed
        if running_thread.thread_id not in self.time_slice_remaining:
            self.time_slice_remaining[running_thread.thread_id] = time_slice
        
        # Decrement time slice
        self.time_slice_remaining[running_thread.thread_id] -= 1
        
        # Check if time slice expired
        if self.time_slice_remaining[running_thread.thread_id] <= 0:
            # Move the thread to the next lower priority queue
            if queue_idx < self.num_queues - 1:
                self.thread_queue[running_thread.thread_id] = queue_idx + 1
            
            # Reset time slice for next run
            next_queue = self.thread_queue[running_thread.thread_id]
            next_time_slice = self.queue_time_slices[min(next_queue, len(self.queue_time_slices) - 1)]
            self.time_slice_remaining[running_thread.thread_id] = next_time_slice
            
            return True
        
        # Check if there's a thread in a higher priority queue
        thread_queue = self.thread_queue.get(running_thread.thread_id, 0)
        for thread in available_threads:
            queue = self.thread_queue.get(thread.thread_id, 0)
            if queue < thread_queue:
                return True
        
        return False
    
    def boost_priority(self, thread_id: str) -> None:
        """
        Boost the priority of a thread.
        
        Args:
            thread_id: ID of the thread
        """
        if thread_id in self.thread_queue:
            # Move to a higher priority queue
            self.thread_queue[thread_id] = max(0, self.thread_queue[thread_id] - 1)


class AffinityScheduler(Scheduler):
    """Processor affinity scheduler implementation."""
    
    def __init__(
        self,
        num_processors: int,
        time_slice: int = 10,
        random_seed: Optional[int] = None,
        default_affinity: Optional[Set[int]] = None,
    ):
        """
        Initialize the affinity scheduler.
        
        Args:
            num_processors: Number of available processor cores
            time_slice: Default time slice for preemptive scheduling
            random_seed: Seed for deterministic scheduling
            default_affinity: Default processor affinity for new threads
        """
        super().__init__(num_processors, time_slice, random_seed)
        self.default_affinity = default_affinity or set(range(num_processors))
        
        # Thread-processor affinity
        self.affinities: Dict[str, Set[int]] = {}
    
    def select_thread(
        self, available_threads: List[Thread], processor_id: int, timestamp: int
    ) -> Optional[Thread]:
        """
        Select the next thread using affinity policy.
        
        Args:
            available_threads: List of available threads
            processor_id: ID of the processor
            timestamp: Current global clock value
            
        Returns:
            Selected thread, or None if no thread available
        """
        if not available_threads:
            return None
        
        # Set default affinity for new threads
        for thread in available_threads:
            if thread.thread_id not in self.affinities:
                self.affinities[thread.thread_id] = self.default_affinity.copy()
        
        # Find threads that have affinity for this processor
        affinity_threads = [
            t for t in available_threads
            if processor_id in self.affinities.get(t.thread_id, set())
        ]
        
        if not affinity_threads:
            # No thread has affinity for this processor
            return None
        
        # Among threads with affinity, prioritize those that last ran on this processor
        for thread in affinity_threads:
            if self.thread_to_processor.get(thread.thread_id) == processor_id:
                return thread
        
        # Otherwise, just take the first thread with affinity
        return affinity_threads[0]
    
    def set_affinity(self, thread_id: str, processor_ids: Set[int]) -> None:
        """
        Set processor affinity for a thread.
        
        Args:
            thread_id: ID of the thread
            processor_ids: Set of processor IDs
        """
        # Ensure the IDs are valid
        valid_ids = {pid for pid in processor_ids if 0 <= pid < self.num_processors}
        self.affinities[thread_id] = valid_ids
    
    def get_affinity(self, thread_id: str) -> Set[int]:
        """
        Get processor affinity for a thread.
        
        Args:
            thread_id: ID of the thread
            
        Returns:
            Set of processor IDs
        """
        return self.affinities.get(thread_id, self.default_affinity.copy())


class DeterministicScheduler(Scheduler):
    """Deterministic scheduler for reproducible parallel executions."""
    
    def __init__(
        self,
        num_processors: int,
        time_slice: int = 10,
        random_seed: int = 42,
        base_policy: SchedulingPolicy = SchedulingPolicy.ROUND_ROBIN,
    ):
        """
        Initialize the deterministic scheduler.
        
        Args:
            num_processors: Number of available processor cores
            time_slice: Default time slice for preemptive scheduling
            random_seed: Seed for deterministic scheduling
            base_policy: Base scheduling policy to use
        """
        super().__init__(num_processors, time_slice, random_seed)
        self.base_policy = base_policy
        
        # Create the base scheduler
        if base_policy == SchedulingPolicy.ROUND_ROBIN:
            self.base_scheduler = RoundRobinScheduler(num_processors, time_slice, random_seed)
        elif base_policy == SchedulingPolicy.PRIORITY:
            self.base_scheduler = PriorityScheduler(num_processors, time_slice, random_seed)
        elif base_policy == SchedulingPolicy.AFFINITY:
            self.base_scheduler = AffinityScheduler(num_processors, time_slice, random_seed)
        else:
            # Default to round-robin
            self.base_scheduler = RoundRobinScheduler(num_processors, time_slice, random_seed)
        
        # Deterministic execution trace for replay
        self.execution_trace: List[Dict[str, Any]] = []
        
        # For recording decisions
        self.decisions: Dict[Tuple[int, int], str] = {}  # (timestamp, processor_id) -> thread_id
    
    def select_thread(
        self, available_threads: List[Thread], processor_id: int, timestamp: int
    ) -> Optional[Thread]:
        """
        Select the next thread deterministically.
        
        Args:
            available_threads: List of available threads
            processor_id: ID of the processor
            timestamp: Current global clock value
            
        Returns:
            Selected thread, or None if no thread available
        """
        if not available_threads:
            return None
        
        # Check if we have a pre-recorded decision
        key = (timestamp, processor_id)
        if key in self.decisions:
            thread_id = self.decisions[key]
            for thread in available_threads:
                if thread.thread_id == thread_id:
                    return thread
        
        # Use the base scheduler
        selected = self.base_scheduler.select_thread(available_threads, processor_id, timestamp)
        
        if selected:
            # Record this decision for deterministic replay
            self.decisions[key] = selected.thread_id
            
            # Record in execution trace
            self.execution_trace.append({
                "timestamp": timestamp,
                "event": "select_thread",
                "processor_id": processor_id,
                "thread_id": selected.thread_id,
                "available_threads": [t.thread_id for t in available_threads],
            })
        
        return selected
    
    def should_preempt(
        self, running_thread: Thread, available_threads: List[Thread], timestamp: int
    ) -> bool:
        """
        Determine if a running thread should be preempted.
        
        Args:
            running_thread: Currently running thread
            available_threads: List of available threads
            timestamp: Current global clock value
            
        Returns:
            True if the thread should be preempted
        """
        # Check if we have a pre-recorded decision
        key = (timestamp, running_thread.processor_id)
        if key in self.decisions:
            # We have a decision to preempt
            return True
        
        # Use the base scheduler
        should_preempt = self.base_scheduler.should_preempt(
            running_thread, available_threads, timestamp
        )
        
        # Record the decision
        if should_preempt:
            self.execution_trace.append({
                "timestamp": timestamp,
                "event": "preempt_thread",
                "processor_id": running_thread.processor_id,
                "thread_id": running_thread.thread_id,
                "available_threads": [t.thread_id for t in available_threads],
            })
        
        return should_preempt
    
    def load_decisions(self, decisions: Dict[Tuple[int, int], str]) -> None:
        """
        Load pre-recorded scheduling decisions.
        
        Args:
            decisions: Dictionary of (timestamp, processor_id) -> thread_id
        """
        self.decisions = decisions
    
    def export_decisions(self) -> Dict[Tuple[int, int], str]:
        """
        Export the recorded scheduling decisions.
        
        Returns:
            Dictionary of (timestamp, processor_id) -> thread_id
        """
        return self.decisions
    
    def get_trace(self) -> List[Dict[str, Any]]:
        """
        Get the execution trace.
        
        Returns:
            List of trace events
        """
        return self.execution_trace