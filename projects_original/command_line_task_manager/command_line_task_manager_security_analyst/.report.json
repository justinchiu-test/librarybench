{"created": 1746955859.757913, "duration": 0.867671012878418, "exitcode": 1, "root": "/Users/justinchiu/code/librarybench/projects/command_line_task_manager/command_line_task_manager_security_analyst", "environment": {}, "summary": {"passed": 39, "failed": 14, "total": 53, "collected": 53}, "collectors": [{"nodeid": "", "outcome": "passed", "result": [{"nodeid": "tests", "type": "Dir"}]}, {"nodeid": "tests/compliance/test_compliance.py", "outcome": "passed", "result": [{"nodeid": "tests/compliance/test_compliance.py::test_compliance_models", "type": "Function", "lineno": 19}, {"nodeid": "tests/compliance/test_compliance.py::test_compliance_mapping", "type": "Function", "lineno": 86}, {"nodeid": "tests/compliance/test_compliance.py::test_compliance_repository_create_framework", "type": "Function", "lineno": 225}, {"nodeid": "tests/compliance/test_compliance.py::test_compliance_repository_add_controls", "type": "Function", "lineno": 264}, {"nodeid": "tests/compliance/test_compliance.py::test_compliance_repository_mappings", "type": "Function", "lineno": 346}, {"nodeid": "tests/compliance/test_compliance.py::test_compliance_repository_update_framework", "type": "Function", "lineno": 458}, {"nodeid": "tests/compliance/test_compliance.py::test_compliance_repository_delete_framework", "type": "Function", "lineno": 497}, {"nodeid": "tests/compliance/test_compliance.py::test_compliance_repository_list_and_count", "type": "Function", "lineno": 527}, {"nodeid": "tests/compliance/test_compliance.py::test_compliance_repository_import_framework", "type": "Function", "lineno": 581}, {"nodeid": "tests/compliance/test_compliance.py::test_compliance_performance", "type": "Function", "lineno": 641}]}, {"nodeid": "tests/compliance", "outcome": "passed", "result": [{"nodeid": "tests/compliance/test_compliance.py", "type": "Module"}]}, {"nodeid": "tests/cvss/test_cvss.py", "outcome": "passed", "result": [{"nodeid": "tests/cvss/test_cvss.py::test_cvss_vector_validation", "type": "Function", "lineno": 13}, {"nodeid": "tests/cvss/test_cvss.py::test_cvss_vector_string_conversion", "type": "Function", "lineno": 57}, {"nodeid": "tests/cvss/test_cvss.py::test_cvss_score_calculation", "type": "Function", "lineno": 128}, {"nodeid": "tests/cvss/test_cvss.py::test_cvss_calculation_with_scope_change", "type": "Function", "lineno": 216}, {"nodeid": "tests/cvss/test_cvss.py::test_cvss_calculation_with_temporal_metrics", "type": "Function", "lineno": 272}, {"nodeid": "tests/cvss/test_cvss.py::test_cvss_vector_string_parsing", "type": "Function", "lineno": 328}, {"nodeid": "tests/cvss/test_cvss.py::test_cvss_performance", "type": "Function", "lineno": 361}, {"nodeid": "tests/cvss/test_cvss.py::test_cvss_edge_cases", "type": "Function", "lineno": 403}]}, {"nodeid": "tests/cvss", "outcome": "passed", "result": [{"nodeid": "tests/cvss/test_cvss.py", "type": "Module"}]}, {"nodeid": "tests/evidence/test_evidence.py", "outcome": "passed", "result": [{"nodeid": "tests/evidence/test_evidence.py::test_evidence_model_validation", "type": "Function", "lineno": 28}, {"nodeid": "tests/evidence/test_evidence.py::test_evidence_store", "type": "Function", "lineno": 98}, {"nodeid": "tests/evidence/test_evidence.py::test_evidence_get_metadata", "type": "Function", "lineno": 151}, {"nodeid": "tests/evidence/test_evidence.py::test_evidence_retrieve", "type": "Function", "lineno": 215}, {"nodeid": "tests/evidence/test_evidence.py::test_evidence_update_metadata", "type": "Function", "lineno": 271}, {"nodeid": "tests/evidence/test_evidence.py::test_evidence_delete", "type": "Function", "lineno": 314}, {"nodeid": "tests/evidence/test_evidence.py::test_evidence_list_and_filter", "type": "Function", "lineno": 353}, {"nodeid": "tests/evidence/test_evidence.py::test_evidence_integrity", "type": "Function", "lineno": 430}, {"nodeid": "tests/evidence/test_evidence.py::test_evidence_store_oversized_file", "type": "Function", "lineno": 464}, {"nodeid": "tests/evidence/test_evidence.py::test_evidence_performance_benchmark", "type": "Function", "lineno": 484}]}, {"nodeid": "tests/evidence", "outcome": "passed", "result": [{"nodeid": "tests/evidence/test_evidence.py", "type": "Module"}]}, {"nodeid": "tests/findings/test_findings.py", "outcome": "passed", "result": [{"nodeid": "tests/findings/test_findings.py::test_finding_model_validation", "type": "Function", "lineno": 16}, {"nodeid": "tests/findings/test_findings.py::test_finding_create", "type": "Function", "lineno": 52}, {"nodeid": "tests/findings/test_findings.py::test_finding_get", "type": "Function", "lineno": 77}, {"nodeid": "tests/findings/test_findings.py::test_finding_update", "type": "Function", "lineno": 103}, {"nodeid": "tests/findings/test_findings.py::test_finding_delete", "type": "Function", "lineno": 138}, {"nodeid": "tests/findings/test_findings.py::test_finding_list_and_filter", "type": "Function", "lineno": 172}, {"nodeid": "tests/findings/test_findings.py::test_finding_crypto_integrity", "type": "Function", "lineno": 242}, {"nodeid": "tests/findings/test_findings.py::test_finding_performance_benchmark", "type": "Function", "lineno": 278}]}, {"nodeid": "tests/findings", "outcome": "passed", "result": [{"nodeid": "tests/findings/test_findings.py", "type": "Module"}]}, {"nodeid": "tests/remediation/test_remediation.py", "outcome": "passed", "result": [{"nodeid": "tests/remediation/test_remediation.py::test_remediation_task_model", "type": "Function", "lineno": 20}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_task_steps", "type": "Function", "lineno": 67}, {"nodeid": "tests/remediation/test_remediation.py::test_workflow_engine", "type": "Function", "lineno": 122}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_tracker_create_task", "type": "Function", "lineno": 204}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_tracker_get_task", "type": "Function", "lineno": 265}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_tracker_update_task", "type": "Function", "lineno": 294}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_tracker_transition_task", "type": "Function", "lineno": 332}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_tracker_get_transition_history", "type": "Function", "lineno": 417}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_tracker_list_and_filter", "type": "Function", "lineno": 467}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_tracker_delete_task", "type": "Function", "lineno": 537}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_tracker_metrics", "type": "Function", "lineno": 577}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_performance", "type": "Function", "lineno": 736}]}, {"nodeid": "tests/remediation", "outcome": "passed", "result": [{"nodeid": "tests/remediation/test_remediation.py", "type": "Module"}]}, {"nodeid": "tests/reporting/test_reporting.py", "outcome": "passed", "result": [{"nodeid": "tests/reporting/test_reporting.py::test_redaction_pattern", "type": "Function", "lineno": 46}, {"nodeid": "tests/reporting/test_reporting.py::test_redaction_engine", "type": "Function", "lineno": 79}, {"nodeid": "tests/reporting/test_reporting.py::test_report_model", "type": "Function", "lineno": 158}, {"nodeid": "tests/reporting/test_reporting.py::test_report_generator_integration", "type": "Function", "lineno": 201}, {"nodeid": "tests/reporting/test_reporting.py::test_report_generator_performance", "type": "Function", "lineno": 425}]}, {"nodeid": "tests/reporting", "outcome": "passed", "result": [{"nodeid": "tests/reporting/test_reporting.py", "type": "Module"}]}, {"nodeid": "tests", "outcome": "passed", "result": [{"nodeid": "tests/compliance", "type": "Dir"}, {"nodeid": "tests/cvss", "type": "Dir"}, {"nodeid": "tests/evidence", "type": "Dir"}, {"nodeid": "tests/findings", "type": "Dir"}, {"nodeid": "tests/remediation", "type": "Dir"}, {"nodeid": "tests/reporting", "type": "Dir"}]}], "tests": [{"nodeid": "tests/compliance/test_compliance.py::test_compliance_models", "lineno": 19, "outcome": "passed", "keywords": ["test_compliance_models", "test_compliance.py", "compliance", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00021441606804728508, "outcome": "passed"}, "call": {"duration": 0.00017475010827183723, "outcome": "passed"}, "teardown": {"duration": 0.00011733314022421837, "outcome": "passed"}}, {"nodeid": "tests/compliance/test_compliance.py::test_compliance_mapping", "lineno": 86, "outcome": "passed", "keywords": ["test_compliance_mapping", "test_compliance.py", "compliance", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00011895783245563507, "outcome": "passed"}, "call": {"duration": 0.00016862526535987854, "outcome": "passed"}, "teardown": {"duration": 0.00010508392006158829, "outcome": "passed"}}, {"nodeid": "tests/compliance/test_compliance.py::test_compliance_repository_create_framework", "lineno": 225, "outcome": "passed", "keywords": ["test_compliance_repository_create_framework", "test_compliance.py", "compliance", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.0003131250850856304, "outcome": "passed"}, "call": {"duration": 0.0021820422261953354, "outcome": "passed"}, "teardown": {"duration": 0.0008641672320663929, "outcome": "passed"}}, {"nodeid": "tests/compliance/test_compliance.py::test_compliance_repository_add_controls", "lineno": 264, "outcome": "passed", "keywords": ["test_compliance_repository_add_controls", "test_compliance.py", "compliance", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00024637533351778984, "outcome": "passed"}, "call": {"duration": 0.004317250102758408, "outcome": "passed"}, "teardown": {"duration": 0.0008431668393313885, "outcome": "passed"}}, {"nodeid": "tests/compliance/test_compliance.py::test_compliance_repository_mappings", "lineno": 346, "outcome": "passed", "keywords": ["test_compliance_repository_mappings", "test_compliance.py", "compliance", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.0002604164183139801, "outcome": "passed"}, "call": {"duration": 0.0030589578673243523, "outcome": "passed"}, "teardown": {"duration": 0.0008475407958030701, "outcome": "passed"}}, {"nodeid": "tests/compliance/test_compliance.py::test_compliance_repository_update_framework", "lineno": 458, "outcome": "passed", "keywords": ["test_compliance_repository_update_framework", "test_compliance.py", "compliance", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00027679093182086945, "outcome": "passed"}, "call": {"duration": 0.0010737497359514236, "outcome": "passed"}, "teardown": {"duration": 0.0006010839715600014, "outcome": "passed"}}, {"nodeid": "tests/compliance/test_compliance.py::test_compliance_repository_delete_framework", "lineno": 497, "outcome": "passed", "keywords": ["test_compliance_repository_delete_framework", "test_compliance.py", "compliance", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.0002409997396171093, "outcome": "passed"}, "call": {"duration": 0.0008413749746978283, "outcome": "passed"}, "teardown": {"duration": 0.0003936672583222389, "outcome": "passed"}}, {"nodeid": "tests/compliance/test_compliance.py::test_compliance_repository_list_and_count", "lineno": 527, "outcome": "failed", "keywords": ["test_compliance_repository_list_and_count", "test_compliance.py", "compliance", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00022083381190896034, "outcome": "passed"}, "call": {"duration": 0.002936791628599167, "outcome": "failed", "crash": {"path": "/Users/justinchiu/code/librarybench/projects/command_line_task_manager/command_line_task_manager_security_analyst/tests/compliance/test_compliance.py", "lineno": 571, "message": "AssertionError: assert 'Payment Card Industry Data Security Standard' < 'NIST Security Controls'\n +  where 'Payment Card Industry Data Security Standard' = ComplianceFramework(id='PCI-DSS-4.0', name='Payment Card Industry Data Security Standard', description='Standard for organizations that handle credit cards', version='4.0', controls=[], references=[], tags=['payment', 'security']).name\n +  and   'NIST Security Controls' = ComplianceFramework(id='NIST-800-53', name='NIST Security Controls', description='Security controls from NIST SP 800-53', version='5', controls=[], references=[], tags=['government', 'security']).name"}, "traceback": [{"path": "tests/compliance/test_compliance.py", "lineno": 571, "message": "AssertionError"}], "longrepr": "temp_dir = '/var/folders/m3/l9jry0zx70jc48bpr6wb03gc0000gp/T/tmp1b_rjksw'\n\n    def test_compliance_repository_list_and_count(temp_dir):\n        \"\"\"Test listing and counting frameworks.\"\"\"\n        repo = ComplianceRepository(temp_dir)\n    \n        # Create multiple frameworks\n        repo.create_framework(\n            id=\"PCI-DSS-4.0\",\n            name=\"Payment Card Industry Data Security Standard\",\n            description=\"Standard for organizations that handle credit cards\",\n            version=\"4.0\",\n            tags=[\"payment\", \"security\"]\n        )\n    \n        repo.create_framework(\n            id=\"NIST-800-53\",\n            name=\"NIST Security Controls\",\n            description=\"Security controls from NIST SP 800-53\",\n            version=\"5\",\n            tags=[\"government\", \"security\"]\n        )\n    \n        repo.create_framework(\n            id=\"ISO-27001\",\n            name=\"ISO Information Security Standard\",\n            description=\"International standard for information security\",\n            version=\"2022\",\n            tags=[\"international\", \"security\"]\n        )\n    \n        # List all frameworks\n        all_frameworks = repo.list_frameworks()\n        assert len(all_frameworks) == 3\n    \n        # Filter by tag\n        security_frameworks = repo.list_frameworks(filters={\"tags\": \"security\"})\n        assert len(security_frameworks) == 3\n    \n        payment_frameworks = repo.list_frameworks(filters={\"tags\": \"payment\"})\n        assert len(payment_frameworks) == 1\n        assert payment_frameworks[0].id == \"PCI-DSS-4.0\"\n    \n        # Sort by name\n        sorted_by_name = repo.list_frameworks(sort_by=\"name\")\n>       assert sorted_by_name[0].name < sorted_by_name[1].name\nE       AssertionError: assert 'Payment Card Industry Data Security Standard' < 'NIST Security Controls'\nE        +  where 'Payment Card Industry Data Security Standard' = ComplianceFramework(id='PCI-DSS-4.0', name='Payment Card Industry Data Security Standard', description='Standard for organizations that handle credit cards', version='4.0', controls=[], references=[], tags=['payment', 'security']).name\nE        +  and   'NIST Security Controls' = ComplianceFramework(id='NIST-800-53', name='NIST Security Controls', description='Security controls from NIST SP 800-53', version='5', controls=[], references=[], tags=['government', 'security']).name\n\ntests/compliance/test_compliance.py:571: AssertionError"}, "teardown": {"duration": 0.001492166891694069, "outcome": "passed"}}, {"nodeid": "tests/compliance/test_compliance.py::test_compliance_repository_import_framework", "lineno": 581, "outcome": "failed", "keywords": ["test_compliance_repository_import_framework", "test_compliance.py", "compliance", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.0005197920836508274, "outcome": "passed"}, "call": {"duration": 0.0008613746613264084, "outcome": "failed", "crash": {"path": "/Users/justinchiu/code/librarybench/projects/command_line_task_manager/command_line_task_manager_security_analyst/securetask/compliance/repository.py", "lineno": 648, "message": "securetask.utils.validation.ValidationError: 3 validation errors for ComplianceFramework\nname\n  Field required [type=missing, input_value={'id': 'INVALID'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\ndescription\n  Field required [type=missing, input_value={'id': 'INVALID'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\nversion\n  Field required [type=missing, input_value={'id': 'INVALID'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing"}, "traceback": [{"path": "tests/compliance/test_compliance.py", "lineno": 639, "message": ""}, {"path": "securetask/compliance/repository.py", "lineno": 648, "message": "ValidationError"}], "longrepr": "self = <securetask.compliance.repository.ComplianceRepository object at 0x10756a740>\nframework_dict = {'id': 'INVALID'}\n\n    def import_framework_from_dict(self, framework_dict: Dict[str, Any]) -> ComplianceFramework:\n        \"\"\"\n        Import a framework from a dictionary.\n    \n        Args:\n            framework_dict: Dictionary representation of a framework\n    \n        Returns:\n            The imported framework\n    \n        Raises:\n            ValidationError: If validation fails\n        \"\"\"\n        try:\n            # Create the framework\n>           framework = ComplianceFramework.model_validate(framework_dict)\nE           pydantic_core._pydantic_core.ValidationError: 3 validation errors for ComplianceFramework\nE           name\nE             Field required [type=missing, input_value={'id': 'INVALID'}, input_type=dict]\nE               For further information visit https://errors.pydantic.dev/2.10/v/missing\nE           description\nE             Field required [type=missing, input_value={'id': 'INVALID'}, input_type=dict]\nE               For further information visit https://errors.pydantic.dev/2.10/v/missing\nE           version\nE             Field required [type=missing, input_value={'id': 'INVALID'}, input_type=dict]\nE               For further information visit https://errors.pydantic.dev/2.10/v/missing\n\nsecuretask/compliance/repository.py:637: ValidationError\n\nDuring handling of the above exception, another exception occurred:\n\ntemp_dir = '/var/folders/m3/l9jry0zx70jc48bpr6wb03gc0000gp/T/tmps50wbzyd'\n\n    def test_compliance_repository_import_framework(temp_dir):\n        \"\"\"Test importing a framework from a dictionary.\"\"\"\n        repo = ComplianceRepository(temp_dir)\n    \n        # Create a framework dictionary\n        framework_dict = {\n            \"id\": \"PCI-DSS-4.0\",\n            \"name\": \"Payment Card Industry Data Security Standard\",\n            \"description\": \"Standard for organizations that handle credit cards\",\n            \"version\": \"4.0\",\n            \"controls\": [\n                {\n                    \"id\": \"PCI-DSS-6.5.1\",\n                    \"name\": \"Injection Flaws\",\n                    \"description\": \"Prevent injection flaws, particularly SQL injection\",\n                    \"section\": \"6.5.1\",\n                    \"guidance\": \"Use parameterized queries and input validation\"\n                },\n                {\n                    \"id\": \"PCI-DSS-6.5.2\",\n                    \"name\": \"Buffer Overflows\",\n                    \"description\": \"Prevent buffer overflows\",\n                    \"section\": \"6.5.2\",\n                    \"guidance\": \"Use safe string functions and boundary checking\"\n                }\n            ],\n            \"references\": [\n                {\n                    \"title\": \"PCI SSC Website\",\n                    \"url\": \"https://www.pcisecuritystandards.org/\"\n                }\n            ],\n            \"tags\": [\"payment\", \"card\", \"security\"]\n        }\n    \n        # Import the framework\n        framework = repo.import_framework_from_dict(framework_dict)\n    \n        assert framework.id == \"PCI-DSS-4.0\"\n        assert framework.name == \"Payment Card Industry Data Security Standard\"\n        assert len(framework.controls) == 2\n        assert len(framework.references) == 1\n        assert len(framework.tags) == 3\n    \n        # Verify it was saved and can be retrieved\n        retrieved = repo.get_framework(\"PCI-DSS-4.0\")\n    \n        assert retrieved.id == \"PCI-DSS-4.0\"\n        assert len(retrieved.controls) == 2\n    \n        # Invalid framework should fail\n        invalid_dict = {\n            \"id\": \"INVALID\",\n            # Missing required fields\n        }\n    \n        with pytest.raises(ValidationError):\n>           repo.import_framework_from_dict(invalid_dict)\n\ntests/compliance/test_compliance.py:639: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <securetask.compliance.repository.ComplianceRepository object at 0x10756a740>\nframework_dict = {'id': 'INVALID'}\n\n    def import_framework_from_dict(self, framework_dict: Dict[str, Any]) -> ComplianceFramework:\n        \"\"\"\n        Import a framework from a dictionary.\n    \n        Args:\n            framework_dict: Dictionary representation of a framework\n    \n        Returns:\n            The imported framework\n    \n        Raises:\n            ValidationError: If validation fails\n        \"\"\"\n        try:\n            # Create the framework\n            framework = ComplianceFramework.model_validate(framework_dict)\n    \n            # Save the framework\n            self._save_framework(framework)\n    \n            # Add to mapping\n            self.mapping.add_framework(framework)\n    \n            return framework\n    \n        except PydanticValidationError as e:\n>           raise ValidationError(str(e))\nE           securetask.utils.validation.ValidationError: 3 validation errors for ComplianceFramework\nE           name\nE             Field required [type=missing, input_value={'id': 'INVALID'}, input_type=dict]\nE               For further information visit https://errors.pydantic.dev/2.10/v/missing\nE           description\nE             Field required [type=missing, input_value={'id': 'INVALID'}, input_type=dict]\nE               For further information visit https://errors.pydantic.dev/2.10/v/missing\nE           version\nE             Field required [type=missing, input_value={'id': 'INVALID'}, input_type=dict]\nE               For further information visit https://errors.pydantic.dev/2.10/v/missing\n\nsecuretask/compliance/repository.py:648: ValidationError"}, "teardown": {"duration": 0.0008670422248542309, "outcome": "passed"}}, {"nodeid": "tests/compliance/test_compliance.py::test_compliance_performance", "lineno": 641, "outcome": "passed", "keywords": ["test_compliance_performance", "test_compliance.py", "compliance", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.0002659172751009464, "outcome": "passed"}, "call": {"duration": 0.02550975000485778, "outcome": "passed"}, "teardown": {"duration": 0.0007904591038823128, "outcome": "passed"}}, {"nodeid": "tests/cvss/test_cvss.py::test_cvss_vector_validation", "lineno": 13, "outcome": "failed", "keywords": ["test_cvss_vector_validation", "test_cvss.py", "cvss", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00012100022286176682, "outcome": "passed"}, "call": {"duration": 0.00014766724780201912, "outcome": "failed", "crash": {"path": "/Users/justinchiu/code/librarybench/projects/command_line_task_manager/command_line_task_manager_security_analyst/securetask/cvss/calculator.py", "lineno": 139, "message": "AttributeError: 'pydantic_core._pydantic_core.ValidationInfo' object has no attribute 'info'"}, "traceback": [{"path": "tests/cvss/test_cvss.py", "lineno": 17, "message": ""}, {"path": "securetask/cvss/calculator.py", "lineno": 139, "message": "AttributeError"}], "longrepr": "def test_cvss_vector_validation():\n        \"\"\"Test that CVSS vector validation works correctly.\"\"\"\n        # Valid vector\n>       vector = CVSSVector(\n            attack_vector=\"N\",\n            attack_complexity=\"L\",\n            privileges_required=\"N\",\n            user_interaction=\"N\",\n            scope=\"U\",\n            confidentiality=\"H\",\n            integrity=\"H\",\n            availability=\"H\"\n        )\n\ntests/cvss/test_cvss.py:17: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <class 'securetask.cvss.calculator.CVSSVector'>, value = 'H'\nfield = ValidationInfo(config={'title': 'CVSSVector'}, context=None, data={'attack_vector': 'N', 'attack_complexity': 'L', 'privileges_required': 'N', 'user_interaction': 'N', 'scope': 'U'}, field_name='confidentiality')\n\n    @field_validator(\"confidentiality\", \"integrity\", \"availability\")\n    @classmethod\n    def validate_impact(cls, value: str, field) -> str:\n        \"\"\"Validate impact metrics.\"\"\"\n>       return validate_cvss_metric(value, [i.value for i in Impact], field.info['name'])\nE       AttributeError: 'pydantic_core._pydantic_core.ValidationInfo' object has no attribute 'info'\n\nsecuretask/cvss/calculator.py:139: AttributeError"}, "teardown": {"duration": 0.0001138332299888134, "outcome": "passed"}}, {"nodeid": "tests/cvss/test_cvss.py::test_cvss_vector_string_conversion", "lineno": 57, "outcome": "failed", "keywords": ["test_cvss_vector_string_conversion", "test_cvss.py", "cvss", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00013366714119911194, "outcome": "passed"}, "call": {"duration": 0.00013904226943850517, "outcome": "failed", "crash": {"path": "/Users/justinchiu/code/librarybench/projects/command_line_task_manager/command_line_task_manager_security_analyst/securetask/cvss/calculator.py", "lineno": 139, "message": "AttributeError: 'pydantic_core._pydantic_core.ValidationInfo' object has no attribute 'info'"}, "traceback": [{"path": "tests/cvss/test_cvss.py", "lineno": 61, "message": ""}, {"path": "securetask/cvss/calculator.py", "lineno": 139, "message": "AttributeError"}], "longrepr": "def test_cvss_vector_string_conversion():\n        \"\"\"Test conversion between vector objects and vector strings.\"\"\"\n        # Create a vector\n>       vector = CVSSVector(\n            attack_vector=\"N\",\n            attack_complexity=\"L\",\n            privileges_required=\"N\",\n            user_interaction=\"N\",\n            scope=\"U\",\n            confidentiality=\"H\",\n            integrity=\"H\",\n            availability=\"H\"\n        )\n\ntests/cvss/test_cvss.py:61: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <class 'securetask.cvss.calculator.CVSSVector'>, value = 'H'\nfield = ValidationInfo(config={'title': 'CVSSVector'}, context=None, data={'attack_vector': 'N', 'attack_complexity': 'L', 'privileges_required': 'N', 'user_interaction': 'N', 'scope': 'U'}, field_name='confidentiality')\n\n    @field_validator(\"confidentiality\", \"integrity\", \"availability\")\n    @classmethod\n    def validate_impact(cls, value: str, field) -> str:\n        \"\"\"Validate impact metrics.\"\"\"\n>       return validate_cvss_metric(value, [i.value for i in Impact], field.info['name'])\nE       AttributeError: 'pydantic_core._pydantic_core.ValidationInfo' object has no attribute 'info'\n\nsecuretask/cvss/calculator.py:139: AttributeError"}, "teardown": {"duration": 0.00010641571134328842, "outcome": "passed"}}, {"nodeid": "tests/cvss/test_cvss.py::test_cvss_score_calculation", "lineno": 128, "outcome": "failed", "keywords": ["test_cvss_score_calculation", "test_cvss.py", "cvss", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.0001220828853547573, "outcome": "passed"}, "call": {"duration": 0.00013362476602196693, "outcome": "failed", "crash": {"path": "/Users/justinchiu/code/librarybench/projects/command_line_task_manager/command_line_task_manager_security_analyst/securetask/cvss/calculator.py", "lineno": 139, "message": "AttributeError: 'pydantic_core._pydantic_core.ValidationInfo' object has no attribute 'info'"}, "traceback": [{"path": "tests/cvss/test_cvss.py", "lineno": 132, "message": ""}, {"path": "securetask/cvss/calculator.py", "lineno": 139, "message": "AttributeError"}], "longrepr": "def test_cvss_score_calculation():\n        \"\"\"Test CVSS score calculation against official examples.\"\"\"\n        # Example 1: Critical severity (AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H) = 9.8\n>       vector1 = CVSSVector(\n            attack_vector=\"N\",\n            attack_complexity=\"L\",\n            privileges_required=\"N\",\n            user_interaction=\"N\",\n            scope=\"U\",\n            confidentiality=\"H\",\n            integrity=\"H\",\n            availability=\"H\"\n        )\n\ntests/cvss/test_cvss.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <class 'securetask.cvss.calculator.CVSSVector'>, value = 'H'\nfield = ValidationInfo(config={'title': 'CVSSVector'}, context=None, data={'attack_vector': 'N', 'attack_complexity': 'L', 'privileges_required': 'N', 'user_interaction': 'N', 'scope': 'U'}, field_name='confidentiality')\n\n    @field_validator(\"confidentiality\", \"integrity\", \"availability\")\n    @classmethod\n    def validate_impact(cls, value: str, field) -> str:\n        \"\"\"Validate impact metrics.\"\"\"\n>       return validate_cvss_metric(value, [i.value for i in Impact], field.info['name'])\nE       AttributeError: 'pydantic_core._pydantic_core.ValidationInfo' object has no attribute 'info'\n\nsecuretask/cvss/calculator.py:139: AttributeError"}, "teardown": {"duration": 0.00015112478286027908, "outcome": "passed"}}, {"nodeid": "tests/cvss/test_cvss.py::test_cvss_calculation_with_scope_change", "lineno": 216, "outcome": "failed", "keywords": ["test_cvss_calculation_with_scope_change", "test_cvss.py", "cvss", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00012020813301205635, "outcome": "passed"}, "call": {"duration": 0.0001665409654378891, "outcome": "failed", "crash": {"path": "/Users/justinchiu/code/librarybench/projects/command_line_task_manager/command_line_task_manager_security_analyst/securetask/cvss/calculator.py", "lineno": 139, "message": "AttributeError: 'pydantic_core._pydantic_core.ValidationInfo' object has no attribute 'info'"}, "traceback": [{"path": "tests/cvss/test_cvss.py", "lineno": 220, "message": ""}, {"path": "securetask/cvss/calculator.py", "lineno": 139, "message": "AttributeError"}], "longrepr": "def test_cvss_calculation_with_scope_change():\n        \"\"\"Test CVSS calculation with scope change.\"\"\"\n        # Example with Scope = Changed (AV:N/AC:L/PR:L/UI:N/S:C/C:H/I:H/A:H) = 9.9\n>       vector = CVSSVector(\n            attack_vector=\"N\",\n            attack_complexity=\"L\",\n            privileges_required=\"L\",\n            user_interaction=\"N\",\n            scope=\"C\",\n            confidentiality=\"H\",\n            integrity=\"H\",\n            availability=\"H\"\n        )\n\ntests/cvss/test_cvss.py:220: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <class 'securetask.cvss.calculator.CVSSVector'>, value = 'H'\nfield = ValidationInfo(config={'title': 'CVSSVector'}, context=None, data={'attack_vector': 'N', 'attack_complexity': 'L', 'privileges_required': 'L', 'user_interaction': 'N', 'scope': 'C'}, field_name='confidentiality')\n\n    @field_validator(\"confidentiality\", \"integrity\", \"availability\")\n    @classmethod\n    def validate_impact(cls, value: str, field) -> str:\n        \"\"\"Validate impact metrics.\"\"\"\n>       return validate_cvss_metric(value, [i.value for i in Impact], field.info['name'])\nE       AttributeError: 'pydantic_core._pydantic_core.ValidationInfo' object has no attribute 'info'\n\nsecuretask/cvss/calculator.py:139: AttributeError"}, "teardown": {"duration": 0.00013479217886924744, "outcome": "passed"}}, {"nodeid": "tests/cvss/test_cvss.py::test_cvss_calculation_with_temporal_metrics", "lineno": 272, "outcome": "failed", "keywords": ["test_cvss_calculation_with_temporal_metrics", "test_cvss.py", "cvss", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00013949954882264137, "outcome": "passed"}, "call": {"duration": 0.0001615830697119236, "outcome": "failed", "crash": {"path": "/Users/justinchiu/code/librarybench/projects/command_line_task_manager/command_line_task_manager_security_analyst/securetask/cvss/calculator.py", "lineno": 139, "message": "AttributeError: 'pydantic_core._pydantic_core.ValidationInfo' object has no attribute 'info'"}, "traceback": [{"path": "tests/cvss/test_cvss.py", "lineno": 276, "message": ""}, {"path": "securetask/cvss/calculator.py", "lineno": 139, "message": "AttributeError"}], "longrepr": "def test_cvss_calculation_with_temporal_metrics():\n        \"\"\"Test CVSS calculation with temporal metrics.\"\"\"\n        # Base vector: AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H = 9.8 (Critical)\n>       base_vector = CVSSVector(\n            attack_vector=\"N\",\n            attack_complexity=\"L\",\n            privileges_required=\"N\",\n            user_interaction=\"N\",\n            scope=\"U\",\n            confidentiality=\"H\",\n            integrity=\"H\",\n            availability=\"H\"\n        )\n\ntests/cvss/test_cvss.py:276: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <class 'securetask.cvss.calculator.CVSSVector'>, value = 'H'\nfield = ValidationInfo(config={'title': 'CVSSVector'}, context=None, data={'attack_vector': 'N', 'attack_complexity': 'L', 'privileges_required': 'N', 'user_interaction': 'N', 'scope': 'U'}, field_name='confidentiality')\n\n    @field_validator(\"confidentiality\", \"integrity\", \"availability\")\n    @classmethod\n    def validate_impact(cls, value: str, field) -> str:\n        \"\"\"Validate impact metrics.\"\"\"\n>       return validate_cvss_metric(value, [i.value for i in Impact], field.info['name'])\nE       AttributeError: 'pydantic_core._pydantic_core.ValidationInfo' object has no attribute 'info'\n\nsecuretask/cvss/calculator.py:139: AttributeError"}, "teardown": {"duration": 0.0001354580745100975, "outcome": "passed"}}, {"nodeid": "tests/cvss/test_cvss.py::test_cvss_vector_string_parsing", "lineno": 328, "outcome": "failed", "keywords": ["test_cvss_vector_string_parsing", "test_cvss.py", "cvss", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00014679227024316788, "outcome": "passed"}, "call": {"duration": 0.000218832865357399, "outcome": "failed", "crash": {"path": "/Users/justinchiu/code/librarybench/projects/command_line_task_manager/command_line_task_manager_security_analyst/tests/cvss/test_cvss.py", "lineno": 353, "message": "AssertionError: assert False == True\n +  where False = <function CVSSCalculator.validate_vector_string at 0x106d59360>('CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H')\n +    where <function CVSSCalculator.validate_vector_string at 0x106d59360> = CVSSCalculator.validate_vector_string"}, "traceback": [{"path": "tests/cvss/test_cvss.py", "lineno": 353, "message": "AssertionError"}], "longrepr": "def test_cvss_vector_string_parsing():\n        \"\"\"Test parsing of CVSS vector strings.\"\"\"\n        # Parse vector string\n        vector_string = \"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\"\n        metrics = CVSSCalculator.parse_vector_string(vector_string)\n    \n        assert metrics[\"AV\"] == \"N\"\n        assert metrics[\"AC\"] == \"L\"\n        assert metrics[\"PR\"] == \"N\"\n        assert metrics[\"UI\"] == \"N\"\n        assert metrics[\"S\"] == \"U\"\n        assert metrics[\"C\"] == \"H\"\n        assert metrics[\"I\"] == \"H\"\n        assert metrics[\"A\"] == \"H\"\n    \n        # Parse vector with temporal metrics\n        temporal_string = \"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H/E:F/RL:O/RC:C\"\n        temporal_metrics = CVSSCalculator.parse_vector_string(temporal_string)\n    \n        assert temporal_metrics[\"E\"] == \"F\"\n        assert temporal_metrics[\"RL\"] == \"O\"\n        assert temporal_metrics[\"RC\"] == \"C\"\n    \n        # Validate vector string\n>       assert CVSSCalculator.validate_vector_string(vector_string) == True\nE       AssertionError: assert False == True\nE        +  where False = <function CVSSCalculator.validate_vector_string at 0x106d59360>('CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H')\nE        +    where <function CVSSCalculator.validate_vector_string at 0x106d59360> = CVSSCalculator.validate_vector_string\n\ntests/cvss/test_cvss.py:353: AssertionError"}, "teardown": {"duration": 0.00014791684225201607, "outcome": "passed"}}, {"nodeid": "tests/cvss/test_cvss.py::test_cvss_performance", "lineno": 361, "outcome": "failed", "keywords": ["test_cvss_performance", "test_cvss.py", "cvss", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00014733290299773216, "outcome": "passed"}, "call": {"duration": 0.000169374980032444, "outcome": "failed", "crash": {"path": "/Users/justinchiu/code/librarybench/projects/command_line_task_manager/command_line_task_manager_security_analyst/securetask/cvss/calculator.py", "lineno": 139, "message": "AttributeError: 'pydantic_core._pydantic_core.ValidationInfo' object has no attribute 'info'"}, "traceback": [{"path": "tests/cvss/test_cvss.py", "lineno": 381, "message": ""}, {"path": "securetask/cvss/calculator.py", "lineno": 284, "message": "in calculate_score"}, {"path": "securetask/cvss/calculator.py", "lineno": 259, "message": "in from_vector_string"}, {"path": "securetask/cvss/calculator.py", "lineno": 139, "message": "AttributeError"}], "longrepr": "def test_cvss_performance():\n        \"\"\"Test CVSS calculation performance.\"\"\"\n        # Create test vectors\n        vectors = [\n            # Critical\n            \"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\",\n            # High\n            \"CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H\",\n            # Medium\n            \"CVSS:3.1/AV:N/AC:H/PR:L/UI:R/S:U/C:H/I:L/A:L\",\n            # Low\n            \"CVSS:3.1/AV:L/AC:H/PR:H/UI:R/S:U/C:L/I:N/A:N\",\n            # None\n            \"CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:N/I:N/A:N\"\n        ]\n    \n        # Test performance for each vector\n        for vector_string in vectors:\n            start_time = time.time()\n>           score, severity = CVSSCalculator.calculate_score(vector_string)\n\ntests/cvss/test_cvss.py:381: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsecuretask/cvss/calculator.py:284: in calculate_score\n    vector = CVSSVector.from_vector_string(vector)\nsecuretask/cvss/calculator.py:259: in from_vector_string\n    return cls(**metrics)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <class 'securetask.cvss.calculator.CVSSVector'>, value = 'H'\nfield = ValidationInfo(config={'title': 'CVSSVector'}, context=None, data={'attack_vector': 'N', 'attack_complexity': 'L', 'privileges_required': 'N', 'user_interaction': 'N', 'scope': 'U'}, field_name='confidentiality')\n\n    @field_validator(\"confidentiality\", \"integrity\", \"availability\")\n    @classmethod\n    def validate_impact(cls, value: str, field) -> str:\n        \"\"\"Validate impact metrics.\"\"\"\n>       return validate_cvss_metric(value, [i.value for i in Impact], field.info['name'])\nE       AttributeError: 'pydantic_core._pydantic_core.ValidationInfo' object has no attribute 'info'\n\nsecuretask/cvss/calculator.py:139: AttributeError"}, "teardown": {"duration": 0.00014845794066786766, "outcome": "passed"}}, {"nodeid": "tests/cvss/test_cvss.py::test_cvss_edge_cases", "lineno": 403, "outcome": "failed", "keywords": ["test_cvss_edge_cases", "test_cvss.py", "cvss", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00016070809215307236, "outcome": "passed"}, "call": {"duration": 0.0001427503302693367, "outcome": "failed", "crash": {"path": "/Users/justinchiu/code/librarybench/projects/command_line_task_manager/command_line_task_manager_security_analyst/securetask/cvss/calculator.py", "lineno": 139, "message": "AttributeError: 'pydantic_core._pydantic_core.ValidationInfo' object has no attribute 'info'"}, "traceback": [{"path": "tests/cvss/test_cvss.py", "lineno": 407, "message": ""}, {"path": "securetask/cvss/calculator.py", "lineno": 139, "message": "AttributeError"}], "longrepr": "def test_cvss_edge_cases():\n        \"\"\"Test CVSS calculation edge cases and invalid combinations.\"\"\"\n        # Edge case: Zero impact (C:N/I:N/A:N)\n>       zero_impact = CVSSVector(\n            attack_vector=\"N\",\n            attack_complexity=\"L\",\n            privileges_required=\"N\",\n            user_interaction=\"N\",\n            scope=\"U\",\n            confidentiality=\"N\",\n            integrity=\"N\",\n            availability=\"N\"\n        )\n\ntests/cvss/test_cvss.py:407: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <class 'securetask.cvss.calculator.CVSSVector'>, value = 'N'\nfield = ValidationInfo(config={'title': 'CVSSVector'}, context=None, data={'attack_vector': 'N', 'attack_complexity': 'L', 'privileges_required': 'N', 'user_interaction': 'N', 'scope': 'U'}, field_name='confidentiality')\n\n    @field_validator(\"confidentiality\", \"integrity\", \"availability\")\n    @classmethod\n    def validate_impact(cls, value: str, field) -> str:\n        \"\"\"Validate impact metrics.\"\"\"\n>       return validate_cvss_metric(value, [i.value for i in Impact], field.info['name'])\nE       AttributeError: 'pydantic_core._pydantic_core.ValidationInfo' object has no attribute 'info'\n\nsecuretask/cvss/calculator.py:139: AttributeError"}, "teardown": {"duration": 0.00019354186952114105, "outcome": "passed"}}, {"nodeid": "tests/evidence/test_evidence.py::test_evidence_model_validation", "lineno": 28, "outcome": "passed", "keywords": ["test_evidence_model_validation", "test_evidence.py", "evidence", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00016016699373722076, "outcome": "passed"}, "call": {"duration": 0.00022725015878677368, "outcome": "passed"}, "teardown": {"duration": 0.0001427922397851944, "outcome": "passed"}}, {"nodeid": "tests/evidence/test_evidence.py::test_evidence_store", "lineno": 98, "outcome": "passed", "keywords": ["test_evidence_store", "test_evidence.py", "evidence", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00046395789831876755, "outcome": "passed"}, "call": {"duration": 0.008184959180653095, "outcome": "passed"}, "teardown": {"duration": 0.00299304211512208, "outcome": "passed"}}, {"nodeid": "tests/evidence/test_evidence.py::test_evidence_get_metadata", "lineno": 151, "outcome": "passed", "keywords": ["test_evidence_get_metadata", "test_evidence.py", "evidence", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.0003049173392355442, "outcome": "passed"}, "call": {"duration": 0.004155292175710201, "outcome": "passed"}, "teardown": {"duration": 0.0033655837178230286, "outcome": "passed"}}, {"nodeid": "tests/evidence/test_evidence.py::test_evidence_retrieve", "lineno": 215, "outcome": "passed", "keywords": ["test_evidence_retrieve", "test_evidence.py", "evidence", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00026891613379120827, "outcome": "passed"}, "call": {"duration": 0.003537459298968315, "outcome": "passed"}, "teardown": {"duration": 0.002181124873459339, "outcome": "passed"}}, {"nodeid": "tests/evidence/test_evidence.py::test_evidence_update_metadata", "lineno": 271, "outcome": "passed", "keywords": ["test_evidence_update_metadata", "test_evidence.py", "evidence", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.0002514161169528961, "outcome": "passed"}, "call": {"duration": 0.0016757077537477016, "outcome": "passed"}, "teardown": {"duration": 0.0012354576028883457, "outcome": "passed"}}, {"nodeid": "tests/evidence/test_evidence.py::test_evidence_delete", "lineno": 314, "outcome": "passed", "keywords": ["test_evidence_delete", "test_evidence.py", "evidence", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00047504203394055367, "outcome": "passed"}, "call": {"duration": 0.0018505002371966839, "outcome": "passed"}, "teardown": {"duration": 0.0009100418537855148, "outcome": "passed"}}, {"nodeid": "tests/evidence/test_evidence.py::test_evidence_list_and_filter", "lineno": 353, "outcome": "failed", "keywords": ["test_evidence_list_and_filter", "test_evidence.py", "evidence", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.0002170829102396965, "outcome": "passed"}, "call": {"duration": 0.005606040824204683, "outcome": "failed", "crash": {"path": "/Users/justinchiu/code/librarybench/projects/command_line_task_manager/command_line_task_manager_security_analyst/tests/evidence/test_evidence.py", "lineno": 417, "message": "AssertionError: assert 'Screenshot Evidence' < 'Log Evidence'\n +  where 'Screenshot Evidence' = Evidence(id='b214a68c-2958-4884-85c4-71ec944a97c4', title='Screenshot Evidence', description='Screenshot showing vulne...b', 'injection'], related_finding_ids=[], encryption_info={'algorithm': 'AES-256-GCM', 'key_id': 'be3261f6'}, notes=[]).title\n +  and   'Log Evidence' = Evidence(id='aef9d198-3212-4b32-9d27-14b1c44209bf', title='Log Evidence', description='Log showing attack attempts', t...server', 'logs'], related_finding_ids=[], encryption_info={'algorithm': 'AES-256-GCM', 'key_id': 'be3261f6'}, notes=[]).title"}, "traceback": [{"path": "tests/evidence/test_evidence.py", "lineno": 417, "message": "AssertionError"}], "longrepr": "temp_dir = '/var/folders/m3/l9jry0zx70jc48bpr6wb03gc0000gp/T/tmprm5xmi00'\n\n    def test_evidence_list_and_filter(temp_dir):\n        \"\"\"Test listing and filtering evidence.\"\"\"\n        vault = EvidenceVault(temp_dir)\n    \n        # Create test files\n        test_content = b\"This is test evidence content\"\n        file_path = create_temp_file(test_content, temp_dir)\n    \n        # Create multiple evidence entries\n        evidence1 = vault.store(\n            file_path=file_path,\n            title=\"Screenshot Evidence\",\n            description=\"Screenshot showing vulnerability\",\n            evidence_type=EvidenceType.SCREENSHOT,\n            uploaded_by=\"analyst1\",\n            tags=[\"web\", \"injection\"]\n        )\n    \n        evidence2 = vault.store(\n            file_path=file_path,\n            title=\"Log Evidence\",\n            description=\"Log showing attack attempts\",\n            evidence_type=EvidenceType.LOG,\n            uploaded_by=\"analyst2\",\n            tags=[\"server\", \"logs\"]\n        )\n    \n        evidence3 = vault.store(\n            file_path=file_path,\n            title=\"Exploit Code\",\n            description=\"Proof of concept exploit code\",\n            evidence_type=EvidenceType.EXPLOIT,\n            uploaded_by=\"analyst1\",\n            access_level=AccessLevel.CONFIDENTIAL,\n            tags=[\"code\", \"exploit\"]\n        )\n    \n        # List all evidence\n        all_evidence = vault.list()\n        assert len(all_evidence) == 3\n    \n        # Filter by uploader\n        analyst1_evidence = vault.list(filters={\"uploaded_by\": \"analyst1\"})\n        assert len(analyst1_evidence) == 2\n    \n        # Filter by type\n        screenshot_evidence = vault.list(filters={\"type\": EvidenceType.SCREENSHOT})\n        assert len(screenshot_evidence) == 1\n        assert screenshot_evidence[0].id == evidence1.id\n    \n        # Filter by tag\n        web_tag_evidence = vault.list(filters={\"tags\": \"web\"})\n        assert len(web_tag_evidence) == 1\n        assert web_tag_evidence[0].id == evidence1.id\n    \n        # Filter by access level\n        confidential_evidence = vault.list(filters={\"access_level\": AccessLevel.CONFIDENTIAL})\n        assert len(confidential_evidence) == 1\n        assert confidential_evidence[0].id == evidence3.id\n    \n        # Sort by title\n        sorted_by_title = vault.list(sort_by=\"title\", reverse=False)\n        assert sorted_by_title[0].title < sorted_by_title[1].title\n>       assert sorted_by_title[1].title < sorted_by_title[2].title\nE       AssertionError: assert 'Screenshot Evidence' < 'Log Evidence'\nE        +  where 'Screenshot Evidence' = Evidence(id='b214a68c-2958-4884-85c4-71ec944a97c4', title='Screenshot Evidence', description='Screenshot showing vulne...b', 'injection'], related_finding_ids=[], encryption_info={'algorithm': 'AES-256-GCM', 'key_id': 'be3261f6'}, notes=[]).title\nE        +  and   'Log Evidence' = Evidence(id='aef9d198-3212-4b32-9d27-14b1c44209bf', title='Log Evidence', description='Log showing attack attempts', t...server', 'logs'], related_finding_ids=[], encryption_info={'algorithm': 'AES-256-GCM', 'key_id': 'be3261f6'}, notes=[]).title\n\ntests/evidence/test_evidence.py:417: AssertionError"}, "teardown": {"duration": 0.001815333031117916, "outcome": "passed"}}, {"nodeid": "tests/evidence/test_evidence.py::test_evidence_integrity", "lineno": 430, "outcome": "passed", "keywords": ["test_evidence_integrity", "test_evidence.py", "evidence", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.0002638748846948147, "outcome": "passed"}, "call": {"duration": 0.0021675419993698597, "outcome": "passed"}, "teardown": {"duration": 0.0009542079642415047, "outcome": "passed"}}, {"nodeid": "tests/evidence/test_evidence.py::test_evidence_store_oversized_file", "lineno": 464, "outcome": "passed", "keywords": ["test_evidence_store_oversized_file", "test_evidence.py", "evidence", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00025524990633130074, "outcome": "passed"}, "call": {"duration": 0.0007369169034063816, "outcome": "passed"}, "teardown": {"duration": 0.0005981661379337311, "outcome": "passed"}}, {"nodeid": "tests/evidence/test_evidence.py::test_evidence_performance_benchmark", "lineno": 484, "outcome": "passed", "keywords": ["test_evidence_performance_benchmark", "test_evidence.py", "evidence", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.0003070002421736717, "outcome": "passed"}, "call": {"duration": 0.012131708208471537, "outcome": "passed"}, "teardown": {"duration": 0.0019948752596974373, "outcome": "passed"}}, {"nodeid": "tests/findings/test_findings.py::test_finding_model_validation", "lineno": 16, "outcome": "failed", "keywords": ["test_finding_model_validation", "test_findings.py", "findings", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.0002460000105202198, "outcome": "passed"}, "call": {"duration": 0.00016733305528759956, "outcome": "failed", "crash": {"path": "/Users/justinchiu/code/librarybench/projects/command_line_task_manager/command_line_task_manager_security_analyst/securetask/findings/models.py", "lineno": 62, "message": "securetask.utils.validation.ValidationError: severity: Invalid severity: invalid. Allowed values: medium, high, info, critical, low"}, "traceback": [{"path": "tests/findings/test_findings.py", "lineno": 34, "message": ""}, {"path": "securetask/findings/models.py", "lineno": 62, "message": "ValidationError"}], "longrepr": "def test_finding_model_validation():\n        \"\"\"Test that finding model validation works correctly.\"\"\"\n        # Valid finding\n        finding = Finding(\n            title=\"SQL Injection in Login Form\",\n            description=\"The login form is vulnerable to SQL injection\",\n            affected_systems=[\"web-app-01\", \"web-app-02\"],\n            discovered_by=\"security-analyst\",\n            severity=\"high\"\n        )\n    \n        assert finding.id is not None\n        assert finding.status == \"open\"\n        assert len(finding.affected_systems) == 2\n    \n        # Invalid severity\n        with pytest.raises(ValidationError):\n>           Finding(\n                title=\"Test\",\n                description=\"Test\",\n                discovered_by=\"security-analyst\",\n                severity=\"invalid\"  # Invalid severity\n            )\n\ntests/findings/test_findings.py:34: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <class 'securetask.findings.models.Finding'>, value = 'invalid'\n\n    @field_validator(\"severity\")\n    @classmethod\n    def validate_severity(cls, value: str) -> str:\n        \"\"\"Validate that the severity is a known value.\"\"\"\n        allowed_severities = {\"critical\", \"high\", \"medium\", \"low\", \"info\"}\n        if value not in allowed_severities:\n>           raise ValidationError(\n                f\"Invalid severity: {value}. Allowed values: {', '.join(allowed_severities)}\",\n                \"severity\"\n            )\nE           securetask.utils.validation.ValidationError: severity: Invalid severity: invalid. Allowed values: medium, high, info, critical, low\n\nsecuretask/findings/models.py:62: ValidationError"}, "teardown": {"duration": 0.0001005418598651886, "outcome": "passed"}}, {"nodeid": "tests/findings/test_findings.py::test_finding_create", "lineno": 52, "outcome": "passed", "keywords": ["test_finding_create", "test_findings.py", "findings", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.000224333256483078, "outcome": "passed"}, "call": {"duration": 0.0005021253600716591, "outcome": "passed"}, "teardown": {"duration": 0.0006114579737186432, "outcome": "passed"}}, {"nodeid": "tests/findings/test_findings.py::test_finding_get", "lineno": 77, "outcome": "passed", "keywords": ["test_finding_get", "test_findings.py", "findings", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00022012507542967796, "outcome": "passed"}, "call": {"duration": 0.0006025410257279873, "outcome": "passed"}, "teardown": {"duration": 0.0006181667558848858, "outcome": "passed"}}, {"nodeid": "tests/findings/test_findings.py::test_finding_update", "lineno": 103, "outcome": "passed", "keywords": ["test_finding_update", "test_findings.py", "findings", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00019941618666052818, "outcome": "passed"}, "call": {"duration": 0.0008753747679293156, "outcome": "passed"}, "teardown": {"duration": 0.0005881250835955143, "outcome": "passed"}}, {"nodeid": "tests/findings/test_findings.py::test_finding_delete", "lineno": 138, "outcome": "passed", "keywords": ["test_finding_delete", "test_findings.py", "findings", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.0003403332084417343, "outcome": "passed"}, "call": {"duration": 0.0007143341936171055, "outcome": "passed"}, "teardown": {"duration": 0.00045187491923570633, "outcome": "passed"}}, {"nodeid": "tests/findings/test_findings.py::test_finding_list_and_filter", "lineno": 172, "outcome": "passed", "keywords": ["test_finding_list_and_filter", "test_findings.py", "findings", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00021900003775954247, "outcome": "passed"}, "call": {"duration": 0.004098041914403439, "outcome": "passed"}, "teardown": {"duration": 0.0008803750388324261, "outcome": "passed"}}, {"nodeid": "tests/findings/test_findings.py::test_finding_crypto_integrity", "lineno": 242, "outcome": "passed", "keywords": ["test_finding_crypto_integrity", "test_findings.py", "findings", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00021900003775954247, "outcome": "passed"}, "call": {"duration": 0.0007376251742243767, "outcome": "passed"}, "teardown": {"duration": 0.0005432078614830971, "outcome": "passed"}}, {"nodeid": "tests/findings/test_findings.py::test_finding_performance_benchmark", "lineno": 278, "outcome": "passed", "keywords": ["test_finding_performance_benchmark", "test_findings.py", "findings", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00034445803612470627, "outcome": "passed"}, "call": {"duration": 0.0008180830627679825, "outcome": "passed"}, "teardown": {"duration": 0.0005420418456196785, "outcome": "passed"}}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_task_model", "lineno": 20, "outcome": "failed", "keywords": ["test_remediation_task_model", "test_remediation.py", "remediation", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.0001193750649690628, "outcome": "passed"}, "call": {"duration": 0.00018708407878875732, "outcome": "failed", "crash": {"path": "/Users/justinchiu/code/librarybench/projects/command_line_task_manager/command_line_task_manager_security_analyst/tests/remediation/test_remediation.py", "lineno": 65, "message": "TypeError: BaseModel.validate() missing 1 required positional argument: 'value'"}, "traceback": [{"path": "tests/remediation/test_remediation.py", "lineno": 65, "message": "TypeError"}], "longrepr": "def test_remediation_task_model():\n        \"\"\"Test the RemediationTask model.\"\"\"\n        # Valid task\n        task = RemediationTask(\n            finding_id=str(uuid.uuid4()),\n            title=\"Fix SQL Injection\",\n            description=\"Fix SQL injection vulnerability in login form\",\n            priority=RemediationPriority.HIGH\n        )\n    \n        assert task.id is not None\n        assert task.state == RemediationState.OPEN\n        assert task.progress_percentage == 0\n    \n        # Test with string values\n        task2 = RemediationTask(\n            finding_id=str(uuid.uuid4()),\n            title=\"Fix XSS\",\n            description=\"Fix XSS vulnerability in comments\",\n            priority=\"medium\",  # String instead of enum\n            state=\"assigned\"    # String instead of enum\n        )\n    \n        assert task2.priority == RemediationPriority.MEDIUM\n        assert task2.state == RemediationState.ASSIGNED\n    \n        # Invalid priority\n        with pytest.raises(ValidationError):\n            RemediationTask(\n                finding_id=str(uuid.uuid4()),\n                title=\"Test\",\n                description=\"Test\",\n                priority=\"invalid_priority\"  # Invalid priority\n            )\n    \n        # Invalid state\n        with pytest.raises(ValidationError):\n            task = RemediationTask(\n                finding_id=str(uuid.uuid4()),\n                title=\"Test\",\n                description=\"Test\",\n                priority=RemediationPriority.HIGH\n            )\n            task.state = \"invalid_state\"  # Set invalid state\n>           task.validate()\nE           TypeError: BaseModel.validate() missing 1 required positional argument: 'value'\n\ntests/remediation/test_remediation.py:65: TypeError"}, "teardown": {"duration": 9.420793503522873e-05, "outcome": "passed"}}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_task_steps", "lineno": 67, "outcome": "passed", "keywords": ["test_remediation_task_steps", "test_remediation.py", "remediation", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00010004080832004547, "outcome": "passed"}, "call": {"duration": 0.0001443326473236084, "outcome": "passed"}, "teardown": {"duration": 9.616697207093239e-05, "outcome": "passed"}}, {"nodeid": "tests/remediation/test_remediation.py::test_workflow_engine", "lineno": 122, "outcome": "passed", "keywords": ["test_workflow_engine", "test_remediation.py", "remediation", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 9.837513789534569e-05, "outcome": "passed"}, "call": {"duration": 0.00017945794388651848, "outcome": "passed"}, "teardown": {"duration": 8.204206824302673e-05, "outcome": "passed"}}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_tracker_create_task", "lineno": 204, "outcome": "failed", "keywords": ["test_remediation_tracker_create_task", "test_remediation.py", "remediation", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00034970929846167564, "outcome": "passed"}, "call": {"duration": 0.0006569996476173401, "outcome": "failed", "crash": {"path": "/Users/justinchiu/code/librarybench/projects/command_line_task_manager/command_line_task_manager_security_analyst/securetask/remediation/workflow.py", "lineno": 314, "message": "securetask.utils.validation.ValidationError: to_state: Invalid state transition from assigned to assigned"}, "traceback": [{"path": "tests/remediation/test_remediation.py", "lineno": 236, "message": ""}, {"path": "securetask/remediation/tracker.py", "lineno": 99, "message": "in create_task"}, {"path": "securetask/remediation/workflow.py", "lineno": 314, "message": "ValidationError"}], "longrepr": "temp_dir = '/var/folders/m3/l9jry0zx70jc48bpr6wb03gc0000gp/T/tmp8tjs73ks'\n\n    def test_remediation_tracker_create_task(temp_dir):\n        \"\"\"Test creating remediation tasks.\"\"\"\n        tracker = RemediationTracker(temp_dir)\n    \n        # Create a task\n        finding_id = str(uuid.uuid4())\n        task = tracker.create_task(\n            finding_id=finding_id,\n            title=\"Fix SQL Injection\",\n            description=\"Fix SQL injection vulnerability in login form\",\n            priority=RemediationPriority.HIGH,\n            created_by=\"security_analyst\",\n            due_date=datetime.now() + timedelta(days=14)\n        )\n    \n        assert task.id is not None\n        assert task.finding_id == finding_id\n        assert task.title == \"Fix SQL Injection\"\n        assert task.priority == RemediationPriority.HIGH\n        assert task.state == RemediationState.OPEN\n        assert len(task.notes) == 1  # Initial note\n    \n        # Verify file was created\n        file_path = os.path.join(temp_dir, \"tasks\", f\"{task.id}.json.enc\")\n        assert os.path.exists(file_path)\n    \n        # Verify HMAC digest was created\n        digest_path = os.path.join(temp_dir, \"tasks\", f\"{task.id}.hmac\")\n        assert os.path.exists(digest_path)\n    \n        # Create a task with assigned state\n>       assigned_task = tracker.create_task(\n            finding_id=str(uuid.uuid4()),\n            title=\"Fix XSS\",\n            description=\"Fix XSS vulnerability in comments\",\n            priority=RemediationPriority.MEDIUM,\n            created_by=\"security_analyst\",\n            assigned_to=\"developer1\",\n            initial_state=RemediationState.ASSIGNED\n        )\n\ntests/remediation/test_remediation.py:236: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsecuretask/remediation/tracker.py:99: in create_task\n    _, transition = self.workflow_engine.transition(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <securetask.remediation.workflow.WorkflowEngine object at 0x107587820>\ntask = RemediationTask(id='62c3d3cc-99ce-46d4-a7cd-91ff84545e6e', finding_id='24dad933-6a92-4b91-a09c-0adeb78f0305', title='F...um and state assigned', 'author': 'security_analyst', 'timestamp': datetime.datetime(2025, 5, 11, 5, 30, 59, 147497)}])\nto_state = <RemediationState.ASSIGNED: 'assigned'>\nperformed_by = 'security_analyst', comments = 'Task assigned to developer1'\nevidence_ids = None, approver = None\n\n    def transition(\n        self,\n        task: RemediationTask,\n        to_state: Union[RemediationState, str],\n        performed_by: str,\n        comments: Optional[str] = None,\n        evidence_ids: Optional[List[str]] = None,\n        approver: Optional[str] = None\n    ) -> Tuple[RemediationTask, StateTransition]:\n        \"\"\"\n        Transition a remediation task to a new state.\n    \n        Args:\n            task: The remediation task to transition\n            to_state: The target state\n            performed_by: ID of the user performing the transition\n            comments: Optional comments about the transition\n            evidence_ids: Optional list of evidence IDs\n            approver: Optional ID of the approver (required for some transitions)\n    \n        Returns:\n            Tuple of (updated task, state transition record)\n    \n        Raises:\n            ValidationError: If the transition is invalid\n        \"\"\"\n        start_time = time.time()\n    \n        # Convert string to enum if needed\n        if isinstance(to_state, str):\n            try:\n                to_state = RemediationState(to_state)\n            except ValueError:\n                raise ValidationError(f\"Invalid state: {to_state}\", \"to_state\")\n    \n        # Check if transition is valid\n        if not self.is_valid_transition(task.state, to_state):\n>           raise ValidationError(\n                f\"Invalid state transition from {task.state} to {to_state}\",\n                \"to_state\"\n            )\nE           securetask.utils.validation.ValidationError: to_state: Invalid state transition from assigned to assigned\n\nsecuretask/remediation/workflow.py:314: ValidationError"}, "teardown": {"duration": 0.001145792193710804, "outcome": "passed"}}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_tracker_get_task", "lineno": 265, "outcome": "passed", "keywords": ["test_remediation_tracker_get_task", "test_remediation.py", "remediation", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.0002709999680519104, "outcome": "passed"}, "call": {"duration": 0.0009596250019967556, "outcome": "passed"}, "teardown": {"duration": 0.0009976248256862164, "outcome": "passed"}}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_tracker_update_task", "lineno": 294, "outcome": "passed", "keywords": ["test_remediation_tracker_update_task", "test_remediation.py", "remediation", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.0002310001291334629, "outcome": "passed"}, "call": {"duration": 0.0010820003226399422, "outcome": "passed"}, "teardown": {"duration": 0.0010089999996125698, "outcome": "passed"}}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_tracker_transition_task", "lineno": 332, "outcome": "passed", "keywords": ["test_remediation_tracker_transition_task", "test_remediation.py", "remediation", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00023620901629328728, "outcome": "passed"}, "call": {"duration": 0.003826832864433527, "outcome": "passed"}, "teardown": {"duration": 0.001656167209148407, "outcome": "passed"}}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_tracker_get_transition_history", "lineno": 417, "outcome": "passed", "keywords": ["test_remediation_tracker_get_transition_history", "test_remediation.py", "remediation", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00021808268502354622, "outcome": "passed"}, "call": {"duration": 0.0031339586712419987, "outcome": "passed"}, "teardown": {"duration": 0.0011909171007573605, "outcome": "passed"}}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_tracker_list_and_filter", "lineno": 467, "outcome": "passed", "keywords": ["test_remediation_tracker_list_and_filter", "test_remediation.py", "remediation", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00021016690880060196, "outcome": "passed"}, "call": {"duration": 0.005021375138312578, "outcome": "passed"}, "teardown": {"duration": 0.001162417232990265, "outcome": "passed"}}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_tracker_delete_task", "lineno": 537, "outcome": "passed", "keywords": ["test_remediation_tracker_delete_task", "test_remediation.py", "remediation", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00022916682064533234, "outcome": "passed"}, "call": {"duration": 0.0016164169646799564, "outcome": "passed"}, "teardown": {"duration": 0.0008184160105884075, "outcome": "passed"}}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_tracker_metrics", "lineno": 577, "outcome": "passed", "keywords": ["test_remediation_tracker_metrics", "test_remediation.py", "remediation", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00021129101514816284, "outcome": "passed"}, "call": {"duration": 0.020057667046785355, "outcome": "passed"}, "teardown": {"duration": 0.0033952081575989723, "outcome": "passed"}}, {"nodeid": "tests/remediation/test_remediation.py::test_remediation_performance", "lineno": 736, "outcome": "passed", "keywords": ["test_remediation_performance", "test_remediation.py", "remediation", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.0002238750457763672, "outcome": "passed"}, "call": {"duration": 0.08825404103845358, "outcome": "passed", "stdout": "Remediation Performance: 1702.10 transitions/second\n"}, "teardown": {"duration": 0.03936320822685957, "outcome": "passed"}}, {"nodeid": "tests/reporting/test_reporting.py::test_redaction_pattern", "lineno": 46, "outcome": "passed", "keywords": ["test_redaction_pattern", "test_reporting.py", "reporting", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00013595819473266602, "outcome": "passed"}, "call": {"duration": 0.00020183296874165535, "outcome": "passed"}, "teardown": {"duration": 0.00010529113933444023, "outcome": "passed"}}, {"nodeid": "tests/reporting/test_reporting.py::test_redaction_engine", "lineno": 79, "outcome": "passed", "keywords": ["test_redaction_engine", "test_reporting.py", "reporting", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00011604232713580132, "outcome": "passed"}, "call": {"duration": 0.0013322504237294197, "outcome": "passed"}, "teardown": {"duration": 9.49581153690815e-05, "outcome": "passed"}}, {"nodeid": "tests/reporting/test_reporting.py::test_report_model", "lineno": 158, "outcome": "passed", "keywords": ["test_report_model", "test_reporting.py", "reporting", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00010262476280331612, "outcome": "passed"}, "call": {"duration": 0.00017454102635383606, "outcome": "passed"}, "teardown": {"duration": 9.154202416539192e-05, "outcome": "passed"}}, {"nodeid": "tests/reporting/test_reporting.py::test_report_generator_integration", "lineno": 201, "outcome": "passed", "keywords": ["test_report_generator_integration", "test_reporting.py", "reporting", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.0002393331378698349, "outcome": "passed"}, "call": {"duration": 0.01923820935189724, "outcome": "passed"}, "teardown": {"duration": 0.0033390000462532043, "outcome": "passed"}}, {"nodeid": "tests/reporting/test_reporting.py::test_report_generator_performance", "lineno": 425, "outcome": "passed", "keywords": ["test_report_generator_performance", "test_reporting.py", "reporting", "tests", "command_line_task_manager_security_analyst", ""], "setup": {"duration": 0.00027241697534918785, "outcome": "passed"}, "call": {"duration": 0.2706575826741755, "outcome": "passed"}, "teardown": {"duration": 0.11881008418276906, "outcome": "passed"}}]}