"""Service for legal term ontology integration."""

import json
import os
from typing import Dict, List, Set, Optional, Union, Any
import logging

from .models import (
    LegalOntology,
    LegalTerm,
    TermRelation,
    TermRelationType,
    OntologyCollection
)


class OntologyService:
    """Service for legal term ontology integration.
    
    This service provides functionality for loading, managing, and using
    legal term ontologies to expand searches with specialized terminology.
    """
    
    def __init__(self, logger=None):
        """Initialize the ontology service.
        
        Args:
            logger: Logger instance
        """
        self.logger = logger or logging.getLogger(__name__)
        self.ontology_collection = OntologyCollection()
        
        # Cache for expanded terms to improve performance
        self._term_expansion_cache: Dict[str, Set[str]] = {}
    
    def load_ontology_from_file(self, file_path: str) -> Optional[LegalOntology]:
        """Load an ontology from a JSON file.
        
        Args:
            file_path: Path to the ontology file
            
        Returns:
            The loaded ontology, or None if loading failed
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                ontology_data = json.load(f)
            
            ontology = LegalOntology.parse_obj(ontology_data)
            self.ontology_collection.add_ontology(ontology)
            self.logger.info(f"Loaded ontology {ontology.ontology_id} with {ontology.count_terms()} terms")
            
            # Clear the expansion cache when loading new ontologies
            self._term_expansion_cache = {}
            
            return ontology
        except Exception as e:
            self.logger.error(f"Failed to load ontology from {file_path}: {e}")
            return None
    
    def load_ontology_from_dict(self, ontology_data: Dict[str, Any]) -> Optional[LegalOntology]:
        """Load an ontology from a dictionary.
        
        Args:
            ontology_data: Ontology data as a dictionary
            
        Returns:
            The loaded ontology, or None if loading failed
        """
        try:
            ontology = LegalOntology.parse_obj(ontology_data)
            self.ontology_collection.add_ontology(ontology)
            self.logger.info(f"Loaded ontology {ontology.ontology_id} with {ontology.count_terms()} terms")
            
            # Clear the expansion cache when loading new ontologies
            self._term_expansion_cache = {}
            
            return ontology
        except Exception as e:
            self.logger.error(f"Failed to load ontology from dictionary: {e}")
            return None
    
    def load_ontologies_from_directory(self, directory_path: str) -> int:
        """Load all ontology files from a directory.
        
        Args:
            directory_path: Path to the directory containing ontology files
            
        Returns:
            Number of successfully loaded ontologies
        """
        loaded_count = 0
        
        try:
            for filename in os.listdir(directory_path):
                if filename.endswith('.json'):
                    file_path = os.path.join(directory_path, filename)
                    if self.load_ontology_from_file(file_path):
                        loaded_count += 1
        except Exception as e:
            self.logger.error(f"Failed to load ontologies from directory {directory_path}: {e}")
        
        return loaded_count
    
    def create_simple_ontology(self, ontology_id: str, name: str, term_mapping: Dict[str, Set[str]],
                              version: str = "1.0") -> LegalOntology:
        """Create a simple ontology from a term mapping.
        
        Args:
            ontology_id: Unique identifier for the ontology
            name: Name of the ontology
            term_mapping: Mapping from terms to related terms
            version: Version of the ontology
            
        Returns:
            The created ontology
        """
        ontology = LegalOntology(
            ontology_id=ontology_id,
            name=name,
            version=version
        )
        
        for term, related_terms in term_mapping.items():
            legal_term = LegalTerm(term=term.lower())
            ontology.terms[term.lower()] = legal_term
            
            for related_term in related_terms:
                relation = TermRelation(
                    from_term=term.lower(),
                    to_term=related_term.lower(),
                    relation_type=TermRelationType.RELATED
                )
                legal_term.relations.append(relation)
        
        self.ontology_collection.add_ontology(ontology)
        
        # Clear the expansion cache when creating new ontologies
        self._term_expansion_cache = {}
        
        return ontology
    
    def expand_terms(self, term: str, max_expansion: int = 50, 
                    relation_types: Optional[List[TermRelationType]] = None,
                    min_confidence: float = 0.5) -> Set[str]:
        """Expand a search term using the loaded ontologies.
        
        Args:
            term: Term to expand
            max_expansion: Maximum number of expanded terms to return
            relation_types: Types of relationships to include (None for all)
            min_confidence: Minimum confidence for relationships
            
        Returns:
            Set of expanded terms, including the original term
        """
        term = term.lower()
        
        # Check the cache first
        cache_key = f"{term}_{max_expansion}_{'-'.join(rt.value for rt in relation_types) if relation_types else 'all'}_{min_confidence}"
        if cache_key in self._term_expansion_cache:
            return self._term_expansion_cache[cache_key]
        
        # Always include the original term
        expanded_terms = {term}
        
        # Expand the term using all ontologies
        for ontology in self.ontology_collection.ontologies.values():
            term_obj = ontology.get_term(term)
            if not term_obj:
                continue
            
            # Get related terms
            related_terms = ontology.get_related_terms(term, relation_types, min_confidence)
            
            # Add related terms to the expanded set
            for related_term in related_terms:
                expanded_terms.add(related_term.lower())
                
                # Stop if we've reached the maximum number of expanded terms
                if len(expanded_terms) >= max_expansion:
                    break
            
            # Stop if we've reached the maximum number of expanded terms
            if len(expanded_terms) >= max_expansion:
                break
        
        # Cache the result
        self._term_expansion_cache[cache_key] = expanded_terms
        
        return expanded_terms
    
    def expand_query(self, query: str, max_terms_per_expansion: int = 10) -> str:
        """Expand a query string using the loaded ontologies.
        
        Args:
            query: Query string to expand
            max_terms_per_expansion: Maximum number of expanded terms per original term
            
        Returns:
            Expanded query string
        """
        # This is a simplified implementation for demonstration purposes
        # A full implementation would need to parse the query properly
        
        terms = query.split()
        expanded_query_parts = []
        
        for term in terms:
            # Skip common operators and punctuation
            if term.upper() in ("AND", "OR", "NOT", "NEAR", "WITHIN") or term in ("(", ")", ",", ";"):
                expanded_query_parts.append(term)
                continue
            
            # Expand the term
            expanded_terms = self.expand_terms(term, max_expansion=max_terms_per_expansion)
            
            # Add the expanded terms to the query
            if len(expanded_terms) == 1:
                # If there's only one term (the original), just add it
                expanded_query_parts.append(term)
            else:
                # Otherwise, add the expanded terms as an OR group
                expanded_terms_str = " OR ".join(expanded_terms)
                expanded_query_parts.append(f"({expanded_terms_str})")
        
        return " ".join(expanded_query_parts)
    
    def get_related_documents(self, term: str, documents: List[Dict[str, Any]], 
                            content_field: str = "content", max_expansion: int = 20) -> List[Dict[str, Any]]:
        """Find documents related to a term using ontology-based expansion.
        
        Args:
            term: Term to search for
            documents: List of documents to search in
            content_field: Field in the documents containing the content to search
            max_expansion: Maximum number of expanded terms to use
            
        Returns:
            List of related documents
        """
        expanded_terms = self.expand_terms(term, max_expansion=max_expansion)
        
        related_documents = []
        for document in documents:
            content = document.get(content_field, "").lower()
            
            # Check if any expanded term is in the content
            if any(expanded_term in content for expanded_term in expanded_terms):
                related_documents.append(document)
        
        return related_documents