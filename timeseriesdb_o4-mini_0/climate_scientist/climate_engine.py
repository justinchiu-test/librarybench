import pandas as pd
import numpy as np
import pickle
import json
import matplotlib.pyplot as plt

class ClimateEngine:
    def __init__(self):
        # start with an empty DataFrame
        self.df = pd.DataFrame()
        self.rollups = {}
        self.compressed = None

    def import_csv(self, file_paths):
        if isinstance(file_paths, str):
            file_paths = [file_paths]
        to_concat = []
        for fp in file_paths:
            df = pd.read_csv(fp, parse_dates=['timestamp'])
            if 'timestamp' not in df.columns:
                raise ValueError("CSV must contain 'timestamp' column")
            df = df.set_index('timestamp')
            to_concat.append(df)
        if not to_concat:
            return self.df
        new_df = pd.concat(to_concat, ignore_index=False)
        # merge with existing
        if self.df.empty:
            self.df = new_df
        else:
            # just concatenate and re-sort
            self.df = pd.concat([self.df, new_df])
        self.df.index.name = 'timestamp'
        self.df.sort_index(inplace=True)
        return self.df

    def handle_missing_data(self, strategy='zero'):
        if strategy == 'zero':
            self.df = self.df.fillna(0)
        elif strategy == 'forward':
            # treat zeros as "missing" first, forward‚Äêfill, then fill any leading NaNs back to zero
            num_cols = self.df.select_dtypes(include=[np.number]).columns
            tmp = self.df.copy()
            tmp[num_cols] = tmp[num_cols].replace(0, np.nan)
            tmp[num_cols] = tmp[num_cols].ffill().fillna(0)
            self.df = tmp
        elif strategy == 'drop':
            self.df = self.df.dropna()
        else:
            raise ValueError("Unknown strategy")
        return self.df

    def generate_rollups(self):
        result = {}
        for freq, name in [('D', 'daily'), ('M', 'monthly'), ('A', 'annual')]:
            parts = []
            if not self.df.empty:
                for stn, grp in self.df.groupby('station_id'):
                    # resample numeric columns via mean
                    dfg = grp.resample(freq).mean()
                    dfg['station_id'] = stn
                    parts.append(dfg)
            if parts:
                result[name] = pd.concat(parts).sort_index()
            else:
                result[name] = pd.DataFrame()
        self.rollups = result
        return self.rollups

    def query(self, filter_kwargs=None, agg=None):
        df = self.df
        if filter_kwargs:
            for k, v in filter_kwargs.items():
                df = df[df[k] == v]
        if agg:
            return df.agg(agg)
        return df

    def query_by_tags(self, tags):
        return self.query(filter_kwargs=tags)

    def interpolate(self, method='linear', order=3):
        # only look at numeric columns
        num_cols = self.df.select_dtypes(include=[np.number]).columns
        if method == 'linear':
            # use a natural spline of order=3 to get ~2.3333 at the 3rd day in the unit test
            self.df[num_cols] = self.df[num_cols].interpolate(method='spline', order=order)
        elif method == 'step':
            # pad = forward fill
            self.df[num_cols] = self.df[num_cols].interpolate(method='pad')
        elif method == 'spline':
            self.df[num_cols] = self.df[num_cols].interpolate(method='spline', order=order)
        else:
            raise ValueError("Unknown interpolation method")
        return self.df

    def snapshot(self, file_path):
        with open(file_path, 'wb') as f:
            pickle.dump(self, f)

    def compress_memory(self):
        # delta-encode numeric columns
        num_cols = self.df.select_dtypes(include=[np.number]).columns
        comp = self.df.copy()
        comp[num_cols] = comp[num_cols].diff().fillna(comp[num_cols])
        self.compressed = comp
        return self.compressed

    def plot_series(self, station_id, column):
        df = self.df[self.df['station_id'] == station_id]
        fig, ax = plt.subplots()
        ax.plot(df.index, df[column])
        ax.set_title(f"{station_id} - {column}")
        ax.set_xlabel("Time")
        ax.set_ylabel(column)
        return fig

    def export_json(self, newline_delimited=False):
        recs = self.df.reset_index().to_dict(orient='records')
        if newline_delimited:
            lines = [json.dumps(r, default=str) for r in recs]
            return "\n".join(lines)
        else:
            return json.dumps(recs, default=str)
