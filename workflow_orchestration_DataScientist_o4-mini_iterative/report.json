{"created": 1746023154.304089, "duration": 0.27901506423950195, "exitcode": 1, "root": "/Users/celine/Research/librarybench", "environment": {}, "summary": {"failed": 1, "passed": 4, "total": 5, "collected": 5}, "collectors": [{"nodeid": "", "outcome": "passed", "result": [{"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative", "type": "Dir"}]}, {"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/pipeline", "outcome": "passed", "result": []}, {"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_dynamic_tasks.py", "outcome": "passed", "result": [{"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_dynamic_tasks.py::test_dynamic_task_creation_and_execution", "type": "Function", "lineno": 7}]}, {"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_error_handling_and_alerting.py", "outcome": "passed", "result": [{"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_error_handling_and_alerting.py::test_unexpected_exception_triggers_alert", "type": "Function", "lineno": 7}]}, {"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_output.txt", "outcome": "passed", "result": []}, {"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_pipeline.py", "outcome": "passed", "result": [{"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_pipeline.py::test_basic_pipeline_execution_and_data_passing", "type": "Function", "lineno": 7}]}, {"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_retry_backoff.py", "outcome": "passed", "result": [{"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_retry_backoff.py::test_retry_with_exponential_backoff", "type": "Function", "lineno": 8}]}, {"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_timeout.py", "outcome": "passed", "result": [{"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_timeout.py::test_task_timeout_and_retry", "type": "Function", "lineno": 8}]}, {"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative", "outcome": "passed", "result": [{"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/pipeline", "type": "Package"}, {"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_dynamic_tasks.py", "type": "Module"}, {"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_error_handling_and_alerting.py", "type": "Module"}, {"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_output.txt", "type": "DoctestTextfile"}, {"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_pipeline.py", "type": "Module"}, {"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_retry_backoff.py", "type": "Module"}, {"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_timeout.py", "type": "Module"}]}], "tests": [{"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_dynamic_tasks.py::test_dynamic_task_creation_and_execution", "lineno": 7, "outcome": "failed", "keywords": ["test_dynamic_task_creation_and_execution", "test_dynamic_tasks.py", "workflow_orchestration_DataScientist_o4-mini_iterative", "librarybench", ""], "setup": {"duration": 0.00010491699504200369, "outcome": "passed"}, "call": {"duration": 0.00021495801047421992, "outcome": "failed", "crash": {"path": "/Users/celine/Research/librarybench/workflow_orchestration_DataScientist_o4-mini_iterative/test_dynamic_tasks.py", "lineno": 39, "message": "AssertionError: assert None == (1 * 2)\n +  where None = get('item_1')\n +    where get = <pipeline.context.ExecutionContext object at 0x105d5f620>.get"}, "traceback": [{"path": "test_dynamic_tasks.py", "lineno": 39, "message": "AssertionError"}], "longrepr": "def test_dynamic_task_creation_and_execution():\n        ctx = ExecutionContext()\n        meta = MetadataStorage()\n        notifier = DummyNotifier()\n    \n        # Preload a list of items in context\n        ctx.set('items', [1, 2, 3])\n    \n        # Creator task: generates processing tasks for each item\n        def creator(context):\n            items = context.get('items')\n            new_tasks = []\n            for item in items:\n                def make_func(i):\n                    def proc(ctx):\n                        return {f'item_{i}': i * 2}\n                    return proc\n                t = Task(\n                    name=f'proc_{item}',\n                    func=make_func(item),\n                    outputs=[f'item_{item}']\n                )\n                new_tasks.append(t)\n            return new_tasks\n    \n        creator_task = Task(name='creator', func=creator, inputs=['items'])\n        pipeline = Pipeline([creator_task], ctx, meta, notifier)\n        pipeline.run()\n    \n        # After run, dynamic tasks should have executed\n        for i in [1,2,3]:\n>           assert ctx.get(f'item_{i}') == i * 2\nE           AssertionError: assert None == (1 * 2)\nE            +  where None = get('item_1')\nE            +    where get = <pipeline.context.ExecutionContext object at 0x105d5f620>.get\n\ntest_dynamic_tasks.py:39: AssertionError"}, "teardown": {"duration": 0.00013549999857787043, "outcome": "passed"}}, {"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_error_handling_and_alerting.py::test_unexpected_exception_triggers_alert", "lineno": 7, "outcome": "passed", "keywords": ["test_unexpected_exception_triggers_alert", "test_error_handling_and_alerting.py", "workflow_orchestration_DataScientist_o4-mini_iterative", "librarybench", ""], "setup": {"duration": 7.495800673495978e-05, "outcome": "passed"}, "call": {"duration": 9.216699982061982e-05, "outcome": "passed"}, "teardown": {"duration": 4.904199158772826e-05, "outcome": "passed"}}, {"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_pipeline.py::test_basic_pipeline_execution_and_data_passing", "lineno": 7, "outcome": "passed", "keywords": ["test_basic_pipeline_execution_and_data_passing", "test_pipeline.py", "workflow_orchestration_DataScientist_o4-mini_iterative", "librarybench", ""], "setup": {"duration": 5.395901098381728e-05, "outcome": "passed"}, "call": {"duration": 7.149999146349728e-05, "outcome": "passed"}, "teardown": {"duration": 4.270800855010748e-05, "outcome": "passed"}}, {"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_retry_backoff.py::test_retry_with_exponential_backoff", "lineno": 8, "outcome": "passed", "keywords": ["test_retry_with_exponential_backoff", "test_retry_backoff.py", "workflow_orchestration_DataScientist_o4-mini_iterative", "librarybench", ""], "setup": {"duration": 0.0001168750022770837, "outcome": "passed"}, "call": {"duration": 7.729200297035277e-05, "outcome": "passed"}, "teardown": {"duration": 5.845900159329176e-05, "outcome": "passed"}}, {"nodeid": "workflow_orchestration_DataScientist_o4-mini_iterative/test_timeout.py::test_task_timeout_and_retry", "lineno": 8, "outcome": "passed", "keywords": ["test_task_timeout_and_retry", "test_timeout.py", "workflow_orchestration_DataScientist_o4-mini_iterative", "librarybench", ""], "setup": {"duration": 7.920799544081092e-05, "outcome": "passed"}, "call": {"duration": 0.22183550000772811, "outcome": "passed"}, "teardown": {"duration": 0.01666329200088512, "outcome": "passed"}}]}