============================= test session starts ==============================
platform darwin -- Python 3.13.2, pytest-8.3.5, pluggy-1.5.0
rootdir: /Users/celine/Research/librarybench
configfile: pyproject.toml
plugins: anyio-4.9.0, json-report-1.5.0, metadata-3.1.1
collected 15 items

tests.py ...F..F.FFF....                                                 [100%]

=================================== FAILURES ===================================
_____________________________ test_task_execution ______________________________

    def test_task_execution():
        """Test execution of a single task."""
        # Successful task
        task = Task(name="success_task", func=successful_task)
        task.execute()
    
        assert task.state == TaskState.SUCCESS
        assert task.result == "success"
        assert task.error is None
    
        # Failing task
        task = Task(name="failing_task", func=failing_task)
>       task.execute()

tests.py:89: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
workflow.py:113: in execute
    raise e
workflow.py:91: in execute
    res = self.func()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def failing_task():
>       raise Exception("Task failed")
E       Exception: Task failed

tests.py:74: Exception
___________________________ test_failure_propagation ___________________________

    def test_failure_propagation():
        """Test failure propagation to dependent tasks."""
        workflow = Workflow()
    
        # Create a failing task that fails immediately for the test
        def test_failing_task():
            raise Exception("Task will always fail")
    
        task1 = Task(name="test_failing_task", func=test_failing_task, max_retries=0)
    
        # Create a dependent task
        task2 = Task(
            name="dependent_task", func=successful_task, dependencies=["test_failing_task"]
        )
    
        workflow.add_task(task1)
        workflow.add_task(task2)
    
        # Run the workflow
        with pytest.raises(TaskFailedError):
            workflow.run()
    
        # Check that the task is in failure state
        assert workflow.tasks["test_failing_task"].state == TaskState.FAILURE
        # Dependent task should be marked as failed due to dependency failure
>       assert workflow.tasks["dependent_task"].state == TaskState.FAILURE
E       AssertionError: assert <TaskState.PENDING: 'pending'> == <TaskState.FAILURE: 'failure'>
E        +  where <TaskState.PENDING: 'pending'> = <workflow.Task object at 0x1067ed710>.state
E        +  and   <TaskState.FAILURE: 'failure'> = TaskState.FAILURE

tests.py:176: AssertionError
_______________________ test_workflow_partial_execution ________________________

    def test_workflow_partial_execution():
        """Test workflow execution with partially completed tasks."""
        workflow = Workflow()
    
        task1 = Task(name="task1", func=lambda: "result1")
        task2 = Task(name="task2", func=lambda: "result2", dependencies=["task1"])
    
        workflow.add_task(task1)
        workflow.add_task(task2)
    
        # Manually mark the first task as complete
        workflow.tasks["task1"].state = TaskState.SUCCESS
        workflow.tasks["task1"].result = "result1"
    
        # Run the workflow - it should skip task1 and only run task2
        results = workflow.run()
    
        assert workflow.tasks["task1"].state == TaskState.SUCCESS
        assert workflow.tasks["task2"].state == TaskState.SUCCESS
>       assert results["task1"] == "result1"
E       KeyError: 'task1'

tests.py:241: KeyError
______________________________ test_task_timeout _______________________________

    def test_task_timeout():
        """Test task timeout functionality."""
    
        def slow_task():
            time.sleep(0.5)
            return "slow result"
    
        task = Task(name="timeout_task", func=slow_task, timeout=0.1)
    
        workflow = Workflow()
        workflow.add_task(task)
    
        with pytest.raises(TaskFailedError, match="timed out"):
>           workflow.run()

tests.py:258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <workflow.Workflow object at 0x106826360>

    def run(self):
        """
        Execute the workflow, running tasks respecting dependencies,
        handling retries, timeouts, failure propagation, parallel execution.
        Returns a dict of task_name -> result.
        Raises TaskFailedError on any failure.
        """
        # Validate DAG
        self.validate()
    
        wf_start = datetime.datetime.now()
        wf_status = "success"
        results = {}
        # build fresh context for this run
        context = {}
    
        # Keep looping until no PENDING/RETRYING tasks remain
        executor = concurrent.futures.ThreadPoolExecutor(max_workers=len(self.tasks))
        try:
            while True:
                # Propagate dependency failures
                for t in self.tasks.values():
                    if t.state in (TaskState.PENDING, TaskState.RETRYING):
                        for dep in t.dependencies:
                            dep_task = self.tasks[dep]
                            if dep_task.state == TaskState.FAILURE:
                                t.state = TaskState.FAILURE
                                t.error = TaskFailedError(f"Dependency {dep} failed")
                # Find ready tasks
                ready = []
                for t in self.tasks.values():
                    if t.state in (TaskState.PENDING, TaskState.RETRYING):
                        if all(self.tasks[dep].state == TaskState.SUCCESS for dep in t.dependencies):
                            ready.append(t)
                if not ready:
                    break  # nothing to run
                # Schedule batch
                futures = {}
                for t in ready:
                    # Prepare context slice
                    ctx = context.copy()
                    fut = executor.submit(t.execute, ctx)
                    futures[fut] = t
                # Collect results
                error_occurred = False
                for fut, t in futures.items():
                    try:
                        # handle timeout
                        if t.timeout is not None:
                            fut.result(timeout=t.timeout)
                        else:
                            fut.result()
                    except concurrent.futures.TimeoutError:
                        # Task timed out
                        t.state = TaskState.FAILURE
                        t.error = TaskFailedError("Task timed out")
                        error_occurred = True
                        fut.cancel()
                    except Exception:
                        # Underlying task.execute sets state appropriately
                        error_occurred = True
                    else:
                        # on success, merge result
                        if isinstance(t.result, dict):
                            context.update(t.result)
                        results[t.name] = t.result
                if error_occurred:
                    wf_status = "failure"
                    break
            # After batches, check if any failure in tasks triggers workflow failure
            if any(t.state == TaskState.FAILURE for t in self.tasks.values()):
                wf_status = "failure"
        finally:
            executor.shutdown(wait=False)
            wf_end = datetime.datetime.now()
            # Build workflow execution record
            task_execs = {}
            for name, t in self.tasks.items():
                # pick latest execution record for this run
                if t.execution_records:
                    rec = t.execution_records[-1]
                    status = t.state.value
                    task_execs[name] = TaskExecutionInfo(rec.start_time, rec.end_time, status)
                else:
                    # never executed (e.g., skipped), mark as success with zero times
                    now = wf_end
                    task_execs[name] = TaskExecutionInfo(now, now, t.state.value)
            self.execution_history.append(WorkflowExecution(wf_start, wf_end, wf_status, task_execs))
    
        if wf_status == "failure":
>           raise TaskFailedError("Workflow failed")
E           workflow.TaskFailedError: Workflow failed

workflow.py:253: TaskFailedError

During handling of the above exception, another exception occurred:

    def test_task_timeout():
        """Test task timeout functionality."""
    
        def slow_task():
            time.sleep(0.5)
            return "slow result"
    
        task = Task(name="timeout_task", func=slow_task, timeout=0.1)
    
        workflow = Workflow()
        workflow.add_task(task)
    
>       with pytest.raises(TaskFailedError, match="timed out"):
E       AssertionError: Regex pattern did not match.
E        Regex: 'timed out'
E        Input: 'Workflow failed'

tests.py:257: AssertionError
_________________________ test_task_retry_with_backoff _________________________

    def test_task_retry_with_backoff():
        """Test task retry with exponential backoff."""
        # Mock a function that fails every time
        mock_func = MagicMock(side_effect=Exception("Intentional failure"))
    
        # Create a task with retry policy
        task = Task(
            name="retry_task",
            func=mock_func,
            max_retries=3,
            retry_delay=0.1
        )
    
        # Record the start time
        start_time = time.time()
    
        # Execute the task (it will fail after all retries)
>       task.execute()

tests.py:281: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
workflow.py:108: in execute
    raise e
workflow.py:91: in execute
    res = self.func()
../../../miniconda3/envs/library/lib/python3.13/unittest/mock.py:1167: in __call__
    return self._mock_call(*args, **kwargs)
../../../miniconda3/envs/library/lib/python3.13/unittest/mock.py:1171: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock id='4405090624'>, args = (), kwargs = {}
effect = Exception('Intentional failure')

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
>               raise effect
E               Exception: Intentional failure

../../../miniconda3/envs/library/lib/python3.13/unittest/mock.py:1226: Exception
--------------------------------- JSON report ----------------------------------
report saved to: report.json
=========================== short test summary info ============================
FAILED tests.py::test_task_execution - Exception: Task failed
FAILED tests.py::test_failure_propagation - AssertionError: assert <TaskState...
FAILED tests.py::test_workflow_partial_execution - KeyError: 'task1'
FAILED tests.py::test_task_timeout - AssertionError: Regex pattern did not ma...
FAILED tests.py::test_task_retry_with_backoff - Exception: Intentional failure
========================= 5 failed, 10 passed in 0.63s =========================
